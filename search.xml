<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[keepalived简介]]></title>
    <url>%2F2019%2F01%2F28%2Fkeepalived%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[keepalived简介 高可用集群概念 集群类型： LB lvs/nginx（http/upstream, stream/upstream） HA 高可用性 SPoF: Single Point of Failure，单点故障 HPC 高性能集群(High Performance Computing) 系统可用性：SLA(Service-Level Agreement) 95%=(602430)*(1-0.9995) （指标）=99%, …, 99.999%，99.9999% 系统故障： 硬件故障：设计缺陷、wear out（损耗）、自然灾害…… 软件故障：设计缺陷 提升系统高用性的解决方案之降低MTTR(平均故障时间) 解决方案：建立冗余机制 active/passive 主/备 active/active 双主 active –&gt; HEARTBEAT（心跳检测机制判断对方是否存活） –&gt; passive active HEARTBEAT active 高可用的是“服务” HA nginx service： vip/nginx process[/shared storage] 资源：组成一个高可用服务的“组件” (1) passive node的数量（从节点的数量） (2) 资源切换（ip地址的切换或者说是服务的切换） shared storage：共享存储 NAS(Network Attached Storage)：网络附加存储，基于网络的共享文件系统。 SAN(Storage Area Network)：存储区域网络，基于网络的块级别的共享 Network partition：网络分区 quorum：法定人数 with quorum： &gt; total/2（剩余存活的节点一定是大于总节点的一半的） without quorum: &lt;= total/2（故障节点的数量，一定要小于总节点的一半） 隔离设备： fence node：STONITH = Shooting The Other Node In The Head 断电重启 资源：断开存储的连接 双节点集群(TWO nodes Cluster) 辅助设备：ping node, quorum disk(仲裁设备) Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作 Failback：故障移回，即某资源的主节点故障后重新修改上线后，将之前已转移至其它节点的资源重新切回的过程 HA Cluster实现方案: AIS(Applicaiton Interface Specification)应用程序接口规范 RHCS：Red Hat Cluster Suite红帽集群套件 heartbeat：基于心跳监测实现服务高可用 pacemaker+corosync：资源管理与故障转移 vrrp(Virtual Router Redundancy Protocol)：虚拟路由冗余协议,解决静态网关单点风险 软件层—keepalived 物理层—路由器、三层交换机、防火墙 高可用集群-&gt;后端存储 高可用集群-&gt;后端存储 JBOD （ Just a Bunch Of Disks ）不是标准的 RAID 等级，它通常用来表示一个没有控制软件提供协调控制的磁盘集合， JBOD 将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘， JBOD 的数据存放机制是由第一块磁盘开始按顺序往后存储，当前磁盘存储空间用完后，再依次往后面的磁盘存储数据， JBOD 存储性能完全等同于单块磁盘，而且也不提供数据安全保护，它只是简单提供一种扩展存储空间的机制， JBOD 可用存储容量等于所有成员磁盘的存储空间之和。 高可用集群-&gt;网络层实现高可用（VRRP） Keepalived简介 Keepalived软件主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。 重要作用 管理LVS负载均衡软件 实现LVS集群节点的健康检查中 作为系统网络服务的高可用性（failover） keepalived: vrrp协议的软件实现，原生设计目的为了高可用ipvs服务 功能： 基于vrrp协议完成地址流动 为vip地址所在的节点生成ipvs规则(在配置文件中预先定义) 为ipvs集群的各RS做健康状态检测 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务，以此支持nginx、haproxy等服务 组件： 用户空间核心组件： vrrp stack-VIP消息通告 checkers-监测real server system call-标记real server权重 SMTP-邮件组件 ipvs wrapper-生成IPVS规则 Netlink Reflector-网络接口 WatchDog-监控进程 控制组件：配置文件分析器 IO复用器 内存管理组件 官方站点：http://keepalived.org/index.html 官方参考手册：http://keepalived.org/documentation.html DOWNLOAD:http://keepalived.org/download.html keepalived： vrrp协议：Virtual Router Redundancy Protocol（keepalived基于此协议实现ip地址的高可用） 术语： 虚拟路由器：Virtual Router 虚拟路由器标识：VRID(0-255)优先级，唯一标识虚拟路由器 物理路由器： master：主设备 backup：备用设备 priority：优先级（优先级数值越大，优先级越高） VIP：Virtual IP VMAC：Virutal MAC (00-00-5e-00-01-VRID)：虚拟mac地址 通告：心跳，优先级等，周期性 工作方式：抢占式，非抢占式 安全工作： 认证： 无认证 简单字符认证：预共享密钥 工作模式： 主/备：单虚拟路由器 主/主：主/备（虚拟路由器1），备/主（虚拟路由器2）]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxyACL]]></title>
    <url>%2F2019%2F01%2F24%2FHAproxyACL%2F</url>
    <content type="text"><![CDATA[HAproxy的ACL过滤器 ACL过滤器（七层http模式下） acl：对接收到的报文进行匹配和过滤，基于请求报文头部中的源地址、源端口、目标地址、目标端口、请求方法、URL、文件后缀等信息内容进行匹配并执行进一步操作（基于类型的调度决策）。 acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] acl &ensp;&ensp; 名称 &ensp;&ensp;&ensp;&ensp; 过滤条件 &ensp;&ensp; &ensp;&ensp; 条件标记位 &ensp;&ensp; 具体操作符 &ensp;&ensp; 操作对象类型 acl image_service hdr_dom(host) -i img.daizhe.net.cn hdr_dom(host)：客户端请求的头部的域名 用hots做匹配条件的好处，可以将ip地址复用，对一个ip进行监听，当用户请求进行请求时，可以将一个地址对应多个A记录解析的域名（一个ip地址监听多个公网的域名）。 hdr_dom(User-Agent) ：客户端请求使用的浏览器的类型 可以根据客户使用的类型，将客户发来的请求做处理转发。调度器转发后其他后端的提供服务的服务器上。 ACL名称，可以使用大字母A-Z、小写字母a-z、数字0-9、冒号：、点.、中横线和下划线，并且严格区分大小写，必须Image_site和image_site完全是两个acl(严格区分大小写)。 Criterion_ACL(定义ACL标准) &lt;criterion&gt; ：匹配条件 dst 目标IP dst_port 目标PORT src 源IP src_port 源PORT hdr &lt;string&gt;用于测试请求头部首部指定内容 hdr_dom(host) 请求的host名称，如 www.daizhe.net.cn hdr_beg(host) 请求的host开头，如 www. img. video. download. ftp. hdr_end(host) 请求的host结尾，如 .com .net .cn path_beg 请求的URL开头，如/static、/images、/img、/css path_end 请求的URL中资源的结尾，如 .gif .png .css .js .jpg .jpeg flags（条件标记位） &lt;flags&gt;-条件标记 -i 不区分大小写(域名经过haproxy调度时不区分域名的字符大小写) -m 使用指定的pattern匹配方法 -n 不做DNS解析 -u 禁止acl重名，否则多个同名ACL匹配或关系(调度器上定义acl的名称尽量不要重名，如果有重名，默认隐含的是或的关系) – 强制flag结束. 当字符串和某个flag相似时使用 operator（具体操作符） [operator]-操作符： 整数比较：eq、ge、gt、le、lt字符比较： exact match (-m str) :字符串必须完全匹配模式 substring match (-m sub) :在提取的字符串中查找模式，如果其中任何一个被发现，ACL将匹配 prefix match (-m beg) :在提取的字符串首部中查找模式，如果其中任何一个被发现，ACL将匹配 suffix match (-m end) :将模式与提取字符串的尾部进行比较，如果其中任何一个匹配，则ACL进行匹配 subdir match (-m dir) :查看提取出来的用斜线分隔（“/”）的字符串，如果其中任何一个匹配，则ACL进行匹配 domain match (-m dom) :查找提取的用点（“.”）分隔字符串，如果其中任何一个匹配，则ACL进行匹配 value（操作对象类型） &lt;value&gt;的类型： Boolean #布尔值 integer or integer range #整数或整数范围，比如用于匹配端口范围 IP address / network #IP地址或IP范围 string （字符串的方式制定域名） exact –精确比较 substring—子串 prefix-前缀比较 subdir-路径， /wp-includes/js/jquery/jquery.js domain-域名，daizhe.net.cn regular expression #正则表达式 hex block #16进制 Acl定义与调用 acl作为条件时的逻辑关系： 与：隐式（默认）使用 或：使用“or” 或 “||”表示 否定：使用“!“ 表示 示例： if invalid_src invalid_port 与关系 if invalid_src || invalid_port 或 if ! invalid_src 非 范例：调度器拒绝172.18.88.88/24的主机访问即调度器检测到此地址段的主机则不今次那个调度到后端的主机上1haproxy_server]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy日志配置及报文操作]]></title>
    <url>%2F2019%2F01%2F23%2FHAproxy%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%8A%A5%E6%96%87%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[HAproxy日志配置及报文操作 一、配置HAProxy状态页1.haproxy状态页面开启1234567891011121314paproxy_server ~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 #默认监听的地址为0.0.0.0,最好不要监听本机的所有地址。监听的端口不要和现有的业务冲突 stats enable log global stats uri /haproxy-status #默认访问状态页面的uri（可以自己定义） stats auth haadmin:q1w2e3r4ys #默认访问uri的用户名和密码 stats auth daizhe:123456 #指定用户访问此uri提供的用户名和密码 stats realm HAPorxy\ Stats\ Page #设置用户访问uri时提示输入密码的提示信息 ~]# systemctl restart haproxy web界面访问查看此状态页面 2.开启管理状态页面12345678910111213~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys stats auth admin:123456 stats realm HAPorxy\ Stats\ Page stats admin if TRUE #如果登陆的是daizhe这个用户则打开状态管理页面 ~]# systemctl restart haproxy web界面访问查看此状态页面 3.隐藏管理状态页面的haproxy的版本号123456789101112131415~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys stats auth admin:123456 stats realm HAPorxy\ Stats\ Page stats admin if TRUE stats hide-version #隐藏版本号 ~]# systemctl restart haproxy web界面访问查看此状态页面 二、HAproxy修改报文首部(http模式) 在请求报文尾部添加指定首部 reqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 在响应报文尾部添加指定首部 rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 示例：rspadd X-Via:\ HAPorxy 1234567891011客户端中可以查看到响应是通过haproxy调度器调度响应的listen web-port-80 mode http rspadd X-Via:\ HAPorxy #### bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.1:8080 cookie web2 check inter 3000 fall 3 rise 5 从请求报文中删除匹配正则表达式的首部 reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;] reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 不分大小写 1234567891011删除响应报文中的server字段的信息listen web-port-80 mode http rspadd X-Via:\ HAPorxy rspdel Server:* bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 从响应报文中删除匹配正则表达式的首部 rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;] rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 示例： rspidel server.* #从相应报文删除server信息 rspidel X-Powered-By:.* #从响应报文删除X-Powered-By信息 三、HAProxy 日志配置 在default配置项定义： log 127.0.0.1 local{1-7} info #基于syslog记录日志到指定设备，级别有(err、warning、info、debug) 范例：基于rsyslog配置收集haproxy日志信息(udp)1234567891011121314151617181920开启haproxy服务器上的rsyslog功能 ~]# vim /etc/rsyslog.conf 15~16行 $ModLoad imudp $UDPServerRun 514 74行 local3.* /var/log/haproxy.log配置haproxy配置文件 ~]# vim /etc/haproxy/haproxy.cfg global ... log 127.0.0.1 local3 info重启服务 ~]# systemctl restart rsyslog haproxy客户访问后端web_server 查看haproxy日志 范例：可以将haproxy日志格式使用tcp/http记录在rsyslog日志中1234567配置HAProxy：listen web_port bind 127.0.0.1:80 mode http log globaloption tcplog server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5 详细日志参考手册：http://cbonte.github.io/haproxy-dconv/1.8/configuration.html#8.1 四、自定义paproxy记录日志 将特定信息记录在日志中 capture cookie &lt;name&gt; len &lt;length&gt; #捕获请求和响应报文中的 cookie并记录日志 capture request header &lt;name&gt; len &lt;length&gt; #捕获请求报文中指定的首部内容和长度并记录日志 capture response header &lt;name&gt; len &lt;length&gt; #捕获响应报文中指定的内容和长度首部并记录日志 示例：配置haproxy配置文件，注意配置字段和生效的位置（最好设置单独的listen中，仅对一组server生效） capture request header Host len 256 capture request header User-Agent len 512 五、压缩功能 compression algo #启用http协议中的压缩机制，常用算法有gzip deflate compression type #要压缩的类型 示例： compression algo gzip compression type compression type text/plain text/html text/css text/xml text/javascript application/javascript Web服务器状态监测 option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 12345678listen web_prot_http_nodes bind 192.168.7.102:80 mode http log global option httpchk GET /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0 #基于指定URL #option httpchk HEAD /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0\r\nHost:\ 192.168.7.102 #通过request获取的头部信息进行匹配进行健康检测 server 192.168.7.102 blogs.studylinux.net:80 check inter 3000 fall 3 rise 5 server 192.168.7.101 192.168.7.101:8080 cookie web1 check inter 3000 fall 3 rise 5]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy基于cookie会话保持]]></title>
    <url>%2F2019%2F01%2F23%2FHAproxy%E5%9F%BA%E4%BA%8Ecookie%E4%BC%9A%E8%AF%9D%E4%BF%9D%E6%8C%81%2F</url>
    <content type="text"><![CDATA[HAproxy基于cookie会话保持 Cookie 配置 cookie &lt;value&gt;：为当前server指定cookie值，实现基于cookie的会话黏性 cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ] &lt;name&gt;：cookie名称，用于实现持久连接 rewrite：重写 insert：插入 prefix：前缀 nocache：当client和hapoxy之间有缓存时，不缓存cookie 范例：使用haproxy实现基于cookie会话保持（haproxy必须在http协议的模式下实现）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#模拟httpd_server不直接对外服务，通过haproxy负载对外进程调度服务#范例：使用haproxy实现基于cookie会话保持（haproxy必须在http协议的模式下实现）也彻底解决会话调度不均衡实验准备 四台主机： haproxy_server : yum install haproxy -y httpd_serverA : yum install httpd -y httpd_serverB : yum install httpd -y windows_firefox配置httpd_server测试页面 httpd_serverA ~]# echo "172.18.135.1" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080 httpd_serverB ~]# echo "172.18.135.5" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080配置haproxy负载 ~]# yum install haproxy -y ~]# cat /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1111 gid 1111 daemon nbproc 4 cpu-map 1 0 cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys #httpd_server基于cookie实现调度 listen web-port-80 #web-port-80指定的此分组的名称 mode http #必须为http bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache #不缓存 server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 # 172.18.135.5为定义的主机的名称，172.18.135.5:8080 定义的后端的主机的地址及服务的端口 server 172.18.135.5 172.18.135.1:8080 cookie web2 check inter 3000 fall 3 rise 5 #cookie 指定cookie的值，实现区分不同的web_server,也可在请求的头部看到此信息 启动查看端口 ~]# systemctl start haproxy ~]# ss -tnl 9999 172.18.135.2:80 windows_firefox测试 客户端访问查看请求的头部（请求不跳转，实现基于cookie的会话保持和负载不均衡的情况） 也可以使用curl命令验证]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy IP地址透传]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxyIP%E5%9C%B0%E5%9D%80%E9%80%8F%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[HAproxy IP地址透传（七层/四层） 四层负载 mode http 七层负载 mode tcp 实验准备12345678910111213```bash#如果客户端访问的地址为公网地址上的一个网站，如果客户端用的是NAT方式出去上网的，则后端的nginx查看的日志信息源ip地址应该是客户端通过NAT方式出去的地址实验准备： haproxy_server 172.18.135.2模拟私网地址 nginx_server 172.18.135.5模拟公网地址 windows_firefox 172.18.88.88模拟客户端浏览器模拟： haproxy_server和windows_firefox 为私网地址 nginx_server 为公网地址#windows_firefox通过haporxy_server的地址透传（NAT）,实现windows_firefox通过访问haporxy_server的地址从跳转至私网地址nginx_server服务器上进行访问 七层地址透传(http)1234567891011121314151617181920212223242526272829303132333435363738394041424344haproxy_server配置haproxy实现透传 ~]# yum install haproxy -y ~]# vim /etc/haproxy/haproxy.cfg #七层地址透传 listen web-port-80 mode http #此透传仅支持http协议，在tcp协议上不影响haproxy启动，但是nginx日志中会写出记录不到真实访问的地址 option forwardfor #如果后端服务器需要获得客户端的真实IP需要配置此参数，将可以从HttpHeader中获得客户端IP bind 172.18.135.2:80 #此地址为调度器的地址 server web1 172.18.135.5:80 weight 2 check inter 2000 fall 3 rise 5 #web1为定义后端主机的名称 ~]# systemctl restart haproxy ~]# curl -I 172.18.135.2:80windown_firefox客户端浏览器访问haproxy_server地址 http://172.18.135.2/nginx_server查看web服务器的访问日志 ~]# yum install nginx -y ~]# vim /etc/nginx/nginx.conf #定义nginx的日志文件为json格式输出，并可以查看到真实的客户端的地址（这里值得是windows_firefox） http &#123; log_format json '&#123;"@timestamp":"$time_iso8601",' '"host":"$server_addr",' '"clientip":"$remote_addr",' '"size":$body_bytes_sent,' '"responsetime":$request_time,' '"upstreamtime":"$upstream_response_time",' '"upstreamhost":"$upstream_addr",' '"http_host":"$host",' '"url":"$uri",' '"referer":"$http_referer",' '"agent":"$http_user_agent",' '"xff":"$http_x_forwarded_for",' '"status":"$status"&#125;'; access_log /var/log/nginx/access_json json; ~]# systemctl start nginx ~]# cat /var/log/nginx/access_json &#123;"@timestamp":"2019-01-22T22:00:54+08:00","host":"172.18.135.5","clientip":"172.18.135.2","size":0,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"172.18.135.2","url":"/poweredby.png","referer":"http://172.18.135.2/","agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0","xff":"172.18.88.88","status":"304"&#125; #可以查看到真实访问的windiws_firefox的真实地址 四层地址透传(tcp)12345678910111213141516171819202122232425262728293031323334353637383940haproxy_server ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 mode tcp bind 172.18.135.2:80 option forwardfor server web1 172.18.135.5:80 send-proxy weight 2 check inter 2000 fall 3 rise 5 ~]# systemctl restart haproxynginx_server ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 proxy_protocol; #TCP获取客户端真实IP日志格式 # listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; ~]# systemctl restart nginx 客户端访查看nginx日志]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy调度算法]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxy%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[HAproxy调度算法（四层） HAProxy 调度算法使用的生效字段： defaults listen backend 动态算法和静态算法 静态算法（算法仅根据算法本身与请求报文特征进行调度 起点公平） 不支持运行时动态调整，不支持慢启动 动态算法（额外考虑后端各RS的当前的负载的状态 结果公平） 支持运行时调整，支持慢启动 HAProxy 静态调度算法 balance： 指明对后端服务器的调度算法，配置在listen或backend静态算法：按照事先定义好的规则轮询公平调度，不关心后端服务器的当前负载、链接数和相应速度等，且无法实时修改权重，只能重启后生效。 static-rr：基于权重的轮询调度，不支持权重的运行时调整及后端服务器慢启动，其后端主机数量没有限制 first：根据服务器在列表中的位置，自上而下进行调度，但是其只会当第一台服务器的连接数达到上限，新请求才会分配给下一台服务，因此会忽略服务器的权重设置。 范例：静态调度--&gt;static-rr:基于权重的轮询调度12345678910111213141516171819roundrobin最大后端主机为4096static-rr 最大后端主机不上限#weight 设置权重#这里设置的172.18.135.1权重为2，172.18.135.5权重为1~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance static-rr server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1~]# systemctl restart haproxy 范例：静态调度--&gt;first:根据服务器在列表中的位置，自上而下进行调度即优先使用第一台，当第一台的连接数上限时，才会调度到其他的主机上1234567891011121314# maxconn 10 设置主机的最大连接数~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance first server 172.18.135.1 172.18.135.1:8080 maxconn 10 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080~]# systemctl restart haproxy HAProxy 动态调度算法 动态算法：基于后端服务器 状态进行调度适当调整，比如优先调度至当前负载较低的服务器，且权重可以在haproxy运行时动态调整无需重启(支持缓慢启动，实现慢慢的将流量均匀的分配到其他的后端服务器上,也支持运行时重载配置文件)。 roundrobin：基于权重的轮询动态调度算法，支持权重的运行时调整，不等于lvs 的rr，支持慢启动即新加的服务器会逐渐增加转发数，每个后端backend中最多支持4095个server，此为默认调度算法，server 权重设置 weight leastconn： 加权的最少连接的动态，支持权重的运行时调整和慢启动，即当前后端服务器连接最少的优先调度，比较适合长连接的场景使用，比如MySQL等场景。 123# 默认动态算法roundrobin：基于权重的轮询动态调度算法#roundrobin 适用于无状态的连接，如果做过session会话共享或者会话绑定也可以使用 HAProxy 调度算法-source source：源地址hash，基于用户源地址hash并将请求转发到后端服务器，默认为静态即取模方式，但是可以通过hash-type支持的选项更改，后续同一个源地址请求将被转发至同一个后端web服务器，比较适用于session保持等场景。 map-based：取模法，基于服务器权重的hash数组取模，该hash是静态的即不支持在线调整权重，不支持慢启动，其对后端服务器调度均衡，缺点是当服务器的总权重发生变化时，即有服务器上线或下线，都会因权重发生变化而导致调度结果整体改变。 consistent：一致性哈希，该hash是动态的，支持在线调整权重，支持慢启动，优点在于当服务器的总权重发生变化时，对调度结果影响是局部的，不会引起大的变动，该算法很容易导致后端服务器负载不均衡，但是比较适合session保持。 HAproxy 服务器动态上下线 静态算法：无法动态上下线 1234567891011121314151617181920212223242526272829303132333435363738394041 ~]# useradd haproxy -s /sbin/nologin #编译安装的需要创建账号，yum安装的则不需要创建账号 ~]# mkdir /var/lib/haproxy ~]# chown haproxy.haproxy /var/lib/haproxy/ -R ~]# vim /etc/haproxy/haproxy.cfg global 4行 stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #主要是基于socket文件对服务器进行动态修改 ... #httpd_server调度 frontend web-port-80 bind 172.18.135.2:80 use_backend web_host backend web_host balance static-rr server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy负载上安装支持的依赖包 ~]# yum install socat -y #输入重定向的工具查看使用帮助 ~]# echo "show info" | socat stdio /var/lib/haproxy/haproxy.sock ~]# echo "help" | socat stdio /var/lib/haproxy/haproxy.sock基于socat动态对话负载haproxy #动态修改主机的权重 ~]# echo "set weight " | socat stdio /var/lib/haproxy/haproxy.sock Require 'backend/server'. #指明backend名称以及server名称 ~]# echo "set weight web_host/172.18.135.1 4" | socat stdio /var/lib/haproxy/haproxy.sock Backend is using a static LB algorithm and only accepts weights '0%' and '100%'. #提示不可以设置为4的权重，因为是使用的静态的算法只能设置为0%或者为100%（在线或者下线）查看权重 ~]# echo "get weight web_host/172.18.135.1" | socat stdio /var/lib/haproxy/haproxy.sock 2 (initial 2) 动态算法：支持动态上下线1234567891011121314151617181920212223242526272829303132#使用consistent：一致性哈希方式1：~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance source hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1方式2：listen~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度listen web-port-80 bind 172.18.135.2:80 balance source hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy动态修改权重（1.8版本的那个太修改权重有BUG，1.5版本就没问题） ~]# echo "set weight web_host/172.18.135.5 3" | socat stdio /var/lib/haproxy/haproxy.sock ~]# echo "get weight web_host/172.18.135.5 3" | socat stdio /var/lib/haproxy/haproxy.sock 2019/01/22 16:42:40 socat[15995] E connect(5, AF=1 "/var/lib/haproxy/haproxy.sock", 31): Connection refused HAProxy 调度算法-uri uri：基于对用户请求的uri做hash并将请求转发到后端指定服务器(多适用于缓存服务器，会使得后端的服务器更好的命中缓存的结果例如缓存服务器 Varnish) map-based：取模法 consistent：一致性哈希 http://example.org/absolute/URI/with/absolute/path/to/resource.txt #URI/URL ftp://example.org/resource.txt #URI/URL /relative/URI/with/absolute/path/to/resource.txt #URI uri: uniform resource identifier，统一资源标识符,是一个用于标识某一互联网资源名称的字符串 范例：uri调度算法示例123456789101112131415161718192021前提： #协议必须是http，不支持tcp，会切换到tcp的roundrobin负载模式 #七层调度：应用层 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 bind 172.18.135.2:80 balance uri hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy客户端请求测试（已经实现基于uri绑定调度） ~]# curl http://172.18.135.2/ 172.18.135.1 ~]# curl http://172.18.135.2/index1.html 172.18.135.2/2 HAProxy 调度算法-url_param url_param： 对用户请求的url中的&lt;params&gt;部分中的参数name作hash计算，并由服务器总权重相除以后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server 假设url = http://www.magedu.com/foo/bar/index.php?k1=v1&amp;k2=v2 范例：根据用户请求的url_param做调度12345678~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度listen web-port-80 bind 172.18.135.2:80 balance url-param name hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 HAProxy 调度算法-hdr hdr(&lt;name&gt;)：针对用户每个http头部(header)请求中的指定信息做hash，此处由&lt;name&gt;指定的http首部将会被取出并做hash计算，然后由服务器总权重相除以后派发至某挑出的服务器，假如无有效的值，则会被轮询调度 hdr( Cookie、 User-Agent、host ) 范例：调度算法-hdr：针对用户每个http头部123456789101112#可以获取报文头部的所有数据因为实在应用层 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 mode http bind 172.18.135.2:80 balance hdr(User-Agent) hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy 测试：基于不同的浏览器做访问 HAProxy 调度算法- rdp-cookie(几乎不用) rdp-cookie对远程桌面的负载，使用cookie保持会话 rdp-cookie(&lt;name&gt;) 1234567#haproxylisten RDPbind 192.168.7.101:3389balance rdp-cookiemode tcpserver rdp0 172.18.139.20:3389 check fall 3 rise 5 inter 2000 weight 1server rdp1 172.18.139.21:3389 check fall 3 rise 5 inter 2000 weight 1 1234#基于iptables实现目标地址转换：#开启内核的转发功能：iptables -t nat -A PREROUTING -d 目标主机地址 -p tcp --dport 目标端口 -j DNAT --to-destination 转换哪个主机的：哪个端口iptables -t nat -A POSTROUTING -s 此网段的地址 -j SNAT --to-source 转换为哪个地址 算法总结及适用场景 static-rr first source:会话保持，小型业务或者用户源地址非集中访问 uri:缓存 roundrobin:无状态，session共享或者会话保持 leastconn:数据库，长连接 url_param hdr:多适用于域名转发，将多个域名转发到同一个地址中 roundrobin——–&gt;tcp/http 动态 leastconn———–&gt;tcp/http 动态 static-rr————–&gt;tcp/http 静态 first——————–&gt;tcp/http 静态 source—————-&gt;tcp/http # uri———————-&gt;http # url_param———-&gt;http # #取决于hash_type是否consistent hdr———————&gt;http # rdp-cookie———&gt;tcp # 四层与七层的区别： 四层： 在四层负载设备中，把client发送的报文目标地址(原来是负载均衡设备的IP地址)，根据均衡设备设置的选择web服务器的规则选择对应的web服务器IP地址，这样client就可以直接跟此服务器建立TCP连接并发送数据。 七层： 七层负载均衡服务器起了一个代理服务器的作用，服务器建立一次TCP连接要三次握手，而client要访问webserver要先与七层负载设备进行三次握手后建立TCP连接，把要访问的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的webserver，然后通过三次握手与此台webserver建立TCP连接，然后webserver把需要的数据发送给七层负载均衡设备，负载均衡设备再把数据发送给client；所以，七层负载均衡设备起到了代理服务器的作用。]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy基本配置]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxy%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[HAproxy基本配置 一、源码编译安装haproxyhaproxy 1.8版本：新特性 多进程：可以最大限度的利用cpu多核心的特性，开启多个工作进程实现最大限度响应用户的目的。 安装包下载路径：https://www.haproxy.org/download/1.8/src/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990安装依赖包 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate -y ~]# cd /usr/local/src/ src]# ls haproxy-1.8.16.tar.gz src]# tar xvf haproxy-1.8.16.tar.gz src]# cd haproxy-1.8.16/ haproxy-1.8.16]# pwd /usr/local/src/haproxy-1.8.16编译安装 haproxy-1.8.16]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy haproxy-1.8.16]# make install PREFIX=/usr/local/haproxy haproxy-1.8.16]# cp haproxy /usr/sbin/创建启动脚本 ~]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target查看haproxy 版本 ~]# haproxy -v HA-Proxy version 1.8.16-5c3f237 2018/12/21 Copyright 2000-2018 Willy Tarreau &lt;willy@haproxy.org&gt;创建目录和用户(默认启动的用户为nobody) ~]# mkdir /etc/haproxy ~]# useradd haproxy -s /sbin/nologin -u 1111 ~]# id haproxy uid=1111(haproxy) gid=1111(haproxy) groups=1111(haproxy)创建配置文件 ~]# vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1000 gid 1000 daemon #nbproc 4 #cpu-map 1 0 #cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys listen web_port bind 0.0.0.0:80 mode http log global server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5启动 ~]# systemctl start haproxy进程查看 ~]# ps -ef | grep haproxy root 5883 1 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid haproxy 5886 5883 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid root 5907 5491 0 09:37 pts/0 00:00:00 grep --color=auto haproxy 二、HAProxy组成 程序环境： 主程序：/usr/sbin/haproxy 配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxy：代理配置段 defaults：为frontend, backend, listen提供默认配置 frontend：前端，相当于nginx中的server {} #指明监听的地址和端口不要写* backend：后端，相当于nginx中的upstream {} listen：同时拥有前端和后端,适用于一对一环境 Haproxy 配置-global（全局配置端） global配置参数： https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3 chroot #锁定运行目录，当haproxy本身出现漏洞被攻击时，工作目录仅限于此运行目录 deamon #以守护进程运行 #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #本地通讯的socket文件 user, group, uid, gid #运行haproxy的用户身份（可以设置用户的id或者用户名称） nbproc #开启的haproxy进程数，与CPU保持一致 nbthread #指定每个haproxy进程开启的线程数，默认为每个进程一个线程 cpu-map 1 0 #绑定haproxy 进程至指定CPU maxconn #每个haproxy进程的最大并发连接数 maxsslconn #SSL每个haproxy进程ssl最大连接数 maxconnrate #每个进程每秒最大连接数 spread-checks #后端server状态check随机提前或延迟百分比时间，建议2-5(20%-50%)之间 pidfile #指定pid文件路径 log 127.0.0.1 local3 info #定义全局的syslog服务器；最多可以定义两个 123456789101112131415~]# vim /etc/haproxy/haproxy.cfg ...nbproc 4 #指定haproxy的进程数cpu-map 1 0 #将第一进程绑定在第0颗cpucpu-map 2 1 #将第二进程绑定在第1颗cpu...#实现了一个主进程多个子进程~]# ps -ef | grep haproxyroot 11803 1 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11805 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11806 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11807 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11808 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 11811 5491 0 10:35 pts/0 00:00:00 grep --color=auto haproxy HAProxy Proxies配置（代理配置段） defaults [&lt;name&gt;] #默认配置项，针对以下的frontend、backend和lsiten生效，可以多个name frontend &lt;name&gt; #前端servername，类似于Nginx的一个虚拟主机 server backend &lt;name&gt; #后端服务器组，等于nginx的upstream listen &lt;name&gt; #将frontend和backend合并在一起配置 注：name字段只能使用”-”、”_”、”.”、和”:”，并且严格区分大小写，例如：Web和web是完全不同的两组服务器即是区分大小写的 Proxies配置- defaults（默认配置项） option redispatch #当server Id对应的服务器挂掉后，强制定向到其他健康的服务器 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 option http-keep-alive #开启会话保持 option forwardfor #开启IP透传 mode http #默认工作类型 timeout connect 120s #连接到一台后端server的最长时间 timeout client 600s #与客户端的最长空闲时间 timeout server 600s #等待服务端的超时时长 timeout http-keep-alive 120s #session 会话保持时间 #timeout check 5s #对后端服务器的检测超时时间 Proxies配置- frontend配置参数(前端servername) bind：指定HAProxy的监听地址，可以是IPV4或IPV6，可以同时监听多个IP或端口，可同时用于listen字段中 bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] mode http/tcp #指定负载协议类型 use_backend backend_name #调用的后端服务器组名称 示例： frontend WEB_PORT bind :80,:8080 #支持以逗号分隔的列表格式指定监听的地址以及端口多个套接字 bind 192.168.7.102:10080,192.168.7.102:10043 use_backend backend_name 范例：使用haproxy实现调度apache1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#模拟httpd_server不直接对外服务，通过haproxy负载对外进程调度服务#配置haproxy实现基客户端第一次请求服务端保留的cookie进行调度实验准备 三台主机： haproxy_server : yum install haproxy -y httpd_serverA : yum install httpd -y httpd_serverB : yum install httpd -y配置httpd_server测试页面 httpd_serverA ~]# echo "172.18.135.1" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080 httpd_serverB ~]# echo "172.18.135.5" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080配置haproxy负载 ~]# yum install haproxy -y ~]# cat /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1111 gid 1111 daemon nbproc 4 cpu-map 1 0 cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys #httpd_server调度 frontend web-port-80 #web-port-80指定的此分组的名称 bind 172.18.135.2:80 #绑定在调度器本地的地址和端口 use_backend web_host #web_hos 定义的服务的主机组 backend web_host #调用web_hos主机组 server 172.18.135.1 172.18.135.1:80 # 172.18.135.1为定义的主机的名称，172.18.135.1:80 定义的后端的主机的地址及服务的端口 server 172.18.135.5 172.18.135.5:80启动查看端口 ~]# systemctl start haproxy ~]# ss -tnl 9999 172.18.135.2:80 -----------------------------------------------------------------------------------------------haproxy的配置文件中调用主机中也可以写为 #此处制定默认的backend，适用于backend少的情况下使用frontend myweb *:80 default_backend webserverbackend webserver server web1 后端主机地址A check server web1 后端主机地址B check----------------------------------------------------------------------------------------------也可以使用listen的方式指定listen myweb bind server web1 后端主机的地址A check server web2 后端主机的地址B check 测试：访问调度器地址验证是否调度成功 默认的调度算法为轮询 也可以使用下面命令的用法来验证调度是否成功 1~]# while true; do curl http://172.18.135.2/; sleep .5; done Proxies配置- backend配置参数 mode http/tcp/health #指定负载协议类型 option #配置选项 server #定义后端real server 注意：option后面加httpchk，smtpchk, mysql-check, pgsql-check，ssl-hello-chk方法，可用于实现更多应用层检测功能。 三、后端服务器状态监测及相关配置 check #对指定real进行健康状态检查，默认不开启 addr IP #可指定的健康状态监测IP port num #指定的健康状态监测端口 inter num #健康状态检查间隔时间，默认2000 ms(2秒) fall num #后端服务器失效检查次数，默认为3 rise num #后端服务器从下线恢复检查次数，默认为2 weight #默认为1，最大值为256，0表示不参与负载均衡 (默认轮询、加权) backup #将后端服务器标记为备份状态 disabled #将后端服务器标记为不可用状态 redir http://www.magedu.com/ #将请求临时重定向至其它URL，只适用于http模式 maxconn &lt;maxconn&gt;：当前后端server的最大并发连接数 backlog &lt;backlog&gt;：当server的连接数达到上限后的后援队列长度 范例：对调度器调度的后端服务器开启健康状态检测123456789101112生产中的定义恢复的次数要比下线的次数要长~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host server 172.18.135.1 172.18.135.1:8080 check addr 172.18.135.1 port 8080 inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080~]# systemctl restart haproxy frontend和backend 字段也可以写为listen（适用于配置较多的场景）1234567891011121314151617181920~]# vim /etc/haproxy/haproxy.cfg listen的配置当时#httpd_server调度listen web-port-80bind 172.18.135.2:80 server 172.18.135.5 172.18.135.5:8080 server 172.18.135.1 172.18.135.1:8080 check inter 2000 fall 3 rise 5frontend和backend配置方式#httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host server 172.18.135.1 172.18.135.1:8080 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 范例：redir将请求临时重定向至其它URL，只适用于http模式12345678910111213141516171819202122编辑paproxy调度器的配置文件 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 frontend web-port-80 bind 172.18.135.2:80 use_backend web_host backend web_host redirect prefix http://www.daizhe.net.cn/ ~]# systemctl restart haproxy客户端访问负载的地址 ~]# curl -I 172.18.135.2:80 HTTP/1.1 302 Found Cache-Control: no-cache Content-length: 0 Location: http://www.daizhe.net.cn//#302临时重定向#301永久重定向]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy简介]]></title>
    <url>%2F2019%2F01%2F21%2FHAproxy%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[HAproxy简介 公有云Web架构 一、什么是负载均衡： 负载均衡(Load Balance，简称LB)是一种服务或基于硬件设备等实现的高可用反向代理技术，负载均衡将特定的业务(web服务、网络流量等)分担给指定的一个或多个后端特定的服务器或设备，从而提高了公司业务的并发处理能力、保证了业务的高可用性、方便了业务后期的水平动态扩展。 阿里云SLB介绍 https://yq.aliyun.com/articles/1803 二、为什么使用负载均衡 Web服务器的动态水平扩展 对用户无感知 增加业务并发访问及处理能力 解决单服务器瓶颈问题 节约公网IP地址 降低IT支出成本 隐藏内部服务器IP 提高内部服务器安全性 配置简单 固定格式的配置文件 功能丰富 支持四层和七层，支持动态下线主机 性能较强 并发数万甚至数十万 三、常见的负载均衡 软件负载： 四层： LVS(Linux Virtual Server)：工作在内核当中 HAProxy(High Availability Proxy) Nginx （1.9.0 以上版本 stream功能） 七层： HAProxy Nginx 硬件负载： F5 Netscaler 应用场景： 四层：Redis、Mysql、RabbitMQ、Memcache等 七层：Nginx、Tomcat、Apache、PHP 、图片、动静分离、API等 四、HAProxy介绍 HAProxy: 是法国开发者Willy Tarreau开发的一个开源软件，是一款具备高并发、高性能的TCP和HTTP负载均衡器，支持基于cookie的持久性，自动故障切换，支持正则表达式为基础的控制运行时间基本web的报表，高级日志记录以帮助排除故障的应用或网络及其他功能。 LB Cluster: 四层：lvs, nginx(stream模式且nginx1.9.0或更新版本)，haproxy(mode tcp) 七层：http: nginx(http), haproxy(mode http), httpd... 官网： http://www.haproxy.org https://www.haproxy.com githun上的文档：https://cbonte.github.io/haproxy-dconv/ 五、HAProxy功能 HAProxy是TCP / HTTP反向代理服务器，尤其适合于高可用性高并发环境 可以针对HTTP请求添加cookie，进行路由后端服务器 可平衡负载至后端服务器，并支持持久连接 支持基于cookie进行调度 支持所有主服务器故障切换至备用服务器 支持专用端口实现监控服务 支持不影响现有连接情况下停止接受新连接请求 可以在双向添加，修改或删除HTTP报文首部 支持基于pattern实现连接请求的访问控制 通过特定的URI为授权用户提供详细的状态信息 HAproxy工作场景：七层http/四层tcp 工作于七层:解析http请求，可以完成对用户请求的按照内容的类型进行分别调度 工作于四层：模拟对其他tcp/udp协议传输的应用层服务的调度转发 工作于前端: 作为https的卸载器 应用场景 六、安装HAproxy1、yum 方式安装haproxy1234567891011121314151617181920212223242526默认base源中HAproxy 1.5版本 ~]# yum list haproxy haproxy.x86_64 1.5.18-8.el7 base ~]# yum install haproxy -y分析haproxy安装的程序文件 ~]# rpm -ql haproxy /etc/haproxy/haproxy.cfg #主配置文件 /etc/sysconfig/haproxy #环境变量的配置文件，用途少，主要用于传递参数 /usr/lib/systemd/system/haproxy.service #程序的启动脚本 #1.7版本之前启动调用的二进制文件，1.8以后则不使用了（ExecStart=/usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy） /usr/sbin/haproxy /usr/sbin/haproxy-systemd-wrapper启动 ~]# systemctl start haproxy ~]# ss -tnl *:5000 查看1.5版本实现的伪多进程 ~]# ps -ef | grep haproxy root 3856 1 0 21:00 ? 00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid #主进程 haproxy 3857 3856 0 21:00 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Ds haproxy 3858 3857 0 21:00 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Ds root 4097 2822 0 21:02 pts/0 00:00:00 grep --color=auto haproxy 2、源码编译安装haproxyhaproxy 1.8版本：新特性 多进程：可以最大限度的利用cpu多核心的特性，开启多个工作进程实现最大限度响应用户的目的。 安装包下载路径：https://www.haproxy.org/download/1.8/src/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687安装依赖包 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate -y ~]# cd /usr/local/src/ src]# ls haproxy-1.8.16.tar.gz src]# tar xvf haproxy-1.8.16.tar.gz src]# cd haproxy-1.8.16/ haproxy-1.8.16]# pwd /usr/local/src/haproxy-1.8.16编译安装 haproxy-1.8.16]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy haproxy-1.8.16]# make install PREFIX=/usr/local/haproxy haproxy-1.8.16]# cp haproxy /usr/sbin/创建启动脚本 ~]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target查看haproxy 版本 ~]# haproxy -v HA-Proxy version 1.8.16-5c3f237 2018/12/21 Copyright 2000-2018 Willy Tarreau &lt;willy@haproxy.org&gt;创建目录和用户 ~]# mkdir /etc/haproxy创建配置文件 ~]# vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 99 gid 99 daemon #nbproc 4 #cpu-map 1 0 #cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys listen web_port bind 0.0.0.0:80 mode http log global server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5启动 ~]# systemctl start haproxy ~]# systemctl enable haproxy进程查看 ~]# ps -ef | grep haproxy root 5883 1 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid nobody 5886 5883 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid root 5907 5491 0 09:37 pts/0 00:00:00 grep --color=auto haproxy 启动验证haproxy状态： 以下是1.8.3版本的单主进程多子进程模式： 1234567891011haproxy-1.8.3]# systemctl daemon-reloadhaproxy-1.8.3]# systemctl restart haproxyhaproxy-1.8.3]# cat /run/haproxy.pid 41998haproxy-1.8.3]# ps -ef | grep haproxyroot 41998 1 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 41999 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42000 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42001 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42002 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 42186 10580 0 16:28 pts/14 00:00:00 grep --color=auto haproxy 以下是1.7版本的传统多进程的haproxy模式： 12345678~]# ps -ef | grep haproxyroot 118786 1 0 17:10 ? 00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 118787 118786 0 17:10 ? 00:00:00 [haproxy] &lt;defunct&gt;nobody 118788 1 6 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118789 1 6 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118790 1 3 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118791 1 5 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsroot 118814 99636 0 17:10 pts/0 00:00:00 grep --color=auto haproxy 以下是Nginx的单主进程多子进程模式，此模式和1.8.3版本的haproxy工作模式是类似的： 1234567891011~]# ps -ef | grep nginxroot 13399 1 0 Jan06 ? 00:00:01 nginx: master process /apps/tengine/sbin/nginx -s startdevops 22165 22122 0 16:20 pts/0 00:00:00 grep --color=auto nginxzceo 22915 13399 0 Jan13 ? 00:41:41 nginx: worker processzceo 22916 13399 0 Jan13 ? 00:41:59 nginx: worker processzceo 22917 13399 0 Jan13 ? 00:41:38 nginx: worker processzceo 22918 13399 0 Jan13 ? 00:41:32 nginx: worker processzceo 22919 13399 0 Jan13 ? 00:41:22 nginx: worker processzceo 22920 13399 0 Jan13 ? 00:41:40 nginx: worker processzceo 22921 13399 0 Jan13 ? 00:42:07 nginx: worker processzceo 22922 13399 0 Jan13 ? 00:41:40 nginx: worker process 以下是apache的单主进程多子进程模式，也和1.8.3版本的haproxy工作模式类似： 12345678910~]# ps -ef | grep apacheroot 6758 1 0 11:01 ? 00:00:00 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6760 6758 0 11:01 ? 00:00:00 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6761 6758 0 11:01 ? 00:00:02 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6762 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6764 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6770 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6771 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6780 6758 0 11:01 ? 00:00:02 /usr/local/apache2.2.17/bin/httpd -k startroot 8076 8038 0 11:50 pts/2 00:00:00 grep apache]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[session一致性架构设计实践]]></title>
    <url>%2F2019%2F01%2F20%2Fsession%E4%B8%80%E8%87%B4%E6%80%A7%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[session一致性架构设计实践 一、缘起什么是session？ 服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文。 Web开发中，web-server可以自动为同一个浏览器的访问用户自动创建session，提供数据存储功能。最常见的，会把用户的登录信息、用户信息存储在session中，以保持登录状态。 什么是session一致性问题？ 只要用户不重启浏览器，每次http短连接请求，理论上服务端都能定位到session，保持会话。 当只有一台web-server提供服务时，每次http短连接请求，都能够正确路由到存储session的对应web-server（废话，因为只有一台）。 此时的web-server是无法保证高可用的，采用“冗余+故障转移”的多台web-server来保证高可用时，每次http短连接请求就不一定能路由到正确的session了。 如上图，假设用户包含登录信息的session都记录在第一台web-server上，反向代理如果将请求路由到另一台web-server上，可能就找不到相关信息，而导致用户需要重新登录。 在web-server高可用时，如何保证session路由的一致性，是今天将要讨论的问题。 二、session同步法 思路：多个web-server之间相互同步session，这样每个web-server之间都包含全部的session 优点：web-server支持的功能，应用程序不需要修改代码 不足： session的同步需要数据传输，占内网带宽，有时延 所有web-server都包含所有session数据，数据量受内存限制，无法水平扩展 有更多web-server时要歇菜 三、客户端存储法 思路：服务端存储所有用户的session，内存占用较大，可以将session存储到浏览器cookie中，每个端只要存储一个用户的数据了 优点：服务端不需要存储 缺点： 每次http请求都携带session，占外网带宽 数据存储在端上，并在网络传输，存在泄漏、篡改、窃取等安全隐患 session存储的数据大小受cookie限制 “端存储”的方案虽然不常用，但确实是一种思路。 四、反向代理hash一致性 思路：web-server为了保证高可用，有多台冗余，反向代理层能不能做一些事情，让同一个用户的请求保证落在一台web-server上呢？ 方案一：四层代理hash 反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个web-server上 方案二：七层代理hash 反向代理使用http协议中的某些业务属性来做hash，例如sid，city_id，user_id等，能够更加灵活的实施hash策略，以保证同一个浏览器用户的请求落在同一个web-server上 优点： 只需要改nginx配置，不需要修改应用代码 负载均衡，只要hash属性是均匀的，多台web-server的负载是均衡的 可以支持web-server水平扩展（session同步法是不行的，受内存限制） 不足： 如果web-server重启，一部分session会丢失，产生业务影响，例如部分用户重新登录 如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session session一般是有有效期的，所有不足中的两点，可以认为等同于部分session失效，一般问题不大。 对于四层hash还是七层hash，个人推荐前者：让专业的软件做专业的事情，反向代理就负责转发，尽量不要引入应用层业务属性，除非不得不这么做（例如，有时候多机房多活需要按照业务属性路由到不同机房的web-server）。 四、后端统一存储 思路：将session存储在web-server后端的存储层，数据库或者缓存 优点： 没有安全隐患 可以水平扩展，数据库/缓存水平切分即可 web-server重启或者扩容都不会有session丢失 不足：增加了一次网络调用，并且需要修改应用代码 对于db存储还是cache，个人推荐后者：session读取的频率会很高，数据库压力会比较大。如果有session高可用需求，cache可以做高可用，但大部分情况下session可以丢失，一般也不需要考虑高可用。 五、总结 保证session一致性的架构设计常见方法： session同步法：多台web-server相互同步数据 客户端存储法：一个用户只存储自己的数据 反向代理hash一致性：四层hash和七层hash都可以做，保证一个用户的请求落在一台web-server上 后端统一存储：web-server重启和扩容，session也不会丢失 对于方案3和方案4，个人建议推荐后者： web层、service层无状态是大规模分布式系统设计原则之一，session属于状态，不宜放在web层 让专业的软件做专业的事情，web-server存session？还是让cache去做这样的事情吧]]></content>
      <categories>
        <category>outside class</category>
      </categories>
      <tags>
        <tag>outside class</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat会话服务]]></title>
    <url>%2F2019%2F01%2F20%2Ftomcat%E4%BC%9A%E8%AF%9D%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Tomcat Session Server session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 session server:后端服务器之后即存储服务器 存储系统种类繁多 Session Manager 需要专门添加并非内建 存储系统性能高 存储系统要保存session ，而session通常都是简单的数据，但是必须要具有流逝化的特性 session变化特别的频繁所以存储系统必须要做到快速的存取 存储系统要有冗余能力 存储系统一旦成为一个集中的session server后，将成为整个系统的单点 Cache 缓存：无持久能力（memcached） 一般而言都是在内存当中或者即便实在磁盘上，通常系统重启后数据则将丢失，无法完成重构。 Store 存储 (redis) 数据的读写有可能是在内存中完成，但是本身却拥有持久存储功能即持久是必备功能 memcached（缓存服务） 缓存的数据的大小不可大于1M，如果数据大于1M则不被缓存 完全基于内存工作 缓存系统使用场景 服务器存储的系统存在热区 服务器的数据读多写少 memcached特证 协议简单 基于libevent的事件处理（单进程处理多路请求） 内置内存存储方式 memcached不互通信额分布式 范例：基于nginx实现负载均衡，实现mamcache会话缓存 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109实验准备 三台主机 nginx_server yum install nginx -y tomcat_serverA yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y yum install memcached -y tomcat_serverB yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y yum install memcached -y 在两台tomcat上分别创建测试页面并定制虚拟主机tomcatA ~]# mkdir /data/webapps/myapp-v0.1 ~]# cd /data/webapps/myapp-v0.1 myapp-v0.1]# mkdir classes lib WEB-INF WETA-INF myapp-v0.1]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="purple"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp ~]# tree /data /data └── webapps ├── myapp -&gt; myapp-v0.1 └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnltomcatB ~]# tree /data /data └── webapps └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF ~]# vim /data/webapps/myapp-v0.1/index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatB.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnl 访问测试是否配置成功 tomcat默认不支持将session会话信息放进memcached中，需要借助第三方MSM（memcached session manager）,意思是将memcached当作session会话的后端的session管理器 支持的存储程序 memcached redis couchbase 托管在github上地址：https://github.com/magro/memcached-session-manager 配置参考手册：https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration 配置tomcatA和tomcatB 可以实现两个tomcat可以使用两个memcached 实现两台memcached各存储部分session 会话信息，实现双活机制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788tomcatA 安装memcached (base仓库) 监听的端口 tcp 11211 / udp 11211 ~]# yum install memcached -y ~]# rpm -ql memcached /etc/sysconfig/memcached #配置文件 /usr/bin/memcached #命令执行文件 usr/lib/systemd/system/memcached.service #启动程序文件 查看memcached命令帮助 ~]# memcached -h -p &lt;num&gt; # 监听tcp 11211端口 -U &lt;num&gt; # 监听UDP 11211端口 ， 设置upd协议为0 表示关闭udp协议的端口 -l &lt;addr&gt; # 指定监听的地址 -d # 运行为守护进程 -u &lt;username&gt; # 指定运行的身份 -m &lt;num&gt; # 使用多大的内存空间当作缓存 ，默认为64M ，必须调大 -M # 内存耗尽禁用LRU 表示内存耗尽禁止新存储的数据存储 -c &lt;num&gt; # 最大并发连接数，默认为1024 -v # 输出信息到前台 -vv # 详细 -vvv # 详详细 -f &lt;factor&gt; # 增长因子 默认为1.25 #查看增长因子 #~]# su - daizhe #~]$ memcached -vvv -m 256m -f 1.25 #slab class 1: chunk size 96 perslab 10922 #slab class 2: chunk size 120 perslab 8738 #slab class 3: chunk size 152 perslab 6898 #slab class 4: chunk size 192 perslab 5461 #slab class 5: chunk size 240 perslab 4369编辑memcache的配置文件启动 ~]# vim /etc/sysconfig/memcached PORT="11211" #端口 USER="memcached" #运行身份 MAXCONN="1024" CACHESIZE="256" #内存空间 OPTIONS="-f 1.1 -M" #指定增长因子 ~]# systemctl start memcached ~]# ss -tnl 11211安装c程序调用memcache依赖的库# php程序员： php-pecl-memcache# python程序员： python-memcached.noarch# c程序员: libmemcached ~]# yum install libmemcached -y 使用telnet连接（memcached支持文本协议即纯文本的字符串） ~]# yum install telnet -y ~]# telnet 127.0.0.1 11211 #stats查看状态使用信息 设置一个键 set mykey 123 60 6 daizhe STORED # 键名：mykey # 值：123 # 超时时长：60内有效 # 指定字节数 查看已经存储的键值 get mykey获取memcached的信息 ~]# memstat -h --servers= #指定服务器地址 ~]# memstat --servers=127.0.0.1:11211dump出所有存储的键 ~]# memdump --servers=127.0.0.1:11211清空所有的键 ~]# memflush删除所有的键 ~]# memrm更新键的时间戳 ~]# memtouch判断存在性 ~]# memexist 123456789101112131415tomcatA 安装memcached ~]# yum install memcached -y编辑memcache的配置文件启动 ~]# vim /etc/sysconfig/memcached PORT="11211" #端口 USER="memcached" #运行身份 MAXCONN="1024" CACHESIZE="256" #内存空间 OPTIONS="-f 1.1 -M" #指定增长因子 ~]# systemctl start memcached ~]# ss -tnl 11211 jar文件下载路径：http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager/123456为tomcatA 节点和 tomcatB 节点的tomcat准备 jar文件 查看默认的tomcat的jar文件的存放路径 ~]# rpm -ql tomcat-lib ~]# cd /usr/share/java/tomcat/ #所有的tomcat节点上都要放置jar文件 将所有的jar文件防止在此路径下 1234567891011121314配置tomcatA和tomcatB 节点的tomcat的配置文件（不要和tomcat_session 会话集群同时使用）tomcatA和tomcatB ~]# vim /etc/tomcat/server.xml #105 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tcA"&gt; #两个节点做区分 tcA / tcB#140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""&gt; &lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" memcachedNodes="172.18.135.1:11211,172.18.135.5:11211" failoverNodes="n1" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$" transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" /&gt;&lt;/Context&gt; 1234启动节点中所有tamcat服务器并监控日志信息 ~]# systemctl restart tomcat ~]#tail -f /var/log/tomcat/catalina.2019-01-20.log 使用nginx调度测试]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat会话集群]]></title>
    <url>%2F2019%2F01%2F19%2Ftomcat%E4%BC%9A%E8%AF%9D%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Tomcat Session Cluster session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 session replication cluster (sesssion复制集群)：后端服务器组织成集群 tomcat中自身就带有了一种cluster机制（集群仅是针对于保持用户session会话问题上实现集群） 将后端多个正常工作的主机在session管理问题上将其基于专有的网络接口或者面向客户端的通用网络接口构建出一个会话集群，此集群可以实现让每一个节点获得会话信息后通过所谓通讯当中的多播机制或者称之为组播机制（Multicast），将自己所获得的会话信息多播到事先约定的多播信道上，实现在同一多播网络中的其他主机获取到相关的会话信息，并将其合并到本地已有的会话信息中。 构建通讯集群的方式 单播：效率最低 多播：多播方式最优，可以配置同一集群中的主机，大家共同使用同一个多播地址（多播域），而后在规定的多播第之内发送多播信息，只有同一多播地址上的主机才可以收到此会话信息。 广播：后端主机获得会话信息后直接以广播的方式发送到其他后端主机上（但是播及面太大，造成影响范围太大）。 tomcat本身就是java语言编写，所以具有完全面向对象的特性，必须使用类来完成任何功能，包括会话管理，在tomcat上会话管理组件称为session manager (会话管理器)，在tomcat上有好几种会话管理机制，统称为会话管理器 默认使用的是持久会话管理 tomcat接收到客户的session会话信息，是先保存在内存中，会周期性的同步在磁盘上进行数据的保存（所以将tomcat重启后，被正常存储好的会话信息会被将回复回来，但是在未到周期同步在磁盘上的session会话信息，也就是存在内存中的会话尚未同步在磁盘上的会话信息在tomcat宕机时会丢失session会话信息） 持久会话管理，一定会影响磁盘的IO性能（受本地的磁盘IO限制） Delta Session Manager 会话管理器 增量变动之意 每一个节点自己后来生成的session会话增量变量的信息，将增量的会话变动通过多播方式，多播到多播域内，同一多播域中的其他主机也存在相同的Delta Session Manager 接收其他主机在多播域内变动的session会话信息，并且合并在本地的session存储中 劣势：session manager 中的每个节点都要保存所有的会话信息并且通常是保存在内存中，一旦客户端访问的数量增多时会使得后端session manager存储会话的节点中都存在大量的会话信息，会使得会话无法被扩展。 Backup Session Manager 备份会话管理器 每一个会话节点（session manager）在保存会话和生成会话时，会将会话同传给集群中的其他一个节点或者说是有限节点，而不是所有会话集群中的所有节点，因为每个节点禁止有所有会话节点中一定比例的会话信息。 此类会话管理须实现前端调度的会话绑定，且保持会话管理的节点一但宕机后可以将此会话信息保持 发送到另一台备份会话信息的会话管理器上（而不是任何一个会话管理节点）。此类会话管理，需要管理员精心介入到调度拓扑结构中。 也就是此类会话管理无会话动态性需要管理员明确管理指定，如有宕机需精确的重定向，那台会话管理节点备份了哪台会话节点的会话信息。 打破了不会让每一个节点持有整个集群的session会话的信息 自定义会话管理器 将tomcat生成的会话信息不记录在服务器的内存中，而是将会话信息存储到外部适配的缓存的服务器上比如mamcached、redis 一旦有session会话保持时通过是配置直接保存在外部存储上，这样则使得tomcat可以是同Session_server保存用户的会话信息 范例：Delta Session Manager 会话管理器参考文档：http://tomcat.apache.org/tomcat-7.0-doc/cluster-howto.html1234567891011121314151617181920212223242526272829303132333435363738394041配置启用集群，将下列配置放置于&lt;engine&gt;或&lt;host&gt;中； &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" #属性指明使用的类 channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" #指定使用的会话管理器 expireSessionsOnShutdown="false" #DeltaManager 用到的属性 notifyListenersOnReplication="true"/&gt; #DeltaManager 用到的属性 &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; #定义多播信息及集群通讯信道 &lt;Membership className="org.apache.catalina.tribes.membership.McastService" #定义集群成员的关系 address="228.0.0.4" #多播地址，D类地址用来组播（224~239），多播即大家使用同一个D类中相同的一个地址 port="45564" #多播端口 frequency="500" #每个多长时间发一次心跳 默认500毫秒 dropTime="3000"/&gt; #多长时间内收不到节点的心跳 判断为超时，从而从集群成员中剔除 &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" #定义如何接收传递的session会话信息 address="auto" port="4000" #监听的端口，如果有冲突，自动切换（4000~4100） autoBind="100" #自动绑定，如有错误自动重新绑定 selectorTimeout="5000" #选择器的超时时长默认5秒 maxThreads="6"/&gt; #最大线程数，默认值为6，已经足够使用 &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; #向外发送心跳以及session会话信息 &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; #心跳大佛那个的方式轮询 &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; #探测器校验信息是否出错 &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" #定义过滤器，过滤复制集群相关的信息 filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; #绑定JVM的路由信息 &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; #集群侦听器，确保集群相关的资源仅被集群中的成员所使用 &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798会话集群配置第一步：配置session集群(修改所有的tomcat服务器会话集群的配置文件) ~]# vim /etc/tomcat/server.xml 105行 添加标注信息 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tcA"&gt; #每个节点上的标识不要相同 128行 &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.100.10" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;第二步：拷贝 web.xml文件到自己定义的路径别名的虚拟主机中(修改所有的tomcat服务器会话集群虚拟主机的web.xml) ~]# cp /etc/tomcat/web.xml /data/webapps/myapp/WEB-INF/ WEB-INF]# pwd /data/webapps/myapp/WEB-INF 23行 &lt;distributable/&gt; #必须虚拟主机路经下存在web.xml 并且改文件中存在&lt;distributable/&gt; 才可使用会话集群第三步：集群成员间的时间必须同步 ~] # ntpdate注意：此时调度器应该继续使用会话粘性，保证客户端请求都调度到一台服务器，因为后端的会话集群服务器同步会话信息并非实时同步。这样可以确保当给客户端提供会话的主机宕机后也可以让令外会话集权中的服务器继续保持会话第四步：重新启动会话集群中的tomcat服务器 ~]# systemctl start tomcat ~]# tail -f /var/log/tomcat/catalina.2019-01-20.log 调度器使用nginx调度测试 ~]# vim /etc/nginx/nginx.conf upstream tcserver &#123; server 172.18.135.1:8080; server 172.18.135.5:8080; &#125; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://tcserver; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; ~]# nginx -t ~]# nginx -s reload 测试(已经实现会话保持和nginx默认的轮询调度)]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat负载均衡--nginx | httpd]]></title>
    <url>%2F2019%2F01%2F19%2Ftomcat%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[tomcat负载均衡及会话保持–nginx | httpd session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 如果对tomcat实现负载均衡调度，一定要考虑到会话保持 如何对tomcat实现负载均衡（ session stick:调度器） 范例：使用nginx实现负载均衡123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109实验准备 三台主机 nginx_server yum install nginx -y tomcat_serverA yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y tomcat_serverB yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y 在两台tomcat上分别创建测试页面并定制虚拟主机tomcatA ~]# mkdir /data/webapps/myapp-v0.1 ~]# cd /data/webapps/myapp-v0.1 myapp-v0.1]# mkdir classes lib WEB-INF WETA-INF myapp-v0.1]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="purple"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp ~]# tree /data /data └── webapps ├── myapp -&gt; myapp-v0.1 └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnltomcatB ~]# tree /data /data └── webapps └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF ~]# vim /data/webapps/myapp-v0.1/index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatB.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnl 访问测试是否配置成功 12345678910111213141516171819202122232425262728293031使用nginx实现客户端的请求完全向后端代理nginx_server ~]# vim /etc/nginx/nginx.conf upstream tcserver &#123; server 172.18.135.1:8080; #tomcat A 地址 server 172.18.135.5:8080; #tomcat B 地址 &#125; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://tcserver/; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; ~]# nginx -t ~]# nginx -s reload ~]# ss -tnl 客户端测试查看（此时是不能保持session会话,服务器认为是不同的session） 1234567891011利用nginx的hash算法实现会话绑定#基于一致性BASH算法实现会话绑定nginx_server upstream tcserver &#123; hash $remote_addr consistent; server 172.18.135.1:8080; server 172.18.135.5:8080; &#125; ~]# nginx -t ~]# nginx -s reload 客户端测试（怎么刷新都会是一个tomcat服务器响应，认为是一个客户端） 但是这用基于bash的机制是存在劣势的，万一响应的服务器宕机则客户端则无法接收到响应 范例：使用http实现负载均衡 httpd也可以实现负载均衡以及会话保持，甚至支持coocki级别的会话保持 持续支持的调度算法（lbmethod） bytraffic:后端服务器流量大小承载调度（流量小被调度） byrequests:根据请求调度，不考虑后端服务器的繁忙程度（轮询） bybusyness ：根据后端繁忙服务器程度进行调度，永不排队（商业版本支持） 参考手册：http://httpd.apache.org/docs/2.4/howto/reverse_proxy.html 方式1:http协议1234567891011121314151617181920212223242526272829#httpd做tomcat前端调度支持的协议（http\ajp 8009）#nginx做tomcat前端调度支持的协议（http）httpd_server httpd协议 ~]# vim /etc/httpd/conf.d/tomcat-cluster.conf &lt;proxy balancer://tcsrvs&gt; BalancerMember http://172.18.135.1:8080 loadfactor=2 #定义负载因子如果不定义默认都为1 BalancerMember http://172.18.135.5:8080 ProxySet lbmethod=byrequests &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName www.centos.com #nginx主机名 ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t ~]# systemctl start httpd 访问测试（此时保证不了会话绑定） 方式2：ajp协议1234567891011121314151617181920212223242526httpd_server ajp协议 &lt;proxy balancer://tcsrvs&gt; BalancerMember ajp://172.18.100.67:8009 BalancerMember ajp://172.18.100.68:8009 ProxySet lbmethod=byrequests &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName lb.magedu.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location /balancer-manager&gt; SetHandler balancer-manager ProxyPass ! Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; 会话粘性（httpd基于cookie的会话粘性）1234567891011#httpd不支持客户端地址的粘性#httpd是根据客户端的cookie做会话粘性httpd服务保持会话粘性： #当服务器第一次收到客户端的请求给他设定cookie时候，在这个cookie中把原有值之外额外设置添加一个对应的键（键名可以自己定义），值则是调度器第一次挑选要负载用户请求的后端服务器的名称，随后用户每后来的访问一定默认会带着cookie,而人为定义之后cookie之中是带有人为设置的键和值的对应信息的（不是基于原ip绑定，而是实现人为的会话中的cookie中插入的键值一致性实现的）Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGEDHeader add Set-Cookie #给客户端设置的cookie ROUTEID= #键名 .%&#123;BALANCER_WORKER_ROUTE&#125;e #调度服务器挑选出后端服务器 path= #指定会话cookie的适用范围 1234567891011121314151617181920212223242526编辑调度器httpd_server设置会话粘性 ~]# vim /etc/httpd/conf.d/tomcat-cluster.conf Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGED &lt;proxy balancer://tcsrvs&gt;BalancerMember http://172.18.135.1:8080 loadfactor=2 route=TomcatA BalancerMember http://172.18.135.5:8080 route=TomcatA loadfactor=1 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t ~]# systemctl restart httpd 客户端测试（已经实现基于cookie的会话粘性。可以使用Chrome开发者模式F12查看）]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置进阶--反代]]></title>
    <url>%2F2019%2F01%2F18%2Ftomcat%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B62%2F</url>
    <content type="text"><![CDATA[tomcat配置进阶–反代 tomcat配置进阶–反代nginx反代配置方式完全代理 客户端请求的所有资源都经由nginx反代给后端tomcat 123456#完全向后反代nginx配置文件location / &#123; proxy_pass http://127.0.0.1:8080/;&#125; 动静分离（动静分离的前提是应用程序支持动态页面和静态页面分开也可以达到客户端请求资源的一致性） nginx配置中指明客户端请求的闻不见类型为jsp或do结尾才代理给后端的tomcat服务器，除了此类型的文件外都经由nginx处理响应客户端的请求 为什么要实现动静分离 nginx的处理静态资源能力超强 主要是nginx处理静态页面的效率远高于tomcat的处理能力，如果tomcat的请求量为1000次，则nginx的请求量为6000次，tomcat每秒的吞吐量为0.6M，nginx的每秒吞吐量为3.6M，可以说，nginx处理静态资源的能力是tomcat处理能力的6倍，优势可见一斑。 动态资源和静态资源分开，使服务器结构更清晰。 动静分离原理： 服务端接收来自客户端的请求中，有一部分是静态资源的请求，例如html,css,js和图片资源等等，有一部分是动态数据的请求。因为tomcat处理静态资源的速度比较慢，所以我们可以考虑把所有静态资源独立开来，交给处理静态资源更快的服务器例如nginx处理，而把动态请求交给tomcat处理。如下图所示，我们在机器上同时安装了nginx和tomcat,把所有的静态资源都放置在nginx的webroot目录下面，把动态请求的程序都放在tomcat的webroot目录下面，当客户端访问服务端的时候，如果是静态资源的请求，就直接到nginx的webroot目录下面获取资源，如果是动态资源的请求，nginx利用反向代理的原理，把请求转发给tomcat进行处理，这样就实现了动静分离，提高了服务器处理请求的性能。 12345678910#有选择的进行反代以便实现动静分离nginx 配置文件location ~* \.(jsp|do)$ &#123; proxy_pass www.tomcat.com:8080; #此处最好使用后端tomcat主机名，如果tomcat在本地，则使用localhost&#125;location / &#123; root /data/myapp/ROOT&#125; 实现nginx反向代理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 这里使用了docker容器化技术，将tomcat运行在docker容器中运行，运行的容器默认使用docker0桥与宿主机建立关联关系,并在宿主机上安装nginx接受客户端的请求代理给运行在docker容器中的tomcat安装docker ~]# cd /etc/yum.repos.d/ yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ~]# yum install docker-ce -y ~]# systemctl start docker获取tomcat镜像 https://hub.docker.com/_/tomcat?tab=tags下载tomcat镜像 ~]# docker pull tomcat:8.5-alpine后启动容器（指定容器中tomcat的工作目录与宿主机的目录生成docker管理的卷的存储卷关系） ~]# docker run --name tc1 -d -v /usr/local/tomcat/webapps tomcat:8.5-alpine ~]# docker container inspect tc1 ~]# cd /var/lib/docker/volumes/12d5e74a0cc8e916b7545898b41d802f85fed1cd0a5996fe7f74582245a8b2a3/_data _data]# ls docs examples host-manager manager ROOT宿主机上测试访问 ~]# curl 172.17.0.2:8080宿主机上安装nginx并配置实现代理 ~]# yum install nginx -y ~]# systemctl start nginx ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://172.17.0.1:8080/; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; ~]# nginx -t ~]# nginx -s reload客户端访问宿主机地址(此时nginx已经实现反向代理到tomcat) ~]# curl 172.18.135.1 #访问宿主机地址实现nginx反代tomcat动静分离（仅查看一下动静分离查看效果） ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; index index.jsp index.html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://172.17.0.2:8080; &#125; location ~* \.(jsp|do)$ &#123; root "映射在宿主机上的存储的卷"; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; 实现httpd反向代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# 这里使用了docker容器化技术，将tomcat运行在docker容器中运行，运行的容器默认使用docker0桥与宿主机建立关联关系,并在宿主机上安装httpd接受客户端的请求代理给运行在docker容器中的tomcatproxy_ajp_module代理配置示例：# &lt;VirtualHost *:80&gt;# ServerName tc1.centos.com# ProxyRequests Off #关闭正向代理# ProxyVia On # 对每一个响应报文都添加一个via首部（可以查看代理的主机地址）# ProxyPreserveHost On #用户请求的主机向后端代理时要不要保留代理服务器使用的主机名# &lt;Proxy *&gt; #定义代理服务# Require all granted #允许任何请求使用代理服务# &lt;/Proxy&gt;# ProxyPass / ajp://tc1.centos.com:8009/ #将用户请求的根代理到服务器端真正的根# ProxyPassReverse / ajp://tc1.centos.com:8009/ #如果tomcat服务器返回一个重写的法则，也将此法则返回给客户端# &lt;Location /&gt; #客户端请求rul根，设置权限# Require all granted #接受所有请求# &lt;/Location&gt;# &lt;/VirtualHost&gt;proxy_http_module代理配置示例：# &lt;VirtualHost *:80&gt;# ServerName tc1.centos.com# ProxyRequests Off# ProxyVia On# ProxyPreserveHost On# &lt;Proxy *&gt;# Require all granted# &lt;/Proxy&gt;# ProxyPass / http://tc1.centos.com:8080/# ProxyPassReverse / http://tc1.centos.com:8080/ # &lt;Location /&gt;# Require all granted# &lt;/Location&gt;# &lt;/VirtualHost&gt; # &lt;LocationMatch "\.(jsp|do)$&gt; #基于正则表达式匹配检查# ProxyPass / http://tc1.centos.com:8080/ #定义反代的url，客户请求的其他的url则不进行反代# &lt;/LocationMatch&gt; 宿主上安装httpd（完全代理） ~]# yum install httpd -y ~]# httpd -M #确认proxy_module反代模块存在，否则不支持httpd反向代理 proxy_module (shared) proxy_ajp_module (shared) #反代支持ajp协议 proxy_http_module (shared) #httpd协议反代 proxy_fcgi_module (shared) 配置httpd ~]# vim /etc/httpd/conf.d/tomcat-http.conf ~]# vim /etc/httpd/conf.d/tomcat-http.conf &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyRequests Off ProxyVia On #对每一个响应报文都添加一个via首部 ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / http://172.17.0.2:8080/ #后端tomcat地址 ProxyPassReverse / http://172.17.0.2:8080/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t Syntax OK~]# systemctl start httpd测试 ~]# curl 172.18.135.1 配置文件中添加 ProxyVia On 可以使用浏览器开发者接口查看到 http基于ajp协议实现反代1234567891011121314 &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyRequests Off ProxyVia On ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / ajp://172.17.0.2:8009/ ProxyPassReverse / ajp://172.17.0.2:8009/&lt;Location /&gt; Require all granted&lt;/Location&gt;&lt;/VirtualHost&gt;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置进阶--热部署]]></title>
    <url>%2F2019%2F01%2F16%2Ftomcat%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[tomcat配置进阶–热部署 tomcat配置进阶–热部署范例：Valve组件（过滤器）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152一、 ~]# vim /etc/tomcat/server.xml &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;#AccessLogValve 定义记录访问日志#directory 日志记录的路径，默认使用的是相对路径#prefix 日志文件的前缀，默认情况下，一天滚动一次（日志的前后缀可以按需求定义）#suffix 日志文件的后缀 （yum安装的生成的日志存放路径： /var/log/tomcat/）#pattern 日志文件所记录的日志格式 #%h远程客户端地址 #%l登陆的用户名 #%t访问时间 #%r请求报文的起始行（请求方法，请求的url,协议报文） #%s响应码 #%b响应的版本#一般而言Valve日志是host级别的，每一个虚拟主机有一个单独专用的日志将自己定义的主机也有自己单独的日志 ~]# vim /etc/tomcat/server.xml &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="centos.com_log." suffix=".log" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt;查看是否生成单独的虚拟主机的日志文件 ~]# systemctl restart tomcat ~]# ls /var/log/tomcat/ a_log.2019-01-16.txt 二、将tomcat的访问日志转化为json格式 修改tomcat的server.xml文件 &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".log" pattern="&#123;&amp;quot;client&amp;quot;:&amp;quot;%h&amp;quot;, &amp;quot;client user&amp;quot;:&amp;quot;%l&amp;quot;, &amp;quot;authenticated&amp;quot;:&amp;quot;%u&amp;quot;, &amp;quot;access time&amp;quot;:&amp;quot;%t&amp;quot;, &amp;quot;method&amp;quot;:&amp;quot;%r&amp;quot;, &amp;quot;status&amp;quot;:&amp;quot;%s&amp;quot;, &amp;quot;send bytes&amp;quot;:&amp;quot;%b&amp;quot;, &amp;quot;Query?string&amp;quot;:&amp;quot;%q&amp;quot;, &amp;quot;partner&amp;quot;:&amp;quot;%&#123;Referer&#125;i&amp;quot;, &amp;quot;Agent version&amp;quot;:&amp;quot;%&#123;User-Agent&#125;i&amp;quot;&#125;"/&gt;三、Valve存在多种类型：（根据客户端原地址做访问控制） 定义访问日志：org.apache.catalina.valves.AccessLogValve 定义访问控制：org.apache.catalina.valves.RemoteAddrValve &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" deny="172\.16\.100\.67"/&gt;#禁止172.16.100.67此台主机对tomcat的访问（黑名单）#可以使用deny与allow做访问控制，可以只用同配符 默认界面分析 点击接口进入：但是需要认证进入，点击取消可以查看如何授权用户访问此管理接口 授权用户一下几种权限： manager-gui - allows access to the HTML GUI and the status pages（授权的用户可以通过web界面访问） manager-script - allows access to the text interface and the status pages（授权的用户可以通过命令行的界面访问） manager-jmx - allows access to the JMX proxy and the status pages（可以只用java管理扩展来进行操作，多用于监控） manager-status - allows access to the status pages only（仅可以用于状态查看的用户即只读用户） 一、部署(manager)部署方式1：范例：授权账号可以访问web界面的manager的控制接口12345678~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; --&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script"/&gt; &lt;/tomcat-users&gt;#此文件是tomcat启动时加载到内存中的所以要重新启动tomcat~]# systemctl restart tomcat 已经授权账号，登陆查看 在图形化管理界面stop一个应用程序并非清除内存，代表着类实例化出的对象还都在JVM的内存区段当中相当于暂停状态。 Undeplay意思为写在完全清除，达到真正的释放资源。 Deploy:部署方式 热部署：（manager部署工具）在tomcat不停机的状态下部署，可以实现客户端访问。 冷部署：先停掉tomcat进程，放上应用程序，启动tomcat加载应用程序。 自动部署：直接将应用程序放进tomcat,自动实现部署。 手动部署：将依赖的类库一个个的装载上。 范例:实现Deploy热部署12345678910111213141516171819202122232425创建目录结构及jsp文件 ~]# mkdir /data/mywebs ~]# mkdir /data/mywebs ~]# cd /data/mywebs/ mywebs]# mkdir classes lib WEB-INF WETA-INFmywebs]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 热部署(重启tomcat也不会配置有影响，虽然不会出现在配置文件中，但是也是持久有效的) 方式2： 诊断（极少用到） 版本信息 帮助 二、运行状态 （server status) 三、管理虚拟主机（Host manager）授权用户访问此虚拟主机类管理界面启用方式和manager相同1234567~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt;&lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt;~]# systemctl restart tomcat 创建新的虚拟主机 注意：因为以上如部署权限过大，所以谨慎做好安全控制12345678# 可以对用户访问的http://172.18.135.1:8080/host-manager/或者http://172.18.135.1:8080/manager/html 做安装访问控制~]# vim /etc/tomcat/tomcat-users.xml &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="172\.16\.100\.67"/&gt;#/host-manager/和/manager/html两个目录仅允许本机客户端地址进行访问连接#或者用不到的话安装tomcat就不要安装这两个组件]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置tomcat]]></title>
    <url>%2F2019%2F01%2F16%2F%E9%85%8D%E7%BD%AEtomcat%2F</url>
    <content type="text"><![CDATA[tomcat配置 部署Tomcat(JDK+Tomcat) 运行者身份不能为root(user:tomcat)端口默认为8080/tcp 部署方式1：OpenJDK(openjdk 11 + tomcat 7.0)12345678910111213141516171819202122232425262728#rel兼容多个版本JDK并存，可以设置默认的JDK版本# ~]# alternatives --install JDK# ~]# alternatives --config javayum安装OpenJDK ~]# yum install java-11-openjdk-devel -y ~]# java -version openjdk version "11.0.1" 2018-10-16 LTS(长期支持版) OpenJDK Runtime Environment 18.9 (build 11.0.1+13-LTS) OpenJDK 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode, sharing) ~]# which java /usr/bin/java ~]# ll /usr/bin/java /usr/bin/java -&gt; /etc/alternatives/java ~]# ll /etc/alternatives/java /etc/alternatives/java -&gt; /usr/lib/jvm/java-11-openjdk-11.0.1.13-3.el7_6.x86_64/bin/java安装tomcat(7.0) tomcat-admin-webapps.noarch #tomcat的web界面的管理的接口 tomcat-docs-webapp.noarch #参考文档 ~]# yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y ~]# systemctl restart tomcat #运行身份为Java虚拟机运行 ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 部署方式2：Oracle JDK(oracle jdk 8u191 + tomcat 8.5)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253oracle jdk 下载地址：https://www.oracle.com/technetwork/java/javase/downloads/index.html ~]# ls jdk-8u191-linux-x64.rpm ~]# rpm -ivh jdk-8u191-linux-x64.rpm 默认安装路径 ~]# ls /usr/java/ default jdk1.8.0_191-amd64 latest ~]# ll /usr/java/ default -&gt; /usr/java/latest #支持设置默认的版本 jdk1.8.0_191-amd64 #同样支持多版本共存 latest -&gt; /usr/java/jdk1.8.0_191-amd64 #支持设置最新的版本 验证是否安装成功（直接运行java程序） 查看版本信息 amd64]# pwd /usr/java/jdk1.8.0_191-amd64 amd64]# /bin/java -version java version "1.8.0_191" Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) 修改PATH变量 ~]# vim /etc/profile.d/java.sh JAVA_HOME=/usr/java/default PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH ~]# source /etc/profile.d/java.sh ~]# printenv tomcat 8.5安装下载路径：http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# tar xvf apache-tomcat-8.5.37.tar.gz -C /usr/local/ ~]# ln -vs /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat （链接形式方便升级） tomcat不可使用root用户运行 ~]# useradd tomcat ~]# chown -R tomcat.tomcat /usr/local/tomcat/ ~]# chown -R tomcat.tomcat /usr/local/tomcat/* ~]# su - tomcat -c "/usr/local/tomcat/bin/catalina.sh start" Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/bin/default Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/u ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） server.xml默认配置 Tomcat： 使用java语言编写： java程序运行环境 运行在JVM虚拟机上 jvm虚拟机组成部分 类加载器 程序运行引擎 tomcat的配置文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； log4j （目前已经在第二版） 12345678910111213141516171819Tomcat的核心组件：server.xml &lt;Server&gt; &lt;Service&gt; &lt;connector/&gt; &lt;connector/&gt; ... &lt;Engine&gt; &lt;Host&gt; &lt;Context/&gt; &lt;Context/&gt; ... &lt;/Host&gt; &lt;Host&gt; ... &lt;/Host&gt; ... &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt; 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型： 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, … 集群类组件：listener, cluster, … 基本web服务器的组成 JSP WebAPP的组织结构：（WEB-INF/和WEB-INF/是当前程序专有的且不可被其他程序所使用，也不能让用户通过互联网路径来访问，因为此文件用于参考部署启动应用程序） /: webapps的根目录 index.jsp, index.html：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； WEB-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类 .java格式； lib/：类文件，当前webapp所提供的类，被打包为jar格式； webapp归档格式： .war：webapp（web_server的应用程序归档文件） .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp； 部署(deploy)webapp的相关操作： deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载至JVM； 部署有两种方式： 自动部署：auto deploy 手动部署: 冷部署：把webapp复制到指定的位置，而后才启动tomcat；- 热部署：在不停止tomcat的前提下进行部署； - 部署工具：manager、ant脚本、tcd(tomcat client deployer)等； undeploy：反部署，停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署； 范例：手动提供一测试类应用，并冷部署12345678910111213141516171819202122232425262728293031323334353637~]# mkdir testapp/~]# cd testapp/创建程序运行的相关的文件格式 testapp]# mkdir classes lib WEB-INF WETA-INF testapp]# ls classes lib WEB-INF WETA-INF创建网页文件 testapp]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello world"); %&gt; &lt;/body&gt; &lt;/html&gt; ~]# cp testapp testapp-v0.1将此文件复制到网页文件根目录（/usr/share/tomcat/webapps） ~]# cd /usr/share/tomcat/webapps webapps]# ls docs examples host-manager manager ROOT sample #ROOT 默认主站文件目录 webapps]# cp -r /root/testapp /usr/share/tomcat/webapps/ webapps]# ls docs examples host-manager manager ROOT sample testapp访问测试 ~]# curl 172.20.101.228:8080/testapp/ 1234567891011121314151617181920212223242526查看tomcat的工作目录 ~]# cd /usr/share/tomcat/work work]# tree . └── Catalina └── localhost #当前虚拟主机的名称 ├── _ │ └── org │ └── apache │ └── jsp │ ├── index_jsp.class │ └── index_jsp.java ├── docs ├── examples ├── host-manager ├── manager ├── sample └── testapp └── org └── apache └── jsp ├── index_jsp.class └── index_jsp.java#将自己定义放置在/usr/share/tomcat/webapps目录下testapp/index.jsp文件转换为java代码，再次编译成.class类文件#将来在生产中部署完应用程序，应该对每个url先自己访问一次，编译完成，然后再上线 tomcat的常用组件配置： Server：代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口； Service：用于实现将一个或多个connector组件关联至一个engine组件； Connector组件：端点 负责接收请求，常见的有三类http/https/ajp； 进入tomcat的请求可分为两类： (1) standalone : 请求来自于客户端浏览器； (2) 由其它的web server反代：来自前端的反代服务器； nginx –&gt; http connector –&gt; tomcat httpd(proxy_http_module) –&gt; http connector –&gt; tomcat httpd(proxy_ajp_module) –&gt; ajp connector –&gt; tomcat httpd(mod_jk) –&gt; ajp connector –&gt; tomcat 属性： port=”8080” protocol=”HTTP/1.1” connectionTimeout=”20000” address：监听的IP地址；默认为本机所有可用地址； maxThreads：最大并发连接数，默认为200； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； secure： sslProtocol： 范例：Server组件（顶级组件）1234567891011121314151617181920212223242526 ~]# vim /etc/tomcat/server.xml &lt;Server port="8005" shutdown="SHUTDOWN"&gt;#Server中两个属性需要定义# - port="8080" #端口# - shutdown="SHUTDOWN"# - 内建的管理接口，只要给SHUTDOWN字串则相当与停止整个tomcat进程 ~]# yum install telnet -y ~]# telnet 127.0.0.1 8005 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. SHUTDOWN Connection closed by foreign host. ~]# ss -tnl#此时tomcat已经停止，所以tomcat的8005端口默认监听在本机的127.0.0.1所以为了安全起见，建议关闭方法1：修改密码&lt;Server port="8005" shutdown="可以将命令修改的复杂"&gt;方法2：关闭监听端口&lt;Server port="-1" shutdown="SHUTDOWN"&gt; 范例：Service组件（类连接器）12345678910111213141516171819202122 ~]# vim /etc/tomcat/server.xml &lt;Service name="Catalina"&gt;........................http协议............................#Service中一个组件#将connector与Engine建立关联关系 &lt;Connector port="8080" protocol="HTTP/1.1" #端口、协议版本（1.1主流协议） connectionTimeout="20000" #超时时长20秒（单位毫秒） redirectPort="8443" /&gt; #&lt;!--#&lt;Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"#maxThreads="150" SSLEnabled="true" scheme="https" secure="true"#clientAuth="false" sslProtocol="TLS" /&gt;#--&gt;#如果启用8443端口表示TLS加密传输，注释行表示如果用户访问的端口为http则重写到https（但是tomcat一般不直接作为web_server运行，tomcat运行jsp本身就很消耗cpu，一般也不使用ssl）........................ajp协议............................ &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; 范例：Engine组件（容器组件）123456 ~]# vim /etc/tomcat/server.xml &lt;Engine name="Catalina" defaultHost="localhost"&gt;#name="Catalina" Engine名称，多个不可同名#defaultHost 默认的虚拟主机#jvmRoute 创建tomcat集群时用到 范例：Host（Host虚拟主机组件）123456789101112131415161718192021222324 ~]# vim /etc/tomcat/server.xml &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt;#appBase 定义网页文件根目录(可以使用相对路径即相对于tomcat的根，最好使用绝对路径)#unpackWARs 如果用户提供的就是.war格式的文件要不要自动展开#autoDeploy 是否支持自动部署(必要时可以关闭，自己手动部署)自己定义新的Host ~]# vim /etc/tomcat/server.xml 141行 &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;/Host&gt; ~]# mkdir -pv /data/webapps ~]# cp -r /root/testapp /data/webspps/ webapps]# mv testapp ROOT webapps]# ls ROOT #ROOT不可使用链接重启验证 ~]# systemctl restart tomcat ~]# curl www.centos.com:8080 范例：Context组件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 ~]# vim /etc/tomcat/server.xml &lt;Context path="/PATH" docBase="/PATH/TO/SOMEDIR" reloadable=""/&gt;#Context path 指明url#docBase 本地文件系统路径#reloadable 支不支持重新载入 webapps]# pwd /data/webapps webapps]# ls ROOT ~]# mkdir /myweb ~]# cd /myweb/ myweb]# vim testapp-v0.1 &lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello aaaaaaaaaa"); %&gt; &lt;/body&gt; &lt;/html&gt; myweb]# ls testapp-v0.1 ~]# ln -sv /myweb/testapp-v0.1 /myweb/testapp ~]# vim /etc/tomcat/server.xml &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/mymyapp" docBase="/myweb/testapp" reloadable=""/&gt; &lt;/Host&gt; ~]# systemctl restart tomcat测试访问： ~]# curl www.centos.com:8080/mymyapp hello aaaaaaaaaa#Context 类似于http的路径别名 ：alias]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat基础与组件]]></title>
    <url>%2F2019%2F01%2F14%2Ftomcat%E5%9F%BA%E7%A1%80%E4%B8%8E%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[tomcat基础与组件 关于Tomcat Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。由于有了Sun 的参与和支持，最新的Servlet 和JSP 规范总是能在Tomcat 中得到体现，Tomcat 5支持最新的Servlet 2.4 和JSP 2.0 规范。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用）页面的访问请求。实际上Tomcat 部分是Apache 服务器的扩展，但它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。 官网地址：http://tomcat.apache.org/ 部署Tomcat(JDK+Tomcat) Tomcat也是java编程语言编写的，是运行在JVM中的一个进程。它定义为【中间件】，顾名思义，是一个在Java项目与JVM之间的中间容器。 java程序写的网站用Tomcat+JDK来运行，Tomcat是一个中间件，真正起作用的，解析Java脚本的是JDK。JDK（Java development kit）是整个Java的核心，它包含了Java运行环境和一堆Java相关的工具以及Java基础库。最主流的JDK是由sun公司发布的JDK，除此之外，IBM公司也有发布JDK，centos上也可以使用yum安装openjdkJava写的网页后缀名是.jsp。 运行者身份不能为root(user:tomcat)端口默认为8080/tcp 部署方式1：OpenJDK(openjdk 11 + tomcat 7.0)12345678910111213141516171819202122232425262728#rel兼容多个版本JDK并存，可以设置默认的JDK版本# ~]# alternatives --install JDK# ~]# alternatives --config java #设置默认的jdk版本yum安装OpenJDK ~]# yum install java-11-openjdk-devel -y ~]# java -version openjdk version "11.0.1" 2018-10-16 LTS(长期支持版) OpenJDK Runtime Environment 18.9 (build 11.0.1+13-LTS) OpenJDK 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode, sharing) ~]# which java /usr/bin/java ~]# ll /usr/bin/java /usr/bin/java -&gt; /etc/alternatives/java ~]# ll /etc/alternatives/java /etc/alternatives/java -&gt; /usr/lib/jvm/java-11-openjdk-11.0.1.13-3.el7_6.x86_64/bin/java安装tomcat(7.0) tomcat-admin-webapps.noarch #tomcat的web界面的管理的接口 tomcat-docs-webapp.noarch #参考文档 ~]# yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y ~]# systemctl restart tomcat #运行身份为Java虚拟机运行 ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 部署方式2：Oracle JDK(oracle jdk 8u191 + tomcat 8.5)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253oracle jdk 下载地址：https://www.oracle.com/technetwork/java/javase/downloads/index.html ~]# ls jdk-8u191-linux-x64.rpm ~]# rpm -ivh jdk-8u191-linux-x64.rpm 默认安装路径 ~]# ls /usr/java/ default jdk1.8.0_191-amd64 latest ~]# ll /usr/java/ default -&gt; /usr/java/latest #支持设置默认的版本 jdk1.8.0_191-amd64 #同样支持多版本共存 latest -&gt; /usr/java/jdk1.8.0_191-amd64 #支持设置最新的版本 验证是否安装成功（直接运行java程序） 查看版本信息 amd64]# pwd /usr/java/jdk1.8.0_191-amd64 amd64]# /bin/java -version java version "1.8.0_191" Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) 修改PATH变量 ~]# vim /etc/profile.d/java.sh JAVA_HOME=/usr/java/default PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH ~]# source /etc/profile.d/java.sh ~]# printenv tomcat 8.5安装下载路径：http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# tar xvf apache-tomcat-8.5.37.tar.gz -C /usr/local/ ~]# ln -vs /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat （链接形式方便升级） tomcat不可使用root用户运行 ~]# useradd tomcat ~]# chown -R tomcat.tomcat /usr/local/tomcat/ ~]# chown -R tomcat.tomcat /usr/local/tomcat/* ~]# su - tomcat -c "/usr/local/tomcat/bin/catalina.sh start" Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/bin/default Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/u ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 欢迎页： Manager App(应用程序管理器、web界面部署其他应用程序) 与 Host Manager 部署的管理程序 Tomcat基本框架及相关配置 如上图，Tomcat可以按功能划分许多不同的组件，这些组件都可以通过/conf/server.xml(部署描述符文件)文件中可定义和配置，包括Server, Service, Connector, Engine, Cluster, Host, Alias, Context, Realm, Valve, Manager, Listener, Resources, ResourceEnvRef, WatchedResource, Store, Transaction, Channel, Membership, Transport, Member, ClusterListener等，一般可分为以下四类： 1、Server顶级组件：位于配置层次的顶级，并且彼此间有着严格的对应关系，有Server组件、Service组件； 2、Connector连接器：连接客户端（可以是浏览器或Web服务器）请求至Servlet容器，只有Connector组件（Connector才是一个具体特定、真正的程序，可以被单独部署和管理、启动停止暂停等。） 3、Engine容器：表示其功能是处理传入请求的组件，并创建相应的响应。如Engine处理对一个Service的所有请求，Host处理对特定虚拟主机的所有请求，并且Context处理对特定web应用的所有请求（容器类容器组件，可以容纳JSP应用程序的顶级组件）； 4、Context被嵌套的组件：位于一个容器当中，但不能包含其它组件；一些组件可以嵌套在任何Container中，而另一些只能嵌套在Context中。 server.xml默认配置 Tomcat： 使用java语言编写： tomcat的配置文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； log4j 12345678910111213141516171819Tomcat的核心组件：server.xml &lt;Server&gt; &lt;Service&gt; &lt;connector/&gt; &lt;connector/&gt; ... &lt;Engine&gt; &lt;Host&gt; &lt;Context/&gt; &lt;Context/&gt; ... &lt;/Host&gt; &lt;Host&gt; ... &lt;/Host&gt; ... &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt; 更多Server配置信息请参考：《Apache Tomcat 8 Configuration Reference》 The Server Component基本组件 1、Server组件 erver（服务器）表示Tomcat的一个实例，因此，它必须是/conf / server.xml配置文件中的单个最外层元素，它的属性表示servlet容器的整体特性。通常一个JVM只能包含一个Tomcat实例。 默认配置表示监听在8005端口以接收shutdown命令，默认仅允许通过本机访问。 2、Service组件 Service（服务）主要用于关联一个Engine和与此Engine相关的Connector，每个Connector通过一个特定的端口和协议接收请求，并将其转发至关联的Engine进行处理。 因此，Service可以包含一个Engine、以有一个或多个Connector；而一个Server可以包含多个Service组件，但通常情下只为一个Server指派一个Service。通常需要给Service命名，可以方便管理员在日志文件中识别不同Service产生的日志。 如默认配置中server只包含一个名为”Catalina”的service，而service里包含两个Connector，其中一个监听8080端口接收HTTP请求，另一个监听8009端口接收AJP协议的请求。 3、Connector组件 如上面所述，Connector（连接器）通过一个特定的端口接收特定协议的客户端请求，并将其转发至关联的Engine进行处理。一个Engine可以配置多个连接器，但这些连接器必须使用不同的端口。 定义连接器可以使用多种属性，有些属性也只适用于某特定的连接器类型。一般说来，连接器类型可以分为两种： （1）、HTTP连接器 HTTP连接器元素表示支持HTTP / 1.1协议的连接器组件，它能使Tomcat能够作为独立的Web服务器。此组件的特定实例侦听服务器上特定TCP端口号上的连接，每个转发到相关联的Engine以执行请求处理并创建响应。 默认配置文件，定义了一个连接器为protocol=”HTTP/1.1” 表示的是使用自动切换机制来选择基于Java NIOConnector或基于APR /Native Connector（需要设置），也可以手动指定 2）、AJP 1.3连接器 AJP连接器元素表示通过AJP(Apache JServ Protocol)协议与Web连接器通信的连接器组件。 AJP协议是基于二进制的格式在Web服务器和Tomcat之间传输数据，这比HTTPP获得更好的效率，但比较复杂不通用。 通常用于将Tomcat集成到现有Apache服务器中，并且希望Apache处理Web应用程序中包含的静态内容或SSL连接处理的情况，即Apache服务器作为代理服务器。Apache与Tomcat结合可以由mod_jk或mod_proxy模块来实现，但它们的使用范围不同：mod_jk支持apache/1.3,apache/2.0，mod_proxy支持apache/2.2+。 默认配置文件中定义了一个监听8009端口的AJP连接器，其实官方文档说明这种连接器不久后不再支持，一般用得不多，就不再多介绍了。 定义连接器时可以配置的属性非常多，但通常定义HTTP连接器时必须定义的属性只有”port”，定义AJP连接器时必须定义的属性只有”protocol”，因为默认的协议为HTTP。以下为常用属性的说明（更多请参考前面给出的文档）： 1、address：指定连接器监听的地址，默认为所有地址，即0.0.0.0； 2、maxThreads：支持的最大并发连接数，默认为200； 3、port：监听的端口，默认为0； 4、protocol：连接器使用的协议，默认为HTTP/1.1，定义AJP协议时通常为AJP/1.3； 5、redirectPort：如果某连接器支持的协议是HTTP，当接收客户端发来的HTTPS请求时，则转发至此属性定义的端口； 6、connectionTimeout：等待客户端发送请求的超时时间，单位为毫秒，默认为60000，即1分钟； 7、enableLookups：是否通过request.getRemoteHost()进行DNS查询以获取客户端的主机名；默认为true； 8、acceptCount：设置等待队列的最大长度；通常在tomcat所有处理线程均处于繁忙状态时，新发来的请求将被放置于等待队列中； 4、Engine组件 Engine（引擎）表示与特定Service相关联的整个请求处理机制，即Servlet容器引擎。它接收和处理来自一个或多个连接器的所有请求，并检查每一个请求的HTTP首部信息以辨别此请求应该发往哪个Host或Context，并将完成的响应返回到连接器，以便最终传输回客户端。 一个Engine元素必须嵌套在Service元素内，它可以包含多个host组件，还可以包含Realm、Listener和Valve等子容器。 常用的属性定义： 1、defaultHost：Tomcat支持基于FQDN的虚拟主机，这些虚拟主机可以通过在Engine容器中定义多个不同的Host组件来实现；但如果此引擎的连接器收到一个发往非非明确定义虚拟主机的请求时则需要将此请求发往一个默认的虚拟主机进行处理，因此，在Engine中定义的多个虚拟主机的主机名称中至少要有一个跟defaultHost定义的主机名称同名。 2、name：Engine组件的名称，用于日志和错误信息记录时区别不同的引擎。 如默认配置中定义了一个名为”Catalina”的Engine，而Engine里包含一个Hots，并被配置为默认的虚拟主机。 5、Host组件 Host（虚拟主机）类似于Apache中的虚拟主机，但在Tomcat中只支持基于FQDN的”虚拟主机”。Host位于Engine容器中用于接收请求并进行相应处理，它是服务器（例如”www.mycompany.com&quot;）的网络名称与运行Tomcat的特定服务器的关联。 客户端通常使用主机名来标识他们希望连接的服务器，但要使客户端能够使用其网络名称连接到Tomcat服务器，此名称必须在管理所属的Internet域的域名服务（DNS）服务器中注册。此主机名也包含在HTTP请求标头中，Tomcat从HTTP头中提取主机名，并查找具有匹配名称的主机；如果未找到匹配项，请求将路由到默认主机。 一个Engine至少要包含一个Host组件，而在Host元素内可以嵌入与此虚拟主机关联的Web应用程序的Context等元素。 常用属性说明： 1、name：此Host的FQDN虚拟主机名称； 2、appBase：此Host的webapps目录，即存放非归档的web应用程序的目录或归档后的WAR文件的目录路径；可以使用基于$CATALINA_HOME的相对路径； 3、autoDeploy：在Tomcat处于运行状态时放置于appBase目录中的应用程序文件是否自动进行deploy；默认为true； 4、unpackWars：在启用此webapps时是否对WAR格式的归档文件先进行展开；默认为true。 如默认配置中定义了一个主机名为”localhost”的Host，而webapps目录为$ CATALINA_BASE相对的”webapps”，即前面说到的默认目录，也可用绝对路径来配置其他目录。 6、Context组件 Context（上下文）表示在特定虚拟主机中运行的Web应用程序，一个Context对应一个Web应用程序，而里面的Wrapper可以理解为一个个Servlet程序。 Context需要根据其定义的上下文路径（path）匹配请求URI的最长前缀（除主机名外）来选择。一旦选择，可以由docBase来找到该上下文将对应的web应用程序部署目录，由目录中web.xml定义的servlet映射选择一个合适的servlet来处理传入的请求。 一个Host可以有多个Context，通常不建议定义在server.xml文件中，而是每一个context定义使用一个单独的XML文件进行，其文件的目录为$CATALINA_HOME/conf/&lt;engine name&gt;/&lt;host name&gt; 可以看到server.xml中默认没有定义Context，但存在/conf/context.xml，在前面说Tomcat配置文件时曾介绍过，context.xml为部署与此Tomcat实例上所有的web应用程序提供的默认配置文件， 通过它可以找到默认的和各web应用程序提供部署描述符文件web.xml，/conf/web.xml定义了Tomcat提供的默认Servlet处理程序，主要用来处理静态资源请求；而各webapp的web.xml可以定义其他的动态请求url映射到不同Servlet程序处理。 常用的属性定义有： 1、docBase：相应的Web应用程序的存放位置；也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径；切记，docBase的路径名不能与相应的Host中appBase中定义的路径名有包含关系，比如，如果appBase为deploy，而docBase绝不能为deploy-bbs类的名字； 2、path：相对于Web服务器根路径而言的URI；如果为空””，则表示为此webapp的根路径；如果context定义在一个单独的xml文件中，此属性不需要定义； 3、reloadable：是否允许重新加载此context相关的Web应用程序的类；默认为false； 7、Realm组件 Realm（领域）表示分配给这些用户的用户名，密码和角色（类似于Unix组）的”数据库”。一个Realm（领域）表示一个安全上下文，它是一个授权访问某个给定Context的用户列表和某用户所允许切换的角色相关定义的列表。 Catalina容器（Engine，Host或Context）可以包含不超过一个Realm元素（但自身可以嵌套）。此外，与引擎或主机关联的领域由低级容器自动继承，除非下级容器显式定义了自己的领域。如果没有为引擎配置领域，将自动为引擎配置空领域的实例。 定义Realm时惟一必须要提供的属性是classname，它是Realm的多个不同实现，用于表示此Realm认证的用户及角色等认证信息的存放位置，Tomcat中实现了多种不同的Realm，如下： UserDatabaseRealm：基于UserDatabase文件(通常是tomcat-user.xml)实现用户认证，它实现是一个完全可更新和持久有效的MemoryRealm，因此能够跟标准的MemoryRealm兼容；它通过JNDI实现； LockOutRealm：提供锁定功能，以便在给定时间段内出现过多的失败认证尝试时提供用户锁定机制； JAASRealm：基于Java Authintication and Authorization Service实现用户认证； JDBCRealm：通过JDBC访问某关系型数据库表实现用户认证； JNDIRealm：基于JNDI使用目录服务实现认证信息的获取； MemoryRealm：查找tomcat-user.xml文件实现用户信息的获取。 可以看到默认配置文件中定义了一个LockOutRealm并嵌套一个UserDatabaseRealm的Realm来通过tomcat-user.xml文件实现用户认证。 8、Valve组件 Valve（阀门）类似于过滤器，用来拦截请求并在将其转至目标之前进行某种处理操作；它可以工作于Engine和Host/Context之间、Host和Context之间以及Context和Web应用程序的某资源之间。 Valve常被用来记录客户端请求、客户端IP地址和服务器等信息，这种处理技术通常被称作请求转储(request dumping)。请求转储valve记录请求客户端请求数据包中的HTTP首部信息和cookie信息文件中，响应转储valve则记录响应数据包首部信息和cookie信息至文件中。 一个容器内可以建立多个Valve，而且Valve定义的次序也决定了它们生效的次序。不同类型的Value具有不同的处理能力，Tomcat中实现了多种不同的Valve： AccessLogValve：访问日志Valve ExtendedAccessValve：扩展功能的访问日志Valve RequestDumperValve：请求转储Valve； RemoteAddrValve：基于远程地址的访问控制； RemoteHostValve：基于远程主机名称的访问控制； SemaphoreValve：用于控制Tomcat主机上任何容器上的并发访问数量； ReplicationValve：专用于Tomcat集群架构中，可以在某个请求的session信息发生更改时触发session数据在各节点间进行复制； SingleSignOn：将两个或多个需要对用户进行认证webapp在认证用户时连接在一起，即一次认证即可访问所有连接在一起的webapp； ClusterSingleSingOn：对SingleSignOn的扩展，专用于Tomcat集群当中，需要结合ClusterSingleSignOnListener进行工作。 通过属性className定义相关的java实现的类名来选择Value。如默认配置文件中定义了一个AccessLogValve的Value来记录访问日志到文件中。 其他组件 1、Logger 日志记录器(Logger)：用于记录组件内部的状态信息，可被用于除Context之外的任何容器中。日志记录的功能可被继承，因此，一个引擎级别的Logger将会记录引擎内部所有组件相关的信息，除非某内部组件定义了自己的Logger组件（前面介绍的AccessLogValve使用自包含的逻辑来写它的日志文件，以获得更好的效率）。 2、Listener Listener用于创建和配置LifecycleListener对象，而LifecycleListener通常被开发人员用来创建和删除容器。 3、Loader Java的动态装载功能是其语言功能强大表现之一，Servlet容器使用此功能在运行时动态装载servlet和它们所依赖的类。Loader可以用于Context中控制java类的加载，即WebApp类加载器。 4、Resources 经常用于实现在Context中指定需要装载的但不在Tomcat本地磁盘上的应用资源，如Java类，HTML页面，JSP文件等。 5、GlobalNamingResources 应用于整个服务器的JNDI映射，此可以避免每个Web应用程序都需要在各自的web.xml创建，这在web应用程序以WAR的形式存在时尤为有用。它通常可以包含三个子元素：Environment、Resource和ResourceEnvRef。 6、WatchedResource WatchedResource可以用于Context中监视指定的webapp程序文件的改变，并且能够在监视到文件内容发生改变时重新装载此文件。 7、Manager Manger对象用于实现HTTP会话管理的功能，Tomcat中有5种Manger的实现： 1)StandardManager Tomcat6的默认会话管理器，用于非集群环境中对单个处于运行状态的Tomcat实例会话进行管理。当Tomcat关闭时，这些会话相关的数据会被写入磁盘上的一个名叫SESSION.ser的文件，并在Tomcat下次启动时读取此文件。 2) PersistentManager 当一个会话长时间处于空闲状态时会被写入到swap会话对象，这对于内存资源比较吃紧的应用环境来说比较有用。 3)DeltaManager 属于ClusterManager，用于Tomcat集群的会话管理器，它通过将改变了会话数据同步给集群中的其它节点实现会话复制。这种实现会将所有会话的改变同步给集群中的每一个节点，也是在集群环境中用得最多的一种实现方式。 但集群节点较多时，会消耗大量的网络资源，一般适用于3、4个节点的集群。 4)BackupManager 属于ClusterManager，用于Tomcat集群的会话管理器，与DeltaManager不同的是，某节点会话的改变只会同步给集群中的另一个而非所有节点。 5)SimpleTcpReplicationManager Tomcat4时用到的版本，过于老旧了。 8、Stores PersistentManager必须包含一个Store元素以指定将会话数据存储至何处。这通常有两种实现方式：FileStore和JDBCStore。 9、Cluster 专用于配置Tomcat集群的元素，可用于Engine和Host容器中。在用于Engine容器中时，Engine中的所有Host均支持集群功能。在Cluster元素中，需要直接定义一个Manager元素，这个Manager元素有一个其值为org.apache.catalina.ha.session.DeltaManager或org.apache.catalina.ha.session.BackupManager的className属性。同时，Cluster中还需要分别定义一个Channel和ClusterListener元素。 10、Channel 用于Cluster中给集群中同一组中的节点定义通信”信道”。Channel中需要至少定义Membership、Receiver和Sender三个元素，此外还有一个可选元素Interceptor。 11、Membership 用于Channel中配置同一通信信道上节点集群组中的成员情况，即监控加入当前集群组中的节点并在各节点间传递心跳信息，而且可以在接收不到某成员的心跳信息时将其从集群节点中移除。Tomcat6中Membership的实现是org.apache.catalina.tribes.membership.McastService。 12、Sender 用于Channel中配置”复制信息”的发送器，实现发送需要同步给其它节点的数据至集群中的其它节点。发送器不需要属性的定义，但可以在其内部定义一个Transport元素。 13、Transport 用于Sender内部，配置数据如何发送至集群中的其它节点。Tomcat有两种Transport的实现： 1) PooledMultiSender 基于Java阻塞式IO，可以将一次将多个信息并发发送至其它节点，但一次只能传送给一个节点。 2)PooledParallelSener 基于Java非阻塞式IO，即NIO，可以一次发送多个信息至一个或多个节点。 14、Receiver 用于Channel定义某节点如何从其它节点的Sender接收复制数据，Tomcat中实现的接收方式有两种BioReceiver和NioReceiver。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat之java基础]]></title>
    <url>%2F2019%2F01%2F14%2Ftomcat%E4%B9%8Bjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[tomcat之java基础 java基础什么是java java所涉及到的相关概念如下图。总体来说就是java语言、java API、jvm等构成。 jvm：java虚拟机，java的代码都是运行在jvm上，这是java语言跨平台的保证，针对不同的系统jvm也不同，这就实现了同一份代码，通过不同jvm的运行可以让对应的操作系统识别。 JRE（java running environment）：就是提供给java代码一个运行环境，java代码运行在jvm上，但是开发程序的时候往往除本身代码外会有引入的api，当程序运行时，jvm会加载相关的类，所以一个能保证代码能正常运行的环境是jvm+api（java se api）。 JDK（java development kit）：java开发环境，JDK=java语言+开发相关的API+JRE。开发环境除了要正常运行程序外（JRE环境），还需要进行开发相关的操作如打包、编译等这类工具。 JAVA API 平时API听多了，但是或许并不了解，这里做下简要解释。一个操作系统会提供很多API接口让程序员使用计算机的硬件资源，这是系统API，这里涉及到一个POSXI的概念，POSIX表示可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ），POSIX标准定义了操作系统应该为应用程序提供的接口标准，为一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行。因为遵循POSXI标准的操作系统，所定义的操作系统API都相同，所以开发程序的时候，使用的API在名称参数上都可以兼容，所以换一个系统，不需要重新编写代码。POSIX是针对API的标准，即针对API的函数名，返回值，参数类型等。POSIX兼容也就指定这些接口函数兼容，但是并不管API具体如何实现。 Java api：就是用java语言编写的功能代码，为访问主机上的本地资源，Java api调用了本地方法（操作系统API），直接通过内核请求调用相关内核函数。而后将功能相似的这些代码归类，组成java api类库。 以linux编程为例：我们编写linux用户程序的时候，是不能直接调用内核里面的函数的，内核里面的函数位于进程虚拟地址空间里面的内核空间，用户空间函数及函数库都处于进程虚拟地址空间里面的用户空间，用户空间调用内核空间的函数只有一个通道，这个通道就是系统调用指令，所以通常要调用glibc等库的接口函数（C语言的API），glibc也是用户空间的，但glibc自己实现了调用特殊的宏汇编系统调用指令进行cpu运行状态的切换，把进程从用户空间切换到内核空间。 JVM 内存结构 java中通过多线程机制使得多个任务同时执行处理，所有的线程共享JVM内存区域main memory，而每个线程又单独的有自己的工作内存，当线程与内存区域进行交互时，数据从主存拷贝到工作内存，进而交由线程处理。 程序计数器（Program Counter Register）：由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器 Java 虚拟机栈（Java Virtual Machine Stacks）：每个放在被执行的时候都会同时创建一个栈帧用于存当前线程中局部基本类型的变量（java中定义的八种基本类型：boolean、char、byte、short、int、long、float、double），操作数栈，动态链接，方法出口等信息。虚拟内存栈就是我们经常讲的“栈”。其中局部变量表所需内存是在编译期完成分配。 方法区（Method Area）：与Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。它有一个别名叫做Non-Heap（非堆），目的应该是与Java 堆区分开来。也称为持久代（Permanet Generation）。 Java 堆（Java Heap）：是Java 虚拟机所管理的内存中最大的一块。它是JVM用来存储对象实例以及数组值的区域，可以认为Java中所有通过new创建的对象的内存都在此分配。Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”（Garbage Collected Heap）。 本地方法栈：与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行Java方法服务，而本地方法栈为虚拟机使用Native方法（系统接口）服务。 WEB CGI 早期的web只能实现静态的页面，如果我们需要一种效果，就是我们向服务器请求时想让web服务器现场处理并将处理过的数据结果返回给我们，该如何实现呢。 第一种方式：开发一个程序，接收用户请求，解析请求内容，查找相关数据进行计算处理，将处理结果封装成响应报文返回给用户。 第二种方式：既然已经存在web服务器了，那没必要重新开发程序来处理HTTP协议的东西，只需要开发另一种方式，让计算机能够将处理后的数据，发送给web服务器，服务器再返回给用户 于是CGI协议就产生了，web服务器接收到请求，可是它自身无法解决请求之中需要经过计算处理的内容，那样服务器就去找帮手，找个能处理这个内容的其他程序，这个其他程序通过一种方式（CGI）和服务器进行交流，处理好之后将结果送给web服务器。 早期使用的web服务器扩展机制CGI，它允许用户调用web服务器上的CGI程序。CGI即是公共网关接口，大多数的CGI程序使用Perl来编写，也使用C、Pyhton或者PHP来编写。用户通过单机某个链接或者直接在浏览器的地址栏中输入Url来访问CGI程序，web服务接收到请求后，发现这个请求是给CGI程序的，于是就启动并运行这个CGI程序，对用户请求进行处理，CGI程序解析请求中的CGI数据，处理数据，并产生了一个响应（通常是HTML页面）。这个响应被返回给Web服务器，Web服务器包装这个响应（例如添加消息报头），以HTTP响应的形式发送给web浏览器 什么是CGI 如上文所述，HTTP服务器是一个很简单的东西，并不负责动态页面的构建，只能转发静态页面，事物总是不断发展，网站也越来越复杂，所以出现动态技术。同时Apache也说，能支持perl，生成动态页面，这个支持perl，其实是Apache越位了，做了一件额外的事情。 既然HTTP Server自己不能做，外包给别人但是要与第三者做个约定，我给你什么，然后你给我什么，就是我把请求参数发给你，然后我接收你的处理结果给客户端，那这个约定就是Common Gatway Interface(CGI) CGI全称是“通用网关接口”，是HTTP服务器与你的或其他机器上的程序进行“交谈”的一种工具，其程序必须运行在网络服务器上，是一种根据请求信息动态产生的响应内容的接口协议，CGI可以用任何一种语言编写，只要这种语言具有标准输入，输出和环境变量。如php，perl,tcl等。 通过CGI,HTTP sERVER可以将根据请求不同启动不同的外部程序，并将请求内容转发给该程序，在程序执行结束后，将执行结果作为回应返回给客户端。也就是说，对于每个请求，都要产生一个新的进程进行处理，因为每个进程都会占有很多服务器的资源和时间，这就导致服务器无法同时处理很多的并发请求，另外CGI程序都是与操作系统平台相关的，虽然在互联网爆发的初期，CGI为开发互联网应用做出了很大的贡献，但是随着技术的发展，开始逐渐衰落。所以，CGI的定义是：外部应用程序与HTTP服务器之间的接口协议。 Serlvet与Servlet容器 当java想实现CGI这样的功能时，因为java代码运行在jvm中，而jvm是没有办法直接跟web服务器进行交流的，所以Servlet就出现了。 当初在Apache Server 开发时CGI这样的功能时还未出现Serlet的概念，所以Apache不能内置支持Servlet。实际上，除了Apache，其他许多HTTP Server软件都不能直接支持Servlet。为了支持Servlet，通常要单独开发程序，这种程序一般称为服务小程序的容器（servlet container） ，有时也叫做服务器小程序引擎（servlet engine）。它的web服务器或者应用程序服务器的一部分，用于在发送的请求和响应之上提供的网络服务，解码基于MMIE的请求，格式化基于MIME的响应，它在Servlet的生命周期内包括和管理Servlet，是一个实时运行的外壳程序，运行时由wab服务器软件处理一般的请求，并把Servlet调用传递给“容器”来处理。 既然java作为编程语言，那么我们可以开发自己想要的功能，我们开发一个程序，使之能够与web服务器进行交互。所以java写了一个servlet类，这个类可以实例化为servlet程序，这个程序可以接受来自web服务器的请求并处理。那问题又来了， 如果多个web请求过来，仅仅一个Servlet程序是不够的，而且请求来了如何对java代码编译呢，于是乎就在外层增加一个管理功能的容器（这里纯属个人臆想），所以如果把Servlet类库完整实现了，那就是Servlet容器。这个容器的作用是什么呢？ 1、利用容器提供的方法，你能轻松的让servlet与web服务器对话，而不用自己建立serversocket、监听某个端口、创建流等等。容器知道自己与web服务器之间的协议，所以你的servlet不用担心web服务器（如Apache）和你自己的web代码之间的API，只需要考虑如何在servlet中实现业务逻辑（比如从数据库或者磁盘中获取数据并处理）。 2、多线程支持：容器会自动为它所接收的每个servlet请求创建一个新的java线程。针对用户的请求，如果servlet已经运行完相应的http服务方法，这个线程就会结束。 3、生命周期管理：servlet容器控制着servlet的生与死，它负责加载类、实例化和初始化servlet，调用servlet方法，以及使servlet实例被垃圾回收。 Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序（服务器响应）之间的中间层，位于Web 服务器内部的服务器端的Java应用程序，与传统的从命令行启动的Java应用程序不同，Servlet由Web服务器进行加载，该Web服务器必须包含支持Servlet的Java虚拟机。客户端发送请求至服务器；服务器启动并调用Servlet，Servlet根据客户端请求生成响应内容并将其传给服务器；服务器将响应返回客户端。 servlet就是一个组件，需要部署到servlet容器才能运行。servlet容器为servlet提供网络相关的服务：即servlet容器为将请求中的相关数据解析出来，并且封装到请求对象(request)里面，这样一来，servlet就不需要理解http协议(只需要调用request对象的相关方法即可获取数)，另外，当servlet处理请求完毕，只需要将结果写到响应对象(response)里面,servlet容器会自动将response对象中的数据打包，发送给浏览器。 java servlet 简单代码实现 Java Servlet与CGI (Common Gateway Interface 公共网关接口)的比较: 与传统的CGI和许多其他类似CGI的技术相比，Java Servlet具有更高的效率，更容易使用，功能更强大，具有更好的可移植性，更节省投资。在未来的技术发展过程中，Servlet有可能彻底取代CGI。 在传统的CGI中，每个请求都要启动一个新的进程，如果CGI程序本身的执行时间较短，启动进程所需要的开销很可能反而超过实际执行时间。而在Servlet中，每个请求由一个轻量级的Java线程处理(而不是重量级的操作系统进程)。 在传统CGI中，如果有N个并发的对同一CGI程序的请求，则该CGI程序的代码在内存中重复装载了N次；而对于Servlet，处理请求的是N个线程，只需要一份Servlet类代码。在性能优化方面，Servlet也比CGI有着更多的选择。 JSP 使用Servlet可以实现java程序和web服务器的交互，但是Servlet和CGI一样存在一个问题，Servlet程序在返回结果的时候必须连带HTML标签一起返回，所以负责格式显示的HTML代码和负责数据产生的Java代码混在一起了，程序员和页面编辑人员无法各自实现自己的工作，就要求java程序员必须要了解HTML显示效果。所以就有了JSP技术产生，有了JSP一个web请求的执行流程如下。 其实JSP也是java的一个类库而已，要想写出的JSP代码能够被识别，这时候就需要一个JSP容器负责来解析。JSP代码最终会被编译成Servlet，然后再由Servlet处理请求。一个JSP页面包含了JSP规范的java代码（元素）和HTML标签（数据模板），元素则交给JSP容器处理，模板数据直接返回给客户端。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mariadb实现二进制安装]]></title>
    <url>%2F2019%2F01%2F13%2Fmariadb%E5%AE%9E%E7%8E%B0%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[mariadb实现二进制安装 通用二进制格式安装过程范例：二进制格式安装的mysql版本为：mysql-10.2 第一步：将二进制编译完的文件传进linux中，解压缩、创建软连接 [root@centos7 ~]# ls mariadb-10.2.19-linux-x86_64.tar.gz [root@centos7 ~]# tar xfv mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local [root@centos7 ~]# ls /usr/local bin games lib libexec sbin src etc include lib64 mariadb-10.2.19-linux-x86_64 share 创建软连接，方便下次升级（链接程序所在路径，因为源码编译时文档中指定程序路径放置在/usr/local/mysql） [root@centos7 ~]# ln -s /usr/local/mariadb-10.2.19-linux-x86_64/ /usr/local/mysql [root@centos7 ~]# ll /usr/local/mysql lrwxrwxrwx. 1 root root 40 Nov 27 17:01 /usr/local/mysql -&gt; /usr/local/mariadb-10.2.19-linux-x86_64/ 第二步：修改程序目录的属性 [root@centos7 ~]# chown -R root:root /usr/local/mysql/ [root@centos7 ~]# ll /usr/local/mysql/ total 180 drwxrwxr-x. 2 root root 4096 Sep 23 10:13 bin 程序 -rw-r--r--. 1 root root 17987 Nov 13 00:32 COPYING -rw-r--r--. 1 root root 86263 Nov 13 00:32 COPYING.thirdparty -rw-r--r--. 1 root root 2354 Nov 13 00:32 CREDITS drwxrwxr-x. 3 root root 18 Nov 13 07:37 data -rw-r--r--. 1 root root 8245 Nov 13 00:32 EXCEPTIONS-CLIENT drwxrwxr-x. 3 root root 19 Nov 13 07:37 include -rw-r--r--. 1 root root 8694 Nov 13 00:32 INSTALL-BINARY drwxrwxr-x. 5 root root 4096 Sep 23 10:14 lib drwxrwxr-x. 4 root root 30 Nov 13 07:37 man drwxrwxr-x. 11 root root 4096 Nov 13 07:37 mysql-test -rw-r--r--. 1 root root 2469 Nov 13 00:32 README.md -rw-r--r--. 1 root root 19510 Nov 13 00:32 README-wsrep drwxrwxr-x. 2 root root 30 Nov 13 07:37 scripts drwxrwxr-x. 32 root root 4096 Nov 13 07:37 share drwxrwxr-x. 4 root root 4096 Nov 13 07:37 sql-bench drwxrwxr-x. 3 root root 275 Nov 13 07:37 support-files 第三步：创建程序用户 [root@centos7 ~]# useradd -r -s /sbin/nologin -d /data/mysql -c "mariadb user" mysql [root@centos7 ~]# getent passwd mysql mysql:x:989:983:mariadb user:/data/mysql:/sbin/nologin 第四步：创建数据库目录：存放数据库的数据 [root@centos7 ~]# ls -ld /data/mysql ls: cannot access /data/mysql: No such file or directory [root@centos7 ~]# mkdir /data/mysql [root@centos7 ~]# install -d /data/mysql -o root -g mysql [root@centos7 ~]# ls -ld /data/mysql drwxr-xr-x. 2 root mysql 6 Nov 27 17:15 /data/mysql 第四步：生成系统数据库 [root@centos7 ~]# ls /usr/local/mysql/ bin include README-wsrep COPYING INSTALL-BINARY scripts COPYING.thirdparty lib share CREDITS man sql-bench data mysql-test support-files EXCEPTIONS-CLIENT README.md 安装数据库的脚本：生成系统数据库 [root@centos7 ~]# ls /usr/local/mysql/scripts/ mysql_install_db [root@centos7 mysql]# pwd /usr/local/mysql [root@centos7 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql 确定是否生成了数据库 [root@centos7 mysql]# ls /data/mysql/ aria_log.00000001 ibdata1 mysql aria_log_control ib_logfile0 performance_schema ib_buffer_pool ib_logfile1 test 第五步：准备数据库的配置文件 [root@centos7 ~]# mkdir /etc/mysql [root@centos7 ~]# ls /usr/local/mysql/support-files/ binary-configure my-medium.cnf policy magic my-small.cnf wsrep.cnf my-huge.cnf mysqld_multi.server wsrep_notify my-innodb-heavy-4G.cnf mysql-log-rotate my-large.cnf mysql.server [root@centos7 ~]# cd /usr/local/mysql/support-files/ [root@centos7 support-files]# cp my-huge.cnf /etc/mysql/my.cnf 第六步：修改配置文件，根据自己定义的数据路径进行修改 [root@centos7 ~]# vim /etc/mysql/my.cnf [mysqld] datadir=/data/mysql port = 3306 socket = /tmp/mysql.sock 第七步：准备程序服务的启动脚本 [root@centos7 ~]# ls /usr/local/mysql/support-files/ mysql.server [root@centos7 ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/ 可以改名，方便启动 [root@centos7 ~]# cd /etc/init.d/ [root@centos7 init.d]# ls functions mysql.server netconsole network README [root@centos7 init.d]# mv mysql.server mysqld 第八步：准备启动 [root@centos7 ~]# chkconfig --add mysqld [root@centos7 ~]# chkconfig --list mysqld 0:off 1:off 2:on 3:on 4:on 5:on 6:off netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:off network 0:off 1:off 2:on 3:on 4:on 5:on 6:off 启动 [root@centos7 ~]# service mysqld restart Restarting mysqld (via systemctl): [ OK ] 准备PATH变量 [root@centos7 ~]# echo 'PATH=/usr/local/mysql/bin:$PATH' &gt; /etc/profile.d/mysql.sh [root@centos7 ~]# source /etc/profile.d/mysql.sh 连接测试 [root@centos7 ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 10 Server version: 10.2.19-MariaDB-log MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\h' for help. Type '\c' to clear the current input statement. MariaDB [(none)]&gt; exit 查看数据库路径 方法1 MariaDB [(none)]&gt; show variables like 'datadir' -&gt; ; +---------------+--------------+ | Variable_name | Value | +---------------+--------------+ | datadir | /data/mysql/ | +---------------+--------------+ 1 row in set (0.01 sec) 方法2 MariaDB [(none)]&gt; select @@datadir -&gt; ; +--------------+ | @@datadir | +--------------+ | /data/mysql/ | +--------------+ 1 row in set (0.00 sec) 执行初始化安装脚本 [root@centos7 ~]# ls /usr/local/mysql/bin/ mysql_secure_installation [root@centos7 ~]# mysql_secure_installation]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mairadb实现源码安装]]></title>
    <url>%2F2019%2F01%2F13%2Fmairadb%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[mairadb实现源码安装 mairadb实现源码安装10.2.19123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112第一步：安装相关的依赖包[root@centos7 yum.repos.d]# yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel第二步：创建对应的账号 （数据库存放数据的路径）[root@centos7 yum.repos.d]# useradd -r -s /sbin/nologin -d /data/mysql/ mysql 第三步：创建数据对应的数据库路径[root@centos7 ~]# mkdir /data/mysql[root@centos7 ~]# chown mysql:mysql /data/mysql第四步：下载源码解压[root@centos7 ~]# lsmariadb-10.2.19.tar.gz[root@centos7 ~]# tar xvf mariadb-10.2.19.tar.gz [root@centos7 ~]# lsmariadb-10.2.19 mariadb-10.2.19.tar.gz[root@centos7 ~]# du -sh mariadb-10.2.19506M mariadb-10.2.19第五步：cmack编译[root@centos7 ~]# cd mariadb-10.2.19/[root@centos7 mariadb-10.2.19]# cmake . \-DCMAKE_INSTALL_PREFIX=/app/mysql \-DMYSQL_DATADIR=/data/mysql/ \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITHOUT_MROONGA_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DENABLED_LOCAL_INFILE=1 \-DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci 多线程编译[root@centos7 ~]# make -j 4 &amp;&amp; make install[root@centos7 mariadb-10.2.19]# ls /app/mysql/bin EXCEPTIONS-CLIENT README.mdCOPYING include README-wsrepCOPYING.thirdparty INSTALL-BINARY scriptsCREDITS lib sharedata man sql-benchdocs mysql-test support-files第五步：生成数据库文件[root@centos7 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql[root@centos7 mysql]# ls -l /data/mysql/total 110620-rw-rw----. 1 mysql mysql 16384 Nov 27 21:02 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Nov 27 21:02 aria_log_control-rw-rw----. 1 mysql mysql 938 Nov 27 21:02 ib_buffer_pool-rw-rw----. 1 mysql mysql 12582912 Nov 27 21:02 ibdata1-rw-rw----. 1 mysql mysql 50331648 Nov 27 21:02 ib_logfile0-rw-rw----. 1 mysql mysql 50331648 Nov 27 21:02 ib_logfile1drwx------. 2 mysql root 4096 Nov 27 21:02 mysqldrwx------. 2 mysql mysql 20 Nov 27 21:02 performance_schemadrwx------. 2 mysql root 6 Nov 27 21:02 test第六步：设置PATH变量[root@centos7 mysql]# echo 'PATH=/app/mysql/bin:$PATH' &gt; /etc/profile.d/mysql.sh[root@centos7 mysql]# source /etc/profile.d/mysql.sh 第七步：拷贝模板配置文件[root@centos7 mysql]# pwd/app/mysql[root@centos7 mysql]# cp support-files/my-huge.cnf /etc/my.cnfcp: overwrite ‘/etc/my.cnf’? y第八步：设置启动脚本[root@centos7 ~]# cd /app/mysql/support-files/[root@centos7 support-files]# lsbinary-configure my-medium.cnf policymagic my-small.cnf wsrep.cnfmy-huge.cnf mysqld_multi.server wsrep_notifymy-innodb-heavy-4G.cnf mysql-log-rotatemy-large.cnf mysql.server[root@centos7 support-files]# cp mysql.server /etc/init.d/mysqld[root@centos7 ~]# chkconfig --add mysqld[root@centos7 ~]# chkconfig --listNote: This output shows SysV services only and does not include native systemd services. SysV configuration data might be overridden by native systemd configuration. If you want to list systemd services use 'systemctl list-unit-files'. To see services enabled on particular target use 'systemctl list-dependencies [target]'.mysqld 0:off 1:off 2:on 3:on 4:on 5:on 6:off启动[root@centos7 ~]# service mysqld restartRestarting mysqld (via systemctl): [ OK ][root@centos7 ~]# ss -ntlLISTEN 0 80 :::3306 :::* 安全脚本mysql_secure_installation]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6安装mysql]]></title>
    <url>%2F2019%2F01%2F13%2Fcentos6%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[centos6安装mysql mysql安装 centos6光盘自带的版本12345678910111213141516171819202122[root@centos6 ~]# yum info mysqlLoaded plugins: fastestmirror, refresh-packagekit, securityLoading mirror speeds from cached hostfile * base: mirror.bit.edu.cn * extras: ftp.sjtu.edu.cn * updates: mirrors.huaweicloud.comAvailable PackagesName : mysqlArch : x86_64Version : 5.1.73Release : 8.el6_8Size : 895 kRepo : baseSummary : MySQL client programs and shared librariesURL : http://www.mysql.comLicense : GPLv2 with exceptionsDescription : MySQL is a multi-user, multi-threaded SQL database : server. MySQL is a client/server implementation : consisting of a server daemon (mysqld) and many different : client programs and libraries. The base package contains : the standard MySQL client programs and generic MySQL : files. rpm 方式安装Mariadb：mysql端口默认为tcp 3306123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113安装：[root@centos6 ~]# yum install mysql-server -y查看安装包主要的文件列表：[root@centos6 ~]# rpm -ql mysql-server/etc/rc.d/init.d/mysqld 服务启动脚本/usr/libexec/mysqld 服务器主程序/var/lib/mysql 存放数据库的数据的路径/var/log/mysqld.log 日志文件/etc/my.cnf 服务的配置文件[root@centos6 ~]# rpm -qf /etc/my.cnf （可以作为mysql数据库的服务器的配置文件，也可以作为客户端的配置文件）mysql-libs-5.1.73-8.el6_8.x86_64启动服务：[root@centos6 ~]# service mysqld starInstalling MySQL system tables...OKFilling help tables...OKTo start mysqld at boot time you have to copysupport-files/mysql.server to the right place for your systePLEASE REMEMBERTO SET A PASSWORD FOR THE MySQL root USER !To do so, start the server, then issue the following command/usr/bin/mysqladmin -u root password 'new-password'/usr/bin/mysqladmin -u root -h centos6.com password 'new-pasd'Alternatively you can run:/usr/bin/mysql_secure_installation 初始化服务脚本，可以设置root口令，也可以更安全的数据库which will also give you the option of removing the testdatabases and anonymous user created by default. This isstrongly recommended for production servers.See the manual for more instructions.You can start the MySQL daemon with:cd /usr ; /usr/bin/mysqld_safe &amp;You can test the MySQL daemon with mysql-test-run.plcd /usr/mysql-test ; perl mysql-test-run.plPlease report any problems with the /usr/bin/mysqlbug script [ ok ]Starting mysqld: [ ok ] 启动程序后，生成数据库数据相关的文件，未启动之前时空的： [root@centos6 ~]# ls /var/lib/mysql/ ibdata1 ib_logfile0 ib_logfile1 mysql mysql.sock（数据库的套接字） test 自己连接本机的mysql服务端，可以走套接字（数据库服务的用户与linux用户无关）使用客户端工具连接数据库[root@centos6 ~]# which mysql/usr/bin/mysql[root@centos6 ~]# rpm -qf /usr/bin/mysqlmysql-5.1.73-8.el6_8.x86_64查看进程：[root@centos6 ~]# ps auxroot 4616 0.0 0.0 108228 1468 pts/1 S 21:05 0:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --（数据库的主程序）mysql 4718 0.0 1.6 367520 30848 pts/1 Sl 21:05 0:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/lmysql数据库是单进程多线程的数据库程序：[root@centos6 ~]# pstree -p├─mysqld_safe(4616)───mysqld(4718)─┬─&#123;mysqld&#125;(4720) │ ├─&#123;mysqld&#125;(4721)线程 │ ├─&#123;mysqld&#125;(4722) │ ├─&#123;mysqld&#125;(4723) │ ├─&#123;mysqld&#125;(4724) │ ├─&#123;mysqld&#125;(4725) │ ├─&#123;mysqld&#125;(4726) │ ├─&#123;mysqld&#125;(4727) │ └─&#123;mysqld&#125;(4728)查看数据库安装脚本[root@centos6 ~]# rpm -q --scripts mysql-serverpreinstall scriptlet (using /bin/sh):/usr/sbin/groupadd -g 27 -o -r mysql &gt;/dev/null 2&gt;&amp;1 || :/usr/sbin/useradd -M -N -g mysql -o -r -d /var/lib/mysql -s /bin/bash \ -c "MySQL Server" -u 27 mysql &gt;/dev/null 2&gt;&amp;1 || :postinstall scriptlet (using /bin/sh):if [ $1 = 1 ]; then /sbin/chkconfig --add mysqldfi/bin/chmod 0755 /var/lib/mysql/bin/touch /var/log/mysqld.logpreuninstall scriptlet (using /bin/sh):if [ $1 = 0 ]; then /sbin/service mysqld stop &gt;/dev/null 2&gt;&amp;1 /sbin/chkconfig --del mysqldfipostuninstall scriptlet (using /bin/sh):if [ $1 -ge 1 ]; then /sbin/service mysqld condrestart &gt;/dev/null 2&gt;&amp;1 || :fi连接数据库：（本地连接数据库是由本机的sock套接字连接） 使用mysql客户端工具连接： mysql -u 数据库用户 -p （提示输入口令）-s 指定套接字路径 （默认为/var/lib/mysql/mysql.sock）[root@centos6 ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' 帮助for help. Type '\c'清屏 to clear the current input statement.mysql&gt; 范例：下面为mysql数据库的客户端命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869下面为mysql数据库的客户端命令mysql&gt; help List of all MySQL commands:Note that all text commands must be first on line and end with ';'? (\?) Synonym for `help'. clear (\c) --清除当前输入的语句connect (\r) --重新连接，通常用于被剔除或异常断开后重新连接，SQL*plus下也有这样一个connect命令delimiter (\d) --设置命令终止符，缺省为；，比如我们可以设定为/来表示语句结束 edit (\e) --编辑缓冲区的上一条SQL语句到文件，缺省调用vi，文件会放在/tmp路径下ego (\G) --控制结果显示为垂直显示exit (\q) --退出mysqlgo (\g) --发送命令到mysql服务help (\h) Display this help.nopager (\n) --关闭页设置，打印到标准输出 notee (\t) --关闭输出到文件pager (\P) --设置pager方式，可以设置为调用more,less等等，主要是用于分页显示print (\p) Print current command. prompt (\R) --改变mysql的提示符 quit (\q) Quit mysql. rehash (\#) --自动补齐相关对象名字 source (\.) --执行脚本文件status (\s) --获得状态信息system (\!) --执行系统命令 tee (\T) --操作结果输出到文件 use (\u) --切换数据库charset (\C) --设置字符集warnings (\W) --打印警告信息nowarning (\w) Don't show warnings after every statement.--上面的所有命令，扩号内的为快捷操作，即只需要输入“\”+ 字母即可执行查看mysql数据库的存储引擎：（服务器端命令）mysql&gt; show engines;+------------+---------+------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+------------+---------+------------------------------------------------------------+--------------+------+------------+| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | DEFAULT | Default engine as of MySQL 3.23 with great performance | NO | NO | NO || InnoDB | YES | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO |+------------+---------+------------------------------------------------------------+--------------+------+------------+5 rows in set (0.00 sec)从服务器中得到相关的状态信息mysql&gt; status--------------mysql Ver 14.14 Distrib 5.1.73, for redhat-linux-gnu (x86_64) using readline 5.1Connection id: 2Current database: Current user: root@localhost（当前连接身份）SSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server version: 5.1.73 Source distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1 （字符集）Db characterset: latin1Client characterset: latin1Conn. characterset: latin1UNIX socket: /var/lib/mysql/mysql.sock（套接字文件路径）Uptime: 1 hour 1 min 14 secThreads: 1（当前线程） Questions: 8 Slow queries: 0 Opens: 15 Flush tables: 1 Open tables: 8 Queries per second avg: 0.2--------------调用linux命令mysql&gt; system hostnamecentos6.com 范例：mysql中的提示符1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162提示符：修改方式建议为了方便我们在平时的使用，有效的给我们提示信息。 建议参考Linux系统的提示符方式命名，即：用户名@主机名+当前所在位置。 在MySQL中可以通过参数来获取提示符信息，下面列表中列出了常用的四个信息，方便我们等下修改MySQL提示符。参数 描述\D 完整的日期\d 当前数据库\h 服务器名称\u 当前用户mysql&gt; PROMPT \u@\h \d &gt; root@localhost (none) &gt;CREATE DATABASE testdb;root@localhost (none) &gt;USE testdb;root@localhost testdb &gt;修改mysql数据库的提示符mysql&gt; prompt mysql--&gt;PROMPT set to 'mysql--&gt;'mysql--&gt;命令行进入mysql顺便修改提示符[root@centos6 ~]# mysql --prompt="\u@\D"Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reservedOracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.root@Tue Nov 27 22:53:50 2018修改mysql提示符，永久保存生效(centos6的服务端和客户端的配置文件在同一个文件中) 编辑数据库的配置文件，写入客户端配置[root@centos6 ~]# vim /etc/my.cnf 服务端配置[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysql# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0服务端配置[mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid客户端配置，写入提示符信息[mysql]prompt='\u@\D-&gt;'保存，进入数据库，查看提示符，是否发生变化[root@centos6 ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.root@Tue Nov 27 22:58:29 2018-&gt;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装mysql]]></title>
    <url>%2F2019%2F01%2F13%2Fcentos7%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[centos7安装mysql mysql安装 centos7光盘自带的版本123456789101112131415161718192021222324[root@centos7 ~]# yum info mariadbLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.tuna.tsinghua.edu.cn * extras: mirror.bit.edu.cn * updates: mirror.bit.edu.cnAvailable PackagesName : mariadbArch : x86_64Epoch : 1Version : 5.5.60Release : 1.el7_5Size : 8.9 MRepo : updates/7/x86_64Summary : A community developed branch of MySQLURL : http://mariadb.orgLicense : GPLv2 with exceptions and LGPLv2 and BSDDescription : MariaDB is a community developed branch of MySQL. : MariaDB is a multi-user, multi-threaded SQL database : server. It is a client/server implementation consisting : of a server daemon (mysqld) and many different client : programs and libraries. The base package contains the : standard MariaDB/MySQL client programs and generic MySQL : files. rpm 方式安装Mariadb：mysql端口默认为tcp 3306123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172安装：[root@centos7 ~]# yum install mariadb-server -y查看安装包主要的文件列表：[root@centos7 ~]# rpm -ql mariadb-server/etc/my.cnf.d/server.cnf 服务器端配置文件/usr/libexec/mysqld 服务器主程序/var/lib/mysql 存放数据库数据的路径/var/log/mariadb/mariadb.log 日志/usr/lib/systemd/system/mariadb.service 服务启动脚本启动程序： 启动前查看数据库数据目录是为空 [root@centos7 ~]# ls /var/lib/mysql/ [root@centos7 ~]# [root@centos7 ~]# systemctl restart mariadbroot@centos7 ~]# ls /var/lib/mysql/aria_log.00000001 ib_logfile0 mysql.sockaria_log_control ib_logfile1 performance_schemaibdata1 mysql test连接数据库：[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; 查看搜索引擎：MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+10 rows in set (0.00 sec)从服务器中得到相关的状态信息MariaDB [(none)]&gt; \s--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 2Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1Db characterset: latin1Client characterset: utf8Conn. characterset: utf8UNIX socket: /var/lib/mysql/mysql.sockUptime: 9 min 44 secThreads: 1 Questions: 6 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 26 Queries per second avg: 0.010-------------- 范例：centos7修改提示符：（centos7mysql的配置文件和客户端是分开的）1234567891011121314151617[root@centos7 ~]# cd /etc/my.cnf.d/[root@centos7 my.cnf.d]# lsclient.cnf mysql-clients.cnf server.cnf编辑客户端配置文件修改提示符[root@centos7 my.cnf.d]# vim mysql-clients.cnf [mysql]prompt='\u@\D-&gt;'查看是否修改成功[root@centos7 my.cnf.d]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 3Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and otherType 'help;' or '\h' for help. Type '\c' to clear the current inputatement.root@Tue Nov 27 15:04:34 2018-&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546MariaDB [(none)]&gt; none:表示当前正在处于哪个数据库里面查看数据库的数据路径目录形式的代表数据库，也是系统自带的数据库，所以可以理解为数据库存放数据 分为系统自身用的数据、用户创建生产的数据库[root@centos7 ~]# ls /var/lib/mysql/aria_log.00000001 ib_logfile0 mysql.sockaria_log_control ib_logfile1 performance_schemaibdata1 mysql test查看当前有多少数据库即表MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)查看当前数据库的版本信息（数据库中带有括号的命令，表现为系统自带的函数）MariaDB [(none)]&gt; select version();+----------------+| version() |+----------------+| 5.5.60-MariaDB |+----------------+1 row in set (0.00 sec)查看当前的用户信息MariaDB [(none)]&gt; select user();+----------------+| user() |+----------------+| root@localhost |+----------------+1 row in set (0.00 sec)查看用户当前所在哪个数据库中MariaDB [(none)]&gt; select database();+------------+| database() |+------------+| NULL |+------------+1 row in set (0.00 sec) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179使用use 客户端工具切换到指定的数据库，作为当前使用的数据库MariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; 查看当前使用的数据库中的所有表列表MariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)命令行指定显示指定数据库中的表列表(意义同上命令)MariaDB [mysql]&gt; show tables from mysql;....上面的数据库中的表实际表现为[root@centos7 ~]# ls /var/lib/mysql/mysql查看服务端命令的帮助help + 服务端命令``` `范例：安装完数据库，linux上的任何用户都可以使用mysql的root用户登陆，也可以使用任何一个用户连接登陆````bash查看mysql存放的用户信息[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 7Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)MariaDB [mysql]&gt; select user,host,password from user;+------+-------------+----------+| user | host | password |+------+-------------+----------+| root | localhost | || root | centos7.com | || root | 127.0.0.1 | || root | ::1 | || | localhost | || | centos7.com | |+------+-------------+----------+6 rows in set (0.00 sec)安全加固，执行初始化命令[root@centos7 ~]# mysql_secure_installation Enter current password for root (enter for none): （输入当前数据库中root用户的口令，若无口令，直接回车）Set root password? [Y/n] （是否设置root的口令）yNew password: 口令Re-enter new password: 确定口令Password updated successfully!Reloading privilege tables.. ... Success!Remove anonymous users? [Y/n] （是否删除匿名用户）yDisallow root login remotely? [Y/n] (是否禁用远程登陆)yRemove test database and access to it? [Y/n] (是否删除测试数据库)yReload privilege tables now? [Y/n] (是否重新加载特权表)yThanks for using MariaDB!再次连接mysql数据库[root@centos7 ~]# mysql -u root -pMariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)MariaDB [mysql]&gt; select user,host,password from user;+------+-----------+-------------------------------------------+| user | host | password |+------+-----------+-------------------------------------------+| root | localhost | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | 127.0.0.1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | ::1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)目前仅可以本机连接，使用centos6连接测试[root@centos6 ~]# mysql -u root -p centos -h 172.18.135.88Enter password: 连接不上 范例：查看mysql账号数据库是否活跃123[root@centos7 ~]# mysqladmin -u root -p pingEnter password: mysqld is alive 范例：停止此用户的数据库123456789101112131415[root@centos7 ~]# mysqladmin -u root -p shutdownEnter password: 测试：连接不上去了[root@centos7 ~]# mysql -u root -pEnter password: ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)启动服务[root@centos7 ~]# systemctl restart mariadb查看连接信息[root@centos7 ~]# mysqladmin statusUptime: 23 Threads: 1 Questions: 3 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 18 Queries per second avg: 0.130`]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql安装和基本操作]]></title>
    <url>%2F2019%2F01%2F13%2Fmysql%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[mysql安装和基本操作 MYSQL的特性插件式存储引擎：也称为“表类型”，存储管理器有多种实现版本，功能和特 性可能均略有差别；用户可根据需要灵活选择,Mysql5.5.5开始&amp;innoDB引擎是 MYSQL默认引擎&ensp;&ensp;MyISAM ==&gt; Aria&ensp;&ensp;InnoDB ==&gt; XtraDB单进程，多线程诸多扩展和新特性提供了较多测试组件开源 安装MYSQLMariadb安装方式：1、源代码：编译安装2、二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用3、程序包管理器管理的程序包CentOS 安装光盘项目官方： https://downloads.mariadb.org/mariadb/repositories/国内镜像： https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadbx.y.z/yum/centos/7/x86_64/ RPM包安装MySQLRPM包安装&ensp;&ensp;CentOS 7：安装光盘直接提供&ensp;&ensp;&ensp;&ensp;mariadb-server 服务器包&ensp;&ensp;&ensp;&ensp;mariadb 客户端工具包&ensp;&ensp;CentOS 6提高安全性&ensp;&ensp;mysql_secure_installation&ensp;&ensp;&ensp;&ensp;设置数据库管理员root口令&ensp;&ensp;&ensp;&ensp;禁止root远程登录&ensp;&ensp;&ensp;&ensp;删除anonymous用户帐号&ensp;&ensp;&ensp;&ensp;删除test数据库 MariaDB程序客户端程序：&ensp;&ensp;mysql: 交互式的CLI工具&ensp;&ensp;mysqldump：备份工具，基于mysql协议向mysqld发起查询请求，并将查得的所有数据转换成insert等写操作语句保存文本文件中&ensp;&ensp;mysqladmin：基于mysql协议管理mysqld&ensp;&ensp;mysqlimport：数据导入工具MyISAM存储引擎的管理工具：&ensp;&ensp;myisamchk：检查MyISAM库&ensp;&ensp;myisampack：打包MyISAM表，只读服务器端程序&ensp;&ensp;mysqld_safe&ensp;&ensp;mysqld&ensp;&ensp;mysqld_multi 多实例（一个程序在系统上运行多次，多个进程，缺点仅能实现单一版本的多实例） ，示例：mysqld_multi –example 用户账号mysql用户账号由两部分组成：&ensp;&ensp;‘USERNAME‘@’HOST‘说明：&ensp;&ensp;HOST限制此用户可通过哪些远程主机连接mysql服务器&ensp;&ensp;支持使用通配符：&ensp;&ensp;&ensp;&ensp;% 匹配任意长度的任意字符&ensp;&ensp;&ensp;&ensp;172.16.0.0/255.255.0.0 或 172.16.%.%&ensp;&ensp;&ensp;&ensp;_ 匹配任意单个字符 Mysql 客户端mysql使用模式：交互式模式：&ensp;&ensp;可运行命令有两类：&ensp;&ensp;客户端命令：&ensp;&ensp;&ensp;&ensp;\h, help&ensp;&ensp;&ensp;&ensp;\u，use&ensp;&ensp;&ensp;&ensp;\s，status&ensp;&ensp;&ensp;&ensp;!，system&ensp;&ensp;服务器端命令：&ensp;&ensp;&ensp;&ensp;SQL语句， 需要语句结束符；脚本模式：&ensp;&ensp;mysql –uUSERNAME -pPASSWORD &lt; /path/somefile.sql&ensp;&ensp;mysql&gt; source /path/from/somefile.sql Mysql客户端mysql客户端可用选项：-A, –no-auto-rehash 禁止补全-u, –user= 用户名,默认为root-h, –host= 服务器主机,默认为localhost-p, –passowrd= 用户密码,建议使用-p,默认为空密码-P, –port= 服务器端口-S, –socket= 指定连接socket文件路径-D, –database= 指定默认数据库-C, –compress 启用压缩-e “SQL“ 执行SQL命令-V, –version 显示版本-v –verbose 显示详细信息–print-defaults 获取程序默认使用的配置 socket地址服务器监听的两种socket地址：&ensp;&ensp;ip socket: 监听在tcp的3306端口，支持远程通信&ensp;&ensp;unix sock: 监听在sock文件上，仅支持本机通信&ensp;&ensp;&ensp;&ensp;如：/var/lib/mysql/mysql.sock)说明：host为localhost,127.0.0.1时自动使用unix sock 执行命令运行mysql命令：默认空密码登录&ensp;&ensp;mysql&gt;use mysql&ensp;&ensp;mysql&gt;select user();查看当前用户&ensp;&ensp;mysql&gt;SELECT User,Host,Password FROM user;登录系统：mysql –uroot –p客户端命令：本地执行&ensp;&ensp;mysql&gt; help&ensp;&ensp;每个命令都完整形式和简写格式&ensp;&ensp;mysql&gt; status 或 \s服务端命令：通过mysql协议发往服务器执行并取回结果 每个命令末尾都必须使用命令结束符号，默认为分号&ensp;&ensp;示例：SELECT VERSION(); 服务器端配置服务器端(mysqld)：工作特性有多种配置方式1、命令行选项：2、配置文件：类ini格式集中式的配置，能够为mysql的各应用程序提供配置信息&ensp;&ensp;[mysqld]&ensp;&ensp;[mysqld_safe]&ensp;&ensp;[mysqld_multi]&ensp;&ensp;[mysql]&ensp;&ensp;[mysqldump]&ensp;&ensp;[server]&ensp;&ensp;[client]格式：parameter = value说明：_和- 相同&ensp;&ensp;1，ON，TRUE意义相同， 0，OFF，FALSE意义相同 配置文件配置文件：后面覆盖前面的配置文件，顺序如下：下面的优先级高/etc/my.cnf &ensp;&ensp; Global选项/etc/mysql/my.cnf &ensp;&ensp; Global选项SYSCONFDIR/my.cnf &ensp;&ensp; Global选项$MYSQL_HOME/my.cnf &ensp;&ensp; Server-specific 选项–defaults-extra-file= path~/.my.cnf &ensp;&ensp; User-specific 选项 MairaDB配置侦听3306/tcp端口可以在绑定有一个或全部接口IP上vim /etc/my.cnf[mysqld]skip-networking=1关闭网络连接，只侦听本地客户端， 所有和服务器的交互都通过一个socket实 现，socket的配置存放在/var/lib/mysql/mysql.sock） 可在/etc/my.cnf修改 通用二进制格式安装过程二进制格式安装过程(1) 准备用户&ensp;&ensp;groupadd -r -g 306 mysql&ensp;&ensp;useradd -r -g 306 -u 306 –d /data/mysql mysql(2) 准备数据目录，建议使用逻辑卷&ensp;&ensp;mkdir /data/mysql&ensp;&ensp;chown mysql:mysql /data/mysql(3) 准备二进制程序&ensp;&ensp;tar xf mariadb-VERSION-linux-x86_64.tar.gz -C /usr/local&ensp;&ensp;cd /usr/local&ensp;&ensp;ln -sv mariadb-VERSION mysql&ensp;&ensp;chown -R root:mysql /usr/local/mysql/(4) 准备配置文件&ensp;&ensp;mkdir /etc/mysql/&ensp;&ensp;cp support-files/my-large.cnf /etc/mysql/my.cnf&ensp;&ensp;[mysqld]中添加三个选项：&ensp;&ensp;datadir = /data/mysql&ensp;&ensp;innodb_file_per_table = on&ensp;&ensp;skip_name_resolve = on 禁止主机名解析，建议使用(5)创建数据库文件&ensp;&ensp;cd /usr/local/mysql/&ensp;&ensp;./scripts/mysql_install_db –datadir=/data/mysql –user=mysql(6)准备服务脚本，并启动服务&ensp;&ensp;cp ./support-files/mysql.server /etc/rc.d/init.d/mysqld&ensp;&ensp;chkconfig –add mysqldservice mysqld start(7)PATH路径&ensp;&ensp;echo ‘PATH=/user/local/mysql/bin:$PATH’ &gt; /etc/profile.d/mysql(8)安全初始化 &ensp;&ensp;/user/local/mysql/bin/mysql_secure_installation 源码编译安装mariadb安装包&ensp;&ensp;yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel做准备用户和数据目录&ensp;&ensp;useradd –r –s /sbin/nologin –d /data/mysql/ mysql&ensp;&ensp;mkdir /data/mysql&ensp;&ensp;chown mysql.mysql /data/mysql&ensp;&ensp;tar xvf mariadb-10.2.18.tar.gzcmake 编译安装&ensp;&ensp;cmake的重要特性之一是其独立于源码(out-of-source)的编译功能，即编译工作可以在 另一个指定的目录中而非源码目录中进行，这可以保证源码目录不受任何一次编译的影 响，因此在同一个源码树上可以进行多次不同的编译，如针对于不同平台编译 编译选项:https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html cd mariadb-10.2.18/cmake . \-DCMAKE_INSTALL_PREFIX=/app/mysql \-DMYSQL_DATADIR=/data/mysql/ \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITHOUT_MROONGA_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DENABLED_LOCAL_INFILE=1 \-DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci make &amp;&amp; make install提示：如果出错，执行rm -f CMakeCache.txt 准备环境变量echo ‘PATH=/app/mysql/bin:$PATH’ &gt; /etc/profile.d/mysql.sh. /etc/profile.d/mysql.sh生成数据库文件cd /app/mysql/scripts/mysql_install_db –datadir=/data/mysql/ –user=mysql准备配置文件cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf准备启动脚本cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld启动服务chkconfig –add mysqld ;service mysqld start 关系型数据库的常见组件数据库：database表：table 行：row 列：column索引：index视图：view用户：user权限：privilege存储过程：procedure存储函数：function触发器：trigger事件调度器：event scheduler，任务计划 SQL语言的兴起与语法标准20世纪70年代，IBM开发出SQL，用于DB21981年，IBM推出SQL/DS数据库业内标准微软和Sybase的T-SQL，Oracle的PL/SQLSQL作为关系型数据库所使用的标准语言，最初是基于IBM的实现在1986年被 批准的。1987年，“国际标准化组织(ISO)”把ANSI(美国国家标准化组织) SQL作为国际标准。SQL：ANSI SQLSQL-1986, SQL-1989, SQL-1992, SQL-1999, SQL-2003 , SQL-2008 SQL-2011 SQL语言规范在数据库系统中，SQL语句不区分大小写(建议用大写)SQL语句可单行或多行书写，以“;”结尾关键词不能跨多行或简写用空格和缩进来提高语句的可读性子句通常位于独立行，便于编辑，提高可读性注释：&ensp;&ensp;SQL标准：&ensp;&ensp;/注释内容/ 多行注释&ensp;&ensp;– 注释内容 单行注释，注意有空格&ensp;&ensp;MySQL注释： # 数据库对象数据库的组件(对象)：&ensp;&ensp;数据库、表、索引、视图、用户、存储过程、函数、触发器、事件调度器等命名规则：&ensp;&ensp;必须以字母开头&ensp;&ensp;可包括数字和三个特殊字符（# _ $）&ensp;&ensp;不要使用MySQL的保留字&ensp;&ensp;同一database(Schema)下的对象不能同名 SQL语句分类SQL语句分类：DDL: Data Defination Language 数据定义语言&ensp;&ensp;CREATE，DROP，ALTERDML: Data Manipulation Language 数据操纵语言&ensp;&ensp;INSERT，DELETE，UPDATEDCL：Data Control Language 数据控制语言&ensp;&ensp;GRANT，REVOKE，COMMIT，ROLLBACKDQL：Data Query Language 数据查询语言&ensp;&ensp;SELECT SQL语句构成SQL语句构成：&ensp;&ensp;Keyword组成clause&ensp;&ensp;多条clause组成语句示例：SELECT * SELECT子句FROM products FROM子句WHERE price&gt;400 WHERE子句说明：一组SQL语句，由三个子句构成，SELECT,FROM和WHERE是关键字 数据库操作创建数据库：&ensp;&ensp;CREATE DATABASE|SCHEMA [IF NOT EXISTS] ‘DB_NAME’;&ensp;&ensp;CHARACTER SET ‘character set name’&ensp;&ensp;COLLATE ‘collate name’删除数据库&ensp;&ensp;DROP DATABASE|SCHEMA [IF EXISTS] ‘DB_NAME’;查看支持所有字符集：&ensp;&ensp;SHOW CHARACTER SET;查看支持所有排序规则：&ensp;&ensp;SHOW COLLATION;获取命令使用帮助：&ensp;&ensp;mysql&gt; HELP KEYWORD;查看数据库列表：&ensp;&ensp;mysql&gt; SHOW DATABASES;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库基础原理]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql数据库基础原理 MYSQL数据库关系型数据库基础安装MySQL管理数据库和表用户和权限管理函数，存储过程和触发器MySQL架构存储引擎服务器选项，系统和状态变量优化查询和索引管理锁和事务管理日志管理备份还原MySQL集群 数据的时代涉及的数据量大数据不随程序的结束而消失数据被多个应用程序共享大数据 数据库的发展史萌芽阶段：文件系统 使用磁盘文件来存储数据初级阶段：第一代数据库 出现了网状模型、层次模型的数据库中级阶段：第二代数据库 关系型数据库和结构化查询语言高级阶段：新一代数据库 “关系-对象”型数据库 文件管理系统的缺点编写应用程序不方便数据冗余不可避免应用程序依赖性不支持对文件的并发访问数据间联系弱难以按用户视图表示数据无安全控制功能 数据库管理系统的优点相互关联的数据的集合较少的数据冗余程序与数据相互独立保证数据的安全、可靠最大限度地保证数据的正确性数据可以并发使用并能同时保证一致性 数据库管理系统数据库是数据的汇集，它以一定的组织形式存于存储介质上DBMS是管理数据库的系统软件，它实现数据库系统的各种功能。是数据库系 统的核心DBA：负责数据库的规划、设计、协调、维护和管理等工作应用程序指以数据库为基础的应用程序 数据库管理系统的基本功能数据定义数据处理数据安全数据备份 网状数据库最早出现的是网状DBMS，1964年通用电气公司的Charles Bachman成功地开发出世界上第一 个网状IDS，也是第一个数据库管理系统，IDS 具有数据模式和日志的特征，只能在GE主机运行 层次数据库 数据库系统的架构单机架构大型主机/终端架构主从式架构（C/S）分布式架构 关系型数据库关系型数据库：使用的是sql语言，结构化的查询语言 ，内部机制特性ACID特性：保证数据库的安全稳定，影响性能NOSQL：redis:高性能，高并发 关系 ：关系就是二维表，其中：表中的行、列次序并不重要行row：表中的每一行，又称为一条记录列column：表中的每一列，称为属性，字段主键（Primary key）：用于惟一确定一个记录的字段域domain：属性的取值范围，如，性别只能是‘男’和‘女’两个值 一个服务器可以搭建多个DBMSDBMS:多个数据库 ，推荐存放一个数据库，防止访问量过大库：同一个项目的相关系数据，多个表表：一个表多个字段和记录 关系数据库RDBMS：&ensp;&ensp;MySQL: MySQL, MariaDB, Percona Server&ensp;&ensp;PostgreSQL: 简称为pgsql，EnterpriseDB &ensp;&ensp;Oracle MSSQL&ensp;&ensp;DB2数据库排名： https://db-engines.com/en/ranking 实体-联系模型E-R实体Entity：客观存在并可以相互区分的客观事物或抽象事件称为实体&ensp;&ensp;在E-R图中用矩形框表示实体，把实体名写在框内属性：实体所具有的特征或性质联系：联系是数据之间的关联集合，是客观存在的应用语义链&ensp;&ensp;实体内部的联系：指组成实体的各属性之间的联系。如职工实体中，职工号和 部门经理号之间有一种关联关系&ensp;&ensp;实体之间的联系：指不同实体之间联系。例：学生选课实体和学生基本信息实 体之间&ensp;&ensp;实体之间的联系用菱形框表示 联系类型联系的类型&ensp;&ensp;一对一联系(1:1)&ensp;&ensp;一对多联系(1:n)&ensp;&ensp;多对多联系(m:n)数据的操作：&ensp;&ensp;数据提取：在数据集合中提取感兴趣的内容。SELECT&ensp;&ensp;数据更新：变更数据库中的数据。INSERT、DELETE、UPDATE数据的约束条件 ：是一组完整性规则的集合&ensp;&ensp;实体（行）完整性 Entity integrity&ensp;&ensp;域（列）完整性 Domain Integrity&ensp;&ensp;参考完整性 Referential Integrity 简易数据规划流程第一阶段：收集数据，得到字段&ensp;&ensp;收集必要且完整的数据项&ensp;&ensp;转换成数据表的字段第二阶段：把字段分类，归入表，建立表的关联&ensp;&ensp;关联：表和表间的关系&ensp;&ensp;分割数据表并建立关联的优点&ensp;&ensp;节省空间&ensp;&ensp;减少输入错误&ensp;&ensp;方便数据修改第三阶段：&ensp;&ensp;规范化数据库 数据库的正规化分析RDMBS设计范式基础概念&ensp;&ensp;设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不 同的规范要求被称为不同范式，各种范式呈递次规范，越高的范式数据库冗余越小&ensp;&ensp;目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式 （3NF）、巴德斯科范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称 完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上 进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般 数据库只需满足第三范式(3NF）即可 1NF：无重复的列，每一列都是不可分割的基本数据项，同一列中不能有多个 值，即实体中的某个属性不能有多个值或者不能有重复的属性。除去同类型的 字段，就是无重复的列说明：第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF） 的数据库就不是关系数据库2NF：属性完全依赖于主键，第二范式必须先满足第一范式，要求表中的每个 行必须可以被唯一地区分。通常为表加上一个列，以存储各个实例的唯一标识 PK，非PK的字段需要与整个PK有直接相关性3NF：属性不依赖于其它非主属性，满足第三范式必须先满足第二范式。第三 范式要求一个数据库表中不包含已在其它表中已包含的非主关键字信息，非PK 的字段间不能有从属关系 SQL概念SQL: Structure Query Language&ensp;&ensp;结构化查询语言&ensp;&ensp;SQL解释器：&ensp;&ensp;数据存储协议：应用层协议，C/SS：server, 监听于套接字，接收并处理客户端的应用请求C：Client&ensp;&ensp;客户端程序接口&ensp;&ensp;&ensp;&ensp;CLI 字符、命令行&ensp;&ensp;&ensp;&ensp;GUI 图形化&ensp;&ensp;应用编程接口 API&ensp;&ensp;&ensp;&ensp;ODBC：Open Database Connectivity 开放的数据库连接&ensp;&ensp;&ensp;&ensp;JDBC：Java Data Base Connectivity java开放数据库的开发接口 mysql：端口tcp 3306oracle：端口tcp 1521sqlserver:端口tcp 1433 约束约束：constraint，表中的数据要遵守的限制&ensp;&ensp;主键pk：一个或多个字段的组合，填入的数据必须能在本表中唯一标识本行； 必须提供数据，即NOT NULL，一个表只能有一个&ensp;&ensp;惟一键uk：一个或多个字段的组合，填入的数据必须能在本表中唯一标识本行； 允许为NULL，一个表可以存在多个&ensp;&ensp;外键fk：一个表中的某字段可填入的数据取决于另一个表的主键或唯一键已有 的数据 ,作用在依赖的表上，被依赖的表上，可以作用主键和唯一键&ensp;&ensp;检查：字段值在一定范围内 基本概念索引：将表中的一个或多个字段中的数据复制一份另存，并且按特定次序排序 存储 （例如：书签，标识）关系运算：&ensp;&ensp;选择：挑选出符合条件的行&ensp;&ensp;投影：挑选出需要的字段&ensp;&ensp;连接：表间字段的关联 数据模型数据抽象：&ensp;&ensp;物理层：数据存储格式，即RDBMS在磁盘上如何组织文件&ensp;&ensp;逻辑层：DBA角度，描述存储什么数据，以及数据间存在什么样的关系&ensp;&ensp;视图层：用户角度，描述DB中的部分数据关系模型的分类：&ensp;&ensp;关系模型&ensp;&ensp;基于对象的关系模型&ensp;&ensp;半结构化的关系模型：XML数据 ：扩展的标记语言 范例：基于xml语言存放的数据12下面目录内的文件都是基于xml语言存放数据的文件[root@centos6 gconf]# cd /etc/gconf/gconf.xml.defaults/ 范例：设置开机自动登陆12345[root@centos6 ~]# vim /etc/gdm/custom.conf # GDM configuration storage[daemon]AutomaticLoginEnable=tureAutomaticLongin=root MySQL历史1979年：TcX公司 Monty Widenius，Unireg1996年：发布MySQL1.0，Solaris版本，Linux版本1999年：MySQL AB公司，瑞典2003年：MySQL 5.0版本，提供视图、存储过程等功能2008年：Sun 收购2009年：Oracle收购sun2009年：Monty成立MariaDB MySQL和MariaDB官方网址：https://www.mysql.com/http://mariadb.org/官方文档https://dev.mysql.com/doc/https://mariadb.com/kb/en/版本演变：MySQL：5.1 –&gt; 5.5 –&gt; 5.6 –&gt; 5.7 –&gt;8.0MariaDB：5.5 –&gt;10.0–&gt; 10.1 –&gt; 10.2 –&gt; 10.3123yum info ..centos6默认光盘安装mysql 5.1.73centos7使用的是mariadb 5.5.56 MYSQL的特性插件式存储引擎：也称为“表类型”，存储管理器有多种实现版本，功能和特 性可能均略有差别；用户可根据需要灵活选择,Mysql5.5.5开始innoDB引擎是 MYSQL默认引擎&ensp;&ensp;MyISAM ==&gt; Aria&ensp;&ensp;InnoDB ==&gt; XtraDB单进程，多线程诸多扩展和新特性提供了较多测试组件开源 raw:裸文件系统：无文件系统：二进制方式存储]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx高并发内核优化]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[nginx作为负载均衡器高并发内核优化 实现nginx高并发linux内核优化 由于默认的linux内核的参数考虑的是最通用的场景，这明显不符合用于支持高并发访问的web服务器的定义，所以需要修改linux内核的参数，是的nginx可以拥有更高的性能，根据业务的特点来进行调整，当nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，其内核的参数调整通常都是不同的，这里针对最通用的、使用nginx支持更多并发请求的tcp网络参数做简单的配置，修改/etc/sysctl.conf来更改内核的参数 file-max = 999999 表示单个进程较大可以打开的句柄数即文件描述符的数量 net.ipv4.tcp_rw_reuse = 1 参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的tcp连接，这对于服务器来说意义重大，因为总有大量TIME_WAIT状态的链接存在 net.ipv4.tcp_keepalive_time = 600 当keeplived启动时。tcp发送keeplived消息的频度；默认为2小时，将其设置为10分钟，可以更快的清理无效的链接 net.piv4.tcp_fin_timeout = 30 当服务器主动关闭连接时，socket保持在FIN_WAIT_2状态的较大时间 net.piv4.tcp_max_tw_buckets - 5000 这个参数表示操作系统允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻被抢出并打印警告信息，默认为8000，过多的TIME_WAIT套接字会使web服务器变慢 net.ipv4.ip_local_portrange = 1024 65000 定义UDP和TCP连接的本地端口的取值范围 net.ipv4.tcp_rmem = 1024 87380 12582912 定义TCP接受缓存的最小值、默认值、最大值 net.ipv4.tcp_wmem = 1024 87380 12582912 定义了TCP发送缓存的最小值、默认值、较大值 net.core.netdev_max_backlog = 8096 当网卡接受数据包的速度大于内核处理速度时，会有一个列队保存这些数据包。这个参数表示该列队的较大值 net.core.rmem_default = 6291456 表示内核套接字接受缓存区默认的大小 net.core.wmem_default = 6291456 表示内核套接字发送缓存区默认的大小 net.core.rmem_max = 12582912 表示内核的套接字接受缓存区较大大小 net.core.wmem_max = 12582912 表示内核套接字发送缓存区较大大小 注意：以上四个参数，需要根据业务的逻辑和实际的硬件成本来综合考虑 net.piv4.tcp_syncookies = 1 与性能无关。用于解决tcp的syn攻击 net.ipv4.tcp_max_syn_backlog = 8192 这个参数表示tcp三次握手建立阶段接受syn请求的列队的较大长度，默认1024，将这个参数设置的大一点可使出现nginx繁忙来不及accept新的连接时，linux不至于丢失客户端的发起连接的请求 net.ipv4.tcp_tw_recycle = 1 这个参数用于设置启用timewait快速回收 net.core.somaxconn = 262114 选项默认值为128，这个参数用于调节系统同时发起的tcp连接数，在高并发的请求中，默认的值可能会导致连接超时或者重传，因此需要结合高并发请求数来调节此值 net.ipv4.tcp_max_orphans = 262114 选项用于设定系统中最多有多少个tcp套接字不被关联到任何一个用户文件句柄中。如果超过这个数字，孤立连接将立即被复位输出警告信息。这个限制指示为了防]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的stream模块]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E4%BC%AA%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[nginx的stream模块（伪四层负载） nginx伪四层负载 Nginx 1.9.0版本起支持四层负载均衡，从而使得Nginx变得更加强大。目前，四层软件负载均衡器用得比较多的是HaProxy；而Nginx也支持四层负载均衡。 ngx_stream_core_module ngx_stream_core_module模块从1.9.0版本开始可用。默认情况下，此模块不是构建的，它应该使用-with-stream配置参数启用。 (1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 监听的端口； 默认为tcp协议； udp: 监听udp协议的端口； ngx_stream_proxy_module ngx_stream_proxy_module模块(1.9.0)允许通过TCP、UDP(1.9.13)和unix域套接字代理数据流。 (1) proxy_pass address; 设置代理服务器的地址。该地址可以指定为域名或IP地址、端口或unix域套接字路径。 (2) proxy_timeout timeout; 设置客户端或代理服务器连接上的两个连续读写操作之间的超时。如果在此时间内没有传输数据，则连接将关闭。- 默认为10m; (3) proxy_connect_timeout time; 定义与代理服务器建立连接的超时。- 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 参考：http://nginx.org/en/docs/stream/ngx_stream_core_module.html#stream 范例：123456789101112131415161718192021222324252627282930313233343536实现nginx_stream代理mysql_server服务器面向客户端提供服务 clent nginx_stream : yum install nginx mysql_server : yum istall mariadb-servermysql_server### 创建账号 MariaDB [(none)]&gt; grant all on *.* to daizhe@'%' identified by 'centos'; 生效权限 MariaDB [(none)]&gt; flush privileges;nginx_server#使用stream四层代理时使用的上下文都在stream &#123;&#125; 上下文当中，不要与http同时使用 ~]# vim /etc/nginx/nginx.conf stream &#123; server &#123; listen 3306; proxy_pass 172.18.135.2:3306; #数据库的地址和端口 &#125; &#125; ~]# nginx -t ~]# nginx -s reload ~]# systemctl restart nginx ~]# ss -tnl LISTEN 0 128 *:3306 client测试 #使用client连接nginx_stream_server服务器验证是否被调度 ~]# mysql -udaizhe -pcentos -h172.18.135.1 #地址为nginx地址 MariaDB [(none)]&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445再次启动一个mysql数据库实现客户端访问的负载均衡#模拟两个数据库的效果，为了使客户调度起来无差别感知，使两个mysql授权的账号和数据相同（生产中可以做主从）（后添加）mysql_server### 创建账号 MariaDB [(none)]&gt; grant all on *.* to daizhe@'%' identified by 'centos'; 生效权限 MariaDB [(none)]&gt; flush privileges;配置nginx_stream_server ~]# vim /etc/nginx/nginx.conf stream &#123; upstream dbserver &#123; server 172.18.135.2:3306; server 172.18.135.5:3306; &#125; server &#123; listen 3306; proxy_pass dbserver; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadclient 测试（为了使得看出差别可以在daizhe账号下创建不同的数据库以便看出算法） ~]# while true; do mysql -udaizhe -pcentos -h172.18.135.1 -e "show databases;"; sleep 1 ;done+--------------------+| Database |+--------------------+| information_schema || db1 || mysql || performance_schema |+--------------------++--------------------+| Database |+--------------------+| information_schema || db2 || mysql || performance_schema |+--------------------+]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的http_upstream模块]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E4%B8%83%E5%B1%82%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[nginx的http_upstream模块（七层负载） nginx的http_upstream模块 我们知道单台服务器的性能是有上限的，当流量很大时，就需要使用多台服务器来共同提供服务，这就是所谓的集群。 负载均衡服务器，就是用来把经过它的流量，按照某种方法，分配到集群中的各台服务器上。这样一来不仅可以承担 更大的流量、降低服务的延迟，还可以避免单点故障造成服务不可用。一般的反向代理服务器，都具备负载均衡的功能。 负载均衡功能可以由硬件来提供，比如以前的F5设备。也可以由软件来提供，LVS可以提供四层的负载均衡(利用IP和端口)， Haproxy和Nginx可以提供七层的负载均衡(利用应用层信息)。 硬件：F5 BigIP, Citrix NetScaler, A10 A10 软件： 四层调度：lvs, nginx(stream module), haproxy(mode tcp) 七层调度：nginx(http_upstream module), haproxy(mode http), httpd, ats, ... mysql: Proxy_SQL, ... ... ... session sticky：会话粘滞 Source IP: sh, persistence Cookie： session replication： session server： ngx_http_upstream_module 参考文档：http://nginx.org/en/docs/http/ngx_http_upstream_module.html ngx_http_upstream_module模块用于定义可以由proxy_pass、fastcgi_pass、uwsgi_pass、scgi_pass和memcached_pass指令引用的服务器组。 (1) upstream name { ... } 定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中； 默认的调度方法是wrr； (2) server address [parameters]; 定义服务器地址和相关的参数； 地址格式： IP[:PORT] HOSTNAME[:PORT] unix:/PATH/TO/SOME_SOCK_FILE 参数： weight=number 权重，默认为1； max_fails=number 失败尝试的最大次数； fail_timeout=time 设置服务器为不可用状态的超时时长，默认为10秒； backup 把服务器标记为“备用”状态（sory server 只有所有的服务器全部没办法工作时才会上线）； down 手动标记其为不可用； 1server 172.18.135.2 weight=2 backup max_fails=10m; (3) least_conn; 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； (4) ip_hash; 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； (5) hash key [consistent]; 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； consistent：参数，指定使用一致性hash算法； 示例： hash $request_uri consistent hash $remote_addr hash $cookie_name (6) keepalive connections; 可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量； 范例：实现nginx调度123456789101112131415161718192021222324252627282930313233343536373839404142三台主机 client nginx_stream_server :yum install nginx -y web_server1 :yum install httpd -y web_server2 :yum install httpd -y配置两台web_server的页面文件 #为了达到负载均衡的web_server网页文件应该是相同的，这里为了演示调度器调度的差别有意的是web_server的网页文件设置有差别 web_server1 ~]# echo "web_server1" &gt; /var/www/html/index.html web_server2 ~]# echo "web_server2" &gt; /var/www/html/index.html编辑nginx实现负载均衡 #在原http配置 ~]# vim /etc/nginx/nginx.conf http &#123; #仅能在http上下文使用 upstream staticwebsrvs &#123; #定义后端服务器组 server 172.18.135.2; #web_server1 server 172.18.135.5; #web_server2 &#125; .... #server中调用服务器组名称 server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadclient客户端测试#默认1:1轮询算法,支持加权轮询（Round-Robin） ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server2 web_server1 web_server2 算法：使用加权轮询（wrr）123456789101112131415161718192021222324使用加权轮询(默认权重都为1) 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; server 172.18.135.2 weight=2; #将web_server1设置权重比为2 server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server2 算法：least_conn做少连接（wlc）1234567891011121314151617181920212223242526#对短链接最好使用：轮询#对长连接最好使用：wlc使用least_conn做少连接算法 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; least_conn; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done 算法：ip_hash (sh)123456789101112131415161718192021222324252627282930313233343536使用ip_hash：bash原ip地址 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; ip_hash; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server1 web_server1 web_server1工作方式：#对客户端ip做bash计算，把后端服务器按权重bash成静态的数组，而后在数据上取模，取出模几，就映射到第几台服务器上缺点：#如果服务器的总数发生了变化则此前的hash结果则发生变动#当后端服务器宕机后，session会丢失；#来自同一局域网的客户端会被转发到同一个后端服务器，可能导致负载失衡；#不适用于CDN网络，不适用于前段还有代理的情况。 算法：consistent bashing 一致性hash12345678910111213141516171819202122232425262728293031323334#无论权重怎么变，但是hash算法是不变的，仅对固定的进行bash取模#bash:可以对任何数据进行hash#consistent一致性hash,如果不添加则便是静态hash与ip_hash相同hash $remote_addr consistent;对原地址进行bash，不过做了一致性hash 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; hash $remote_addr consistent; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server1 web_server1 web_server1 123456789101112131415161718对用户请求的uri进项hash(适用于后端服务器为缓存服务器，提高命中率)hash $request_uri consistent; ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; hash $request_uri consistent; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; 1234nginx+才支持nginx-sticky-module的使用（基于cookie的会话保持）使用sticky_cookie_insert启用会话亲缘关系，这会导致来自同一客户端的请求被传递到一组服务器在同一台服务器。与ip_hash不同之处在于，它不是基于IP来判断客户端的，而是基于cookie来判断。因此可以避免上述ip_hash中来自同一局域网的客户端和前段代理导致负载失衡的情况。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的fastcgi模块]]></title>
    <url>%2F2019%2F01%2F12%2Fnginx%E7%9A%84fastcgi%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx的fastcgi模块 nginx的fastcgi模块1.1 什么是 FastCGI FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等。同时，FastCGI也被许多脚本语言支持，其中就有PHP。 FastCGI是从CGI发展改进而来的。传统CGI接口方式的主要缺点是性能很差，因为每次HTTP服务器遇到动态程序时都需要重新启动脚本解析器来执行解析，然后将结果返回给HTTP服务器。这在处理高并发访问时几乎是不可用的。另外传统的CGI接口方式安全性也很差，现在已经很少使用了。 FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 1.2 Nginx+FastCGI运行原理(nginx+fcgi_module–&gt;fpm(php))=NMP Nginx不支持对外部程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用。FastCGI接口在Linux下是socket（这个socket可以是文件socket，也可以是ip socket）。为了调用CGI程序，还需要一个FastCGI的wrapper（wrapper可以理解为用于启动另一个程序的程序），这个wrapper绑定在某个固定socket上，如端口或者文件socket。当Nginx将CGI请求发送给这个socket的时候，通过FastCGI接口，wrapper接收到请求，然后派生出一个新的线程，这个线程调用解释器或者外部程序处理脚本并读取返回数据；接着，wrapper再将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx；最后，Nginx将返回的数据发送给客户端。这就是Nginx+FastCGI的整个运作过程， ngx_http_fastcgi_module模块： 1、fastcgi_pass address; address为fastcgi server的地址； location, if in location； 2、fastcgi_index name; fastcgi默认的主页资源; 3、fastcgi_param parameter value [if_not_empty]; 设置应该传递给FastCGI服务器的参数。该值可以包含文本、变量及其组合。(用于向后端的fastcgi或者fpm_server来传递参数) 12345678910111213141516171819202122232425262728293031323334353637383940414243#安装完nginx时在目录中就有fastcgi_paeams文件，里面装的时nginx给fpm服务传递的参数，（每个默认的参数都要启动生效，每一个默认值fastcgi服务端执行fpm服务时要配置启用的参数的默认设定） ~]# ls /etc/nginx/ fastcgi_params 两台主机 client proxy_nginx_server :yum install nginx -y fpm_server :yum install php-fpm编辑代理nginx_server server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; location ~* \.php$ &#123; fastcgi_pass 172.18.135.2:9000; #定义如果客户端请求的资源为.php结尾的文件转发到fpm_server服务器上 fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; #/data是在fpm_server上 include fastcgi_params; &#125; ~]# nginx -t ~]# nginx -s reloadfpm_server创建.php文件供客户端访问 ~]# cat /data/info.php &lt;?php phpinfo(); ?&gt; 编辑fpm的配置文件的允许监听的地址 ~]# vim /etc/php-fpm.d/www.conf listen = 172.18.135.2:9000 listen.allowed_clients = any ~]# systemctl restart php-fpmclient访问 http://172.18.135.1/info.php 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253使用压测工具进行压测（ab） ~]# yum install httpd-tools -y ab 命令（n&gt;c） -c 模拟并发的数量 -n 指定请求的个数对nginx调度器进行压测 ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php Requests per second: 2389.18 [#/sec] (mean)----------------------------------------------------------------------对nginx调度器的fastcgi模块启用缓存#http上下文定义键 ~]# vim /etc/nginx/nginx.conf http &#123; fastcgi_cache_path /var/cache/fastcgi levels=1:1:2 keys_zone=fastcgi:10m max_size=2G; .... #调用http定义的键 server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; location ~* \.php$ &#123; fastcgi_pass 172.18.135.2:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; fastcgi_cache fastcgi; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; &#125; ~]# mkdir -p /var/cache/fastcgi ~]# nginx -t ~]# nginx -s reload再次访问测试验证是否加速 ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php #第一次访问生成缓存 [root@centos7 ~]# tree /var/cache/fastcgi/ /var/cache/fastcgi/ └── 5 └── 6 └── af └── 48fe86dcef16714ba3e4f82bba2daf65 3 directories, 1 file ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php Requests per second: 10657.12 [#/sec] (mean) 4、fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 5、fastcgi_cache zone | off; 调用指定的缓存空间来缓存数据；http, server, location 6、fastcgi_cache_key string; 定义用作缓存项的key的字符串； 7、fastcgi_cache_methods GET | HEAD | POST …; 为哪些请求方法使用缓存； 8、fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9、fastcgi_cache_valid [code …] time; 不同的响应码各自的缓存时长； 10、fastcgi_keep_conn on | off; 默认情况下，FastCGI服务器会在发送响应后立即关闭连接。但是，当这个指令被设置为on时，nginx将指示FastCGI服务器保持连接打开。 范例：fastcgi模块内键有两个url可以输出fastcgi健康状态以及健康页面信息1234567891011121314151617181920212223242526272829303132333435363738fastcgi_server配置文件中开启两个内建的url(这两个url的输出默认使用的fastcgi协议) ~]# vim /etc/php-fpm.d/www.conf 121 pm.status_path = /pm_status 133 ping.path = /ping #ping·pong ~]# systemctl restart php-fpm编辑nginx代理 ~]# vim /etc/nginx/nginx.conf location ~* ^/(pm_status|ping)$ &#123; fastcgi_pass 172.18.135.2:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; &#125; ~]# nginx -t ~]# nginx -s reload客户端访问测试 ~]# curl 172.18.135.1/pm_status pool: www process manager: dynamic start time: 12/Jan/2019:17:09:39 +0800 start since: 57 accepted conn: 1 listen queue: 0 max listen queue: 0 listen queue len: 128 idle processes: 4 active processes: 1 total processes: 5 max active processes: 1 max children reached: 0 slow requests: 0 ~]# curl 172.18.135.1/ping pong]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的proxy模块]]></title>
    <url>%2F2019%2F01%2F10%2Fnginx%E7%9A%84proxy%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx的proxy模块 nginx的proxy模块一、反向代理 1.什么是反向代理（DNAT）通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中由代理服务器向Internet上的web服务器发起请求，最终达到客户机上网的目的（也就是正向代理）。 而反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 Nginx只做请求的转发，后台有多个http服务器提供服务，nginx的功能就是把请求转发给后面的服务器，决定把请求转发给谁 ngx_http_proxy_module模块： 1、proxy_pass URL; Context: location, if in location, limit_except 作用：将用户的请求代理到哪个URL上（完成的是两个路径的映射关系） 注意：proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； 123456789101112131415161718192021222324252627282930313233343536 server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy http://hos[:port]; &#125; ... &#125; http://HOSTNAME/uri --&gt; http://host/uri proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri； server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy http://host/new_uri/; &#125; ... &#125; http://HOSTNAME/uri/ --&gt; http://host/new_uri/ 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； server &#123; ... server_name HOSTNAME; location ~|~* /uri/ &#123; proxy http://host; &#125; ... &#125; http://HOSTNAME/uri/ --&gt; http://host/uri/； 范例：实现简单的代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150使用docker镜像创建两个web_server服务器#容易已经绑定宿主机的存储卷，默认安装完docker生成的一个net的地址桥#无需暴漏端口，因为此web_server仅用于和前端内网中的nginx_proxy_server通讯不需要直接和客户端进行通讯 ~]# docker run --name webser1 -it --network bridge -v /vols/websrv1:/vole/htdocs1 busybox / # httpd -f -v -h /vole/htdocs1 #-f 运行在前台 #-v 打印信息在前台 #-h 指定家目录 ~]# docker run --name webser2 -it --network bridge -v /vols/websrv2:/vole/htdocs1 busybox / # httpd -f -v -h /vole/htdocs1在宿主机上创建对应的存储卷上对应的网页文件 ~]# mkdir -p /vols/websrv1 ~]# mkdir -p /vols/websrv2 ~]# echo "webser1" &gt; /vols/websrv1/index.html ~]# echo "webser2" &gt; /vols/websrv2/index.html ~]# curl 172.17.0.2 websrv1 ~]# curl 172.17.0.3 websrv2配置nginx代理 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; location / &#123; proxy_pass http://172.17.0.2/; #proxy_pass的优先级比root的优先级要高 ,/有和无是有区别的。 &#125; &#125; ~]# nginx -t ~]# nginx -s reload客户端请求nginx代理的地址 ~]# curl 172.18.135.1:8080 websrv1-----------------------------------------------------------------------###实验说明/有和无是有区别的##无/## server &#123; listen 8080; root /nginx/html; location /bbs &#123; proxy_pass http://172.17.0.2; &#125; &#125; ~]# mkdir -p /nginx/html/ddb ~]# mkdir -p /nginx/html/bbs ~]# echo "/nginx/html/bbs/index.html" &gt; /nginx/html/bbs/index.html测试 ~]# curl 172.18.135.1:8080/bbs /nginx/html/bbs/index.html查看web_server打印的日志 [::ffff:172.17.0.1]:50650: response:404##有/## server &#123; listen 8080; root /nginx/html; location /bbs &#123; proxy_pass http://172.17.0.2/; &#125; &#125; ~]# curl 172.18.135.1:8080/bbs websrv1查看web_server打印的日志 [::ffff:172.17.0.1]:50648: response:200··············································································范例：使用正则表达式匹配客户端请求的文件进行代理配置nginx代理#"proxy_pass"不能在正则表达式给出的位置中 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; location ~* \.(jpg|png|jpeg) &#123; #如果客户端请求这些资源则代理则将客户段的请求代理到web_server的/images/目录下文件 proxy_pass http://172.17.0.1; #proxy_pass定义的匹配条件后面不可以url（客户的请求资源url和自动补在服务器上，如果客户请求的http://172.18.135.1:8888/bbs/a.jpg,如果后端的web服务器上有这个资源，则客户端也回加载此图片（后面的uri是原封不动的放在后端服务器上的）） &#125; &#125; ~]# nginx -t ~]# nginx -s reload在web_server上放置图片提供访问（从宿主机上查找图片放在容器对应映射在宿主机上的存储卷） ~]# cd /vols/websrv1/ websrv1]# cp /usr/share/cups/www/images/smiley.jpg .客户端访问测试 http://172.18.135.1:8888/smiley.jpg 查看web_server是否接受请求 [::ffff:172.17.0.1]:50720: response:200##测试请求web_server下的其他url的图片宿主机放置资源在存储卷上bbs]# pwd/vols/websrv1/bbs请求测试http://172.18.135.1:8888/bbs/profile.jpg``` - `2、proxy_set_header field value;` - 设定发往后端主机的请求报文的请求首部的值；Context: http, server, location - proxy_set_header X-Real-IP $remote_addr; - proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`范例：proxy_set_header ：将请求报文发送给后端被代理的服务器时，修改请求报文的某些或者某个首部````bash七层调度是可以操纵两路报文： 第一：把请求转给后端时，可以操作报文 第二：将后端服务器的响应发还给客户端时，可以操作报文-----------------------------------------------------------实现被调度的服务器显示的日志查看到的源地址为客户端的地址#利用变量操作客户端请求被调度的服务器的请求报文的源地址的修改#proxy_set_header X-Real-IP $remote_addr#日志查看被调度的默认的请求的客户端的地址，默认显示的不是真正的客户端的地址，显示的是调度的器的地址（请求报文的源地址）#[::ffff:172.17.0.1]:50728: response:200 （让代理服务器发请求报文时添加特定的请求首部，修改为真正的客户端地址，让后端被调度的服务器记录日志时，改为记录新的日志）编辑被调度的web服务的配置文件 1.查看后端web服务器的使用的日志的格式 CustomLog /path/to/file 格式定义（common、combined、combinedio） 2.修改web后端使用的日志的格式 LogFormat "%&#123;X-Real-IP&#125;i %l %u %t \"%r\" %&gt;s %b" common 3.修改nginx调度器的配置文件 ~]# vim /etc/nginx/nginx.conf server &#123; proxy_set_header X-Real-IP $remote_addr; listen 8888; location ~* \.(jpg|png|jpeg) &#123; proxy_pass http://172.18.135.2; &#125; &#125; ~]# nginx -t ~]# nginx -s reload 4.客户端访问调度器并查看后端的web_server服务器的访问日志信息 ~]# cat /var/log/httpd/access_log 172.18.135.5 - - [12/Jan/2019:10:08:05 +0800] "GET /smiley.jpg HTTP/1.0" 200 14120 (此地址文真实客户端地址) 3、proxy_cache_path 定义可用于proxy功能的缓存；Context: http proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 范例： 定义可用于proxy功能的缓存12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970页面缓存（http服务）#nginx作为反向代理服务器时支持缓存功能的，缓存是由缓存模块个缓存机制来提供的，对于缓存服务来说要想启用起来，是由代理模块自带的，在nginx上想要使用代理，必须要匹配模式，在nginx中的缓存是要先定义在使用的，levels=levels #定义使用几级索引，做多使用三级=每级索引当中打算使用几个字符创建多少个子项（一个字符是16个，两个字符就是256个，2^8）#inactive=time 非活动时间#max_size=size 整个磁盘空间用于缓存的时间的空间的大小#manager_sleep=time 每隔多长时间检查缓存的有效性#manager_threshold=time 如果缓存时间沾满，如何使用LRU（最近最少使用算法）算法激活，并清理缓存范例：配置nginx的proxy功能的页面缓存#直接定义在http的上下文# proxy_cache_path定义缓存的放置路径，并确保定义的缓存的目录的存在,应该放置在当前主机上的io性能最好的设备上（固态硬盘）（缓存对cpu的压力小，但是最磁盘io的压力很大）#levels=1:1:1 定义缓存的路由级别，每个路由有16个子目录#keys_zone 定义内存空间的路径和定义内存数据或者索引数据的缓存（K/V）#max_size=size 指定磁盘空间的大小#proxy_cache 调用缓存的名称#proxy_cache_key $schene$proxy_host$is_args$args; #定义使用的键bash（协议：服务器地址：端口：请求的uri）如果是服务器的地址使用了泛域名解析，则要去掉协议和服务器地址#proxy_cache_valid 定义缓存进来的键被保留多长时间#proxy_cache_methods(默认为GET、POST)(对web服务器来讲通常仅缓存读操作，不缓存写操作，查询缓存时只对读操作查缓存)#proxy_cache_use_stale (缓存的内容不一定是权威的内容，所有能够响应客户端的前提是后端服务器时ok的，如果客户的某一请求来了服务器时不在了，代理联系不到后端的服务器，并且缓存中的内容已经过期了客户端的且缓存中的内容还是存在的，决定代理服务器还要不要给客户端返回结果)off代表如果服务器有问题时代理服务器不拿缓存中数据去对客户端进行响应，定义服务器出现问题是代理继续使用未过期的缓存进行响应proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;编辑nginx代理节点的配置文件#定义缓存功能 ~]# vim /etc/nginx/nginx.conf http &#123; proxy_cache_path /var/cache/nginx levels=1:1:2 keys_zone=webcache:10m max_size=2G; .... #调用缓存 server &#123; proxy_set_header X-Real-IP $remote_addr; listen 8888; location ~* \.(jpg|png|jpeg) &#123; proxy_pass http://172.18.135.2; proxy_cache webcache; proxy_cache_key $request_uri; #设置仅使用uri当客户端请求的bash的键 proxy_cache_valid 200 302 10m; #根据用户第一次请求的响应码定义缓存的时长 proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; &#125; &#125; ~]# nginx -t ~]# nginx -s reload 客户端进行访问测试 http://172.18.135.1:8888/smiley.jpg调度器查看是否生成缓存 ~]# tree /var/cache/nginx /var/cache/nginx └── 2 #一级桶 └── b #二级桶 └── df #三级桶 └── ac2582e15d13e9fa21b8da128b16dfb2 3 directories, 1 file ~]# cat /var/cache/nginx/2/b/df/ac2582e15d13e9fa21b8da128b16dfb2 ޷ 9\YJ9\u9\¼b]"3728-57f392ebe4ca8" KEY: /smiley.jpg HTTP/1.1 200 OK Date: Sat, 12 Jan 2019 05:05:11 GMT Server: Apache/2.4.6 (CentOS) Last-Modified: Sat, 12 Jan 2019 02:00:57 GMT ETag: "3728-57f392ebe4ca8" Accept-Ranges: bytes Content-Length: 14120 Connection: close Content-Type: image/jpeg 4、proxy_cache zone | off; 指明要调用的缓存，或关闭缓存机制；Context: http, server, location 5、 proxy_cache_key string; 缓存中用于“键”的内容； 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 6、proxy_cache_valid [code …] time; 定义对特定响应码的响应内容的缓存时长； 定义在http{…}中； proxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=pxycache:20m max_size=1g; 定义在需要调用缓存功能的配置段，例如server{…}； proxy_cache pxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; 7、proxy_cache_use_stale proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off …; 确定在与代理服务器通信期间发生错误时，可以在哪些情况下使用陈旧的缓存响应。 8、proxy_cache_methods GET | HEAD | POST …; 如果在这个指令中列出了客户机请求方法，那么响应将被缓存。“GET”和“HEAD”方法总是添加到列表中，但是建议显式地指定它们。 9、proxy_hide_header field; #操纵发送给客户端的响应报文 默认情况下，nginx不传递头字段“Date”、“Server”、“X-Pad”和“X-Accel-…”从代理服务器到客户机的响应。proxy_hide_header指令设置不传递的其他字段。 (参考文档：http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_purge) 10、proxy_connect_timeout time; 定义与代理服务器建立连接的超时。应该注意的是，这个超时通常不能超过75秒。 默认为60s；最长为75s； 11、proxy_read_timeout time; 定义从代理服务器读取响应的超时。超时仅在两个连续读取操作之间设置，而不是为整个响应的传输设置。 12、proxy_send_timeout time; 设置将请求发送到代理服务器的超时。仅在两个连续的写操作之间设置超时，而不是为整个请求的传输设置超时。如果代理服务器在此期间没有收到任何消息，则连接将关闭。 ngx_http_headers_module模块 ngx_http_headers_module模块允许将“Expires”和“Cache-Control”报头字段以及任意字段添加到响应报头中。 向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值； 1、add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; add_header X-Accel $server_name; 2、expires [modified] time; expires epoch | max | off; 用于定义Expire或Cache-Control首部的值；]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置和使用基础--Webserver]]></title>
    <url>%2F2019%2F01%2F09%2Fnginx%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%802%2F</url>
    <content type="text"><![CDATA[Nginx-Webserver:第二章：配置指令 程序环境 程序环境 配置文件的组成部分： 主配置文件：nginx.conf include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主程序文件：/usr/sbin/nginx Unit File：nginx.service 配置： 主配置文件的配置指令： directive value [value2 …]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name nginx支持三类功能在配置文件中放在三个不同的上下文配置段中（一般这三种配置不会同时出现） web http{} mail mail{} 四层调度机制 stream{} 主配置文件结构：1234567891011121314151617181920212223242526272829303132333435 main block：主配置段，也即全局配置段； event &#123; ... &#125;：事件驱动相关的配置； http &#123; ... &#125;：http/https 协议相关的配置段； mail &#123; ... &#125; stream &#123; ... &#125; http协议相关的配置结构 http &#123; ... ...：各server的公共配置 server &#123; ... &#125;：每个server用于定义一个虚拟主机； server &#123; ... listen #监听端口 server_name #服务器名称 root #网页文件根目录 alias location [OPERATOR] URL &#123; ... if CONDITION &#123; ... &#125; &#125; &#125; &#125; 配置指令main配置段常见的配置指令： 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user Syntax: user user [group]; Default: user nobody nobody; Context: main 定义工作进程使用的用户和组凭据。如果省略组，则使用名称与user相同的组。 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置： 1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; nginx进程的CPU亲缘性； CPU MASK：(cpu位掩码称为bit mask) 00000000： 0000 0001：0号CPU 0000 0010：1号CPU 0000 0100：2号CPU … … 0000 0011：0和1号CPU； 优点：提升缓存的命中率 context switch:会产生cpu不必要的消耗 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,20] （数字越小优先级越高，默认的值为0） 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限； time_resolution 计时器解析度，降低此值，可减少gettimeofday()系统调用的次数 调试、定位问题：如果是编译安装想要使用一下功能必须在编译时使用–with-debug功能开启 1、daemon on|off; 是否以守护进程方式运行Nignx； 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on；(适用于追踪和调试问题，开启以单进程模式运行nginx，主进程直接处理用户的请求) 3、error_log file [level]; 错误日志和日志级别（web服务器一般有两种日志：访问日志和错误日志）123456在配置nginx.conf 的时候，有一项是指定错误日志的，默认情况下你不指定也没有关系，因为nginx很少有错误日志记录的。但有时出现问题时，是有必要记录一下错误日志的，方便我们排查问题。error_log 级别分为 debug, info, notice, warn, error, crit 默认为crit, 该级别在日志名后边定义格式如下：error_log /your/path/error.log crit; crit 记录的日志最少，而debug记录的日志最多。如果你的nginx遇到一些问题，比如502比较频繁出现，但是看默认的error_log并没有看到有意义的信息，那么就可以调一下错误日志的级别，当你调成error级别时，错误日志记录的内容会更加丰富。 事件驱动相关的配置:1234567891011121314151617181920212223242526272829303132333435363738394041#事件驱动中的参数定义决定了每一个子进程支持的并发连接数events &#123; ...&#125; ``` - `1、worker_connections number;` - 每个worker进程所能够打开的最大并发连接数数量； - 整个nginx并发连接数（进程数*每个进程可以打开的并发连接数） - worker_processes * worker_connections - 2、use [epoll|rtsig|select|poll]; - 指明并发连接请求的处理方法； - 事件驱动机制模型： use epoll; - 建议让nginx自行选择- 3、accept_mutex on | off;（是否打开互斥锁） - 处理新的连接请求的方法；on意味着由各worker轮流处理新请求，Off意味着每个新请求的到达都会通知所有的worker进程；- 4、lock_file file; - accept_mutex用到的锁文件的路径；## http协议的相关配置```bashhttp协议的相关配置： http &#123; #http全局配置，可共享给多个server使用 ... ... server &#123; #一到多个server,每一个server用来定义一个虚拟主机 ... listen # server_name root location [OPERATOR] /uri/ &#123; ... &#125; &#125; server &#123; ... &#125; &#125; 与套接字相关的配置 1、server { … } 配置一个虚拟主机； 12345server &#123; listen address[:PORT]|PORT; #指定要监听的地址和端口，仅指定监听的端口，表示监听本机可用的所有此端口，或者指定地址，代表监听此地址的80端口，或者仅监听在本机的unix.socket server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; &#125; 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] default_server：设定为默认虚拟主机； ssl：限制仅能够通过ssl连接提供服务； http2:要求支持http2协议； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小； 3、server_name name …; 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串； 支持*通配任意长度的任意字符； server_name .magedu.com www.magedu. 支持~起始的字符做正则表达式模式匹配； server_name ~^www\d+.magedu.com$ 匹配机制： - (1) 首先是字符串精确匹配; - (2) 左侧*通配符； - (3) 右侧*通配符； - (4) 正则表达式；（尽量不要使用正则表达式，引擎在处理字符串影响效率） 4、 tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项； tcp_nopush on|off; 在sendfile模式下，是否启用TCP_CORK选项； 5、sendfile on | off; 是否启用sendfile功能； 定义路径相关的配置 6、root path; 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； 可用的位置：http（对整个http生效）, server（仅对一个server生效）, location（仅对一个location生效）, if in location； 7、location [ = | ~ | ~* | ^~ ] uri { ... } 用来表达nginx中，一组有匹配模式的url路径下的资源访问的属性定义和访问控制机制的 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射； ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849客户请求到收到请求，服务端的匹配路由 Nginx--&gt;server_name server server Server--&gt;Location location&#123;&#125; #仅为一个location所匹配处理 if if location&#123;&#125;=：对URI做精确匹配；例如, http://www.9727.top/，http://www.9727.top/index.html location = / &#123; ... &#125; ~：对URI做正则表达式模式匹配，区分字符大小写； ~*：对URI做正则表达式模式匹配，不区分字符大小写； ^~：对URI的左半部分做匹配检查，不区分字符大小写； 不带符号：以URI为前缀的所有uri； 匹配优先级：=, ^~, ～/～*，不带符号； 让我们通过一个例子来说明以上内容： location = / &#123; [ configuration A ] &#125; location / &#123; [ configuration B ] &#125; location /documents/ &#123; [ configuration C ] &#125; location ^~ /images/ &#123; [ configuration D ] &#125; location ~* \.(gif|jpg|jpeg)$ &#123; [ configuration E ] &#125; “ /”请求将匹配配置A，“ /index.html”请求将匹配配置B，“ /documents/document.html”请求将匹配配置C，“ /images/1.gif”请求将匹配配置D，“ /documents/1.jpg”请求将匹配配置E. “ @”前缀定义命名位置。这样的位置不用于常规请求处理，而是用于请求重定向。它们不能嵌套，也不能包含嵌套位置。 范例： 用来表达nginx中，一组有匹配模式的url路径下的资源访问的属性定义和访问控制机制的12345678910111213141516171819~]# vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name www.centos.com; root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123;&#125;&#125; ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful~]# nginx -s reload~]# curl 172.18.135.1:8080/web/nginx/html/index.html~]# curl 172.18.135.1:8080/images//ngx/html/images/index.html 8、alias path; 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； 范例：alias path123456789101112131415161718192021222324252627282930313233#aliasserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; alias "/ngx/html";&#125;&#125;~]# curl 172.18.135.1:8080/images//ngx/html/index.html#rootserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; root "/ngx/html";&#125;&#125;~]# curl 172.18.135.1:8080/images//ngx/html/images/index.html 9、index file …; 默认资源；http, server, location； 10、error_page code ... [=[response]] uri; 12345#定义一个错误页面即错误重定向 error_page 404 /404.html; location = /404.html &#123; root "/www/error_pages"; &#125; 范例：error_page code ... [=[response]] uri; 定义一个错误页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152status(状态码)：告诉客户端的请求发生的结果：1XX：100-101，信息提示2XX：200-206，成功类型信息3XX：300-305，重定向的资源4XX：400-415，错误类型的信息，客户端的错误，5XX：500-505，错误类型错误，服务器端错误常用的状态码：200：:成功响应，请求的所有数据通过相应报文的entity-body部分发送，OK301：请求的URL执行的资源已经被删除；但在相应报文中通过首部Location指明了资源的所在位置；Moved Permanently （永久重定向）302：与301相似，但在相应报文中通过首部Location指明了资源现在所处临时新位置；Found （临时重定向）304：客户端发出了条件式请求，但服务器的资源为曾发生改变，则通过相应此响应状态码通知客户端，Not Modified401：需要输入账号和密码认证方能访问资源：Unauthorized403：请求被禁止：Forbidden404：服务器无法找到客户端请求的资源：Not Found500：服务器内部错误：InternalServerError502：:代理服务器从后端服务器中收到的一条伪响应：Bad Gateway定义一个404服务器无法找到客户端请求的资源的错误页面~]# vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html"; &#125; location /images &#123; root "/ngx/html"; &#125; error_page 404 /404.html;&#125;~]# curl 172.18.135.1:8080/aaaa//web/nginx/html/404.htmlserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; root "/ngx/html";&#125; error_page 404 /xx.html; location = /xx.html&#123; root "/etc/nginx/error/"&#125; &#125; 11、try_files file … uri; 定义客户端请求的相关配置 12、keepalive_timeout timeout [header_timeout]; 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 13、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 14、keepalive_disable none | browser …; 对哪种浏览器禁用长连接； 15、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 16、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 17、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置 18、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 19、limit_except method … { … } 限制对指定的请求方法之外的其它方法的使用客户端； 1234limit_except GET &#123; allow 192.168.1.0/24; deny all; &#125; 文件操作优化的配置 20、aio on | off | threads[=pool]; 是否启用aio功能； 21、directio size | off; 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m; 22、open_file_cache off; open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息： (1) 文件的描述符、文件大小和最近一次的修改时间； (2) 打开的目录结构； (3) 没有找到的或者没有权限访问的文件的相关信息； max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现缓存管理； inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项； 23、open_file_cache_valid time; 缓存项有效性的检查频率；默认为60s; 24、open_file_cache_min_uses number; 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项； 25、open_file_cache_errors on | off; 是否缓存查找时发生错误的文件一类的信息；modules模块ngx_http_access_module模块：实现基于ip的访问控制功能 26、allow address | CIDR | unix: | all; 27、deny address | CIDR | unix: | all; http, server, location, limit_except 该ngx_http_access_module模块允许限制对某些客户端地址的访问。 访问也可以通过 密码，子请求的 结果或JWT来限制。通过地址和密码同时限制访问由satisf指令控制。 1234567891011示例配置（默认为allow）location / &#123; deny 192.168.1.1; #单独拒绝此地址 allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; # 拒绝所有&#125;按顺序检查规则，直到找到第一个匹配项。在此示例中，仅允许IPv4网络访问 10.1.1.0/16并且192.168.1.0/24 不包括地址192.168.1.1，以及IPv6网络2001:0db8::/32。如果有很多规则， 最好使用 ngx_http_geo_module模块变量。 ngx_http_auth_basic_module模块:实现基于用户的访问控制，使用basic机制进行用户认证； 28、auth_basic string | off; 29、auth_basic_user_file file; 1234567 location /admin/ &#123; alias /webapps/app1/data/; auth_basic "Admin Area"; #注释信息 auth_basic_user_file /etc/nginx/.ngxpasswd; #放置授权加密可以访问的用户名密码文件路径&#125; 注意：htpasswd命令由httpd-tools所提供； 范例：基于ngx_http_auth_basic_module模块:实现基于用户的访问控制，使用basic机制进行用户认证 1234567891011121314151617181920212223242526272829303132333435363738配置nginx实现basic加密认证访问 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/ngx/html"; location / &#123; auth_basic "prvate images"; #注释信息 auth_basic_user_file "/etc/nginx/.ngxpasswd"; #存放用户名密码的文件定义 &#125; &#125;安装htpasswd命令htpasswd命令由httpd-tools所提供 ~]# yum install httpd-tools -y创建存放实现加密的用户名和密码文件 -c 仅用于第一次创建用户时使用 -m 指定MD5加密算法 -b 直接给定密码，不使用交互式 ~]# htpasswd -c -m /etc/nginx/.ngxpasswd daizhe New password: centos Re-type new password: centos Adding password for user daizhe #创建daizhe用户 ~]# htpasswd -m -b /etc/nginx/.ngxpasswd nn centos Adding password for user nn查看创建的加密的账号以及测试访问 ~]# cat /etc/nginx/.ngxpasswd daizhe:$apr1$5kVocZ7d$KIumQtuh5wGySn0iUomd30 nn:$apr1$ayW.DtQE$sN5QCmC4enr.a1rUkTHHK0 ~]# nginx -t ~]# nginx -s reload测试 ngx_http_stub_status_module模块：用于输出nginx的基本状态信息； 30、stub_status; 配置示例： 12345678910111213141516171819202122232425262728293031323334location /basic_status &#123; stub_status; &#125; ``` - Active connections: 291 - server accepts handled requests- 16630948 16630948 31070465 - Reading: 6 Writing: 179 Waiting: 106 - Active connections: 活动状态的连接数； - accepts：已经接受的客户端请求的总数； - handled：已经处理完成的客户端请求的总数； - requests：客户端发来的总的请求数； - Reading：处于读取客户端请求报文首部的连接的连接数； - Writing：处于向客户端发送响应报文过程中的连接数； - Waiting：处于等待客户端发出请求的空闲连接数；范例：ngx_http_stub_status_module模块：用于输出nginx的基本状态信息；```bash~]# vim /etc/nginx/nginx.conf &#125; location = /ngx_status &#123; #声明访问指定的location可以查看nginx的基本状态信息 stub_status; &#125;~]# nginx -t~]# nginx -s reload[root@host-192-168-35-104 ~]# curl 172.20.101.158:8080/ngx_status Active connections: 1 server accepts handled requests 9 9 8 Reading: 0 Writing: 1 Waiting: 0 ngx_http_log_module模块:gx_http_log_module模块以指定的格式写入请求日志。 (访问日志) 31、log_format name string ...; string可以使用nginx核心模块及其它模块内嵌的变量； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#string可以使用nginx核心模块及其它模块内嵌的变量#string可以命名为一下变量$bytes_sent发送到客户端的字节数$connection连接序列号$connection_requests通过连接发出的当前请求数（1.1.18）$msec以秒为单位的时间，日志写入时的分辨率为毫秒$pipe“ p”如果请求是流水线的，“ .”否则$request_length请求长度（包括请求行，标题和请求正文）$request_time以毫秒为单位请求处理时间（以秒为单位）; 从客户端读取第一个字节之间经过的时间，并将最后一个字节发送到客户端后的日志写入$status回应状态$time_iso8601当地时间采用ISO 8601标准格式$time_local通用日志格式的本地时间$remote_addr 远程客户端地址$http_referer~]# curl -e "www.baidu.com" 172.20.101.158:8080/ngx_status~]# cat /var/log/nginx/access.log 172.20.101.158 - - [10/Jan/2019:10:18:57 +0800] "GET /ngx_status HTTP/1.1" 200 100 "www.baidu.com" "curl/7.29.0" "-"按字母顺序排列的变量索引http://nginx.org/en/docs/varindex.html#查看安装完nginx默认定义的日志的格式#默认放置在http上下文，对所有的sever生效http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"';#调用此日志格式access_log /var/log/nginx/access.log main; 32、access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置； buffer=size flush=time 33、open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; #关闭 缓存各日志文件相关的元数据信息； max：缓存的最大文件描述符数量； min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项； inactive：非活动时长； valid：验正缓存中各缓存项是否为活动项的时间间隔； ngx_http_gzip_module：(压缩传输)ngx_http_gzip_module模块是一个过滤器，它使用“gzip”方法压缩响应。这通常有助于将传输数据的大小减少一半甚至更多 1、gzip on | off; （总开关，是否开启压缩功能）#cpu资源紧缺尽量不要压缩，节省带宽，cpu不紧缺则可以考虑开启压缩传输（对文本文件进行压缩，其他格式的文件内容本身就是压缩的，压缩比不大，或许还可以增长） 2、gzip_comp_level level; 设置响应的gzip压缩级别。可接受的值在1到9之间。（数字越大，压缩比越高，也越消耗cpu） 3、 gzip_disable regex …; 禁用“User-Agent”头字段匹配任何指定正则表达式的请求的响应gzipping。 4、 gzip_min_length length; 启用压缩功能的响应报文大小阈值； (资源压缩的最小下限阀值，一个资源已经3k了还怎么压缩，设置最小的下限) 5、gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小；（内存资源较为充沛时启用，可以加速压缩的速度） 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any …; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用压缩 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； any：对任何可以压缩的内容都压缩 7、gzip_types mime-type …; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；（纯文本和html格式的内容默认就是压缩的内容） 范例：启用压缩123456789101112131415161718192021222324252627定义服务器的压缩功能#定义在http上下文对所有的server都生效，定义在单独的server中仅对单个server生效 ~]# vim /etc/nginx/nginx.conf http &#123; ......... gzip on; #开启压缩 gzip_comp_level 6; #压缩比为6 gzip_min_length 64; #低于64个字节则不压缩 gzip_proxied any; #任何被代理的内容都压缩 gzip_types text/xml text/css application/javasctipt; #压缩的文件类型 ......... ~]# nginx -t ~]# nginx -s reload使用curl命令请求服务端进行压缩 [root@host-192-168-35-104 ~]# curl --compressed -I 172.20.101.158 HTTP/1.1 200 OK Server: nginx/1.12.2 Date: Thu, 10 Jan 2019 03:39:11 GMT Content-Type: text/html Last-Modified: Thu, 10 Jan 2019 03:24:04 GMT Connection: keep-alive ETag: W/"5c36bad4-1293ae" Content-Encoding: gzip测试 ngx_http_ssl_module模块： 1、 ssl on | off; 为给定的虚拟服务器启用HTTPS协议。 2、ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3、ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4、ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5、ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； [shared:name:size]：在各worker之间使用一个共享的缓存； 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 范例：ssl加密传输nginx12345678910111213141516171819202122232425262728 ~]# vim /etc/nginx/nginx.conf server &#123; listen 443 ssl; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #加密算法，不写使用默认的加密算法 ssl_certificate /etc/nginx/certs/nginx.crt; #私钥 ssl_certificate_key /etc/nginx/certs/nginx.key; #证书 ssl_session_cache shared:SSL:10m; #加密传输的缓存的大小10m ssl_session_timeout 10m; location / &#123; root "/web/nginx/html" &#125; &#125; 生成自签名的证书 ~]# cd /etc/nginx/ nginx]# mkdir certs nginx]# cd certs/ certs]# openssl genrsa -out nginx.key 2048 #私钥 certs]# openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj "/CN=www.centos.com" #证书测试 ~]# mkdir -p /web/nginx/html ~]# echo "123" &gt; /web/nginx/html/index.html ~]# nginx -t ~]# nginx -s reload ngx_http_rewrite_module模块：实现url重写，将用户请求的URI基于regex所描述的模式进行检查，而后完成替换； 1、rewrite regex replacement [flag] 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI； 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端； 301：永久重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302：临时重定向 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301：永久重定向 范例：将用户对bbs的访问，转成对forum的访问123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566~]# mkdir /web/nginx/html/forum~]# echo "/web/nginx/html/forum/index.html" &gt; /web/nginx/html/forum/index.html#此时对forum/index.html访问url路径为：http://172.10.101.158/forum实现用户访问http://172.10.101.158/bbs跳转到http://172.10.101.158/forum响应（bbs目录可以不存在）~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/var/www/nginx"; location /bbs/ &#123; rewrite ^/bbs/(.*)$ /forum/$1; #后面未加任何控制符相当于last&#125;&#125; #如果访问此server的/var/www/nginx/bbs则重写到此server的/var/www/nginx/forum(此格式仅限单个的重写操作写法)设置用户对bbs的访问和对forum的访问统统改为其他的其他的server访问http://www.centos.com/bbs和http://www.centos.com/forum响应的访问请求一个新的serverwww.linux.com的访问 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/var/www/nginx"; location ~* ^/(bbs|forum) &#123; rewrite ^/(bbs|froum)/(.*)$ http://www.linux.com/$2;&#125;&#125; server &#123; server_name www.linux.com; listen 8080; root "/web/nginx/forum";&#125;实现对本机的任何的不安全的172.20.101.158下的所有资源都会跳转到www.centos.com的https server &#123; 66 listen 443 ssl; 67 server_name www.centos.com 68 ssl_protocols TLSv1.1 TLSv1.2; 69 ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4- MD5; 70 ssl_certificate /etc/nginx/certs/nginx.crt; 71 ssl_certificate_key /etc/nginx/certs/nginx.key; 72 ssl_session_cache shared:SSL:10m; 73 ssl_session_timeout 10m; 74 location / &#123; 75 root "/web/nginx/html"; 76 &#125; 77 &#125; 78 7 80 server &#123; 81 listen 8080; 82 server_name 172.20.101.158; 83 root "/var/www/nginx"; 84 rewrite ^/(.*)$ https://centos.com/$1; 85 location / &#123; 86 &#125; 87 &#125;临时重定向 rewrite ^/(.*)$ https://centos.com/$1 redirect;永久重定向 rewrite ^/(.*)$ https://centos.com/$1 permanent; 2、return return code [text]; return code URL; return URL; 3、 rewrite_log on | off; 是否开启重写日志； 4、 if (condition) { … } 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令；一般用在：server, location； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 5、set $variable value; #在nginx里自己定义变量 用户自定义变量 ； ngx_http_referer_module模块：ngx_http_referer_module模块用于阻止“Referer”头字段中值无效的请求访问站点。引用者，显示上级url的来源（盗链） 1、valid_referers none | blocked | server_names | string …; 定义referer首部的合法可用值(合法的链接)； none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*.a.com； 范例:防盗链12345678910111213141516171819#定义正常引用和非正常引用链接的跳转 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name 172.20.101.158; valid_referers none blocked server_name 172.20.101.158 172.20.101.82 *.centos.com; #定义允许外链访问的地址 if ($invalid_referer) &#123; #除了上面定义的地址外可以外链访问主页，其余的地址直接跳转至http://172.20.101.158:8080/; return http://172.20.101.158:8080/&#125; root "/var/www/nginx"; rewrite ^/(.*)$ https://www.daizhe.111/$1; location / &#123;&#125;&#125;-e 模拟外链来的地址~]# curl -I -e "www.baidu.com" http://172.20.101.158/]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置和使用基础--Webserver]]></title>
    <url>%2F2019%2F01%2F07%2Fnginx%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Nginx-Webserver:第一章：工作模型 Nginx简介一、Nginx的产生 Nginx是一款高性能的 HTTP 和反向代理服务器，由俄罗斯人Igor Sysoev（伊戈尔·赛索耶夫）为俄罗斯网站Rambler.ru开发的，在Rambler.ru网站平稳的运行了四年，而且俄俄罗斯超过20%的虚拟主机平台采用Nginx作为反向代理服务器。 在国内，使用nginx网站用户有：百度、京东、金山爱词霸、新浪、校内网、、淘宝、YUPOO相册、豆瓣、迅雷看看、网易、腾讯等。 二、Nginx的优点 1.高并发量：根据官方给出的数据，能够支持高达 50,000 个并发连接数的响应 2.内存消耗少：处理静态文件，同样起web 服务，比apache 占用更少的内存及资源，所有它是轻量级的 3.简单稳定：配置简单，基本在一个conf文件中配置，性能比较稳定，可以7*24小时长时间不间断运行 4.模块化程度高：Nginx是高度模块化的设计，编写模块相对简单，包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter，支持 SSL 和 TLSSNI。 5.支持Rwrite重写规则：能够根据域名、URL的不同， 将HTTP请求分发到不同的后端服务器群组。 6.低成本：Nginx可以做高并发的负载均衡，且Nginx是开源免费的，如果使用F5等硬件来做负载均衡，硬件成本比较高。 7.支持多系统：Nginx代码完全用C语言从头写成，已经移植到许多体系结构和操作系统，包括：Linux、FreeBSD、Solaris、Mac OS X、AIX以及Microsoft Windows，由于Nginx是免费开源的，可以在各系统上编译并使用。 三、Nginx的缺点 1.动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，apache作为后端处理动态请求。 2.rewrite弱：虽然nginx支持rewrite功能，但是相比于Apache来说，Apache比nginx 的rewrite 强大。 nginx特征及基础概念 nginx(web 服务器、web代理、反向代理) 调用libevent:高性能的网络服务程序库 epoll():基于事件驱动的开发好的库文件 nginx特性： 模块化设计、较好的扩展性 高可靠(组成部分一个主控进程+多个子进程组成) master—&gt;worker master主控进程负责解析配置文件，启动子进程（读取和验证配置，创建或绑定关闭套接字以及启动终止worker进程以及控制worker进程的个数，无需重新启动进程让新的配置文件加载、完成平滑版本升级等..） worker子进程才是真正响应用户请求的进程（worker子进程有多种种类：有的子进程是实现缓存加载多适用于反向代理、接受用户的请求-接收传入并处理客户端的连接请求，cache实现缓存） 低内存消耗（一个线程相应多个请求） 10000个保持连接状态模式下的连接nginx仅需2.5MB的内存 支持热部署 不停机而且更新配置文件、日志文件滚动、升级程序版本 nginx的基本功能 支持event模型 支持epool机制 支持异步IO（事件驱动） 支持内存映射 基本功能 静态资源的web服务器，能缓存打开的文件描述符 支持http、smtp、pop3协议的反向代理服务器（缓存加速、缓存在本地是基于键值对关系缓存的，键是用户请求的url,值为对应的取得的数据流极大的减轻了后端服务器的压力） 反向代理服务器：仅为接受用户请求并且自行到某个有限的服务器上去取内容（只要是把自己扮演成某个特定服务器的样子） 正向代理：代表客户端出去请求任何网站(把自己扮演成所有服务器的样子) 支持缓存加速、负载均衡机制（反向代理） 支持fastcgi(fpm,LNMP),uWSGI(python)等 模块化（非DSO机制）、过滤器zip，SSI（服务器端包含）及图像打大小调整 支持ssl 扩展功能 基于名称和ip和端口的虚拟主机 支持keepalive 支持平滑升级 定制访问日志、支持日志缓冲区 支持路径别名 支持基于ip以及用户的访问控制 支持速率限制、支持并发数限制 nginx的基本架构特性 一个master进程，生成一个或者多个worker进程 事件驱动：epoll（边缘触发）、Kqueue,/dev/poll IO复用器 select,poll,rt signal(实时信号) 支持sendfile,sendfile64 支持AIO（异步IO） 支持非阻塞模型 支持内存映射（mmap） nginx工作模式：基于非阻塞、事件驱动、由一个master进程生成多个worker线程，每一个worker响应n个请求 一般单机并发3w请求，在反代的情况下会影响其性能 nginx的模块类型 核心模块 标准的http模块（Standard http modules） 可选的http模块（Optional http modules ） 邮件模块（Mail modules） 第三方模块（3rd party modules） nginx是基于epel源安装nginx的安装配置： 官方的预制包： http://nginx.org/packages/centos/7/x86_64/RPMS/ Fedora-EPEL: 1234567891011121314151617181920212223yum安装 yum install nginx 编译安装： ~]# yum groupinstall "Development Tools" "Server Platform Development" ~]# yum install pcre-devel openssl-devel zlib-devel ~]# useradd -r nginx ~]# ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aio # make &amp;&amp; make installnginx -t #检查nginx语法格式nginx -s relod #重新服务配置文件man nginx -s signal Send a signal to the master process. The argument signal can be one of: stop, quit, reopen, reload. The following table shows the cor‐ responding system signals: stop SIGTERM quit SIGQUIT reopen SIGUSR1 reload SIGHUP]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议及io模型]]></title>
    <url>%2F2019%2F01%2F06%2Fio%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[http协议及io模型 HTTP 协议和IO模型一：HTTP协议 http协议：HyperText Transfer Procotol超文本传输协议，http协议是无状态的，监听在80端口，TCP协议上。HTTP协议的特点有以下几点： 1.支持客户/服务器模式。 2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。 由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 二：HTTP协议Procatol 在服务器不是持久连接的状况下，客户端在第一次访问服务器时服务器会记录客户端的个人标志信息，当客户端刷新或者再次访问时，服务器就要要求客户端输个人的标识信息，记录访问者的信息。也就是说在不是持久连接的状况下，服务器无法追踪访问者的来源。 1.于是就出现了 cookie和session html：HyperText Mark Language：超文标记语言 web资源： 静态文件：.jpg .gif .html .txt .js .css.mp3 .avi 动态文件：.php .jsp 2.http早期版本只能传输文本内容，到HTTP/1.0之后支持MIME。使HTTP协议支持传输多媒体信息。 MIME：Multipurpose Internet Mailextention MIME类型：Major/minor text/plain image/jpeg image/gif 3.URI:Uniform Resource Idetifier ：统一资源标识符 URL：Uniform Resource Locate：统一资源定位符 用于描述某服务特定资源的位置 格式：Scheme://Server:Poert/Path/to/resource URN：Uniform Resource Naming：统一资源命名符。 URL方案：scheme 服务器地址：IP：Port 资源路径 基本语法： &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 4.http事务 （请求—&gt;响应） request:请求报文 报文格式 &lt;method&gt;&lt;URL&gt;&lt;version&gt;&lt;HEADERS&gt;&lt;body&gt; 请求的方法.url.协议版本.请求报文的首部.主体 response:响应报文 响应报文 &lt;version&gt;&lt;status&gt;&lt;reason phrase&gt;&lt;HEADERS&gt;&lt;body&gt; 协议的版本.状态码.原因短语.响应报文的首部.主体 协议格式 文本 二进制 5.method：请求的方法： 常用请求的方法： GET：从服务器获取一个资源 HEAD：只从服务器获取文档的响应首部 POST：向服务器发送要处理的数据 PUT：将请求的主题部分存储服务器上 DEETE：强求删除服务器上指定的文档 TRACE：追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 6.status(状态码)：告诉客户端的请求发生的结果： 1XX：100-101，信息提示 2XX：200-206，成功类型信息 3XX：300-305，重定向的资源 4XX：400-415，错误类型的信息，客户端的错误， 5XX：500-505，错误类型错误，服务器端错误 常用的状态码： 200：:成功响应，请求的所有数据通过相应报文的entity-body部分发送，OK 301：请求的URL执行的资源已经被删除；但在相应报文中通过首部Location指明了资源的所在位置；Moved Permanently （永久重定向） 302：与301相似，但在相应报文中通过首部Location指明了资源现在所处临时新位置；Found （临时重定向） 304：客户端发出了条件式请求，但服务器的资源为曾发生改变，则通过相应此响应状态码通知客户端，Not Modified 401：需要输入账号和密码认证方能访问资源：Unauthorized 403：请求被禁止：Forbidden 404：服务器无法找到客户端请求的资源：Not Found 500：服务器内部错误：InternalServerError 502：:代理服务器从后端服务器中收到的一条伪响应：Bad Gateway 7.hearders首部： 通用首部： Date：报文的创建时间 Connection：连接状态，keep-alive,close via：显示报文经过的中间节点 Cache-Control：控制缓存 no-cache： max-age Transfer-Encoding WEB 服务器表明自己对本响应消息体（不是消息体里面的对象）作了怎样的编码，比如是否分块（chunked），例如：Transfer-Encoding: chunked pragma 上图为请求首部： Accept：通过服务器自己能够接受的媒体类型 Accept_Charset Accept_Encoding：告诉服务器自己能接受的编码格式，如gzip Accept-Language：通知服务器自己能接受的语言 Host：请求的服务器名称或者端口号 Referer：包含了当前正在请求的资源的上一级资源。 User-Agent：客户端代理 7.1条件式请求首部 Expect： If-Modified-Since：自从指定的时间之后，请求的资源是否发生过修改 If-Unmodufied-Since： If-None-Match：本地缓存中存储的文档的ETag标签是否与服务器文档的Etag不匹配。 If-Match; 7.2安全请求首部： Authorization:向服务器发送认证信息，如账号密码 Cookie：客户端向服务器发送cookie Cookie2： 7.3代理请求首部： Proxy-authorization:向代理服务器认证 8.响应首部： 信息性： Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多种表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其他首部列表 安全响应首部： Set-Cookie：向客户端设置Cookie Set-Cookie2 WWW-Authenticate：来自服务器的对客户端质询认证表单 9.实体首部： Allow：列出次实体可使用的请求方法： Location：告诉客户端真正的实体位于何处 Content-encoding：编码格式 Content-language Content-Length：实体的长度 Content-Location：实体真正所在的位置 Content-Type：主体的对象类型 缓存相关： Etag:实体的扩展标签 Expires：实体的过期时间 三：web页面，多个资源 浏览器自身的限制是针对于单一域名访问的限制，最多能打开几个线程进行访问，。而在一个公司网站使用多个域名的话，当用户使用浏览器访问时，浏览器会针对不同的域名开启多个线程来访问页面资源。如，在单一域名 www.nginx.com进行访问，浏览器可能开启2个线程进行页面资源的访问。假如在 www.nginx.com 域名下的图片资源又单独使用一个域名 www.image.com 。那么浏览器会再次开启两个线程进行访问。所以在公司内部使用多个域名，这也是提升访问速度的一种方法。 1.web服务器的认证： 基于IP认证： 基于用户认证： basic认证 digest认证 2.web服务器的资源映射 a.DocumentRoot b.路径别名Alias c.虚拟主机DocumentRoot b.用户家目录DocumentRoot 3.支持第三方模块：支持模块的动态加载 四：一次完整的http请求 （1）建立连接或处理连接：接收客户端请求或拒绝请求 （2）接收请求 接收来自网络的请求报文对某一个资源的请求 并发服务器访问响应模型（Web I/O） 单进程I/O机结构：启动一个进程处理用户请求，而且一次只处理一个请求，多个请求被串行响应。 多进程I/O结构：并行启动多个线程，每个进程响应一个请求，一个请求称为一个pv。 复用I/O 结构：一个进程响应多个n个请求 多线程模型：一个进程生成多个线程，每个线程响应一个用户请求。 事件驱动机制：事件回调来完成事件请求：event-driven 复用的多进程I/O结构：启动多个（m）进程，每个进程响应n个请求。 c10K问题 :1w个并发连接： （3）处理请求：对请求报文进行解析，并获取请求的资源及请求方法等相关信息 元数据：请求报文首部 请求方法&lt;method&gt; &lt;method&gt;&lt;URL&gt;&lt;VerSion&gt; （4）访问资源:获取请求报文中请求的资源 web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源，这些资源放置在本地文件系统某路径下，此路径通常为DocRoot web服务器资源路径的映射方式： a.docroot b.路径别名 c.虚拟主机docroot b.用户家目录docroot 5）构建响应报文 MIME类型： 显示分类 魔法分类 协商分类 URL重定向： cdn web服务构建的响应并非客户端请求的资源，而是资源另一个访问路径。 游走重定向： 永久重定向： （6）发送响应报文 （7）记录日志 五：I/O模型 (1)I/O类型： 同步IO和异步IO：synchronous ,asyncronous：关注的是消息通知机制 同步：调用发出之后不会立即返回，但一旦返回，则返回最终结果。 异步：调用发出之后，被调用方立即返回消息，但返回的并不是最终结果被调用者通过状态，通知机制等通知调用者，或通过回调函数来处理结果。 阻塞IO和非阻塞IO：nlock，nonlock：关注的是调用者等待被调用者返回调用结果时的状态：（调用者的状态） 阻塞：调用结果返回之前，调用者会被挂起；调用真只有在得到调用结果之后才能继续。 非阻塞：调用者在调用结果返回之前，不会被挂起，即调用不会阻塞调用者 (2)常用的IO模型： blocking IO ：阻塞型IO noblocking IO 非阻塞型IO IO multiplexing：复用型IO signal driven IO：事件驱动型IO asynchronnous IO：异步型IO 通过磁盘IO总体解释： 一个用户进程发起一次磁盘IO调用时，将有两个阶段组成，一次是内核向磁盘取数据，存放到内存空间，另一次是数据从内存空间取出，将数据存到用户进程的内存中。真正被称为执行IO的阶段是：数据从内核内存到进程内存的过程。 阻塞型IO： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对磁盘read来说内核从磁盘获取数据）。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。 实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在此期间，线程将无法执行任何运算或响应任何的网络请求。 一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。 非阻塞IO： 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 复用型IO： 内核提供了两种调用，select（），poll(),当用户进程发起系统调用时，内核中的selecte会接受这个系统调用，并select自身将系统调用发送给内核，内核再进行准备数据和拷贝数据。当用户进程发起一次系统调用给select之后，用户进程在等待数据返回的过程中，还可以发起多次系统调用，每次系统调用都要经过select发送内核进行处理。也就是说，selects是一个代理。比如，（例子不是很恰当）公司老板向人事部发布通知要裁员，此时老板通过助理把裁员名单送给人事部。在发送和得到结果之前，公司老板还可以通过助理让销售部经理来老板办公室。其实这就相当于复用IO的模型，助理就相当于select。 select不能超过1024个。 prefork模型和worker模型就是基于复用IO模型的。并发响应有限。 调用者被阻塞者select上，但可以处理其他请求或IO 事件驱动型IO： 事件驱动型IO： 在第一阶段内：当用户进程发起系统调用时，内核会立即通知给用户进程系统调用已经收到，并且会在数据收集和准备完成时通知用户进程。此时用户进程就可以处理其他事物。 在第二阶段内：当系统将磁盘数据取到内存空间中后，通知调用者，调用者会使用回调函数进行处理，来获取数据。这个阶段会发生阻塞状况。 假如一个用户进程在第一次发送系统调用请求后，在第一阶段内，继续发送第二次系统调用请求。当用户进程第一次请求被阻塞第二阶段时，内核告知用户进程，第二次请求的数据也已经准备好了，让用户进程来获取。此时就出现了冲突状态 通知机制： 水平触发：多次通知 边缘触发：只通知一次： event模型就是使用的此IO模型。 Nginx支持此IO模型，采用的通知机制为边缘触发。 异步型IO： 异步IO模型和复用IO模型区别之处就是：在数据准备第二阶段，内核将数据直接存放到用户进程的内存空间中，不需要用户进程使用回调函数从内核中获取数据。如当一个web服务进程发送请求后，后续过程直接交给内核，在内核处理的过程时间内，此进程可以响应其他的用户请求。当内核将数据返回到进程内存中后，进程就可以把数据直接返回给用户，这大大提高了响应的速度。 Nginx也支持异步IO模型，还可以基于内存映射的机制来完成数据的发放、所以说Nginx并发能力强。 几种IO模型的比较:]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四层调度和七层调度器的区别]]></title>
    <url>%2F2019%2F01%2F05%2F%E5%9B%9B%E5%B1%82%E8%B0%83%E5%BA%A6%E5%92%8C%E4%B8%83%E5%B1%82%E8%B0%83%E5%BA%A6%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[四层调度和七层调度器的区别 （一） 简单理解四层和七层负载均衡: 1.所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。 2.所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。 比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。 3.负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。 1负载均衡分为L4 switch（四层交换），即在OSI第4层工作，就是TCP层啦。此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）。例子：LVS，F5。 2另一种叫做L7 switch（七层交换），OSI的最高层，应用层。此时，该Load Balancer能理解应用协议。例子： haproxy，MySQL Proxy。 注意：上面的很多Load Balancer既可以做四层交换，也可以做七层交换。 （二） 负载均衡设备也常被称为”四到七层交换机”，那么四层和七层两者到底区别在哪里？ 第一，技术原理上的区别。 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 - `所谓七层负载均衡`，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 - 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。 第二，应用场景的需求。 七层应用负载的好处，是使得整个网络更”智能化”。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。 另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。 现在的7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。 第三，七层应用需要考虑的问题。 1：是否真的必要，七层应用的确可以提高流量智能化，同时必不可免的带来设备配置复杂，负载均衡压力增高以及故障排查上的复杂性等问题。在设计系统时需要考虑四层七层同时应用的混杂情况。 2：是否真的可以提高安全性。例如SYN Flood攻击，七层模式的确将这些流量从服务器屏蔽，但负载均衡设备本身要有强大的抗DDoS能力，否则即使服务器正常而作为中枢调度的负载均衡设备故障也会导致整个应用的崩溃。 3：是否有足够的灵活度。七层应用的优势是可以让整个应用的流量智能化，但是负载均衡设备需要提供完善的七层功能，满足客户根据不同情况的基于应用的调度。最简单的一个考核就是能否取代后台Nginx或者Apache等服务器上的调度功能。能够提供一个七层应用开发接口的负载均衡设备，可以让客户根据需求任意设定功能，才真正有可能提供强大的灵活性和智能性。 （本节出自 “ADC技术博客” 博客，请务必保留此出处http://virtualadc.blog.51cto.com/3027116/591396） （三） 负载均衡四七层介绍: 负载均衡（Load Balance）建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。 负载均衡有两方面的含义：首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间；其次，单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高。 本文所要介绍的负载均衡技术主要是指在均衡服务器群中所有服务器和应用程序之间流量负载的应用，目前负载均衡技术大多数是用于提高诸如在Web服务器、FTP服务器和其它关键任务服务器上的Internet服务器程序的可用性和可伸缩性。 负载均衡技术分类 目前有许多不同的负载均衡技术用以满足不同的应用需求，下面从负载均衡所采用的设备对象、应用的网络层次（指OSI参考模型）及应用的地理结构等来分类。 软/硬件负载均衡 软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，如DNS Load Balance，CheckPoint Firewall-1 ConnectControl等，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。 软件解决方案缺点也较多，因为每台服务器上安装额外的软件运行会消耗系统不定量的资源，越是功能强大的模块，消耗得越多，所以当连接请求特别大的时候，软件本身会成为服务器工作成败的一个关键；软件可扩展性并不是很好，受到操作系统的限制；由于操作系统本身的Bug，往往会引起安全问题。 硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。 负载均衡器有多种多样的形式，除了作为独立意义上的负载均衡器外，有些负载均衡器集成在交换设备中，置于服务器与Internet链接之间，有些则以两块网络适配器将这一功能集成到PC中，一块连接到Internet上，一块连接到后端服务器群的内部网络上。 一般而言，硬件负载均衡在功能、性能上优于软件方式，不过成本昂贵。 本地/全局负载均衡 负载均衡从其应用的地理结构上分为本地负载均衡(Local Load Balance)和全局负载均衡(Global Load Balance，也叫地域负载均衡)，本地负载均衡是指对本地的服务器群做负载均衡，全局负载均衡是指对分别放置在不同的地理位置、有不同网络结构的服务器群间作负载均衡。 本地负载均衡能有效地解决数据流量过大、网络负荷过重的问题，并且不需花费昂贵开支购置性能卓越的服务器，充分利用现有设备，避免服务器单点故障造成数据流量的损失。其有灵活多样的均衡策略把数据流量合理地分配给服务器群内的服务器共同负担。即使是再给现有服务器扩充升级，也只是简单地增加一个新的服务器到服务群中，而不需改变现有网络结构、停止现有的服务。 全局负载均衡主要用于在一个多区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度，也可用于子公司分散站点分布广的大公司通过Intranet（企业内部互联网）来达到资源统一合理分配的目的。 网络层次上的负载均衡 针对网络上负载过重的不同瓶颈所在，从网络的不同层次入手，我们可以采用相应的负载均衡技术来解决现有问题。 随着带宽增加，数据流量不断增大，网络核心部分的数据接口将面临瓶颈问题，原有的单一线路将很难满足需求，而且线路的升级又过于昂贵甚至难以实现，这时就可以考虑采用链路聚合（Trunking）技术。 链路聚合技术（第二层负载均衡）将多条物理链路当作一条单一的聚合逻辑链路使用，网络数据流量由聚合逻辑链路中所有物理链路共同承担，由此在逻辑上增大了链路的容量，使其能满足带宽增加的需求。 现代负载均衡技术通常操作于网络的第四层或第七层。第四层负载均衡将一个Internet上合法注册的IP地址映射为多个内部服务器的IP地址，对每次 TCP连接请求动态使用其中一个内部IP地址，达到负载均衡的目的。在第四层交换机中，此种均衡技术得到广泛的应用，一个目标地址是服务器群VIP（虚拟 IP，Virtual IP address）连接请求的数据包流经交换机，交换机根据源端和目的IP地址、TCP或UDP端口号和一定的负载均衡策略，在服务器IP和VIP间进行映射，选取服务器群中最好的服务器来处理连接请求。 第七层负载均衡控制应用层服务的内容，提供了一种对访问流量的高层控制方式，适合对HTTP服务器群的应用。第七层负载均衡技术通过检查流经的HTTP报头，根据报头内的信息来执行负载均衡任务。 第七层负载均衡优点表现在如下几个方面： 通过对HTTP报头的检查，可以检测出HTTP400、500和600系列的错误信息，因而能透明地将连接请求重新定向到另一台服务器，避免应用层故障。 可根据流经的数据类型（如判断数据包是图像文件、压缩文件或多媒体文件格式等），把数据流量引向相应内容的服务器来处理，增加系统性能。 能根据连接请求的类型，如是普通文本、图象等静态文档请求，还是asp、cgi等的动态文档请求，把相应的请求引向相应的服务器来处理，提高系统的性能及安全性。 第七层负载均衡受到其所支持的协议限制（一般只有HTTP），这样就限制了它应用的广泛性，并且检查HTTP报头会占用大量的系统资源，势必会影响到系统的性能，在大量连接请求的情况下，负载均衡设备自身容易成为网络整体性能的瓶颈。 负载均衡策略 在实际应用中，我们可能不想仅仅是把客户端的服务请求平均地分配给内部服务器，而不管服务器是否宕机。而是想使Pentium III服务器比Pentium II能接受更多的服务请求，一台处理服务请求较少的服务器能分配到更多的服务请求，出现故障的服务器将不再接受服务请求直至故障恢复等等。 选择合适的负载均衡策略，使多个设备能很好的共同完成任务，消除或避免现有网络负载分布不均、数据流量拥挤反应时间长的瓶颈。在各负载均衡方式中，针对不同的应用需求，在OSI参考模型的第二、三、四、七层的负载均衡都有相应的负载均衡策略。 负载均衡策略的优劣及其实现的难易程度有两个关键因素：一、负载均衡算法，二、对网络系统状况的检测方式和能力。 考虑到服务请求的不同类型、服务器的不同处理能力以及随机选择造成的负载分配不均匀等问题，为了更加合理的把负载分配给内部的多个服务器，就需要应用相应的能够正确反映各个服务器处理能力及网络状态的负载均衡算法： 轮循均衡（Round Robin）：每一次来自网络的请求轮流分配给内部中的服务器，从1至N然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。 权重轮循均衡（Weighted Round Robin）：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。例如：服务器A的权值被设计成1，B的权值是 3，C的权值是6，则服务器A、B、C将分别接受到10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。 随机均衡（Random）：把来自网络的请求随机分配给内部中的多个服务器。 权重随机均衡（Weighted Random）：此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程。 响应速度均衡（Response Time）：负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。 最少连接数均衡（Least Connection）：客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。 处理能力均衡：此种均衡算法将把服务请求分配给内部中处理负荷（根据服务器CPU型号、CPU数量、内存大小及当前连接数等换算而成）最轻的服务器，由于考虑到了内部服务器的处理能力及当前网络运行状况，所以此种均衡算法相对来说更加精确，尤其适合运用到第七层（应用层）负载均衡的情况下。 DNS响应均衡（Flash DNS）：在Internet上，无论是HTTP、FTP或是其它的服务请求，客户端一般都是通过域名解析来找到服务器确切的IP地址的。在此均衡算法下，分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求，并在同一时间内把此域名解析成各自相对应服务器的IP地址（即与此负载均衡设备在同一位地理位置的服务器的IP地址）并返回给客户端，则客户端将以最先收到的域名解析IP地址来继续请求服务，而忽略其它的IP地址响应。在种均衡策略适合应用在全局负载均衡的情况下，对本地负载均衡是没有意义的。 尽管有多种的负载均衡算法可以较好的把数据流量分配给服务器去负载，但如果负载均衡策略没有对网络系统状况的检测方式和能力，一旦在某台服务器或某段负载均衡设备与服务器网络间出现故障的情况下，负载均衡设备依然把一部分数据流量引向那台服务器，这势必造成大量的服务请求被丢失，达不到不间断可用性的要求。所以良好的负载均衡策略应有对网络故障、服务器系统故障、应用服务故障的检测方式和能力： Ping侦测：通过ping的方式检测服务器及网络系统状况，此种方式简单快速，但只能大致检测出网络及服务器上的操作系统是否正常，对服务器上的应用服务检测就无能为力了。 TCP Open侦测：每个服务都会开放某个通过TCP连接，检测服务器上某个TCP端口（如Telnet的23口，HTTP的80口等）是否开放来判断服务是否正常。 HTTP URL侦测：比如向HTTP服务器发出一个对main.html文件的访问请求，如果收到错误信息，则认为服务器出现故障。 负载均衡策略的优劣除受上面所讲的两个因素影响外，在有些应用情况下，我们需要将来自同一客户端的所有请求都分配给同一台服务器去负担，例如服务器将客户端注册、购物等服务请求信息保存的本地数据库的情况下，把客户端的子请求分配给同一台服务器来处理就显的至关重要了。有两种方式可以解决此问题，一是根据IP地址把来自同一客户端的多次请求分配给同一台服务器处理，客户端IP地址与服务器的对应信息是保存在负载均衡设备上的；二是在客户端浏览器 cookie内做独一无二的标识来把多次请求分配给同一台服务器处理，适合通过代理服务器上网的客户端。 还有一种路径外返回模式（Out of Path Return），当客户端连接请求发送给负载均衡设备的时候，中心负载均衡设备将请求引向某个服务器，服务器的回应请求不再返回给中心负载均衡设备，即绕过流量分配器，直接返回给客户端，因此中心负载均衡设备只负责接受并转发请求，其网络负担就减少了很多，并且给客户端提供了更快的响应时间。此种模式一般用于HTTP服务器群，在各服务器上要安装一块虚拟网络适配器，并将其IP地址设为服务器群的VIP，这样才能在服务器直接回应客户端请求时顺利的达成三次握手。 负载均衡实施要素 负载均衡方案应是在网站建设初期就应考虑的问题，不过有时随着访问流量的爆炸性增长，超出决策者的意料，这也就成为不得不面对的问题。当我们在引入某种负载均衡方案乃至具体实施时，像其他的许多方案一样，首先是确定当前及将来的应用需求，然后在代价与收效之间做出权衡。 针对当前及将来的应用需求，分析网络瓶颈的不同所在，我们就需要确立是采用哪一类的负载均衡技术，采用什么样的均衡策略，在可用性、兼容性、安全性等等方面要满足多大的需求，如此等等。 不管负载均衡方案是采用花费较少的软件方式，还是购买代价高昂在性能功能上更强的第四层交换机、负载均衡器等硬件方式来实现，亦或其他种类不同的均衡技术，下面这几项都是我们在引入均衡方案时可能要考虑的问题： 性能：性能是我们在引入均衡方案时需要重点考虑的问题，但也是一个最难把握的问题。衡量性能时可将每秒钟通过网络的数据包数目做为一个参数，另一个参数是均衡方案中服务器群所能处理的最大并发连接数目，但是，假设一个均衡系统能处理百万计的并发连接数，可是却只能以每秒2个包的速率转发，这显然是没有任何作用的。性能的优劣与负载均衡设备的处理能力、采用的均衡策略息息相关，并且有两点需要注意：一、均衡方案对服务器群整体的性能，这是响应客户端连接请求速度的关键；二、负载均衡设备自身的性能，避免有大量连接请求时自身性能不足而成为服务瓶颈。有时我们也可以考虑采用混合型负载均衡策略来提升服务器群的总体性能，如DNS负载均衡与NAT负载均衡相结合。另外，针对有大量静态文档请求的站点，也可以考虑采用高速缓存技术，相对来说更节省费用，更能提高响应性能；对有大量ssl/xml内容传输的站点，更应考虑采用ssl/xml加速技术。 可扩展性：IT技术日新月异，一年以前最新的产品，现在或许已是网络中性能最低的产品；业务量的急速上升，一年前的网络，现在需要新一轮的扩展。合适的均衡解决方案应能满足这些需求，能均衡不同操作系统和硬件平台之间的负载，能均衡HTTP、邮件、新闻、代理、数据库、防火墙和 Cache等不同服务器的负载，并且能以对客户端完全透明的方式动态增加或删除某些资源。 灵活性：均衡解决方案应能灵活地提供不同的应用需求，满足应用需求的不断变化。在不同的服务器群有不同的应用需求时，应有多样的均衡策略提供更广泛的选择。 可靠性：在对服务质量要求较高的站点，负载均衡解决方案应能为服务器群提供完全的容错性和高可用性。但在负载均衡设备自身出现故障时，应该有良好的冗余解决方案，提高可靠性。使用冗余时，处于同一个冗余单元的多个负载均衡设备必须具有有效的方式以便互相进行监控，保护系统尽可能地避免遭受到重大故障的损失。 易管理性：不管是通过软件还是硬件方式的均衡解决方案，我们都希望它有灵活、直观和安全的管理方式，这样便于安装、配置、维护和监控，提高工作效率，避免差错。在硬件负载均衡设备上，目前主要有三种管理方式可供选择：一、命令行接口（CLI：Command Line Interface），可通过超级终端连接负载均衡设备串行接口来管理，也能telnet远程登录管理，在初始化配置时，往往要用到前者；二、图形用户接口（GUI：Graphical User Interfaces），有基于普通web页的管理，也有通过Java Applet 进行安全管理，一般都需要管理端安装有某个版本的浏览器；三、SNMP（Simple Network Management Protocol，简单网络管理协议）支持，通过第三方网络管理软件对符合SNMP标准的设备进行管理。]]></content>
      <categories>
        <category>lvs</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvs负载均衡]]></title>
    <url>%2F2019%2F01%2F05%2Flvs%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[lvs负载均衡 lvs负载均衡 负载均衡集群是 Load Balance(负载均衡器) 集群。是一种将网络上的访问流量分布于各个节点，以降低服务器压力，更好的向客户端提供服务的一种方式。常用的负载均衡。 调度器分类： 硬负载 (专用硬件) F5-Big Ip NetScaler-Citrix A10-A10 软负载(pc server) 四层：LVS,Nginx(stream模块伪四层),HAProxy（mode tcp） 七层：Nginx,HAProxy,ATS,Envoy,Traefik,Kong… 七层调度器（应用程序调度器） 如果调度器是根据OSI第七层应用层的报文的格式来识别客户端身份并根据算法获取其中数据完成后端客户端挑选的称之为七层调度器或者称之为应用层调度器。。 四层调度器（内核级调度） 仅根据客户端请求时请求的套接字（ip+port）完成后端客户端挑选。 一、负载均衡LVS基本介绍 LB集群的架构和原理很简单，就是当用户的请求过来时，会直接分发到Director Server上，然后它把用户的请求根据设置好的调度算法，智能均衡地分发到后端真正服务器(real server)上。为了避免不同机器上用户请求得到的数据不一样，需要用到了共享存储，这样保证所有用户请求的数据是一样的。 LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的官方网站是 http://www.linuxvirtualserver.org 现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。LVS 是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。 二、LVS的基本工作原理 三、LVS的组成 1.lvs分为两个部分，分别是内核模块和lvs的管理工具。 LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及相关的RealServer； ipvs：工作于内核空间的netfilter的INPUT钩子之上的框架； 目前来说，centos7及其以上的内核版本已经包括了ipvs的相关模块了。 内核支持的ipvs模块 上图中的rr，wrr，lc，wlc，lblc等等都是lvs中调度器的调度算法，根据不同的调度算法可以更好的分配服务，实现负载均衡。 而ipvs(ip virtual server)：一段代码工作在内核空间，实现调度。 ipvsadm客户端管理工具 上图是ipvsadm。负责为ipvs内核框架编写规则，定义谁是集群服务，而谁是后端真实的服务器(Real Server)。1234567891011121314151617181920212223242526#调度算法为内建在内核中的模块一共有10种[root@centos7 ~]# grep -i "ip_vs" /boot/config-3.10.0-862.el7.x86_64 CONFIG_IP_VS=mCONFIG_IP_VS_IPV6=y# CONFIG_IP_VS_DEBUG is not setCONFIG_IP_VS_TAB_BITS=12CONFIG_IP_VS_PROTO_TCP=yCONFIG_IP_VS_PROTO_UDP=yCONFIG_IP_VS_PROTO_AH_ESP=yCONFIG_IP_VS_PROTO_ESP=yCONFIG_IP_VS_PROTO_AH=yCONFIG_IP_VS_PROTO_SCTP=yCONFIG_IP_VS_RR=mCONFIG_IP_VS_WRR=mCONFIG_IP_VS_LC=mCONFIG_IP_VS_WLC=mCONFIG_IP_VS_LBLC=mCONFIG_IP_VS_LBLCR=mCONFIG_IP_VS_DH=mCONFIG_IP_VS_SH=mCONFIG_IP_VS_SED=mCONFIG_IP_VS_NQ=mCONFIG_IP_VS_SH_TAB_BITS=8CONFIG_IP_VS_FTP=mCONFIG_IP_VS_NFCT=yCONFIG_IP_VS_PE_SIP=m 四.LVS的调度算法前面已经说了，调度器（directory） 是通过一定的调度算法将服务请求一个一个的分发下去。现在了解一下调度算法 LVS一共有10种调度算法。 静态算法（算法仅根据算法本身与请求报文特征进行调度 起点公平） 动态算法（额外考虑后端各RS的当前的负载的状态 结果公平） 静态调度算法（4个） 1.rr（轮叫调度） 轮叫调度：这种是最简单的调度算法，就是将请求A一个，B一个，A一个，B一个 …… 循环的发。就算A主机挂掉了，调度器还是会将请求发送到A。十分均衡。 2.wrr（加权轮叫） 加权轮叫调度：这种算法是在rr基础上实现的，只不过加了权重，权重范围为1-100，假设A的服务器性能好，就给A的权重设置的高一点，设为2，而B主机是1。这样就实现A二个，B一个，A二个，B一个 …… 循环的发。这样照顾到了服务器性能。 3.sh（源地址哈希） 源地址散列：主要是实现将此前的session（会话）绑定。将此前客户的源地址作为散列键，从静态的散列表中找出对应的服务器，只要目标服务器是没有超负荷的就将请求发送过去。就是说某客户访问过A,现在这个客户又来了，所以客户请求会被发送到服务过他的A主机。 4.dh（目的地址哈希） 目的地址散列：以目的地址为关键字查找一个静态hash表来获得需要的RS。以目标地址为标准挑选。 功能是和sh近似的，但应用场景不同 （dh举个例子：假设1号客户访问了web集群的一个动态页面，调度器将请求转发个A服务器，A服务器的PHP将这个动态请求运行了一遍，生成了缓存并回应1号客户。这下2号客户也访问了这个动态页面，调度器应该将请求发给A。毕竟A已经跑过这段程序了，有缓存，对吧。所以这既是dh算法） 接下来是动态算法，动态算法与静态算法最大的区别就是动态算法考虑了服务器的压力。活动链接（active）：客户与服务器建立连接并且有数据传送非活动链接（inactive）：只是建立连接，没有数据传送，没有断开连接 动态调度算法（6个） 1.lc（最少链接） 最少连接调度：这种算法是看A，和B的主机谁的连接少，请求就发给谁，如果负载相同，自上而下调度。 负载的简单算法：active*256+inactive （谁小发给谁） 2.wlc（加权最少链接）LVS的理想算法，也是默认的算法 加权最少链接：这种算法就是比lc多了一个加权。 简单算法：( active*256+inactive )/weight (谁小就发给谁) 3.sed（最短期望延迟） 基于wlc算法，假设A，B的权重分别是1，2 。而A的链接数为1，B的链接数为2 。这样的话，用wlc算法得出的结果一样，而明显B的权重大，B的能力较强。用sed算法的话，就可以避免wlc出现的问题。 简单算法：（active+1)256/weight （活动的连接数+1）256/除以权重 谁小发给谁 A：（1+1）/1 B：（2+1）/2 （B小，交给B） 4.nq（永不排队） 基于sed算法：在sed的基础上，若谁的链接数为0，直接将请求发送给他，没二话 5.LBLC（基于局部性的最少连接）类似于dh，目标地址hash 这个算法主要用于Cache集群系统，因为Cache集群的中客户请求报文的目标IP地址的变化，将相同的目标URL地址请求调度到同一台服务器，来提高服务器的访问的局部性和Cache命中率。从而调整整个集群的系统处理能力。但是，如果realserver的负载处于一半负载，就用最少链接算法，将请求发送给活动链接少的主机。 6.LBLCR（带复制的基于局部性的最少链接） 该算法首先是基于最少链接的，当一个新请求收到后，一定会将请求发给最少连接的那台主机的。但这样又破坏了cache命中率。但这个算法中，集群服务是cache共享的，假设A的PHP跑了一遍，得到缓存。但其他realserver可以去A那里拿缓存，这是种缓存复制机制。 五、lvs类型（工作拓扑结构及转发机制） LVS 的工作模式分为4中分别是 NAT，DR，TUN，FULL-NAT。其中做个比较，由于工作原理的关系的，NAT的配置最为简单，但是NAT对调度器的压力太大了，导致其效率最低，DR和TUN的工作原理差不多，但是DR中，所有主机必须处于同一个物理环境中，而在TUN中，所有主机可以分布在不同的位置，服务器一个在纽约，一个在深圳。最多应用的是FULL-NAT。 lvs-nat：修改请求报文的目标IP,多目标IP的DNAT lvs-dr：操纵封装新的MAC地址 lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP 其中的专业术语 DS：Director Server。指的是前端负载均衡器。 RS：Real Server。后端真实的工作服务器。 VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 RIP：Real Server IP，后端服务器的IP地址。 CIP：Client IP，访问客户端的IP地址。 1.NAT模式 客户发出请求，发送请求给链接调度器的VIP，调度器将请求报文中的目标Ip地址改为RIP。这样服务器RealServer将请求的内容发给调度器，调度器再将报文中的源IP地址改为VIP。 (a). 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP (b). PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c). IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP (d). POSTROUTING链通过选路，将数据包发送给Real Server (e). Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP (f). Director Server在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP Nat模型的特点 1.很好配置，原理简单易懂 2.由于调度器的工作量太大，很容易成为整个集群系统的瓶颈。 3.RS应该使用私有地址，RS的网关必须指向DIP 4.支持端口映射 5.多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发； 6.RIP和DIP必须在同一个IP网络，且应该使用私网地址；RS的网关要指向DIP； 7.请求报文和响应报文都必须经由Director转发；Director易于成为系统瓶颈； 8.支持端口映射，可修改请求报文的目标PORT； 9.vs必须是Linux系统，rs可以是任意系统； 2.DR模式 整个DR模式都是停留在第二层的数据链路层。直接修改MAC。实现报文的转发。 (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP (b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c) IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址 (d) 由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。 (e) RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP (f) 响应报文最终送达至客户端 LVS-DR的特点 1.在前端路由器做静态地址路由绑定，将对于VIP的地址仅路由到Director Server 2.arptables：在arp的层次上实现在ARP解析时做防火墙规则，过滤RS响应ARP请求。 3.修改RS上内核参数（arp_ignore和arp_announce）将RS上的VIP配置在网卡接口的别名上，并限制其不能响应对VIP地址解析请求。 4.确保前端路由器将目标IP为VIP的请求报文发往Director： (a) 在前端网关做静态绑定； (b) 在RS上使用arptables； (c) 在RS上修改内核参数以限制arp通告及应答级别； arp_announce arp_ignore 5.RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director； 6.RS跟Director要在同一个物理网络； 7.请求报文要经由Director，但响应不能经由Director，而是由RS直接发往Client； 8.不支持端口映射； 3.TUN模式 和DR模式差不多，但是比DR多了一个隧道技术以支持realserver不在同一个物理环境中。就是realserver一个在北京，一个工作在上海。 在原有的IP报文外再次封装多一层IP首部，内部IP首部(源地址为CIP，目标IIP为VIP)，外层IP首部(源地址为DIP，目标IP为RIP (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 。 (b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c) IPVS比对数据包请求的服务是否为集群服务，若是，在请求报文的首部再次封装一层IP报文，封装源IP为为DIP，目标IP为RIP。然后发至POSTROUTING链。 此时源IP为DIP，目标IP为RIP (d) POSTROUTING链根据最新封装的IP报文，将数据包发至RS（因为在外层封装多了一层IP首部，所以可以理解为此时通过隧道传输）。 此时源IP为DIP，目标IP为RIP (e) RS接收到报文后发现是自己的IP地址，就将报文接收下来，拆除掉最外层的IP后，会发现里面还有一层IP首部，而且目标是自己的lo接口VIP，那么此时RS开始处理此请求，处理完成之后，通过lo接口送给eth0网卡，然后向外传递。 此时的源IP地址为VIP，目标IP为CIP (f) 响应报文最终送达至客户端 LVS-TUN的特点 1 .RIP、VIP、DIP全是公网地址 2.RS的网关不会也不可能指向DIP 3.不支持端口映射 4.RS的系统必须支持隧道 lvs-fullnat模式： 通过同时修改请求报文的源IP地址和目标IP地址进行转发； CIP DIP VIP RIP lvs-fullnat 特点： (1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP； (2) RS收到的请求报文源地址是DIP，因此，只能响应给DIP；但Director还要将其发往Client； (3) 请求和响应报文都经由Director； (4) 支持端口映射； 注意：此类型默认不支持；]]></content>
      <categories>
        <category>lvs</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker资源限制以及compose基础应用]]></title>
    <url>%2F2019%2F01%2F04%2Fdocker%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[docker资源限制以及compose基础应用 docker资源限制 在使用docker运行容器时，一台主机上可能会运行几百个容器，这些容器虽然互相隔离，但是底层却使用着相同的CPU，内存和磁盘资源。如果不对容器使用的资源进行限制，那么容器之间会互相影响，小的来说会导致容器资源使用不公平;大的来说，可能会导致主机和集群资源耗尽，服务完全不可用.docker 作为容器的管理者，自然提供了控制容器资源的功能。正如使用内核的命名空间来做赚容器之间的隔离，docker也是通过内核的cgroups来做容器的资源限制。 1. 内存（不可压缩资源） 1.1 了解耗尽内存的风险 不让正在运行的容器消耗太多的主机内存是很重要的。在 Linux 主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个 OOME内存耗尽 或 Out Of Memory Exception，并开始查杀进程以释放内存。任何进程都可能被杀掉，包括 Docker 和其他重要应用程序。如果终止了错误进程，有可能导致系统宕机。 Docker 尝试通过调整 Docker 守护进程的 OOM 优先级来降低这些风险，从而使其和系统上的其他进程相比更不容易被杀掉。容器的 OOM 优先级不调整。这使得单个容器被杀死的可能性要比 Docker 守护进程或其他系统进程被终止的可能性要大。不应该通过手动将守护程序或容器上的 –oom-score-adj 设置为极端负数，或通过在容器上设置 –oom-disable-kill 来尝试规避这些安全措施。 生产环境一般不建议使用swap，因为使用swap会严重影响服务器性能。 选项 描述 -m 或 –memory= 容器可用的最大内存。如果设置了这个值，最小可用内存是 4MB。 –memory-swap* 允许容器放入磁盘 swap 中的内存数量。 –memory-swappiness 默认情况下，主机内核可以交换容器使用的匿名页面的百分比。可以设置为介于0和100之间的值，以调整此百分比。用来定义系统是使用的交换分区的倾向性（数值越大越倾向使用，数值越低越少越晚的使用能不用则不用） –memory-reservation 软限制。指定一个小于 –memory 的软限制，当 Docker 检测到主机上的争用或内存不足时，会采用这个限制来替换 –memory。如果使用这个限制，则必须将其设置为低于 –memory，以使其优先。不能保证容器不会超出限制。 –kernel-memory 容器可以使用的最大内核内存量。允许的最小值是 4m。由于内核内存不能被换出，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其他容器产生副作用。 –oom-kill-disable 默认情况下，如果发生内存不足（OOM）错误，内核会杀死容器中的进程。使用 –oom-kill-disable 选项可以更改此行为。注意只能在同时设置了-m/–memory 选项的容器上使用此选项，因为如果未设置 -m 标志，可能会耗尽主机的内存，导致内核需要终止主机系统的进程以释放内存。 1.2 限制容器对内存的访问 Docker 可以对内存实施两种限制：硬限制，允许容器使用不超过给定数量的用户或系统内存；软限制，允许容器使用尽可能多的内存，除非满足某些条件，例如内核检测到内存不足或主机上的争用。其中一些选项在单独使用或同时设置多个选项时会有不同的效果。 这些选项大多数都是一个正整数，后跟一个后缀 b，k，m，g，以表示字节，千字节，兆字节或千兆字节。 1.3 –memory-swap 详情 –memory-swap 是一个修饰符标志，只有在 –memory 也被设置时才有意义。使用 swap 使得容器可以在耗尽所有可用 RAM 时，将多余的内存需求写入磁盘。对于经常将内存交换到磁盘的应用程序会有性能损失。 其设置可能会产生复杂的效果： 如果 –memory-swap 设置为正整数，那么 –memory 和 –memory-swap 都需要设置。–memory-swap 表示所有可用的内存和 swap 之和，并且 –memory 控制非 swap 内存数量。因此，如果 –memory=”300m” 和 –memory-swap=”1g”，则容器可以使用 300MB 内存和 700MB swap。 如果 –memory-swap 设置为 0，则会忽略这个设置。 如果 –memory-swap 设置的值与 –memory相同，并且 –memory 设置为正整数，则容器无法访问 swap。 如果 –memory-swap 未设置，并且 –memory 设置了，如果主机容器配置了交换内存，则容器会使用 –memory 设置值的两倍作为 swap 的大小。例如，如果 –memory=”300m”，–memory-swap没有设置，则容器可以使用 300MB 内存和 600MB swap。 如果 –memory-swap 显式设置为 -1，允许容器使用无限制的 swap，直到达到主机系统可用值。 禁止容器使用 SWAP 如果 –memory-swap 设置的值与 –memory相同，则容器无法访问 swap。这是因为 –memory-swap 设置的值是可用的内存与 swap 之和，而 –memory 是可用的物理内存量。 1.4 –memory-swappiness 详情 值为 0 时，关闭匿名页的 swap。 值为 100 时，所有匿名页都可以 swap。 默认情况下，如果没有设置 –memory-swappiness，会从主机继承这个值。 1.5 –kernel-memory 详情 内核内存限制以分配给指定容器的全部内存来表示。考虑以下情况： 无限内存，无限内核内存：这是默认行为。 无限内存，有限内核内存：当所有 cgroup 所需的内存大于主机上实际存在的内存时，这是合适的。可以将内核内存配置为永远不会覆盖主机上可用的内容，而需要更多内存的容器需要等待。 有限内存，无限内核内存：整个内存是有限的，但内核内存不是。 有限内存，有限内核内存：限制用户和内核内存可用于调试与内存相关的问题。如果某个容器对任意一种内存的使用数量超量，则会导致内存不足但不会影响其他容器或主机。在此设置下，如果内核内存限制低于用户内存限制，则内核内存用尽会导致容器遇到 OOM 错误。如果内核内存限制高于用户内存限制，则内核限制不会导致容器体验 OOM。 当打开任何内核内存限制时，主机会在每个进程的基础上跟踪“high water mark”（高位标记）统计信息，以便跟踪哪些进程（在这种情况下是容器）正在使用多余的内存。可以通过在主机上查看 /proc//status 来查看每个进程。 2. CPU（可压缩资源） 默认情况下，每个容器对主机 CPU 的周期访问是无限的。可以设置各种约束来限制给定容器访问主机的 CPU 周期。大多数用户使用和配置默认的 CFS 调度器。在 Docker 1.13 及更高版本中，还可以配置实时调度器 2.1 配置默认的 CFS 调度器 CFS 是用于普通 Linux 进程的 Linux 内核 CPU 调度程序。几个运行时标志允许配置容器的 CPU 资源访问量。使用这些设置时，Docker 会修改主机上容器的 cgroup 设置。 压测此镜像可以进行压测，参考镜像地址：https://hub.docker.com/r/lorel/docker-stress-ng 12345拖下测试镜像 [root@centos7 ~]# docker pull lorel/docker-stress-ng查看镜像的使用帮助 [root@centos7 ~]# docker run --name pc1 -it --rm lorel/docker-stress-ng --help docker compose容器编排工具官网：https://docs.docker.com/compose/ 1.Compose介绍 Docker Compose是一个用来定义和运行复杂应用的Docker工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose不再需要使用shell脚本来启动容器。 Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 2.Compose和Docker兼容性 Docker版本变化说明： Docker从1.13.x版本开始，版本分为企业版EE和社区版CE，版本号也改为按照时间线来发布，比如17.03就是2017年3月。 Docker的linux发行版的软件仓库从以前的https://apt.dockerproject.org和https://yum.dockerproject.org变更为目前的https://download.docker.com, 软件包名字改为docker-ce和docker-ee。 范例：打算部署一个wordpress123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960WordPress:1. 在你的主文件夹中创建一个名为my_wordpress的新目录，并将cd放入其中:#yum install docker-compose# systemctl start docker# mkdir ~/my_wordpress/# cd ~/my_wordpress/ # docker pull wordpress:latest# docker pull mysql:5.7 2. 创建一个名为docker-compose的文件。并在此文件夹中添加以下内容。为WORDPRESS_DB_PASSWORD、MYSQL_ROOT_PASSWORD和MYSQL_PASSWORD环境选项设置您自己的密码。为WORDPRESS_DB_PASSWORD和MYSQL_PASSWORD输入的密码应该相同。# rpm -q docker-compose#docker-compose-1.18.0-2.el7.noarchvim docker-compose.ymlversion: '3.3'services: wordpress: #服务 depends_on: - db image: wordpress:latest #互联网镜像为wordpress(http、php、php-mysql、wordpress) volumes: - wordpress_files:/var/www/html ports: - "80:80" #端口映射,左侧宿主机右侧容器 restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_NAME: wordpress WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: my_wordpress_db_password db: #服务 image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: my_db_root_password MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: my_wordpress_db_passwordvolumes: wordpress_files: db_data: 3. 从my_wordpress目录，开始你的Docker容器:# docker-compose up -d 4. Docker容器启动WordPress和MySQL需要一到两分钟。之后，您可以在web浏览器中访问您的IP地址，您应该被引导到WordPress设置表单。 文档出处， https://www.linode.com/docs/quick-answers/linux/wordpress-with-docker-compose/ docker ps 命令： 过滤器：过滤标志(-f或–filter)格式是key=value。如果超过一个过滤，就传递多个标志(如–filter “foo=bar” –filter “bif=baz”) 目前支持的过滤有如下这些: id(容器id) label(label=或label=&gt;) name(容器名称) exited(整数 – 容器退出码。只在使用–all才有用) status (created restarting running paused exited dead) ancestor([:], or ) – 过滤从指定镜像创建的容器。 before (容器的名称或id) – 过滤在给定id或名称之前创建的容器。 since (容器的名称或id) – 过滤在给定id或名称之后创建的容器。 isolation (default process hyperv) (Windows daemon only) volume (数据卷名称或挂载点) – 过滤挂载有指定数据卷的容器。 network (网络id或名称) – 过滤连接到指定网络的容器。 --format为格式化输出。格式化选项(–format)使用Go模板来美化打印容器输出。 Go模板有效的占位符如下： .ID 容器ID .Image 镜像ID .Command Quoted command .CreatedAt 创建容器的时间点. .RunningFor 从容器创建到现在过去的时间. .Ports 暴露的端口. .Status 容器状态. .Size 容器占用硬盘大小. .Names 容器名称. .Labels 容器所有的标签. .Label 指定label的值 例如&apos;{{.Label “com.docker.swarm.cpu”}}’ .Mounts 挂载到这个容器的数据卷名称 Docker参考手册： https://docs.docker.com/engine/reference/commandline/dockerd/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker私有仓库]]></title>
    <url>%2F2019%2F01%2F03%2Fdocker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E5%92%8C%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[docker私有仓库 ocker Registry 分类 Registry用于保存docker镜像，包括镜像的层次结构和元数据 用户可自建Registry，也可使用官方的Docker Hub 分类 Sponsor Registry：第三方的registry，供客户和Docker社区使用 Mirror Registry：第三方的registry，只让客户使用 Vendor Registry：由发布Docker镜像的供应商提供的registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供的registry Registry(repository and index) Repository 由某特定的docker镜像的所有迭代版本组成的镜像仓库 一个 Registry中可以存在多个Repository Repository可分为“顶层仓库”和“用户仓库” 用户仓库名称格式为“用户名/仓库名” 每个仓库可以包含多个Tag(标签) ，每个标签对应一个镜像 Index 维护用户帐户、镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 docker简单的私有仓库123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180[root@centos7 yum.repos.d]# yum info docker-distributionLoaded plugins: fastestmirror, langpacksRepository extras is listed more than once in the configurationLoading mirror speeds from cached hostfile * base: mirrors.huaweicloud.com * extras: mirrors.tuna.tsinghua.edu.cn * updates: mirrors.huaweicloud.comAvailable PackagesName : docker-distributionArch : x86_64Version : 2.6.2Release : 2.git48294d9.el7Size : 3.5 MRepo : extras/7/x86_64Summary : Docker toolset to pack, ship, store, and deliver contentURL : https://github.com/docker/distributionLicense : ASL 2.0Description : Docker toolset to pack, ship, store, and deliver content #######################################################################################实验前提###################################################################################说明:Docker工具集用于打包、运输、存储和交付内容实现自建简单的docker私有仓库 两台主机间共享私用仓库 发送镜像端:172.18.135.1 distribution服务器：主机名为www.centos7.com(172.18.135.1)####################接收镜像的节点distribution服务器########################################安装docker#############################################################################[root@centos7 yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@centos7 yum.repos.d]# yum install docker-ce -y安装docker-distribution[root@centos7 yum.repos.d]# yum install docker-distribution.x86_64 [root@centos7 ~]# systemctl start docker-distribution[root@centos7 ~]# rpm -ql docker-distribution /etc/docker-distribution/registry/config.yml #配置文件/usr/bin/registry/usr/lib/systemd/system/docker-distribution.service/usr/share/doc/docker-distribution-2.6.2/usr/share/doc/docker-distribution-2.6.2/AUTHORS/usr/share/doc/docker-distribution-2.6.2/CONTRIBUTING.md/usr/share/doc/docker-distribution-2.6.2/LICENSE/usr/share/doc/docker-distribution-2.6.2/MAINTAINERS/usr/share/doc/docker-distribution-2.6.2/README.md/var/lib/registry #存储用户pull下来的所有镜像配置文件[root@centos7 ~]# vim /etc/docker-distribution/registry/config.ymlversion: 0.1 #版本log: #日志 fields: #存储 service: registry storage: cache: #使用本地内存做缓存 layerinfo: inmemory filesystem: #用户所有pull下来的文件存放在/var/lib/registry rootdirectory: /var/lib/registryhttp: #仅提供http协议的传输 addr: :5000 #默认监听本机的所有地址的5000端口启动docker-distribution服务[root@centos7 ~]# systemctl start docker-distribution[root@centos7 ~]# ss -tnlLISTEN 0 128 :::5000 :::* distribution的registry做的非常简单#无用户名认证#默认情况下不区分任何用户空间#仅有顶层仓库，仅供公司内部临时使用####################发送镜像端#################################################打标签发送###########################################################################################打标签时指明distribution服务器地址、端口（确认可以名字解析解析到distribution服务器地址）打标签[root@centos7 ~]# docker tag lamp:v0.1 www.centos7.com:5000/myimg:v0.1[root@centos7 ~]# docker image lswww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 6 hours ago 279MB上传到distribution服务器（失败原因是默认使用的https发送的请求，对端使用的是http接收双方不匹配）[root@centos7 ~]# docker push www.centos7.com:5000/myimg:v0.1 The push refers to repository [www.centos7.com:5000/myimg]Get https://www.centos7.com:5000/v2/: dial tcp 172.18.135.2:5000: connect: no route to host编辑daemon.json 开启明文不安装的仓库传输，默认使用https加密协议，使用明文http协议[root@centos7 ~]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries": ["www.centos7.com:5000"]&#125;[root@centos7 ~]# systemctl restart docker推镜像[root@centos7 ~]# docker push www.centos7.com:5000/myimg:v0.1The push refers to repository [www.centos7.com:5000/myimg]a92cb897b523: Pushed 071d8bd76517: Pushed v0.1: digest: sha256:274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 size: 741####################接收镜像的节点distribution服务器########################################安装docker#############################################################################查看是否推送成功[root@centos7 ~]# ls /var/lib/registry/dockerroot@centos7 ~]# tree /var/lib/registry//var/lib/registry/└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 27 │ │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ │ └── data │ ├── a0 │ │ └── a02a4930cb5d36f3290eb84f4bfa30668ef2e9fe3a1fb73ec015fc58b9958b17 │ │ └── data │ ├── ab │ │ └── ab9147d4eb81842f3eccbb7c75ef8cad91a9dadfd22233050acae0d2f37d9fba │ │ └── data │ └── f3 │ └── f3c216eb1c6f3fe2e271835d79e94e9ede430d7cd75f9734cf44dd9c5fbf095c │ └── data └── repositories └── myimg ├── _layers │ └── sha256 │ ├── a02a4930cb5d36f3290eb84f4bfa30668ef2e9fe3a1fb73ec015fc58b9958b17 │ │ └── link │ ├── ab9147d4eb81842f3eccbb7c75ef8cad91a9dadfd22233050acae0d2f37d9fba │ │ └── link │ └── f3c216eb1c6f3fe2e271835d79e94e9ede430d7cd75f9734cf44dd9c5fbf095c │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ │ └── link │ └── tags │ └── v0.1 │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ └── link └── _uploads31 directories, 10 files使用此镜像（可以解析到本机域名）#本身也不支持httpds修改daemon.json [root@centos7 ~]# cat /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries":["www.centos7.com:5000"]&#125;[root@centos7 ~]# systemctl restart docker[root@centos7 ~]# docker info[root@centos7 ~]# docker pull www.centos7.com:5000/myimg:v0.1[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEwww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 7 hours ago 279MB-------------------------------------------------------------------------将别人的镜像推送到自己的仓库中使用（本地的centos7打个标签传到自己本地的仓库）[root@centos7 ~]# docker tag centos:7 www.centos7.com:5000/centos:7[root@centos7 ~]# docker image lswww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 7 hours ago 279MB[root@centos7 ~]# docker push www.centos7.com:5000/centos:7 Harbor源代码托管在github:https://github.com/goharbor/harbor Harbor是一个开源的可信云本机注册表项目，用于存储，签名和扫描内容。Harbor通过添加用户通常需要的功能（如安全性，身份和管理）来扩展开源Docker Distribution。使注册表更接近构建和运行环境可以提高图像传输效率。Harbor支持在注册表之间复制映像，还提供高级安全功能，如用户管理，访问控制和活动审计。 Harbour由Cloud Native Computing Foundation（CNCF）托管。如果您是一个希望帮助塑造云原生技术发展的组织，请考虑加入CNCF。有关谁参与以及Harbour如何扮演角色的详细信息，请阅读CNCF 公告。 系统要求： 在Linux主机上： docker 17.03.0-ce +和docker-compose 1.10.0+。 下载Harbor版本的二进制文件，然后按照安装和配置指南安装Harbour。 如果您想在Kubernetes上部署Harbour，请使用Harbor图表。 有关如何使用Harbor的更多详细信息，请参阅用户指南。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#Harbor服务传输使用的也是https协议传输，可以将此功能关掉,生产中若使用Harbor建议启用https加密以及从节点复制功能。港口可以通过以下三种方法之一安装： 1.在线安装程序：安装程序从Docker hub下载Harbor的图像。因此，安装程序的尺寸非常小。 2.脱机安装程序：当主机没有Internet连接时使用此安装程序。安装程序包含预先构建的图像，因此其大小更大。安装步骤归结为以下内容： 1.下载安装程序 2.配置harbor.cfg 配置参数位于文件harbor.cfg中。 在harbor.cfg中有两类参数，必需参数和可选参数 3.运行install.sh安装并启动Harbor第一步：安装docker-compose(epel源) [root@centos7 ~]# yum install docker-compose第二步：下载离线安装程序包，并解压 下载地址：https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.0.tgz [root@centos7 local]# pwd /usr/local [root@centos7 local]# tar xvf harbor-offline-installer-v1.7.0.tgz 第三步：编辑harbor配置文件、并运行装载harbor（详细设置参考github中harbor安装手册） [root@centos7 harbor]# pwd /usr/local/harbor [root@centos7 harbor]# vim harbor.cfg 8行 hostname = www.centos7.com #修改主机名，确保此名称可以解析 [root@centos7 harbor]# systemctl start docker #运行 ./install.sh 前确保docker已经启动 [root@centos7 harbor]# pwd /usr/local/harbor [root@centos7 harbor]# ./install.sh [root@centos7 harbor]# docker image ls #可以查看默认的离线下载下来的镜像第四步：此时默认的运行的https容器已经启动，以及访问查看[root@centos7 harbor]# ss -tnl #监听的端口默认映射为宿主机的端口 LISTEN 0 128 :::80 :::* LISTEN 0 128 :::443 :::* LISTEN 0 128 :::4443 :::* http://172.18.135.2/harbor/sign-in#使用默认的账号和密码登陆账号admin密码Harbor12345 1自己创建账号并定义项目名称并向自己定义的仓库中推送镜像 12345678910111213141516171819202122232425第五步：推送镜像到自己创建的harbor仓库中 [root@centos7 harbor]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries":["www.centos7.com"] &#125; [root@centos7 harbor]# systemctl restart docker 查看本地已有的镜像 [root@centos7 harbor]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE goharbor/harbor-db v1.7.0 45d94fe5fee5 3 weeks ago 133MB 打标签 [root@centos7 harbor]# docker tag goharbor/harbor-db:v1.7.0 www.centos7.com/public/harbor:v0.1 登陆、推送到harbor [root@centos7 harbor]# docker login www.centos7.com Username: daizhe Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded [root@centos7 harbor]# docker push www.centos7.com/public/harbor:v0.1]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dockerfile详解]]></title>
    <url>%2F2019%2F01%2F02%2Fdockerfile%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[dockerfile详解 docker的镜像分层 分层 Cow 联合挂载 base image ,app image = base image docker里的镜像绝大部分都是在别的镜像的基础上去进行创建的，也就是使用镜像的分层结构。 那么为什么会有两个镜像呢？这是由于docker的镜像分层结构所导致的，如下图所示。 一个docker镜像由多个可读的镜像层组成，然后运行的容器会在这个docker的镜像上面多加一层可写的容器层，任何的对文件的更改都只存在此容器层。因此任何对容器的操作均不会影响到镜像。 至于容器如何获取镜像层文件而又不影响到是镜像层的呢？docker是这样实现的？ 如果需要获取某个文件，那么容器曾会从上到下去下一层的镜像层去获取文件，如果该层文件不存在，那么就会去下一镜像层去寻找，直到最后一层。 对于用户而言，用户面向的是一个叠加后的文件系统。 而任何对于文件的操作都会记录在容器层，例如说修改文件，容器层会把在镜像层找到的文件拷贝到容器层然后进行修改，删除文件则会在容器层内记录删除文件的记录。 About Dockerfile Dockerfile只不过是建造码头工人的源代码自动图像码头工人可以构建图像读取指令从Dockerfile。 Dockerfile是一个文本文件,包含所有的命令在命令行用户可以叫组装一个图像型码头工人建立用户可以创建一个自动构建执行一些命令行指令 Dockerfile Dockerfile其实可以看做一个命令集。每行均为一条命令。每行的第一个单词，就是命令command。 后面的字符串是该命令所要接收的参数。 比如ENTRYPOINT /bin/bash。ENTRYPOINT命令的作用就是将后面的参数设置为镜像的entrypoint。 至于现有命令的含义，这里不再详述。 DockOne上有很多的介绍。 一、Docker Image building 宿主机指定工作目录： 1.此文件中仅用于放置Dockerfile以及Dockerfile文件中指定要被依赖到的文件，不要放置其他文件或目录。 2.此宿主机的工作目录相当于隐式运行的容器的卷，仅能从此卷中复制文件到容器中。 Dockerfile的文件名也只能叫做Dockerfile，放置在宿主机上的工作目录中。 二、Dockerfile文件格式 格式（Format） #注释 指令参数 该指令本身不区分字符大小 惯例要求的指令要写成纯大写 以便更容易地与参数区分开来 dockerfile文件本身没有循环、选择等分支，也没有跳转语句 一般来讲在dockerfile文件中的第一条指令是“FROM”（新版的dockerfile有松动，早期的dockerfile把第一条执行的第一条指令必须是“FROM”），因为“FROM”就是我们用来指定基础镜像的。 三、Dockerfile的镜像层构建 在dockerfile中构建镜像，与我们手动的显式的启动一个容器构建镜像不同的是dockerfile文件中的每一条指令都会生成一个新的单有的镜像层。 分层过多会导致在读写访问过程中的效率降低，因为首次访问镜像一定是Cow机制完成 镜像分的过于精细的好处是可以其他让镜像让享同一层底层的镜像即镜像层越精细越多越容易共享，越容易共享代表在镜像仓库与客户端和dockerhost之间传输时可以单独传输，传输的过程越易控，起码在打包、分发。 应该把关系比较紧密的操作放置在一层操作当中。 docker镜像制作的两种运行场景 制作新镜像的过程 运行新镜像的阶段 dockerfile环境变量 环境变量(用ENV语句声明)也可以在某些指令中使用，因为Dockerfile将解释的变量在Dockerfile中以$variable名或${variable_name标记 ${variable_name} 语法还支持一些标准的bash修饰符 $ivariable:-word} 表示如果设置了变量，则结果将是该值。 如果变量没有设置，那么结果将是word ${variable:+word} 表示如果设置了变量，则word为结果，否则结果为空字符串 .dockerignore file在docker CLI将上下文发送给docker守护进程之前，它将查找一个名为。如果该文件存在，CLI将修改该上下文以排除与其模式匹配的文件和目录。dockerignore file是一个以新行分隔的模式列表，类似于Unix shell的文件全局 Dockerfile指令build阶段Dockerfile文件中的指令(build阶段：做很多设定以便于在目标镜像文件中可以打包进入所期望的文件或者程序文件) FROM FROM指令是最重的一个且必须为Dockerfile文件开篇的第一个非注释行，用于 为映像文件构建过程指定基准镜像，后续的指令运行于此基准镜像所提供的运 行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在 docker主机上查找指定的镜像文件，在其不存在时，则会从Docker Hub Registry 上拉取所需的镜像文件 如果找不到指定的镜像文件，docker build会返回一个错误信息 Syntax(语法)(repository仓库、tag标签、digest唯一标识id即镜像校验码) FROM &lt;repository&gt;[:&lt;tag&gt;] 或 FROM &lt;resository&gt;@&lt;digest&gt; &lt;reposotiry&gt;：指定作为base image的名称； &lt;tag&gt;：base image的标签，为可选项，省略时默认为latest； LABEL 用于让Dockerfile制作者提供本人的详细信息(支持提供此镜像的任何制作的附加介绍信息以及附加的元数据) Syntax: LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... COPY 用于从Docker主机复制文件至创建的新映像文件 Syntax(语法) COPY &lt;src&gt; ... &lt;dest&gt; 或 COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则， COPY指定则以WORKDIR为其起始路径； 注意：在路径中有空白字符时，通常使用第二种格式 文件复制准则 &lt;src&gt;必须是build上下文中的路径，不能是其父目录中的文件 如果&lt;src&gt;是目录，则其内部文件或子目录会被递归复制，但&lt;src&gt;目录自身不会被复制 如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用了通配符，则&lt;dest&gt;必须是一个目录，且必须以/ 结尾 如果&lt;dest&gt;事先不存在，它将会被自动创建，这包括其父目录路径 ADD ADD指令类似于COPY指令，ADD支持使用TAR文件和URL路径 Syntax ADD &lt;src&gt; ... &lt;dest&gt; 或 ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 操作准则 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接被创建为&lt;dest&gt; ；如果&lt;dest&gt;以/结尾，则文件名URL指定的文件将被直接下载并保存为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式的tar文件，它将被展开为一个目录，其行为类似于 “tar -x”命令；然而，通过URL获取到的tar文件将不会自动展开； 如果&lt;src&gt;有多个，或其间接或直接使用了通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径 ；如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt;； WORKDIR 用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定 设定工作目录 Syntax WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指令可出现多次，其路径也可以为相对路径，不过，其是相对此前 一个WORKDIR指令指定的路径 另外，WORKDIR也可调用由ENV指定定义的变量 例如 WORKDIR /var/log WORKDIR $STATEPATH VOLUME 存储卷 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的 卷 Syntax VOLUME &lt;mountpoint&gt; 或 VOLUME [&quot;&lt;mountpoint&gt;&quot;] 如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 EXPOSE 用于为容器打开指定要监听的端口以实现与外部通信 Syntax EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议,空格分隔可以创建多个 EXPOSE指令可一次指定多个端口， 例如 EXPOSE 11211/udp 11211/tcp ENV 用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令 （如ENV、ADD、COPY等）所调用 调用格式为$variable_name或${variable_name} Syntax ENV &lt;key&gt; &lt;value&gt; 或 ENV &lt;key&gt;=&lt;value&gt; ... 第一种格式中，&lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只 能设置一个变量； 第二种格式可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果 &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另 外，反斜线也可用于续行； 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 ARG ARG指令定义了一个变量，用户可以在构建时将该变量传递给然后使用 `–bulis-arg= flag 如果用户指定了一个没有在dockerfile中定义的构建参数,构建输出一个警告.` syntax ARG&lt;name&gt;[&lt;default value&gt;] 1.使用FROM、LABEL、COPY制作镜像1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#######################################################################################创建docker的工作目录###############################################################################[root@centos7 ~]# mkdir /docker/[root@centos7 ~]# cd /docker/#######################################################################################编写dockerfile#####################################################################################[root@centos7 docker]# vim DockerfileFROM busybox:latest #对宿主机上已有的哪个镜像进行创建LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" #作者描述COPY index.html /data/web/html/ #将宿主机上docker目录下的index.html文件复制到容器中的/data/web/html/目录。如果写为/data/web/html则代表将 index.html改名为html，在容器中的/data/web/html/获取并未存在，可以自动创建。#################################################################################查看宿主机上的dockerfile的工作目录############################################################################[root@centos7 ~]# cd /docker/[root@centos7 docker]# echo "123456" &gt; index.html[root@centos7 docker]# lsindex.html#########################################################################################构建新的镜像############################################################################################dicker image build = docker build[root@centos7 docker]# docker image build -hUsage: docker image build [OPTIONS] PATH | URL | -Options: --add-host list 添加自定义主机到ip映射(主机:ip) --build-arg list 设置构建时变量 --cache-from strings 将图像视为缓存源 --rm 成功构建后删除中间容器(默认为true) -t, --tag list 制定的新的镜像设置新的仓库名和标签'name:tag' [root@centos7 docker]# docker image build /docker/ -t mybox:v0.1 #执行命令的目录，要求写dockerfile文件所在的目录中Sending build context to Docker daemon 3.072kBStep 1/3 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/3 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Running in 746880c7205cRemoving intermediate container 746880c7205c ---&gt; 7ccdca9907ceStep 3/3 : COPY index.html /data/web/html/ ---&gt; 7062cd4f08e0Successfully built 7062cd4f08e0Successfully tagged mybox:v0.1 [root@centos7 docker]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEmybox v0.1 7062cd4f08e0 ############################################################################基于创建的镜像启动容器查看COPY的文件是否存在############################################################################[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.1 /bin/sh/ # cat /data/web/html/index.html 123456 2.COPY本身也是可以是可以支持通配符12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455##################################################################################使用.dockerignore限制copy的文件############################################################################[root@centos7 docker]# pwd/docker[root@centos7 docker]# mkdir /docker/data/[root@centos7 docker]# cd !$cd /docker/data/[root@centos7 data]# echo "123" &gt; test1.html[root@centos7 data]# echo "123" &gt; test2.html[root@centos7 data]# echo "123" &gt; test3.html[root@centos7 docker]# tree.├── data│ ├── test1.html│ ├── test2.html│ └── test3.html└── Dockerfile###################################################################打算将/docker/data/目录下的文件全部复制到容器中排除test3.html文件###################################################################[root@centos7 docker]# vim .dockerignore #定义的.dockerignore 文件要写Dockerfile的相对路径，文件内也支持通配符data/test3.html#######################################################################################编辑Dockerfile文件###########################################################################################[root@centos7 docker]# vim /docker/Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"COPY data /data/web/html/ #如果源是目录会cp源目录下的文件不会cp目录本身##########################################################################################创建新的镜像###########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.4Sending build context to Docker daemon 5.632kBStep 1/3 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/3 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/3 : COPY data /data/web/html/ ---&gt; Using cache ---&gt; 5b5cd427fb81Successfully built 5b5cd427fb81Successfully tagged mybox:v0.4#############################################################################################创建容器查看#####################################################################################[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.4 /bin/sh/ # ls /data/web/html/*/data/web/html/test1.html /data/web/html/test2.html 3.Dockerflie文件中ADD指令123456789101112131415161718192021222324252627282930313233[root@centos7 docker]# pwd/docker[root@centos7 docker]# lsDockerfile wordpress-4.9-zh_CN.tar.gz[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ADD http://nginx.org/download/nginx-1.14.2.tar.gz /data/ #将网上的url打入镜像中，并运行容器是自动下载此压缩包放置在容器中的/data目录中ADD wordpress-4.9-zh_CN.tar.gz /data2/ #此压缩包是放置在docker的工作目录中，会在容器运行时解压到容器中/data2目录中。[root@centos7 docker]# docker image build /docker/ -t mybox:v0.3Sending build context to Docker daemon 10.13MBStep 1/4 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/4 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/4 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz /data/Downloading 1.015MB/1.015MB ---&gt; 62b1d80179e4Step 4/4 : ADD wordpress-4.9-zh_CN.tar.gz /data2/ ---&gt; 6bfaa9b46d21Successfully built 6bfaa9b46d21Successfully tagged mybox:v0.3[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.3 /bin/sh/ # ls /datadata/ data2// # ls /datanginx-1.14.2.tar.gz/ # ls /data2wordpress 4.Dockerfile文件中WORKDIR指令123456789101112131415161718192021222324252627282930313233343536373839404142###########################################################################################定义工作目录##########################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR / #定义工作目录，表示/data/ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ #定义工作目录，表示/data/haha/ADD wordpress-4.9-zh_CN.tar.gz haha/###########################################################################################制作镜像并运行查看######################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.4Sending build context to Docker daemon 10.13MBStep 1/6 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/6 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/6 : WORKDIR / ---&gt; Running in a9ef74256526Removing intermediate container a9ef74256526 ---&gt; 89e2798cf96cStep 4/6 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/Downloading 1.015MB/1.015MB ---&gt; 653df7aeb99bStep 5/6 : WORKDIR /data/ ---&gt; Running in 55e4223e543cRemoving intermediate container 55e4223e543c ---&gt; 471c356643dcStep 6/6 : ADD wordpress-4.9-zh_CN.tar.gz haha/ ---&gt; c1d30647ca27Successfully built c1d30647ca27Successfully tagged mybox:v0.4[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.4 /bin/sh/data # ls /data/haha nginx-1.14.2.tar.gz/data # ls /data/haha/wordpress 5.Dockerfile文件中VOLUME指定存储卷指令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465docker管理的卷（要是想要指定绑定在宿主机的某个目录进行映射关联关系的存储卷继续使用-v选项指定）####################################################################################################docker管理的卷###################################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR /ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ADD wordpress-4.9-zh_CN.tar.gz haha/VOLUME /data/web/html #指定容器中的此目录与宿主机上的某一个目录做存储卷映射关系#####################################################################################################打镜像--运行容器##############################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.5Sending build context to Docker daemon 10.15MBStep 1/7 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/7 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/7 : WORKDIR / ---&gt; Using cache ---&gt; 89e2798cf96cStep 4/7 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/Downloading 1.015MB/1.015MB ---&gt; Using cache ---&gt; 653df7aeb99bStep 5/7 : WORKDIR /data/ ---&gt; Using cache ---&gt; 471c356643dcStep 6/7 : ADD wordpress-4.9-zh_CN.tar.gz haha/ ---&gt; Using cache ---&gt; c1d30647ca27Step 7/7 : VOLUME /data/web/html ---&gt; Running in 388c0312f897Removing intermediate container 388c0312f897 ---&gt; 54cf9694d119Successfully built 54cf9694d119Successfully tagged mybox:v0.5[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.5 /bin/sh/data # ls /data/web/html//data # #################################################################################################宿主机上查看对应的随机的存储卷#########################################################################################[root@centos7 ~]# docker image inspect mybox:v0.5 "Volumes": &#123; "/data/web/html/": &#123;&#125; &#125;,[root@centos7 ~]# docker container inspect pc1 "Mounts": [ &#123; "Type": "volume", "Name": "177fd037174ad4af75866df8d07c575f1e4dbee2ee65613c6e36842b4e6de49e", "Source": "/var/lib/docker/volumes/177fd037174ad4af75866df8d07c575f1e4dbee2ee65613c6e36842b4e6de49e/_data", "Destination": "/data/web/html", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" &#125; 6.Dockerfile中EXPOSE指令1234567891011121314151617181920212223242526272829303132333435363738################################################################################################编写Dockerfile端口暴露tcp80###########################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR /ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ADD wordpress-4.9-zh_CN.tar.gz haha/VOLUME /data/web/htmlEXPOSE 80/tcp################################################################################################创建镜像并运行查看端口是否暴露##########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.6[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.6 /bin/sh[root@centos7 ~]# docker container inspect pc1 "Config": &#123; "Hostname": "b8bb78bbe2fb", "Domainname": "", "User": "", "AttachStdin": true, "AttachStdout": true, "AttachStderr": true, "ExposedPorts": &#123; "80/tcp": &#123;&#125; &#125;,[root@centos7 _data]# docker container port pc1#默认没有端口暴露，虽然在Dockerfile文件中已经定义，由于网络风险需要在启动容器是指定端口暴露这种暴露和存储卷相同，都是宿主机随机动态#############################################################################################此时可以手动指定开始端口暴漏##################################################################################################[root@centos7 docker]# docker run --name pc1 -it -P --rm mybox:v0.6 /bin/sh[root@centos7 ~]# docker container port pc180/tcp -&gt; 0.0.0.0:32768 7.Dockerfile文件中ENV指令12345678910111213[root@centos7 docker]# vim Dockerfile FROM busybox:latestENV webhome="/data/web/html/"LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR $&#123;webhome&#125;ADD http://nginx.org/download/nginx-1.14.2.tar.gz $&#123;webhome&#125;WORKDIR $&#123;webhome&#125; ADD wordpress-4.9-zh_CN.tar.gz ./ VOLUME $&#123;webhome&#125;EXPOSE 80/tcp[root@centos7 docker]# docker image build /docker/ -t mybox:v0.7[root@centos7 docker]# docker run --name pc2 -it --rm mybox:v0.7 /bin/sh 8.Dockerfile文件中ARG指令1234567891011121314151617181920212223242526build的时对变量传值的做法#Dockerfile中定义了创建容器时的变量参数。如果想临时修改参数可以在命令行中使用ARG定义变量，--build-arg,在执行docker image buil 命令命令行选项可以改变变量的值（docker新版本中支持）########################################################################################################使用ARG定义变量########################################################################################################[root@centos7 ~]# cd /docker/[root@centos7 docker]# vim Dockerfile FROM busybox:latestARG webhome="/data/web/html/"LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR $&#123;webhome&#125; ADD http://nginx.org/download/nginx-1.14.2.tar.gz $&#123;webhome&#125; WORKDIR $&#123;webhome&#125;ADD wordpress-4.9-zh_CN.tar.gz ./ VOLUME $&#123;webhome&#125;EXPOSE 80/tcp######################################################################################打镜像，并使用--build-arg指定新的便令再次打镜像#########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.8#这个镜像执行与EVN执行的镜像一样#使用--build-arg指定新的变量的值[root@centos7 docker]# docker image build --build-arg webhome="/var/www/html" /docker/ -t mybox:v0.7[root@centos7 docker]# docker run --name pc2 -it --rm mybox:v0.7 /bin/sh/var/www/html # run阶段Dockerfile文件中的指令 (run阶段：指明在bulid时做一些通过运行shell命令来达到去设定目标镜像的目的） RUN 用于指定docker build过程中运行的程序，其可以是任何命令（run的任何命令代表基础镜像支持的命令） Syntax RUN &lt;command&gt; 或 #以shell解释运行 RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] #不以shell解释运行 第一种格式中，&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程 在容器中的PID不为1，不能接收Unix信号，因此，当使用docker stop &lt;container&gt;命令停止容器 时，此进程接收不到SIGTERM信号； 第二种语法格式中的参数是一个JSON格式的数组，其中&lt;executable&gt;为要运行的命令，后面的 &lt;paramN&gt;为传递给命令的选项或参数；然而，此种格式指定的命令不会以“/bin/sh -c”来发起 ，因此常见的shell操作如变量替换以及通配符(?,*等)替换将不会进行；不过，如果要运行的命令 依赖于此shell特性的话，可以将其替换为类似下面的格式。 RUN [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;] 注意：json数组中，要使用双引号 CMD 类似于RUN指令，CMD指令也可用于运行任何命令或应用程序，不过，二者 的运行时间点不同 RUN指令运行于映像文件构建过程中，而CMD指令运行于基于Dockerfile构建出的新映像 文件启动一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器也 将终止；不过，CMD指定的命令其可以被docker run的命令行选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅最后一个会生效 Syntax CMD &lt;command&gt; 或 #以shell运行 CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或 #不以shell解释运行 CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;] 前两种语法格式的意义同RUN 第三种则用于为ENTRYPOINT指令提供默认参数 ENTRYPOINT 类似CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个 单独的可执行程序 与CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令行指定的 参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定 指定的程序 不过，docker run命令的–entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序 Syntax ENTRYPOINT &lt;command&gt; ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到 ENTRYPOINT命令最后做为其参数使用 Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效 Dockerfile文件中RUN指令12345678910111213141516#运行起来的命令还是shell[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# cat Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/* #删除yum生成的缓存不免刻录至镜像中[root@centos7 dockerlamp]# docker run --name pc1 --rm -it lamp:v0.1 /bin/shsh-4.2# rpm -q httpd phphttpd-2.4.6-88.el7.centos.x86_64php-5.4.16-46.el7.x86_64 Dockerfile文件中CMD指令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#RUN在bulid阶段#CMD在run阶段#实现容器运行起来不是shell而是httpd，实现httpd运行在前台###################################################################如何实现将httpd实现前台运行cat /usr/lib/systemd/system/httpd.service ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND####################################################################[root@centos7 ~]# cd /dockerlamp/[root@centos7 dockerlamp]# cat Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*CMD ["usr/sbin/httpd","-DFOREGROUND"][root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.2[root@centos7 dockerlamp]# docker run --name pc2 -it --rm lamp:v0.2 #烟验证[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf6b5dd3c9664 lamp:v0.2 "usr/sbin/httpd -DFO…" About a minute ago Up About a minute pc2[root@centos7 dockerlamp]# docker exec -it pc2 /bin/bash[root@f6b5dd3c9664 /]# netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN###############################################################################################################改进#####################################################制作Dockerfile文件并添加测试页打包至镜像###################[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# vim php.php&lt;?php phpinfo();?&gt;[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;CMD ["usr/sbin/httpd","-DFOREGROUND"]#########################################################################################################打镜像并运行容器测试##################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.3[root@centos7 dockerlamp]# docker run --name pc3 -it --rm lamp:v0.3 #测试[root@centos7 dockerlamp]# docker exec -it pc3 /bin/bash[root@b1da3c0ce6d8 /]# curl 172.17.0.2#########################################################################################################说明#################################################################################################################此时也可以用户在命令行中运行指定使用/bin/bash运行的##可以手动指定命令来覆盖镜像Dockerfile文件中CMD的##上一个镜像文件中默认已经定义运行容器默认运行的进程为httpd的，可以手动运行/bin/bash[root@centos7 dockerlamp]# docker run --name pc3 -it --rm lamp:v0.3 /bin/bash[root@97ef0a13d4fc /]# [root@97ef0a13d4fc /]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.1 0.1 11820 1884 pts/0 Ss 07:48 0:00 /bin/bashroot 16 0.0 0.0 51740 1732 pts/0 R+ 07:49 0:00 ps aux#Dokcerfile文件中定义的运行httpd已经被覆盖，查看进程httpd进程未被启动，如果想要CMD不被覆盖则此时应该用到ENTRYPOINT Dockerfile文件中ENTRYPOINT指令( --entrypoint )12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#ENTRYPOINT单独使用情况下作用于CMD大致相同除了不可被用户命令行运行容器时任意被覆盖#####################################################################################################常见Dockerfile文件########################################################################################################[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;EXPOSE 80/tcpVOLUME $&#123;root&#125;ENTRYPOINT ["usr/sbin/httpd","-DFOREGROUND"][root@centos7 dockerlamp]# lsDockerfile php.php#####################################################################################################打镜像运行容器############################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.4[root@centos7 dockerlamp]# docker run --name pc1 -it -P --rm lamp:v0.4#####################################################################################################宿主机检测################################################################################################################[root@centos7 dockerlamp]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0031f963fce6 lamp:v0.4 "usr/sbin/httpd -DFO…" 41 seconds ago Up 41 seconds 80/tcp pc1[root@centos7 dockerlamp]# docker container port pc180/tcp -&gt; 0.0.0.0:32769[root@centos7 dockerlamp]# curl 172.18.135.1:32769######################################################################################测试试图覆盖Docker文件中定义的执行的ENTRYPOINT指令#########################################################################################[root@centos7 dockerlamp]# docker run --name pc1 -P -it --rm lamp:v0.4 /bin/bashUsage: usr/sbin/httpd [-D name] [-d directory] [-f file]#报错拒绝覆盖Docker文件中定义的执行的ENTRYPOINT指令#命令行运行时添加的/bin/bash则当作了Docker文件中定义的执行的ENTRYPOINT指令后面的参数（httpd不支持/bin/bash当作参数）##################################################################################用户执行命令时如何指明强制覆盖Docker文件中定义的执行的ENTRYPOINT指令############################################################################[root@centos7 dockerlamp]# docker run --name pc1 -P -it --rm --entrypoint "/bin/bash" lamp:v0.4[root@5de1663077eb /]# Dockerfile文件中ENTRYPOINT指令于CMD指令同时使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#CMD定义的命令都要统统作为ENTRYPOINT的参数#一下两种格式意义相同CMD ["usr/sbin/httpd","-DFOREGROUND"] #CMD作为ENTRYPOINT的参数执行ENTRYPOINT ["/bin/bash","-c"]=========================================================================CMD /usr/bin/httpd -DFOREGROUD##########################################################################ENTRYPOINT与CMD分隔开来写的意义： 在ENTRYPOINT运行一个脚本，CMD的指令会被当作脚本的参数传递给脚本，脚本作为传统应用程序和容器化运行的中间层，来处理配置文件的，同时此配置文件是可以接受环境变量为参数来设置配置文件。#########################################################################################Dockerfile文件中ENTRYPOINT指令于CMD指令同时使用######################################################################################[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;ADD ent.sh /bin/EXPOSE 8080/tcpVOLUME $&#123;root&#125;CMD ["usr/sbin/httpd","-DFOREGROUND"]ENTRYPOINT ["/bin/ent.sh"]#编写的脚本的解释器一定是基础镜像中所被支持解释的类型[root@centos7 dockerlamp]# vim ent.sh#!/bin/bash##如果用户没定义此为默认的变量listen_port=$&#123;LISTEN_PORT:-8080&#125;server_name=$&#123;SERVER_NAME:-localhost&#125;doc_root=$&#123;DOC_ROOT:-/var/www/html&#125;cat &gt; /etc/httpd/conf.d/myweb.conf &lt;&lt;EOFlisten $listen_port&lt;VirtualHost *:$&#123;listen_port&#125;&gt; ServerName "$server_name" DocumentRoot "$doc_root" &lt;Directory "$doc_root"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/Virtualhost&gt;EOF#引用一个脚本的所有参数,默认的httpd进程/bin/bash的子进程&gt;，要想使得httpd作为init下的一级进程则如下写法(目标进程替换shell进程,让shell自动退出)exec "$@"[root@centos7 dockerlamp]# chmod +x /dockerlamp/ent.sh [root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.5[root@centos7 dockerlamp]# docker run --name pc1 -it --rm lamp:v0.5(可以在命令行中使用-e选项对容器中的环境变量传值 使用printenv命令可以查看传入变量的值 )[root@centos7 ~]# docker container port pc1[root@centos7 ~]# curl 172.18.135.1:32777[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@5b32b59d73ef /]# cat /etc/httpd/conf.d/myweb.conf listen 8080&lt;VirtualHost *:8080&gt; ServerName "localhost" DocumentRoot "/var/www/html" &lt;Directory "/var/www/html"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/Virtualhost&gt;#httpd的进程号为1[root@2967451fc4a9 /]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.7 408092 13436 pts/0 Ss+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 8 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 9 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 10 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 11 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 12 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUND#########################################################################################run是使用-e选项对容器进行变量复制######################################################################################################(可以在命令行中使用-e选项对容器中的环境变量传值 使用printenv命令可以查看传入变量的值 )[root@centos7 dockerlamp]# docker run --name pc1 -it --rm -P -e LISTEN_PORT=1010 lamp:v0.10[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@067566aa1878 /]# printenv LISTEN_PORT=1010[root@centos7 dockerlamp]# docker run --name pc1 -it --rm -P -e hi=hehe lamp:v0.10[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@2967451fc4a9 /]# echo $hi hehe USER 用于指定运行image时的或运行Dockerfile中任何RUN、CMD或ENTRYPOINT 指令指定的程序时的用户名或UID 默认情况下，container的运行身份为root用户 Syntax USER | 需要注意的是，可以为任意数字，但实践中其必须为/etc/passwd中某用户的有效 UID，否则，docker run命令将运行失败 HEALTHCHECK健康状态检测（新版支持） HEALTHCHECK指令告诉Docker如何测试一个容器，以检查它是否仍在工作。这可以检测出一些情况，比如web服务器陷入无限循环，无法处理新连接，即使服务器进程仍在运行。 HEALTHCHECK指令有两种形式: HEALTHCHECK [OPTIONS] CMD命令(通过在容器内运行命令来检查容器的健康状况) HEALTHCHECK NONE(不做任何健康检测) HEALTHCHECK(2) 在CMD之前可以出现的选项有: –interval=DURATION (default: 30s) #每隔多久检测一次，检测频率默认为30秒 –timeout=DURATION (default: 30s) #相对方发起检测请求，等待超时时长默认为30秒 –start-period=DURATION (default: 0s) #在什么时间开始进程健康检测，0表示容易以启动立刻做第一次健康检测 –retries=N (default: 3) #检测失败，重试检测多少吃后失败再判定为失败，默认为检测3次 命令的退出状态指示容器的健康状态。可能的值是: 0: success 成功 1: unhealthy 不健康 2: reserved 保留 范例： HEALTHCHECK –interval=5m –timeout=3s \ CMD curl -f http://localhost/ || exit 1 Dockerfile文件中HEALTHCHECK健康状态检测指令（新版支持）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657####################################################################################################定制健康检查计划############################################################################################################[root@centos7 ~]# vim /dockerlamp/Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql curl &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD ok.html php.php $&#123;root&#125;ADD ent.sh /bin/EXPOSE 8080/tcpVOLUME $&#123;root&#125;HEALTHCHECK --interval=3s --timeout=3s --start-period=2s CMD curl -f http://localhost/ok.html || exit 1CMD ["usr/sbin/httpd","-DFOREGROUND"]ENTRYPOINT ["/bin/ent.sh"][root@centos7 dockerlamp]# lsDockerfile ent.sh php.php[root@centos7 dockerlamp]# echo "ok" &gt; ok.html################################################################################################打镜像测试健康计划############################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v1.0[root@centos7 dockerlamp]# docker run --name pc1 -it --rm lamp:v1.0 #查看状态健康的[root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES763a1536b62d lamp:v1.0 "/bin/ent.sh usr/sbi…" 6 seconds ago Up 5 seconds (healthy) 8080/tcp pc1##############################################################################################删除文件查看是否不健康############################################################################################################[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@763a1536b62d /]# rm -rf /var/www/html/ok.html [root@centos7 dockerlamp]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES763a1536b62d lamp:v1.0 "/bin/ent.sh usr/sbi…" 3 minutes ago Up 3 minutes (unhealthy) 8080/tcp pc1#一旦发现容器出错时，手动将容器杀死重新构建，此功能是容器引擎做不到的，需要借助容器编排工具#如果再构建镜像的时候未构建也可以再运行命令行运行容器时手动指定（人为的在外部定义）[root@centos7 dockerlamp]# docker run --helpUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] --health-cmd string Command to run to check health --health-interval duration Time between running the check (ms|s|m|h) (default 0s) --health-retries int Consecutive failures needed to report unhealthy --health-start-period duration Start period for the container to initialize before starting health-retries countdown (ms|s|m|h) (default 0s) --health-timeout duration Maximum time to allow one check to run SHELL 指令允许覆盖命令的SHELL形式所使用的默认SHELL。 Linux上的默认shell是[“/bin/sh”， “-c”] Windows上的默认shell是[“cmd”， “/S”， “/C”] SHELL指令必须以JSON格式写入Dockerfile中 语法:SHELL[“可执行”，”参数”] 外壳指令可以出现多次。每个SHELL指令覆盖前面的所有SHELL指令，并影响后面的所有指令。 STOPSIGNAL 指令设置将发送到容器的系统调用信号以退出 这个信号可以是一个有效的无符号数字 它匹配内核的syscall表中的一个位置，例如9 也可以是SIGNAME格式的一个信号名，例如SIGKILL。 Syntax: STOPSIGNAL signal ONBUILD 用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件，此映像文件亦可作为base image被另一个Dockerfile 用作FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时，将会“触发”创 建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 Syntax ONBUILD 尽管任何指令都可注册成为触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和 MAINTAINER指令 使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild 在ONBUILD指令中使用ADD或COPY指令应该格外小心，因为新构建过程的上下文在缺少指 定的源文件时会失败 Dockerfile文件中的ONBUILD指令12345678910111213141516171819202122232425当别人利用自己的镜像做基础镜像你自己先前定义好的dockerfile，当别人拿自己镜像做基础镜像再次创建的dockerfile文件，自己填写的ONBUILD指令在自己run的时候不会运行，当别人拿自己镜像在此基础上创建的dockerfile执行的时候才会运行自己定义的ONBUILD指令。#定义ONBUILD，当别人拿自己的镜像做基础镜像再次做dockerfile执行时则在/data/data目录中下载URL，自己run时则不执行[root@centos7 ~]# mkdir /test[root@centos7 ~]# cd /test/[root@centos7 test]# vim DockerfileFROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"RUN mkdir -p /data/dataONBUILD ADD http://nginx.org/download/nginx-1.2.9.tar.gz /data/data#打镜像[root@centos7 test]# docker image build /test/ -t haha:v0.1#在自己制作的基础上再次制作[root@centos7 ~]# mkdir /test1[root@centos7 ~]# cd !$cd /test1[root@centos7 test1]# vim DockerfileFROM haha:v0.1RUN mkdir -p /data/haha#此时第一次制作的镜像定义的ONBUILD 会执行[root@centos7 test1]# docker image build /test1/ -t hehe:v0.1 如何将自己本地制作的镜像分享给别人1234567891011121314此场景适用于内部临时是使用、本地间的节点间共享将本地的镜像文件打包，剥离远程镜像仓库的格式，打包未tar文件，实现节点共享#####################抽取本地上的镜像######################[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhehe v0.1 e75cb1954996 7 minutes ago 1.93M[root@centos7 ~]# docker image save hehe:v0.1 -o ./jingxiang.tar[root@centos7 ~]# lsjingxiang.tar#####################复制到其他节点，使用此镜像#################[root@centos7 ~]# docker image load -i jingxiang.tar]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker存储卷]]></title>
    <url>%2F2019%2F01%2F01%2Fdocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[docker容器存储卷 一、什么是存储卷 Docker镜像由多个只读层叠加而成，启动容器时，Docker会加载只读镜 像层并在镜像栈顶部添加一个读写层 如果运行中的容器修改了现有的一个已经存在的文件，那该文件将会 从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在， 只是已经被读写层中该文件的副本所隐藏，此即“写时复制(COW)”机制 关闭并重启容器，其数据不受影响；但删除Docker容器，则其更改将会 全部丢失 存在的问题 存储于联合文件系统中，不易于宿主机访问； •容器间数据共享不便 删除容器其数据会丢失 解决方案：“卷(volume)” “卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机 上的某目录“绑定(关联)” Docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在 宿主机上的位置有所不同； 绑定挂载的卷 宿主机上的目录是用户指定的，在容器中的目录也是用户指定的 docker管理的卷 容器中的目录是用户指定的，在宿主机上的目录是在固定目录下自动生成的 脱离容器的生命周期，也可以脱离节点的生命周期 二 、存储卷实现 1.docker管理的卷123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051##################################################################################docker管理的卷###############################################################################1.容器中的目录是用户指定的，在宿主机上的目录是在固定目录下自动生成的，-v选项指定绑定的卷，自动在容器中创建对应的目录，并且指定的容器中的目录与宿主机上目录建立了关联关系#2.创建容器的命令行中使用--rm选项则退出容器时删除容器，宿主机上对应的存储卷则也将删除#3.停止容器宿主机上的存储卷不会被删除#3.如果使用docker container rm 容器，宿主机上对应的存储卷不会被删除[root@centos7 ~]# docker run --name pc1 -it -v /mydata busybox # lsmydata #可查看pc1容器对应的宿主机上的目录的关联关系[root@centos7 ~]# docker volume ls[root@centos7 ~]# docker container inspect pc1 "Mounts": [ &#123; "Type": "volume", "Name": "29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0", "Source": "/var/lib/docker/volumes/29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0/_data", "Destination": "/mydata", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" &#125;#容器中创建文件/ # cd /mydata//mydata # ls/mydata # touch a#宿主机在关联的目录中查看文件是否存在[root@centos7 ~]# cd /var/lib/docker/volumes/29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0/_data[root@centos7 _data]# lsa#退出容器/mydata # exit#宿主机上查看对应的目录[root@centos7 ~]# docker container ps -a[root@centos7 _data]# lsa#删除容器[root@centos7 ~]# docker container rm pc1pc1#宿主机上查看对应的存储卷目录[root@centos7 _data]# lsa 2.绑定挂载的卷123456789101112131415161718192021222324252627##################################################################################绑定挂载的卷#####################################################################################宿主机上的目录是用户指定的，在容器中的目录也是用户指定的#宿主上指定目录[root@centos7 ~]# mkdir /daizhe#创建容器并指定宿主机上的存储卷和指定容器中的目录进行关联#/daizhe为手动指定的宿主机的目录#/mydata为手动指定的容器中的目录[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox/ # lsmydata#测试/ # cd /mydata//mydata # touch a[root@centos7 ~]# ls /daizhe/a#删除容器卷不会被删除[root@centos7 ~]# docker container rm pc1pc1[root@centos7 ~]# ls /daizhe/a 3.多个容器挂载到宿主机上的同一个存储卷上1234567891011121314151617181920212223242526############################################################################多个容器挂载到宿主机上的同一个存储卷上####################################################################创建三个容器，同时容器到宿主机的存储卷指定为同一个目录[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox[root@centos7 ~]# docker run --name pc2 -it -v /daizhe:/mydata2 busybox[root@centos7 ~]# docker run --name pc3 -it -v /daizhe:/mydata3 busybox#测试是否同时挂载上宿主机上的同一个卷#宿主机在此目录下创建文件[root@centos7 ~]# cd /daizhe/[root@centos7 daizhe]# touch a c ddd#检测宿主机上文件是否存在[root@centos7 ~]# docker container exec pc1 ls /mydataacddd[root@centos7 ~]# docker container exec pc2 ls /mydata2acddd[root@centos7 ~]# docker container exec pc3 ls /mydata3acddd 利用存储卷实现容器间共享数据 名称空间共享 可共享 Net、IPC、UTS 不可共享 Mount、User、PID -v, –volume list 绑定安装卷 –volume-driver string 容器的可选卷驱动程序 –volumes-from list 从指定安装卷 4.容器间共享存储卷即容器间复制存储卷12345678910111213141516171819#创建容器，将容器中的/mydata目录与宿主机的/daizhe进行挂载实现存储卷[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox / # lsmydata / # touch /mydata/a c ddd/ # ls /mydata/a c ddd#创建一个容器命令为pc2复制pc1的存储卷[root@centos7 ~]# docker run --name pc2 -it --volumes-from pc1 busybox/ # lsbin etc mydata root tmp vardev home proc sys usr/ # ls /mydata/a c ddd#宿主机上查看[root@centos7 daizhe]# lsa c ddd 在容器中使用Volumes12345678- 为docker run命令使用-v选项即可使用Volume - Docker-managed volume - ~]# docker run -it -name bbox1 –v /data busybox - ~]# docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox1 - 查看bbox1容器的卷、卷标识符及挂载的主机目录 - Bind-mount Volume - ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name bbox2 busybox - ~]# docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox2 详细信息过滤1234567891011#显示的文件为json的文件格式- 字段内嵌[root@centos7 ~]# docker container inspect pc1#引用一级字段过滤[root@centos7 ~]# docker container inspect -f &#123;&#123;.NetworkSettings&#125;&#125; pc1&#123;&#123; c01b6a9b6146da49e5374db58e8aae168286c29b5b2fb0a814673415a4e4d796 false 0 map[] /var/run/docker/netns/c01b6a9b6146 [] []&#125; &#123;3db3b94ed903cdc6e5dfa72af482b30ff16faf23a08d697e4e3d3f0c01175e42 172.17.0.1 0 172.17.0.2 16 02:42:ac:11:00:02&#125; map[bridge:0xc4205aa000]&#125;#引用二级字段过滤[root@centos7 ~]# docker container inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; pc1172.17.0.2 josn格式文件美观显示1[root@centos7 ~]# yum install jq -y]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker网络模型]]></title>
    <url>%2F2018%2F12%2F31%2Fdocker%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[docker网络模型 Docker网络模型详解 docker安装完会修改默认的防火墙规则 将FORWARD链默认的accept修改为drop 如果用到转发的功能可以修改docker的启动文件如下 12345678910111213141516171819202122修改docker的启动文件[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPTExecStart=/usr/bin/dockerd -H unix://ExecReload=/bin/kill -s HUP $MAINPIDTimeoutSec=0RestartSec=2Restart=always~]# systemctl daemon-reload~]# systemctl restart docker~]# iptables -vnLChain FORWARD (policy ACCEPT 0 packets, 0 bytes) 四种网络 桥网络bridge： 默认docker0 NET桥 共享桥、共享接口：（共享网络名称空间） 联盟式网络 容器直接使用宿主机网络的共享 host网络 空网络、无网络、none网络123456查看docker可以使用的网络类型[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE38c0658bea06 bridge bridge local9b7ecc0031ef host host localc0de873b7341 none null local 共享桥 无网络：仅lo,仅自己通讯 –network none 桥网络 (详情查看 dacker network inspact brige) –network brige (默认) 容器间共享网络（联盟式网络） –network contariner:指定已有网容器（相同主机名，不同容器，但是网络是共享，仅共享网络，可以基于127.0.0.1通讯） 共享主机网络 –network host 无网络123456789[root@centos7 ~]# docker run --name pc1 -it --rm --network none busybox:latest/ # ifconfiglo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 桥网络123456789101112131415161718192021# (默认docker0 NET桥,详情查看 dacker network inspact brige)[root@centos7 ~]# docker run --name pc2 -it --rm --network bridge busybox:latest/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:508 (508.0 B) TX bytes:0 (0.0 B)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)#查看默认的net桥的详情[root@centos7 ~]# docker network inspect bridge 容器间共享网络1234567891011121314151617181920212223242526272829303132333435363738394041424344#容器间共享：NET,IPC,UTS第一个容器 [root@centos7 ~]# docker run --name pc2 -it --rm --network bridge busybox:latest / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:7 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:578 (578.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname 45ec3fb534cd第二个容器（共享第一个容器的地址） [root@centos7 ~]# docker run --name pc3 -it --rm --network container:pc2 busybox:latest / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:648 (648.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname 45ec3fb534cd 共享宿主机网络1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 [root@centos7 ~]# docker run --name pc4 -it --rm --network host busybox:latest / # ifconfig docker0 Link encap:Ethernet HWaddr 02:42:D4:BB:AF:CF inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 inet6 addr: fe80::42:d4ff:febb:afcf/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:21 errors:0 dropped:0 overruns:0 frame:0 TX packets:41 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:3522 (3.4 KiB) TX bytes:3758 (3.6 KiB) ens33 Link encap:Ethernet HWaddr 00:0C:29:14:4D:62 inet addr:192.168.52.1 Bcast:192.168.52.255 Mask:255.255.255.0 inet6 addr: fe80::bbfd:d184:6a67:3c45/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:264 errors:0 dropped:0 overruns:0 frame:0 TX packets:38 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:29263 (28.5 KiB) TX bytes:4779 (4.6 KiB) ens37 Link encap:Ethernet HWaddr 00:0C:29:14:4D:6C inet addr:172.18.135.1 Bcast:172.18.135.255 Mask:255.255.255.0 inet6 addr: fe80::4587:5c47:4c05:570b/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:33565 errors:0 dropped:0 overruns:0 frame:0 TX packets:8191 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:14694609 (14.0 MiB) TX bytes:1013772 (990.0 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:98 errors:0 dropped:0 overruns:0 frame:0 TX packets:98 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:10996 (10.7 KiB) TX bytes:10996 (10.7 KiB) veth7ff20ba Link encap:Ethernet HWaddr C2:81:A1:34:BA:5F inet6 addr: fe80::c081:a1ff:fe34:ba5f/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:648 (648.0 B) virbr0 Link encap:Ethernet HWaddr 52:54:00:FF:0B:1F inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname centos7.com 其他网络相关的命令123456789101112131415161718192021222324252627282930313233343536373839404142############################指定主机名########################## -h, --hostname string Container host name#默认的主机名是docker容器对应的id[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com busybox:latest / # hostnamep1.com##########################外部指定host文件以及文件的内容############ --add-host list Add a custom host-to-IP mapping (host:ip)#适用于容器间使用主机名通信，可多次使用[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com --add-host wg.p1.com:172.18.0.1 busybox:latest / # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.18.0.1 wg.p1.com172.17.0.2 p1.com p1[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com --add-host wg.p1.com:172.18.0.1 --add-host www.p1.com:8.8.8.8 busybox:latest #############创建容器时指定NDS服务器地址以及搜索域################# --dns list Set custom DNS servers --dns-search list Set custom DNS search domains[root@centos7 ~]# docker run --name pc1 -it --rm --hostname pc1.com --add-host www.pc1.com:1.1.1.1 --dns 8.8.8.8 --dns 114.114.114.114 --dns-search com busybox/ # cat /etc/hosts 127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters1.1.1.1 www.pc1.com172.17.0.2 pc1.com pc1/ # cat /etc/resolv.conf search comnameserver 8.8.8.8nameserver 114.114.114.114 服务暴漏 expose,public让私有网络中的主机上的服务被外部主机访问到—DNAT -p选项的使用格式 -p &lt;containerPort&gt; 将指定的容器端口映射至宿主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至宿主机上指定的主机端口&lt;hostPort&gt;（宿主机上所有地址的此端口） -p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至宿主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至宿主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口，具体的映射结果可使用docker port命令查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596-p选项的使用演示，可重复使用多次##########################################################################docker容器的80端口映射宿主机上的随机端口#######################################################################################[root@centos7 ~]# docker container run --name pc5 -it -p 80 busybox#ctrl + p ctrl + q#宿主机查看防火墙[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 214 packets, 20360 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:32770 to:172.17.0.2:80#可以访问宿主机的映射的端口从而访问容器的httpd服务[root@centos7 ~]# docker exec -it pc5 /bin/sh/ # /bin/httpd -h /etc/ # psPID USER TIME COMMAND 1 root 0:00 sh 7 root 0:00 /bin/sh 13 root 0:00 /bin/httpd -h /etc 14 root 0:00 ps/ # read escape sequence[root@centos7 ~]# curl 172.18.135.1:32770&lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;404 Not Found&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;H1&gt;404 Not Found&lt;/H1&gt;The requested URL was not found&lt;/BODY&gt;&lt;/HTML&gt;###########################################################################docker容器的80端口映射宿主机上的所有地址的80端口#########################################################################[root@centos7 ~]# docker run --name pc2 -it --network bridge -p 80:80 busybox/ # #查看防火墙[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 42 packets, 3276 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7e622f638dba busybox "sh" 3 minutes ago Up 3 minutes 0.0.0.0:80-&gt;80/tcp pc2##########################################################################docker容器的80端口映射宿主机上的指定地址的80端口###########################################################################第一个端口为宿主机的端口，第二个端口为容器的端口[root@centos7 ~]# docker container run --name pc1 -it --rm --network bridge -p 172.18.135.1:80:80 busybox/ # #容器的80地址绑定到宿主机的135.1地址的80端口[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 9 packets, 702 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 172.18.135.1 tcp dpt:80 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe87a037e4348 busybox "sh" About a minute ago Up About a minute 172.18.135.1:80-&gt;80/tcp pc1###########################################################################docker容器的80端口映射宿主机上的指定地址的随机端口##########################################################################[root@centos7 ~]# docker container run --name pc1 -it --rm --network bridge -p 172.18.135.1::80 busybox/ # [root@centos7 ~]# #宿主机检验[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 15 packets, 1151 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 172.18.135.1 tcp dpt:32768 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8dd54f2321cd busybox "sh" About a minute ago Up About a minute 172.18.135.1:32768-&gt;80/tcp pc1########################################################################################端口映射关系查看#################################################################################################[root@centos7 ~]# docker container port pc2443/tcp -&gt; 192.168.52.1:44380/tcp -&gt; 172.18.135.1:80 范例：-p 选项多重复使用1234567[root@centos7 ~]# docker container run --name pc2 -it --rm --network bridge -p 172.18.135.1:80:80 -p 192.168.52.1:443:443 busybox/ # [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES028e3e9f581f busybox "sh" 13 seconds ago Up 13 seconds 172.18.135.1:80-&gt;80/tcp, 192.168.52.1:443-&gt;443/tcp pc28dd54f2321cd busybox "sh" 5 minutes ago Up 5 minutes 172.18.135.1:32768-&gt;80/tcp pc1 自建网络类型 docker network create [OPTIONS] NETWORK -d, –driver string #指定网络类型，默认为bridge，NET –subnet strings #指定子网地址，默认第一个地址设置为桥接口（网关）的地址 –gateway strings #不使用默认的手动指定网关 –ip-range strings #指定网络分配的地址，如果不指定则除网关外全部分配 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465############################自建网络地址######################[root@centos7 ~]# docker network create -d bridge --subnet 10.0.0.0/24 mybr09902c4e06158ac6bcbabd2aa917b421e3b90d10100c7c457214da834268946e2[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE499e8e1a5fe6 bridge bridge local9b7ecc0031ef host host local9902c4e06158 mybr0 bridge localc0de873b7341 none null local[root@centos7 ~]# ifconfigbr-9902c4e06158: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 ether 02:42:c9:35:05:ce txqueuelen 0 (Ethernet) RX packets 384 bytes 43480 (42.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 38 bytes 4779 (4.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0####################将新创建的容器添加到自建的网络中###############[root@centos7 ~]# docker run --name pc1 --rm -it --network mybr1 busybox[root@centos7 ~]# docker exec -it pc1 /bin/sh[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B)#可以自己修改网卡名字[root@centos7 ~]# ifconfig br-9902c4e06158 down[root@centos7 ~]# ip link set br-9902c4e06158 name mybr0[root@centos7 ~]# ifconfig mybr0 up#但是要重新启动docker[root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl restart docker######################将此容器连接到bridge网络中#################[root@centos7 ~]# docker network connect bridge pc1[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B)eth1 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:7 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:578 (578.0 B) TX bytes:0 (0.0 B)#####################将一个网络接口从此容器中拆除###################[root@centos7 ~]# docker network disconnect bridge pc1[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B) 修改默认的docker0桥12345678910111213141516171819自定义docker0桥的网络属性信息：/etc/docker/daemon.json文件[root@centos7 ~]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "bip": "192.168.1.5/24", "fixed-cidr": "10.20.0.0/16", "fixed-cidr-v6": "2001:db8::/64", "mtu": 1500, "default-gateway": "10.20.1.1", "default-gateway-v6": "2001:db8:abcd::89", "dns": ["10.20.1.2","10.20.1.3"] &#125; 核心选项为bip，即bridge ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。[root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl restart docker 文档路径： https://docs.docker.com/engine/userguide/networking/default_network/custom-docker0/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker应用基础]]></title>
    <url>%2F2018%2F12%2F30%2Fdocker%E5%BA%94%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[docker应用基础 docker：容器使用的前端工具 组件：(彼此间通过http/https协议进行通讯) Client : 客户端 Daemon ：docker守护进程、服务端 Registry : docker镜像仓库 docker安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105##########################确保时间同步########################[root@centos7 yum.repos.d]# ntpdata ...#######################下载docker yum源######################[root@centos7 yum.repos.d]# pwd/etc/yum.repos.d[root@centos7 yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #下载的docker源为阿里云#####################安装docker社区版########################如果有报错Error: Package: 3:docker-ce-18.09.0-3.el7.x86_64 (docker-ce-stable) Requires: container-selinux &gt;= 2.9 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigestyum install http://vault.centos.org/centos/7.3.1611/extras/x86_64/Packages/container-selinux-2.9-4.el7.noarch.rpm[root@centos7 yum.repos.d]# yum install docker-ce############################使用镜像加速#####################方式一：aliyun官网镜像加速 https://cr.console.aliyun.com方式二：docker公共加速器 http://www.docker-cn.com/registry-mirror支持两种方式同时使用[root@centos7 ~]# mkdir -p /etc/docker[root@centos7 ~]# tee /etc/docker/daemon.json &lt;&lt;-'EOF'&gt; &#123;&gt; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com","https://registry.docker-cn.com"]&gt; &#125;&gt; EOF[root@centos7 ~]# systemctl daemon-reload[root@centos7 ~]# systemctl restart docker###################查看docker客户端版本和服务端版本############查看版本信息[root@centos7 ~]# docker versionClient: #客户端版本 Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community #服务端版本 Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:19:08 2018 OS/Arch: linux/amd64 Experimental: false查看更详细的docker环境信息[root@centos7 ~]# docker infoContainers: 0 #系统上总共有多少个容器 Running: 0 #容器运行态个数 Paused: 0 #容器暂停态个数 Stopped: 0 #容器停止态个数Images: 0 #当前系统上镜像的个数Server Version: 18.09.0Storage Driver: overlay2 #存储驱动 Backing Filesystem: xfs #放置在本地的文件系统的格式，建议使用xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfs #资源配额功能，需要的虚拟文件系统格式Plugins: #插件 Volume: local #存储卷的插件，仅支持本地 Network: bridge host macvlan null overlay #网络插件，支持桥接、主机、叠加、不使用等 Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog #日志系统插件Swarm: inactive #集群管理工具Runtimes: runc #运行时环境Default Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: seccomp Profile: defaultKernel Version: 3.10.0-862.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.779GiBName: centos7.comID: CUT4:A7LF:QJ4B:OORH:POA7:AZ7I:SWFT:7F4H:YKBQ:YFXH:BBBV:WGNQDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: #镜像加速服务 https://xr8r3tc3.mirror.aliyuncs.com/Live Restore Enabled: falseProduct License: Community Engine docker资源管理 两类资源 images:镜像资源管理（静态） docker image -h Usage: docker image COMMAND Commands: build history import inspect load ls prune pull #从远程下载镜像 push #将本地的镜像上传 rm #删除 docker image rm = docker rmi save tag #给镜像打标签,一个镜像可以有多个标签 container：容器管理（动态） Usage: docker container COMMAND Commands: attach commit #保存镜像 cp create #创建容器 diff exec #执行容器中的命令 export inspect kill #杀死容器 logs ls pause #暂停容器 port prune rename #重命名容器 restart #重启容器 rm #删除容器 run start #启动容器 stats stop #停止容器 top unpause #继续容器 update wait docker容器状态 容器的状态docker container ps = docker ps running 运行态 stopped 停止态 paused 暂停态 created 创建态 deleted 删除态 OOM:内存耗尽 docker容器命令使用 创建容器 docker create docker run -t,tty -i,–interactive –name #容器的名字一定不要同名 docker0 : 桥 172.17.0.0/16 –network : 指定网络接口 –rm : 如果容器停止寓意容器引擎立即将其容器删除 # 适用于临时的容器与-d 选项项抵触 -d,detach : 守护，运行在后台剥离与当前终端的关系 #与–rm选项相抵触不可同时使用 容器中执行命令 #只有终端id号为1 的进程则此容器才会停止 docker container exec = docker exec -i:交互式接口 -t:分配终端 docker常用命令 docker stop #停止容器的运行 docker rm #删除容器，直接删除则容器中的数据也将删除，代表容器内的存储单元也被删除掉，且慎用。 查看容器的日志信息 docker container logs = docker logs docker日志是直接发往终端控制台 查看容器使用占用的内存空间 docker container stats = docker stats 显示容器运行的所有的进程的相关信息 docker container top = docker top 列出所有的相关镜像 docker images = docker image ls 返回容器的终端 docker container attach = docker attach 去docker hub中下载nginx镜像时：最后一位数字为奇数数位金丝雀版，非稳定版，开发版。生产中最好使用偶数或者stable 某一程序如果运行在容器中，并且id号为1的进程时，此进程必须运行在前台。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168###################根据关键字来了解镜像################[root@centos7 ~]# docker search redis###################拖取镜像到本地#########################################默认从hub.docker.com拖取###########[root@centos7 ~]# docker image pull centos:7[root@centos7 ~]# docker pull redis:4-alpine4-alpine: Pulling from library/rediscd784148e348: Pull complete #分层拖下来的，每一个都是一个层48d4c7155ddc: Pull complete 6d908603dbe8: Pull complete fd4371c1c78e: Pull complete e6818dc808c2: Pull complete f1884d594f6f: Pull complete Digest: sha256:775bbf766a5b711acce88e4142faf56cd587d63ddc4d57b49f7872f71d56fab6Status: Downloaded newer image for redis:4-alpine###################显示本地镜像########################REPOSITORY：镜像仓库仓库名TAG：标签IMAGE ID: 镜像idCREATED: 镜像的创建时间SIZE：镜像存储在本地的大小[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEredis 4-alpine 37abb58bfd68 9 days ago 30MB######################删除镜像#########################[root@centos7 ~]# docker image rm 镜像名称#######################查看镜像的详细信息###############[root@centos7 ~]# docker image inspect redis:4-alpine#显示一个jesn格式镜像信息#########################启动容器######################docker run = docker container run - it :交互式，并附加终端--name:容器名字[root@centos7 ~]# docker container run -it --name c1 centos:7 /bin/bash[root@3aee0a6acdfd /]# [root@3aee0a6acdfd /]# yum install net-tools[root@3aee0a6acdfd /]# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255[root@3aee0a6acdfd /]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0如果运行容器主机上默认生成一docker0的桥，默认网段172.17.0.0 ，随后创建的容器都会加载到此桥上，此桥为NET桥[root@centos7 ~]# ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:ddff:fed7:23fb prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:dd:d7:23:fb txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 14 bytes 1770 (1.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@centos7 ~]# brctl show #容器引擎动态实现bridge name bridge id STP enabled interfacesdocker0 8000.0242ddd723fb no 启动容器后也会生成默认防火墙规则 前期使用建议关闭firewalld##################查看所有运行状态的容器#####################- docker ps = docker container ps[root@centos7 ~]# docker ps -a #查看容器的所有状态[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3aee0a6acdfd centos:7 "/bin/bash" 12 minutes ago Up 12 minutes c1#####################显示当前docker支持的网络接口#############- 默认bridge,代表docker0桥[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE777fc349679b bridge bridge local9b7ecc0031ef host host localc0de873b7341 none null local##################运行redis进程且放到后台不影响当前终端########[root@centos7 ~]# docker run --name redis -d redis:4-alpine 100f426c23ae6f50e015e7ad5fd13cdee33180c9ac43835f7d6ecef422b38f1c- CONTAINER ID：短格式id- IMAGE :容器启动用的镜像- COMMAND：容器运行的命令- CREATED：容器创建的时间- STATUS：容器运行的状态- PORTS：容器监听的端口，监听的端口是在容器内部的- NAMES：容器的名称[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES100f426c23ae redis:4-alpine "docker-entrypoint.s…" 8 seconds ago Up 6 seconds 6379/tcp redis######################删除正在运行容器#########################[root@centos7 ~]# docker container stop redisredis[root@centos7 ~]# docker container rm redis #如果容器停止寓意容器引擎立即将其容器删除redis#####################外部在容器中执行命令##################以交互式接口中运行bash[root@centos7 ~]# docker container exec -it redis /bin/sh/data # /data # ps auxPID USER TIME COMMAND 1 redis 0:00 redis-server #只有终端id号为1 的进程则此容器才会停止，所以退出交互式终端并非结束了次容器 17 root 0:00 /bin/sh 23 root 0:00 ps aux#######################w外部终端查看容器运行状态#############- 在不进入容器的交互式接口，显示的信息为容器内部的运行状态信息[root@centos7 ~]# docker container exec redis ps auxPID USER TIME COMMAND 1 redis 0:00 redis-server 24 root 0:00 ps aux######################创建容器在停止状态是自动删除###########- 拉取一个nginx的镜像[root@centos7 ~]# docker image pull nginx:1.15-alpine- 运行执行的/bin/sh,并且退出终端时结束删除此进程[root@centos7 ~]# docker run --name web -it --rm nginx:1.15-alpine /bin/sh/ # / # exit[root@centos7 ~]# docker ps -a######################以守护进程运行nginx#####################-d与--rm 选项不可同时使用[root@centos7 ~]# docker run --name web -d nginx:1.15-alpine [root@centos7 ~]# docker container exec web ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0[root@centos7 ~]# curl 172.17.0.2 #外部主机访问容器中的服务[root@centos7 ~]# wget -O - -q 172.17.0.2[root@centos7 ~]# elinks -dump 172.17.0.2#######################查看容器的日志信息#######################- docker日志是直接发往终端控制台，[root@centos7 ~]# docker container logs web####################显示容器运行的所有的进程的相关信息###########- 仅显示指定的容器的运行的进程的相关信息[root@centos7 ~]# docker top webUID PID PPID C STIME TTY TIME CMD###########################attach########################## 剥离容器当前运行的终端，但是容器仅是退出了运行的终端，但不停止容器# 剥离终端 ctrl+p ,ctrl+q[root@centos7 ~]# docker run --name c2 centos:7[root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2b5aa9c9e6ad centos:7 "/bin/bash" 8 seconds ago Exited (0) 6 seconds ago c2[root@centos7 ~]# docker rm c2c2[root@centos7 ~]# docker run --name c2 -it centos:7[root@49e278ef42ca /]# [root@centos7 ~]# [root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES49e278ef42ca centos:7 "/bin/bash" 40 seconds ago Up 39 seconds c2[root@centos7 ~]# docker container attach c2[root@49e278ef42ca /]# docker镜像 About Docker Images Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用 于创建并启动docker容器 采用分层构建机制，最底层为bootfs，其之为rootfs bootfs：用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以 节约内存资源； rootfs：位于bootfs之上，表现为docker容器的根文件系统; 传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为“只读”模式，完整性自检完成 后将其重新挂载为读写模式； docker中，rootfs由内核挂载为“只读”模式，而后通过“联合挂载 ”技术额外挂载一个“可写”层。 Docker Image Layer（层） 位于下层的镜像称为父镜像(parent image)，最底层的称为基础镜像(base image) - 最上层为“可读写”层，其下的均为“只读”层 wirtable最上面的可写层并非镜像提供，而是容器提供的 建构在本地的二级文件系统 /var/lib/docker/image/overlay2/ distribution imagedb layerdb repositories.json Aufs advanced multi-layered unification filesystem：高级多层统一文件系统 用于为Linux文件系统实现“联合挂载” aufs是之前的UnionFS的重新实现，2006年由Junjiro Okajima开发； Docker最初使用aufs作为容器文件系统层，它目前仍作为存储后端之一来支持； aufs的竞争产品是overlayfs，后者自从3.18版本开始被合并到Linux内核； docker的分层镜像，除了aufs，docker还支持btrfs, devicemapper和vfs等 在Ubuntu系统下，docker默认Ubuntu的 aufs；而在CentOS7上，用的是devicemapper。Docker Registry 启动容器时，docker daemon会试图从本地获取相关的镜像；本地镜像 不存在时，其将从Registry中下载该镜像并保存到本地。 分类 Registry用于保存docker镜像，包括镜像的层次结构和元数据 用户可自建Registry，也可使用官方的Docker Hub Sponsor Registry：第三方的registry，供客户和Docker社区使用 Mirror Registry：第三方的registry，只让客户使用 Vendor Registry：由发布Docker镜像的供应商提供的registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供的registry Docker Registry中的镜像通常由开发人员制作，而后推送至“公共”或“ 私有”Registry上保存，供其他人员使用，例如“部署”到生产环境. 制作docker仓库docker Hub https://hub.docker.com 麻雀虽小五脏俱全的linux发行版--很忙的盒子12345678[root@centos7 ~]# docker image pull busybox:latestbusybox:一个微型的linux发行版（很忙的盒子）[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 758ec7f3a1ee 4 days ago 1.15M[root@centos7 ~]# docker run --name box1 -it busybox:latest /bin/sh/ # lsbin dev etc home proc root sys tmp usr var 范例：制作镜像仓库docker container commit –helpUsage: docker container commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Options: -a, –author string #指定镜像的作者 -c, –change list #对底层镜像默认运行的程序 进行修改 -m, –message string -p, –pause #表示制作镜像的时候将容器暂时暂停，避免数据结构不一致 1234567891011121314151617181920212223242526272829303132333435363738394041#########对本地很忙的盒子进行修改并推送到自己docker hub镜像仓库#######[root@centos7 ~]# docker run --name box1 -it busybox:latest /bin/sh/ # lsbin dev etc home proc root sys tmp usr var/ # mkdir /daizhe/ # lsbin dev home root tmp vardaizhe etc proc sys usr#####################保存修改的镜像并打标签########################确保容器终端不要关闭[root@centos7 ~]# docker container commit box1 docker19980110/mybox:v0.1sha256:42956b7e3ff8df5b77abd5b44654aac46bc00fd2ec2e690f1e92847e9879fd99[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox v0.1 c6a32f929f07 15 seconds ago 1.15MB###############本机启动测试查看保存的数据数据结构是否存在#############[root@centos7 ~]# docker run --name mybox -it docker19980110/mybox:v0.1 / # lsbin dev home root tmp vardaizhe etc proc sys usr#####################登陆docker hub###############################[root@centos7 ~]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: docker19980110Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded#####################将本地的镜像推送到docker hub#####################如果原仓库总有相同的镜像，当推送时，仅推送变化的那一层[root@centos7 ~]# docker image push docker19980110/mybox:v0.1 The push refers to repository [docker.io/docker19980110/mybox]5190a84cd271: Pushed 23bc2b70b201: Mounted from library/busybox v0.1: digest: sha256:05ce13e43087ab6249c717c3278e9f2c8d1199310447ac806c527ee85b0dfcb8 size: 734 范例：制作镜像并对底层镜像默认运行的程序 进行修改以及标签设置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465############################很忙的盒子中默认带有http程序####################/ # /bin/httpd -h/bin/httpd: option requires an argument -- hBusyBox v1.29.3 (2018-12-24 21:25:20 UTC) multi-call binary.Usage: httpd [-ifv[v]] [-c CONFFILE] [-p [IP:]PORT] [-u USER[:GRP]] [-r REALM] [-h HOME]or httpd -d/-e/-m STRINGListen for incoming HTTP requests -i Inetd mode -f Don't daemonize -v[v] Verbose -p [IP:]PORT Bind to IP:PORT (default *:80) -u USER[:GRP] Set uid/gid after binding to port -r REALM Authentication Realm for Basic Authentication -h HOME Home directory (default .) -c FILE Configuration file (default &#123;/etc,HOME&#125;/httpd.conf) -m STRING MD5 crypt STRING -e STRING HTML encode STRING -d STRING URL decode STRING####################对很忙的盒子进行修改，启动默认运行httpd############保存原有的镜像#启动运行http -f 前台运行，不适用守护进行 -h 执行家目录[root@centos7 ~]# docker container commit -p -a "daizhe&lt;daizhe.com&gt;" -c 'CMD ["/bin/sh","-c","/bin/httpd -f -h /data/web/html"]' myboxsha256:eced8dbd5d14dcb5c4be938d509103a9440cf3d7080620b49dac8fbbbe309974#保存的镜像未打标签[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; eced8dbd5d14 26 seconds ago 1.15MB##########################将保存的镜像添加标签######################使用id号指定镜像来重新添加标签[root@centos7 ~]# docker image tag eced8dbd5d14 docker19980110/mybox:v0.2[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox v0.2 eced8dbd5d14 6 minutes ago 1.15MB########################将一个镜像打多个标签#######################latest表示最新的意思[root@centos7 ~]# docker tag docker19980110/mybox:v0.2 docker19980110/mybox:latest[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox latest eced8dbd5d14 8 minutes ago 1.15MBdocker19980110/mybox v0.2 eced8dbd5d14 8 minutes ago 1.15MB#########################再次将本地的镜像推送到docker hub仓库########[root@centos7 ~]# docker push docker19980110/mybox:v0.v0.1 v0.2 [root@centos7 ~]# docker push docker19980110/mybox:v0.2 The push refers to repository [docker.io/docker19980110/mybox]355c5bc17ee9: Pushed 5190a84cd271: Layer already exists 23bc2b70b201: Layer already exists v0.2: digest: sha256:ab14ea25f1fbcc40a623343dd44a76224568a0200820f1ee5b61dc81c96ca12a size: 941[root@centos7 ~]# docker push docker19980110/mybox:latest The push refers to repository [docker.io/docker19980110/mybox]355c5bc17ee9: Layer already exists 5190a84cd271: Layer already exists 23bc2b70b201: Layer already exists latest: digest: sha256:ab14ea25f1fbcc40a623343dd44a76224568a0200820f1ee5b61dc81c96ca12a size: 941]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基础]]></title>
    <url>%2F2018%2F12%2F30%2Fdocker%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[docker基础即认识docker 先从认识容器开始 什么是容器？ 先来看看容器较为官方的解释： 一句话概括容器：容器就是将软件打包成标准化单元，以用于开发、交付和部署。 容器镜像是轻量的、可执行的独立软件包 ，包含软件运行所需的所有内容：代码、运行时环境、系统工具、系统库和设置。 容器化软件适用于基于Linux和Windows的应用，在任何环境中都能够始终如一地运行。 容器赋予了软件独立性，使其免受外在环境差异（例如，开发和预演环境的差异）的影响，从而有助于减少团队间在相同基础设施上运行不同软件时的冲突。Container 再来看看容器较为通俗的解释： 如果需要通俗的描述容器的话，我觉得容器就是一个存放东西的地方，就像书包可以装各种文具、衣柜可以放各种衣服、鞋架可以放各种鞋子一样。我们现在所说的容器存放的东西可能更偏向于应用比如网站、程序甚至是系统环境。 容器是一种基础工具；泛指任何可以用于容纳其它物品的工具，可以 部分或完全封闭，被用于容纳、储存、运输物品；物体可以被放置在 容器中，而容器则可以保护内容物； 人类使用容器的历史至少有十万年，甚至可能有数百万年的历史； 容器的类型 • 瓶 - 指口部比腹部窄小、颈长的容器。 • 罐 - 指那些开口较大、一般为近圆筒形的器皿。 箱 - 通常是立方体或圆柱体。形状固定。 篮 - 以条状物编织而成。 桶 - 一种圆柱形的容器。 袋 - 柔性材料制成的容器，形状会受内容物而变化。 瓮 - 通常是指陶制，口小肚大的容器。 碗 - 用来盛载食物的容器。 柜 - 指一个由盒组成的家俱。 鞘 - 用于装载刀刃的容器。 图解物理机、虚拟机与容器 关于虚拟机与容器的对比在后面会详细介绍到，这里只是通过网上的图片加深大家对于物理机、虚拟机与容器这三者的理解。 物理机 虚拟机 容器 再来谈谈Docker的一些概念 通过上面这三张抽象图，我们大概可以通过类比概括出： 容器虚拟化的是操作系统而不是硬件，容器之间是共享同一套操作系统资源的。虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统。因此容器的隔离级别会稍低一些。 相信通过上面的解释大家对于容器这个既陌生又熟悉的概念有了一个初步的认识，下面我们就来谈谈Docker的一些概念。 什么是Docker 关于Docker是什么并太好说，下面我通过四点向你说明Docker到底是个什么东西。 Docker是世界领先的软件容器平台。 Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于LXC。 Docker能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。 用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker思想 集装箱 标准化： ①运输方式、②存储方式、 ③API接口 隔离 Docker容器的特点 轻量，在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。 标准，Docker容器基于开放式标准，能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。 安全，Docker赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。 为什么要用Docker Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现“这段代码在我机器上没问题啊”这类问题；——一致的运行环境 可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。——更快速的启动时间 避免公用的服务器，资源会容易受到其他用户的影响。——隔离性 善于处理集中爆发的服务器使用压力；——弹性伸缩，快速扩展 可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。——迁移方便 使用Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。——持续交付和部署。 容器 VS 虚拟机 容器和虚拟机具有相似的资源隔离和分配优势，但功能有所不同，因为容器虚拟化的是操作系统，而不是硬件，因此容器更容易移植，效率也更高。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 容器与虚拟机 (VM) 总结 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动 。 虚拟机（VM）是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此占用大量空间。而且VM启动也十分缓慢 。 容器与虚拟机（VM）两者是可以共存的 Docker基本概念 Docker包括三个基本概念： 镜像（Image） 容器（Container） 仓库（Repository） 镜像（Image）——一个特殊的文件系统 操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。 Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。 Docker设计时，就充分利用Union FS的技术，将其设计为分层存储的架构。 镜像实际是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器（Container）——镜像运行时的实体 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。前面讲过镜像使用的是分层存储，容器也是如此。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照Docker最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新run，数据却不会丢失。 仓库（Repository）——集中存放镜像文件的地方 镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 一个Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以latest作为默认标签。 Docker Registry公开服务和私有Docker Registry的概念： Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。 最常使用的Registry公开服务是官方的Docker Hub ，这也是默认的Registry，并拥有大量的高质量的官方镜像，网址为：hub.docker.com/ 。在国内访问Docker Hub可能会比较慢国内也有一些云服务商提供类似于Docker Hub的公开服务。 除了使用公开服务外，用户还可以在本地搭建私有Docker Registry 。Docker官方提供了Docker Registry镜像，可以直接使用做为私有Registry服务。开源的Docker Registry镜像只提供了Docker Registry API的服务端实现，足以支持Docker命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群]]></title>
    <url>%2F2018%2F12%2F28%2Fredis%E7%BC%93%E5%AD%982%2F</url>
    <content type="text"><![CDATA[redis集群、架构 一： redis 集群 上一个步骤的主从架构无法实现master和slave角色的自动切换，即当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障转移(将slave提升为master)，需要手动改环境配置才能切换到slave redis服务器，另外也无法横向扩展Redis服务的并行写入性能，当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题，即：1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用 2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的。 Redis 集群实现方式：客户端分片 代理分片 Redis Cluster（做集群一般使用奇数台服务器做集群，3、5、7,损坏的节点剩余要大于总节点的一半） Sentinel(哨兵)：测试主从是否正常通讯：ping GONG(集群实现的前提是要使主从的版本相同) Sentinel 进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用，其已经被集成在redis2.6+的版本中，Redis的哨兵模式到了2.8版本之后就稳定了下来。一般在生产环境也建议使用Redis的2.8版本的以后版本。哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel) 进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master。每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息，以确认对方是否”活”着，如果发现对方在指定配置时间(可配置的)内未得到回应，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” ，英文名称：Subjective Down，简称SDOWN。有主观宕机，肯定就有客观宕机。当“哨兵群”中的多数Sentinel进程在对Master主服务器做出 SDOWN 的判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”，英文名称是：Objectively Down， 简称 ODOWN。通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务器节点，然后自动修改相关配置，并开启故障转移（failover）。Sentinel 机制可以解决master和slave角色的切换问题。 1234Sentinel(哨兵)：哨兵判断服务器是否存活的方式 [root@centos7 redis]# redis-cli -h 127.0.0.1 -p 6379 127.0.0.1:6379&gt; ping PONG 实现哨兵默认端口26379(在生产中建议哨兵是一台独立的服务器，这里演示的时redis服务器上实现哨兵，哨兵判断节点的存活状态机制：ping :pang)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475实验准备： 三台主机：全部编译安装，为了避免实验出现差别，尽量使用相同版本 主节点：172.18.135.1 从节点1：172.18.135.2 从节点2：172.18.135.3实验目的如果主节点挂了，自动其中一个从节点上选择一个自动升级为主节点第一步：编辑所有主机的配置文件 修改本机的监听地址 76行 bind 0.0.0.0 修改主从结构的配置 286 replicaof 192.168.7.103 6379 293 masterauth 123456 #master如果密码需要设置 [root@centos7 ~]# systemctl restart redis.service 第二步：首先实现一主两从架构 从节点1： 127.0.0.1:6379&gt; info [ # Replication role:slave master_host:172.18.135.1 master_port:6379 master_link_status:up 从节点2： 127.0.0.1:6379&gt; info [ # Replication role:slave master_host:172.18.135.1 master_port:6379 master_link_status:up第三步：哨兵可以不和Redis服务器部署在一起配置哨兵：编辑配置文件sentinel.conf： master 、slave1、slave2 配置： [root@centos7 ~]# cp /usr/local/src/redis-5.0.3/sentinel.conf /usr/local/redis/etc [root@centos7 ~]# vim /usr/local/redis/etc/sentinel.conf port 26379 daemonize yes pidfile /usr/local/redis/data/redis-sentinel_26379.pid logfile "/usr/local/redis/logs/sentinel_26379.log" dir /usr/local/redis/data sentinel monitor mymaster 172.18.131.1 6379 2 sentinel auth-pass mymaster 123456 sentinel down-after-milliseconds mymaster 15000 #15秒 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000第四步：启动哨兵 每个节点上都启动哨兵 [root@centos7 ~]# /usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel.conf [root@centos7 etc]# ss -tnl LISTEN 0 511 *:26379 查看哨兵的日志文件第五步：哨兵验证 [root@centos7 ~]# redis-cli -p 26379 127.0.0.1:26379&gt; info Sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=mymaster,status=ok,address=172.18.135.1:6379,slaves=2,sentinels=3已经实现哨兵 可以创建值，并停用主节点，哨兵自动选举新的主节点 哨兵配置文件详情12345678910111213[root@redis-s1 etc]# grep "^[a-Z]" /usr/local/redis/etc/sentinel.conf bind 0.0.0.0port 26379daemonize yes #守护进程运行pidfile "/usr/local/redis/redis-sentinel.pid"logfile "/usr/local/redis/sentinel_26379.log"dir "/usr/local/redis" # 哨兵运行产生的数据目录sentinel monitor mymaster 192.168.7.101 6379 2 #这里的2表示，多少个哨兵决定主节点挂掉则提升新的主,此实验的哨兵有三个sentinel auth-pass mymaster 123456 #主节点的密码，为了安全建议添加密码sentinel down-after-milliseconds mymaster 30000 #(SDOWN)主观下线的时间，主节点多长时间没有反应则代表下线，根据生产需求设置sentinel parallel-syncs mymaster 1 #发生故障转移时候同时向新master同步数据的slave数量，数字越小总同步时间越长sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间（单位秒）sentinel deny-scripts-reconfig yes #代表没有调用其他脚本 应用程序如何连接redis？： java客户端连接redis是通过jedis来实现的，java代码用的时候只要创建jedis对象就可以建多个jedis连接池来连接redis，应用程序再直接调用连接池即可连接Redis。 而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves服务充当Master。这个时候,我们的应用即使使用了Jedis连接池,Master服务挂了,我们的应用奖还是无法连接新的Master服务，为了解决这个问题,Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知我们的应用,把我们的应用连接到新的Master服务。 Jedis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，Jedis Sentinel底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行连接的切换，JedisSentinelPool在每次从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。 二： Redis Cluster部署 Redis cluster之前的分布式方案： 1) 客户端分区：由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入分配、高可用管理和故障转移等 2)代理方案：基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈。 在哨兵sentinel机制中，可以解决redis高可用的问题，即当master故障后可以自动将slave提升为master从而可以保证redis服务的正常使用，但是无法解决redis单机写入的瓶颈问题，即单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和整个集群状态,每个节点都和其他所有节点连接，特点如下： 1：所有Redis节点使用(PING-PING机制)互联 2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效 3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。 4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。 5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候，会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上，从而有效解决单机瓶颈。 Redis cluster基本架构 假如三个主节点分别是：A, B, C 三个节点，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是： 节点A覆盖0－5460 节点B覆盖5461－10922 节点C覆盖10923－16383 此结构缺点是主节点之间无法数据同步 Redis cluster主从架构： Redis cluster的架构虽然解决了并发的问题，但是又引入了一个新的问题，每个Redis master的高可用如何解决？ 部署redis集群：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#####################环境准备####################三台服务器，每台服务器启动6379和6380两个redis 服务，生产环境建议直接6台服务器。另外预留一台服务器做集群添加节点测试。实验方式：基于端口的不同实现（生产环境中最好使用6台主机实现）172.18.135.1:6379/6380 172.18.135.5:6379/6380172.18.135.2:6379/6380 ##############创建redis cluster集群的前提####目前仅有三台节点####1.每个redis node节点采用相同的硬件配置、相同的密码2.每个节点必须开启参数(确保每台节点都是主节点) #编辑配置文件507 requirepass 123456 # 建议每个节点都设置密码，但是保证每个节点的密码保持一致838 cluster-enabled yes #必须开启集群状态，开启后redis 进程会有cluster显示846 cluster-config-file nodes-6380.conf #此文件有redis cluster集群自动创建和维护，不需要任何手动操作################模拟一台节点上创建第二个节点###################每台节点上模拟创建第二台节点实现一台机器上两个节点[root@centos77 ~]# cp /usr/local/redis/etc/redis.conf /usr/local/redis/etc/redis6380.conf #对原配置文件拷贝进行简单修改bind 0.0.0.0port 6380pidfile "/var/run/redis_6380.pid"logfile "/usr/local/redis/logs/6380.log"cluster-config-file nodes-6380.conf创建启动脚本[root@centos77 ~]# cp /usr/lib/systemd/system/redis.service /usr/lib/systemd/system/redis6380.service[root@centos77 ~]# vim !$vim /usr/lib/systemd/system/redis6380[Unit]Description=Redis persistent key-value databaseAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis6380.conf --supervised systemdExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDType=notifyUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755[Install]WantedBy=multi-user.target######################## 启动############################[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.2:/usr/local/redis/etc/[root@centos77 ~]# scp /usr/lib/systemd/system/redis6380.service root@172.18.135.2:/usr/lib/systemd/system/[root@centos77 ~]# scp /usr/lib/systemd/system/redis6380.service root@172.18.135.1:/usr/lib/systemd/system/启动查看端口[root@centos77 etc]# ss -tnl 6379 6380 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657######################创建集群#####################[root@redis-s1 ~]# redis-cli -a 123456 --cluster create 192.168.7.101:6379 192.168.7.101:6380 192.168.7.102:6379 192.168.7.102:6380 192.168.7.103:6379 192.168.7.103:6380 --cluster-replicas 1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.7.102:6380 to 192.168.7.101:6379Adding replica 192.168.7.101:6380 to 192.168.7.102:6379Adding replica 192.168.7.103:6380 to 192.168.7.103:6379&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[OK] Perfect anti-affinity obtained!M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 #带M的为master slots:[0-5460] (5461 slots) master #当前master的槽位起始和结束位S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 #带S的slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master #当前master的槽位起始和结束位S: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master #当前master的槽位起始和结束位S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afCan I set the above configuration? (type 'yes' to accept): yes #输入yes自动创建集群&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.....&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.101:6379)M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 #master的ID及端口 slots:[0-5460] (5461 slots) master #已经分配的槽位 1 additional replica(s) #分配了一个slaveS: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave #slave没有分配槽位 replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64af[OK] All nodes agree about slots configuration. #所有节点槽位分配完成&gt;&gt;&gt; Check for open slots... #检查打开的槽位&gt;&gt;&gt; Check slots coverage... #检查插槽覆盖范围[OK] All 16384 slots covered. #所有槽位(16384个)分配完成#########################检查状态######################由于未设置masterauth认证密码，所以主从未建立起来，但是集群已经运行，所以需要在每个slave控制台使用config set设置masterauth密码，或者写在每个redis配置文件中，最好是在控制点设置密码之后再写入配置文件当中。 123456789101112131415#######################分别设置masterauth密码#############[root@redis-s1 ~]# redis-cli -h 192.168.7.101 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.101:6380&gt; CONFIG SET masterauth 123456OK[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6380&gt; CONFIG SET masterauth 123456OK[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6380&gt; CONFIG SET masterauth 123456OK#######################确认slave状态为up################## 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465########################验证master状态###################[root@redis-s1 ~]# redis-cli -h 192.168.7.101 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.101:6379&gt; INFO Replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.7.102,port=6380,state=online,offset=840,lag=0master_replid:0aa3281030eb29bf268f3317d4afe401f661a917master_replid2:0000000000000000000000000000000000000000master_repl_offset:840second_repl_offset:-1repl_backlog_active:1repl_backlog_size:4026531840repl_backlog_first_byte_offset:1repl_backlog_histlen:840192.168.7.101:6379&gt;###################管理要用集群的命令管理#######################################验证集群状态#################192.168.7.101:6379&gt; CLUSTER INFOcluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:1474cluster_stats_messages_pong_sent:1507cluster_stats_messages_sent:2981cluster_stats_messages_ping_received:1502cluster_stats_messages_pong_received:1474cluster_stats_messages_meet_received:5cluster_stats_messages_received:2981########################查看集群node对应关系################使用命令cluster nodes：192.168.7.103:6380&gt; cluster nodes7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545659135000 4 connected7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 myself,slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545659135000 6 connectedf4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545659135000 1 connected 0-5460116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545659136000 3 connected 5461-1092270de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545659134000 5 connected 10923-163832b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545659135946 5 connected##########################验证集群写入key##################192.168.7.101:6379&gt; SET key1 value1 #经过算法计算，当前key的槽位需要写入指定的node (error) MOVED 9189 192.168.7.102:6379 #槽位不在当前node所以无法写入192.168.7.103:6379&gt; SET key1 value1 (error) MOVED 9189 192.168.7.102:6379 192.168.7.102:6379&gt; SET key1 value1 #指定的node就可以写入OK192.168.7.102:6379&gt; KEYS *1) "key1"192.168.7.101:6379&gt; KEYS *(empty list or set)192.168.7.103:6379&gt; KEYS *(empty list or set)#############################集群状态监控#################### redis-cli -a 123456 --cluster check 192.168.7.101:6379 Redis cluster集群节点维护 集群运行时间长久之后，难免由于硬件故障、网络规划、业务增长等原因对已有集群进行相应的调整， 比如增加Redis node节点、减少节点、节点迁移、更换服务器等。增加节点和删除节点会涉及到已有的槽位重新分配及数据迁移。 集群维护之动态添加节点： 增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别启动两台Redis node，因为一主一从。 案例： 因公司业务发展迅猛，现有的三主三从redis cluster架构可能无法满足现有业务的并发写入需求，因此公司紧急采购一台服务器192.168.7.104，需要将其动态添加到集群当中其不能影响业务使用和数据丢失，则添加过程如下: 1234567891011121314为了满足生产需求创建新的服务器##同步之前Redis node的配置文件到192.168.7.104 Redis编译安装目录，注意配置文件的监听 IP##scp redis.conf 192.168.7.104:/usr/local/redis/etc/scp redis_6380.conf 192.168.7.104:/usr/local/redis/etc/##################分别启动redis服务##########################systemctl daemon-reloadsystemctl restart redis/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis_6380.conf################将新创建的新的服务器添加节点到集群############在新创建的节点上配置（新加入的节点是没有槽位的）要添加的redis节点IP和端口 添加到的集群中的master IP:端口# redis-cli -a 123456 --cluster add-node 192.168.7.104:6379 192.168.7.101:6379 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#############################分配槽位######################添加主机之后需要对添加至集群种的新主机重新分片否则其没有分片在新创建的节点上配置（分配的槽位是从以前每个节点上瓜分槽位来给新加入的服务器）使用命令重新分配槽位:[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.104:6379)M: 886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379 slots: (0 slots) masterM: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62S: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afM: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 4096 #分配多少个槽位192.168.7.104:6379What is the receiving node ID? 886338acd50c3015be68a760502b239f4509881c #手动输入192.168.7.104的node IDPlease enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1: all #将哪些源主机的槽位分配给192.168.7.104:6379，all是自动在所有的redis node选择划分，如果是从redis cluster删除主机可以使用此方式将主机上的槽位全部移动到别的redis主机……………………………….. Moving slot 6823 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6824 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6825 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6826 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 10923 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10924 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10925 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10926 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62………………………………….. Moving slot 1364 from f4cfc5cf821c0d855016488d6fbfb62c03a14fdaDo you want to proceed with the proposed reshard plan (yes/no)? yes #确认分配##################验证重新分配槽位之后的集群状态#############重新分配槽位是自动从每个Redis node上移动一些槽位到新的master上 123456789101112131415161718192021222324252627282930313233###################为新的master添加slave节点################master节点必须有salvae一但挂掉损失惨重命令格式：(这样加入的192.168.7.104:6380 默认为master)# redis-cli -a 123456 --cluster add-node 192.168.7.104:6380 192.168.7.104:6379###################更改新节点更改状态为slave###############需要手动将其指定为某个master 的slave，否则其默认角色为master[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6380 -a 123456 #登录到新添加节点Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6380&gt; CLUSTER NODES #查看当前集群节点，找到目标master 的ID7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545700464964 3 connected116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545700470516 3 connected 6827-109222b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545700468498 5 connectedb9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 myself,master - 0 1545700464000 0 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 master - 0 1545700465468 7 connected 0-1364 5461-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545700467489 5 connected 12288-16383f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545700464461 1 connected 1365-54607186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545700469508 1 connected192.168.7.104:6380&gt; CLUSTER REPLICATE 886338acd50c3015be68a760502b239f4509881c #将其设置slave，设置为192.168.7.104:6379的slave #命令格式为cluster replicate MASTERIDOK192.168.7.104:6380&gt; CLUSTER NODES #再次查看集群节点状态，验证节点是否已经更改为指定master 的slave7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545700517970 3 connected116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545700514942 3 connected 6827-109222b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545700518979 5 connectedb9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 myself,slave 886338acd50c3015be68a760502b239f4509881c 0 1545700509000 0 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 master - 0 1545700516456 7 connected 0-1364 5461-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545700519988 5 connected 12288-16383f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545700515953 1 connected 1365-54607186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545700516962 1 connected192.168.7.104:6380&gt;#########################验证当前集群状态######################## 集群维护之动态删除节点 添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除。如果一个Redis node节点上的槽位没有被完全迁移，删除该node的时候会提升有数据且无法删除。 案例： 由于192.168.7.101服务器使用年限已经超过三年，已经超过厂商质保期而且硬盘出现异常报警，经运维部架构师提交方案并同开发同事开会商议，决定将现有Redis集群的4台服务器分别是192.168.7.101/192.168.7.102/192.168.7.103/192.168.7.104中的192.168.7.101临时下线，三台服务器的并发写入性能足够支出未来1-2年的业务需求，则删除Redis node 192.168.7.101的操作如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748##############迁移master 的槽位之其他master##################[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.102:6379Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.102:6379)M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)M: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s)S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afS: b9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380 slots: (0 slots) slave replicates 886338acd50c3015be68a760502b239f4509881cS: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaS: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 4096 #迁移master上的多少个槽位What is the receiving node ID? 886338acd50c3015be68a760502b239f4509881c #接收槽位的服务器IDPlease enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1: f4cfc5cf821c0d855016488d6fbfb62c03a14fda #从哪个服务器迁移4096个槽位Source node #2: done #写done，表示没有其他master了 Moving slot 5457 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5458 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5459 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5460 from f4cfc5cf821c0d855016488d6fbfb62c03a14fdaDo you want to proceed with the proposed reshard plan (yes/no)? yes #是否继续迁移完成！######################验证槽位迁移完成######################## 123456789101112131415161718192021####################从集群删除服务器##########################虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除命令格式： redis-cli -a 123456 --cluster del-node IP:Port ID#删除master：[root@redis-s1 ~]# redis-cli -a 123456 --cluster del-node 192.168.7.101:6379 f4cfc5cf821c0d855016488d6fbfb62c03a14fdaWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Removing node f4cfc5cf821c0d855016488d6fbfb62c03a14fda from cluster 192.168.7.101:6379&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.#删除slave：该节点上如果还有其他节点上master 的slave，但是由于服务器下架也要一并删除，因此要提前把保证每个master至少有一个slave。[root@redis-s1 ~]# redis-cli -a 123456 --cluster del-node 192.168.7.101:6380 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Removing node 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 from cluster 192.168.7.101:6380&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.####################验证node 是否删除######################发现192.168.7.101已经被删除，但是由于192.168.7.101:6380之前是192.168.7.103:6379的slave，所以删除后会导致相应的master缺少slave，需要重新为没有slave的master分配slave。可以发现下图的192.168.7.104有两个slave，分别是192.168.7.102:6380和192.168.7.104:6380，因此需要将其中一个slave转移为192.168.7.103的slave。 12345678910111213141516####################重新分配slave#########################将192.168.7.104:6380 转移为192.168.7.103的slave[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6379&gt; CLUSTER NODES116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545708439000 3 connected 6827-10922b9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 slave 886338acd50c3015be68a760502b239f4509881c 0 1545708440717 7 connected7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave 886338acd50c3015be68a760502b239f4509881c 0 1545708437682 7 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 myself,master - 0 1545708439000 7 connected 0-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545708440000 5 connected 12288-163837eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545708438697 3 connected192.168.7.104:6380&gt; CLUSTER REPLICATE 70de3821dde4701c647bd6c23b9dd3c5c9f24a62OK##################验证集群Master与Slave对应关系#################Redis Slave节点一定不能个master在一个服务器，必须为跨主机交叉备份模式，避免主机故障后主备全部挂掉，如果出现Redis Slave与Redis master在同一台Redis node的情况，则需要安装以上步骤重新进行slave分配，直到不相互交叉备份为止。 集群维护之模拟Master宕机123456789101112131415161718192021目前的架构为三主三从，互为跨主机master slave模式。#####################测试数据写入###########################测试在master写入数据，并在其对应的slave验证数据：192.168.7.102:6379&gt; SET key1 value1OK192.168.7.102:6379&gt; get key1"value1"#######################slave验证数据########################192.168.7.103:6380&gt; KEYS *1) "key1"192.168.7.103:6380&gt; get key1(error) MOVED 9189 192.168.7.102:6379 #slave不提供读写，只提供数据备份即master选举####################停止master并验证故障转移################Redis Master服务停止之后，其对应的slave会被选举为master继续处理数据的读写操作。# systemctl stop redis######################验证slave 日志######################## tail -f /usr/local/redis/redis_6380.log 1#####################验证slave状态######################## 123456789101112######################验证数据读写#########################确认slave 192.168.7.103:6380切换为master之后可以继续为业务提供读写业务且数据没有丢失。192.168.7.103:6380&gt; KEYS *1) "key1"192.168.7.103:6380&gt; SET aaa bbbOK192.168.7.103:6380&gt; get key1"value1"192.168.7.103:6380&gt; get aaa"bbb"192.168.7.103:6380&gt;注：服务恢复之后重新验证各master的slave。 集群维护之导入现有Redis数据 导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。 案例： 公司将redis cluster部署完成之后，需要将之前的数据导入之Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。1234567891011121314151617181920212223242526272829303132333435363738394041#########################基础环境准备#####################导入数据之前需要关闭各redis 服务器的密码，包括集群中的各node和源Redis server，避免认证带来的环境不一致从而无法导入，但是可以加参数--cluster-replace 强制替换Redis cluster已有的key。[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6379&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6379&gt; CONFIG SET requirepass ""OK192.168.7.103:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6379&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit#######################执行数据导入###########################将源Redis server的数据直接导入之redis cluster。命令格式：#redis-cli --cluster import 集群服务器IP:PORT --cluster-from 外部Redis node-IP:PORT --cluster-copy --cluster-replace[root@redis-s2 redis]# redis-cli --cluster import 192.168.7.103:6379 --cluster-from 192.168.7.101:6379 --cluster-copy 1#####################edis cluster验证数据#################### redis扩展集群方案 除了Redis 官方自带的Redis cluster集群之外，还有一写开源的集群解决方案可供参考使用 codis： Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有显著区别 (不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。 codis-proxy相当于redis，即连接codis-proxy和连接redis是没有任何区别的，codis-proxy无状态，不负责记录是否在哪保存，数据在zookeeper记录，即codis proxy向zookeeper查询key的记录位置，proxy 将请求转发到一个组进行处理，一个组里面有一个master和一个或者多个slave组成，默认有1024个槽位，redis cluster 默认有16384个槽位，其把不同的槽位的内容放在不同的group。 Github 地址：https://github.com/CodisLabs/codis/blob/release3.2/doc/tutorial_zh.md twemproxy 由Twemproxy代替客户端实现分片，即代替用户将数据分片并到不同的后端服务器进行读写，其还支持memcached，可以为proxy配置算法，缺点为twemproxy是瓶颈，不支持数据迁移 官方github地址https://github.com/twitter/twemproxy/ Github 地址：https://github.com/twitter/twemproxy]]></content>
      <categories>
        <category>linux服务</category>
      </categories>
      <tags>
        <tag>redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis缓存]]></title>
    <url>%2F2018%2F12%2F26%2Fredis%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[redis缓存及架构 一： 缓存概念： 缓存概念 缓存是为了调节速度不一致的两个或多个不同的物质的速度，在中间对速度较快的一方起到一个加速访问速度较慢的一方的作用，比如CPU的一级、二级缓存是保存了CPU最近经常访问的数据，内存是保存CPU经常访问硬盘的数据，而且硬盘也有大小不一的缓存，甚至是物理服务器的raid 卡有也缓存，都是为了起到加速CPU 访问硬盘数据的目的，因为CPU的速度太快了，CPU需要的数据硬盘往往不能在短时间内满足CPU的需求，因此PCU缓存、内存、Raid 卡以及硬盘缓存就在一定程度上满足了CPU的数据需求，即CPU 从缓存读取数据可以大幅提高CPU的工作效率。 系统缓存 1.buffer与cache：buffer：缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存在写入磁盘，buffer 一般用于写缓冲，用于解决不同介质的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的部分数据。cache：缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。 2.cache的保存位置： 客户端：浏览器 内存：本地服务器、远程服务器 硬盘：本机硬盘、远程服务器硬盘 速度对比： 客户端浏览器-内存-远程内存-硬盘-远程硬盘。 3.cache的特性： 过期时间 强制过期，源网站更新图片后CDN是不会更新的，需要强制是图片缓存过期 命中率，即缓存的读取命中率 用户层缓存： 1.DNS缓存： 默认为60秒，即60秒之内在访问同一个域名就不在进行 DNS解析： 查看chrome浏览器的DNS缓存： chrome://net-internals/#dns 浏览器缓存过期机制： 最后修改时间： 系统调用会获取文件的最后修改时间，如果没有发生变化就返回给浏览器304的状态码，表示没有发生变化，然后浏览器就使用的本地的缓存展示资源， Etag标记： 基于Etag标记是否一致做判断页面是否发生过变化 过期时间： 以上两种都需要发送请求，即不管资源是否过期都要发送请求进行协商，这样会消耗不必要的时间，因此有了缓存的过期时间，即第一次请求资源的时候带一个资源的过期时间，默认为30天，当前这种方式使用的比表较多，但是无法保证客户的时间都是准确并且一致的，因此假如一个最大生存周期，使用用户本地的时间计算缓存数据是否超过多少天，下面的过期时间为2027年，但是缓存的最大生存周期计算为天等于3650天即10年，过期时间如下： CDN缓存： 什么是CND： 内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够就近获取，有效降低访问延迟，提升服务可用性，CDN 第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了，第二解决不同运营商之间的互联，因为可以让联通的网络访问联通让电信的网络访问电信，起到加速用户访问的目的， 第三：解决用户访问的地域问题，就近返回用户资源。 百度CDN：https://cloud.baidu.com/product/cdn.html 阿里CDN：https://www.aliyun.com/product/cdn?spm=5176.8269123.416540.50.728y8n 腾讯CDN：https://www.qcloud.com/product/cdn 用户请求CDN流程： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根据访问的热度不同而进行不同级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。 CDN主要优势： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快 调度准确-将用户调度到最近的边缘节点 性能优化-CDN 专门用于缓存响应速度快 安全相关-抵御攻击 节省带宽：由于用户请求由边缘节点响应，因此大幅降低到源站带宽。 应用层缓存： Nginx、PHP等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代码上线后字节码没有更新的现象。 其他层面缓存： CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存 磁盘缓存 RAID卡 分布式缓存：redis、memcache # MegaCli64 -LDinfo -Lall -aAll 二： redis部署与使用： redis基础： 官网地址：https://redis.io/ Redis和Memcached是非关系型数据库也成为NoSQL，MySQL、Mariadb、SQL Server、PostgreSQL、Oracle 数据库属于关系型数据(RDBMS, Relational Database Management System) redis简介： Redis(Remote Dictionary Server)在2009年发布，开发者Salvatore Sanfilippo是意大利开发者，他本想为自己的公司开发一个用于替换MySQL的产品Redis，但是没有想到他把Redis开源后大受欢迎，短短几年，Redis就有了很大的用户群体，目前国内外使用的公司有知乎网、新浪微博、GitHub等 redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还提供了易扩展、高性能、具备数据持久性等功能。Redis在高并发、低延迟环境要求比较高的环境使用量非常广泛，目前redis在DB-Engine月排行榜https://db-engines.com/en/ranking 中一直比较靠前，而且一直是键值型存储类的首位。 redis对比memcached： 支持数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文件中恢复数据到内存继续使用。 支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合) 支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF。 支持更大的value数据：memcache单个key value最大，支持1MB，而redis最大支持512MB。 Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。 支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提升性能和数据安全性。 都是基于C语言开发。 redis 典型应用场景： Session 共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享 消息队列：ELK的日志缓存、部分业务的订阅发布系统 计数器：访问排行榜、商品浏览数等和次数相关的场景 缓存：数据查询、电商网站商品信息、新闻内容 微博/微信社交场合：共同好友、点赞评论等 Redis安装及使用： 官方下载地址：http://download.redis.io/releases/ yum安装redis 123456789[root@centos7 ~]# yum list redisLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileAvailable Packagesredis.x86_64 3.2.12-2.el7 [root@centos7 ~]# yum install redis -y[root@centos7 ~]# systemctl start redis &amp;&amp; systemctl enable redis[root@centos7 ~]# redis-cli127.0.0.1:6379&gt; 编译安装redis 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101官方的安装命令： https://redis.io/download 创建一个适合自己程序防止路径 [root@centos7 ~]# mkdir -pv /usr/local/src [root@centos7 ~]# cd !$ cd /usr/local/src [root@centos7 src]# pwd /usr/local/src [root@centos7 src]# ls redis-5.0.3.tar.gz解压 [root@centos7 src]# tar xvf redis-5.0.3.tar.gz 安装开发包组 [root@centos7 redis-5.0.3]# yum groupinstall "Development Tools"编译安装（大小写敏感） [root@centos7 redis-5.0.3]# make PREFIX=/usr/local/redis install [root@centos7 redis]# cd /usr/local/redis/bin/ [root@centos7 bin]# ls redis-benchmark redis-check-rdb redis-sentinel redis-check-aof redis-cli redis-server创建主配置文件以及程序文件 [root@centos7 ~]# cd /usr/local/redis/ [root@centos7 redis]# ls bin [root@centos7 redis]# mkdir etc logs run data root@centos7 redis]# cp /usr/local/src/redis-5.0.3/redis.conf /usr/local/redis/etc/ [root@centos7 redis]# ln -sv /usr/local/redis/bin/* /usr/bin/初次启动解决当前警报启动 [root@centos7 redis]# redis-server /usr/local/redis/etc/redis.conf 34186:C 26 Dec 2018 22:10:01.659 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 34186:C 26 Dec 2018 22:10:01.659 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=34186, just started 34186:C 26 Dec 2018 22:10:01.659 # Configuration loaded 34186:M 26 Dec 2018 22:10:01.660 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 34186 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 34186:M 26 Dec 2018 22:10:01.662 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 34186:M 26 Dec 2018 22:10:01.662 # Server initialized 34186:M 26 Dec 2018 22:10:01.662 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect. 34186:M 26 Dec 2018 22:10:01.662 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 34186:M 26 Dec 2018 22:10:01.662 * Ready to accept connections解决第一次启动出现的三个报警 [root@centos7 ~]# vim /etc/sysctl.conf net.core.somaxconn = 512 vm.overcommit_memory = 1 [root@centos7 ~]# sysctl -p net.core.somaxconn = 512 vm.overcommit_memory = 1 [root@centos7 ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 永久生效写进配置文件间，开机自动加载 vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled chmod a+x /etc/rc.d/rc.local再次启动则无报警 [root@centos7 ~]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 35112:C 27 Dec 2018 10:17:12.662 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 35112:C 27 Dec 2018 10:17:12.662 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=35112, just started 35112:C 27 Dec 2018 10:17:12.662 # Configuration loaded 35112:M 27 Dec 2018 10:17:12.663 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 35112 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 35112:M 27 Dec 2018 10:17:12.667 # Server initialized 35112:M 27 Dec 2018 10:17:12.667 * Ready to accept connections 解决当前的警告提示： 警报：tcp-backlog： backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。 net.core.somaxconn = 512 警报：vm.overcommit_memory： 0、表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1、表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2、表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 警报：transparent hugepage： 开启大页内存动态分配，需要关闭让redis 负责内存管理。 临时生效 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 永久生效写进配置文件间，开机自动加载 vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled chmod a+x /etc/rc.d/rc.local123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051redis启动默认使再前台工作，编写启动脚本将服务的启动送往后台执行服务启动对应的端口已经默认监听的端口 [root@centos7 ~]# ss -tnl LISTEN 0 511 127.0.0.1:6379 编辑redis服务启动脚本 服务的配置文件放在了/usr/local/redis/bin/redis-servier 服务的主配置文件放在了/usr/local/redis/etc/redis.conf [root@centos7 ~]# vim /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf --supervised systemd ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target编辑主配置文件 vim /usr/local/redis/etc/redis.conf daemonize yes #让redis作为守护进程运行创建redis 用户和数据目录： [root@centos7 ~]# useradd redis -s /sbin/nologin [root@centos7 ~]# chown -R redis.redis /usr/local/redis/ [root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl start redis.service [root@centos7 ~]# ss -tnl LISTEN 0 511 127.0.0.1:6379 创建命令软连接 [root@centos7 ~]# ln -sv /usr/local/redis/bin/* /usr/bin/修改服务器的监听端口，默认监听在本机的127.0.0.1 [root@centos7 ~]# vim /usr/local/redis/etc/redis.conf bind 127.0.0.1 172.18.135.1 (bind 地址绑定到本机哪个地址供谁可以访问0.0.0.0代表本机监听在本机的所有的地址)使用客户端连接本机的redis服务器 [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; info 编译安装后的命令： [root@redis-s1 ~]# ll /usr/local/redis/bin/total 32656 -rwxr-xr-x 1 redis redis 4365488 Dec 13 09:21 redis-benchmark #redis性能测试工具 -rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-aof #AOF文件检查工具 -rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-rdb #RDB文件检查工具 -rwxr-xr-x 1 redis redis 4800752 Dec 13 09:21 redis-cli #redis #客户端工具 lrwxrwxrwx 1 redis redis 12 Dec 13 09:21 redis-sentinel -&gt; redis-server #哨兵，软连接到 使用客户端连接redis： #/usr/local/redis/bin/redis-cli -h IP/HOSTNAME -p PORT -a PASSWORD redis配置文件： redis主要配置项： bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP protected-mode yes #redis3.2 之后加入的新特性，在没有设置bind IP和密码的时候只允许访问127.0.0.1:6379 port 6379 #监听端口 tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值。 timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时。 tcp-keepalive 300 #tcp 会话保持时间 daemonize no #认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes,当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面 supervised no #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程，centos 7以后都使用systemd pidfile /var/run/redis_6379.pid #pid文件路径,确定生成的日志目录是有权限的，实际上存放的就是进程号。 loglevel notice #日志级别 logfile “” #日志路径 databases 16 #设置db 库数量，默认16个库，可以连接到redis后使用select # ,切换库 always-show-logo yes #在启动redis 时是否显示log save 900 1 #在900秒内有一个键内容发生更改就出就快照机制 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes #快照出错时是否禁止redis 写入操作（默认为yes，建议使用no，出错的原因，磁盘满了，权限问题，改为no的原因是系统是由监控的，所以不会等磁盘满了防止数据丢失） rdbcompression yes #持久化到RDB文件时，是否压缩，”yes”为压缩，”no”则反之 rdbchecksum yes #是否开启RC64校验，默认是开启（检查RDB文件是否完整） dbfilename dump.rdb #快照文件名 dir ./ #快照文件保存路径 replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式：1) 如果replica-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果replica-serve-stale-data设置为no，除去指定的命令之外的任何请求都会返回一个错误”SYNC with master in progress”。 replica-read-only yes #是否设置从库只读 repl-diskless-sync no #是否使用socket方式复制数据，目前redis复制提供两种方式，disk和socket，如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件，有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave，socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave，disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件，socket的方式就是一个个slave顺序复制，只有在磁盘速度缓慢但是网络相对较快的情况下才使用socket方式，否则使用默认的disk方式 repl-diskless-sync-delay 5 #diskless复制的延迟时间，设置0为关闭，一旦复制开始还没有结束之前，master节点不会再接收新slave的复制请求，直到下一次开始 repl-ping-slave-period 10 #slave根据master指定的时间进行周期性的PING 监测 repl-timeout 60 #复制链接超时时间，需要大于repl-ping-slave-period，否则会经常报超时 repl-disable-tcp-nodelay no #在socket模式下是否slave套接字发送SYNC之后禁用 TCP_NODELAY，如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果你选择了 “no” 数据传输到salve的延迟将会减少但要使用更多的带宽 repl-backlog-size 1mb #复制缓冲区大小，只有在slave连接之后才分配内存。 repl-backlog-ttl 3600 #多次时间master没有slave连接，就清空backlog缓冲区。 replica-priority 100 #当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。 requirepass foobared #设置redis 连接密码 rename-command #重命名一些高危命令 maxclients 10000 #最大连接客户端（根据生产进行调整） maxmemory #最大内存，单位为bytes字节，8G内存的计算方式8(G)1024(MB)1024(KB)*1024(Kbyte)，需要注意的是slave的输出缓冲区是不计算在maxmemory内。（如果不限制，则redis无限使用物理内存，最后将服务器的进程kill掉，最好给予系统内存的一半，生产使用redis建议服务器16G给redis服务器8G） appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。 appendfilename “appendonly.aof” #AOF文件名 appendfsync everysec #aof持久化策略的配置,no表示不执行fsync,由操作系统保证数据同步到磁盘,always表示每次写入都执行fsync，以保证数据同步到磁盘,everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。 no-appendfsync-on-rewrite no在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。默认为no,表示”不暂缓”,新的aof记录仍然会被立即同步，Linux的默认fsync策略是30秒，如果为yes 可能丢失30秒数据，但由于yes性能较好而且会避免出现阻塞因此比较推荐。 auto-aof-rewrite-percentage 100 # 当Aof log增长超过指定比例时，重写log file， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，而确保保存最完整的数据。 auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件尺寸 aof-load-truncated yes #是否加载由于其他原因导致的末尾异常的AOF文件(主进程被kill/断电等) aof-use-rdb-preamble yes #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内存则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）。 lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒 cluster-enabled yes #是否开启集群模式，默认是单机模式 cluster-config-file nodes-6379.conf #由node节点自动生成和的集群配置文件 cluster-node-timeout 15000 #集群中node节点连接超时时间 cluster-replica-validity-factor 10 #在执行故障转移的时候可能有些节点和master断开一段时间数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移 cluster-migration-barrier 1 #一个主节点拥有的至少正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。 cluster-require-full-coverage yes #集群槽位覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes情况下redis集群槽位验证不全就不再对外提供服务，而no则可以继续使用但是会出现查询数据查不到的情况(因为有数据丢失)。 cluster-replica-no-failover no#Slow log 是 Redis 用来记录查询执行时间的日志系统，slow log 保存在内存里面，读写速度非常快，因此你可以放心地使用它，不必担心因为开启 slow log 而损害 Redis 的速度。 slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。 slowlog-max-len 128 #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除 三： redis持久化： redis 虽然是一个内存级别的缓存程序，即redis 是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF RDB模式： RDB：基于时间的快照，只保留当前最新的一次快照，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据。 RDB实现的具体过程Redis从主进程先fork出一个子进程，使用写时复制机制，子进程将内存的数据保存为一个临时文件，比如dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做RDB快照的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有保存完整就突然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。 RDB模式的优缺点： 优点： RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点北备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。 可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作 RDB在大量数据比如几个G的数据，恢复的速度比AOF的快 缺点： 不能时时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据 数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒 AOF模式： AOF:按照操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录。 AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的时候执行fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响 AOF模式优缺点： AOF的文件大小要大于RDB格式的文件 根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec即每秒执行一次fsync 四： redis 数据类型： 1.字符串(string)： 字符串是所有编程语言中最常见的和最常用的数据类型，而且也是redis最基本的数据类型之一，而且redis中所有的key的类型都是字符串。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182连接redis [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; 添加一个key 172.18.135.1:6379&gt; set key1 value1 （后面可以添加过期时间，如果不加则永不过期） OK查看key对应的值 172.18.135.1:6379&gt; get key1 "value1"查看key的类型 172.18.135.1:6379&gt; type key1 string（字符串）删除key的值 （DEL可以删除任何类型的key） 172.18.135.1:6379&gt; DEL key1 (integer) 1 (返回值为1，则表示成功，0表示不成功) 172.18.135.1:6379&gt; get key1 (nil)批量创建多个key 172.18.135.1:6379&gt; mset key1 value1 key2 value2 .... OK批量获取多个key的值 172.18.135.1:6379&gt; mget key1 key2 1) "value1" 2) "value2"批量删除多个key 172.18.135.1:6379&gt; del key1 key2 (integer) 2 172.18.135.1:6379&gt; mget key1 key2 1) (nil) 2) (nil)清空当前库的所有数据 172.18.135.1:6379&gt; flushdb OK查看当前数据库的所有key值 172.18.135.1:6379&gt; keys * (empty list or set)清空所有数据库的key 172.18.135.1:6379&gt; FLUSHALL数值递增：（必须是数字且数个整数） 172.18.135.1:6379&gt; SET num 0 OK 172.18.135.1:6379&gt; INCR num (integer) 1 172.18.135.1:6379&gt; GET num "1"数值递减 172.18.135.1:6379&gt; INCR num (integer) 2 172.18.135.1:6379&gt; GET num "2" 172.18.135.1:6379&gt; DECR num (integer) 1 172.18.135.1:6379&gt; GET num "1"向列表追加数据： 127.0.0.1:6379&gt; LPUSH list1 tom (integer) 2 127.0.0.1:6379&gt; RPUSH list1 jack (integer) 3获取列表长度： 127.0.0.1:6379&gt; LLEN list1 (integer) 3移除列表数据： 127.0.0.1:6379&gt; RPOP list1 #最后一个 "jack" 127.0.0.1:6379&gt; LPOP list1 #第一个 "tom" 2.集合(set)： Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455生成集合key:SADD：无序集合 127.0.0.1:6379&gt; SADD set1 v1 (integer) 1 127.0.0.1:6379&gt; SADD set2 v2 v4 (integer) 2 127.0.0.1:6379&gt; TYPE set1 set 127.0.0.1:6379&gt; TYPE set2 set查看集合中的所有值 127.0.0.1:6379&gt; SMEMBERS set1追加数值：追加的时候不能追加已经存在的数值 127.0.0.1:6379&gt; SADD set1 v2 v3 v4 (integer) 3 127.0.0.1:6379&gt; SADD set1 v2 #没有追加成功 (integer) 0 127.0.0.1:6379&gt; TYPE set1 set 127.0.0.1:6379&gt; TYPE set2 set查看集合的所有数据：同set的值不可重复，不同 set的值可以相同 127.0.0.1:6379&gt; SMEMBERS set1 1) "v4" 2) "v1" 3) "v3" 4) "v2" 127.0.0.1:6379&gt; SMEMBERS set2 1) "v4" 2) "v2"获取集合的差集：差集：已属于A而不属于B的元素称为A与B的（差集） 127.0.0.1:6379&gt; SDIFF set1 set2 1) "v1" 2) "v3"获取集合的交集：交集：已属于A且属于B的元素称为A与B的(交集） 127.0.0.1:6379&gt; SINTER set1 set2 1) "v4" 2) "v2"获取集合的并集：并集：已属于A或属于B的元素为称为A与B的(并集） 127.0.0.1:6379&gt; SUNION set1 set2 1) "v2" 2) "v4" 3) "v1" 4) "v3" 3.sorted set(有序集合): Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员，不同的是每个元素都会关联一个double(双精度浮点型)类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序，序集合的成员是唯一的,但分数(score)却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)， 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950生成有序集合： 127.0.0.1:6379&gt; ZADD zset1 1 v1 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 2 v2 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 2 v3 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 3 v4 (integer) 1 127.0.0.1:6379&gt; TYPE zset1 zset 127.0.0.1:6379&gt; TYPE zset2 zset排行案例： 192.168.7.104:6379&gt; ZADD paihangbang 10 key1 20 key2 30 key3 (integer) 3 192.168.7.104:6379&gt; ZREVRANGE paihangbang 0 -1 withscores 1) "key3" 2) "30" 3) "key2" 4) "20" 5) "key1" 6) "10"批量添加多个数值： 127.0.0.1:6379&gt; ZADD zset2 1 v1 2 v2 4 v3 5 v5 (integer) 4获取集合的长度数： 127.0.0.1:6379&gt; ZCARD zset1 (integer) 4 127.0.0.1:6379&gt; ZCARD zset2 (integer) 4基于索引返回数值： 127.0.0.1:6379&gt; ZRANGE zset1 1 3 1) "v2" 2) "v3" 3) "v4" 127.0.0.1:6379&gt; ZRANGE zset1 0 2 1) "v1" 2) "v2" 3) "v3"返回某个数值的索引： 127.0.0.1:6379&gt; ZRANK zset1 v2 (integer) 1 127.0.0.1:6379&gt; ZRANK zset1 v3 (integer) 2 4.哈希(hash)： hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象,Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。12345678910111213141516171819202122232425262728生成hash key： 127.0.0.1:6379&gt; HSET hset1 name tom age 18 (integer) 1 127.0.0.1:6379&gt; TYPE hset1 hash获取hash key字段值： 127.0.0.1:6379&gt; HGET hset1 name "tom" 127.0.0.1:6379&gt; HGET hset1 age "18"删除一个hash key的字段： 127.0.0.1:6379&gt; HDEL hset1 age (integer) 1获取所有hash表中的字段： 127.0.0.1:6379&gt; HSET hset1 name tom age 19 (integer) 1 127.0.0.1:6379&gt; HKEYS hset1 1) "name" 2) "age"设定key的过期时间 127.0.0.1:6379&gt; set test1 value1 ex 5 #设定这个key的过期时间，43200半天时间，g根据用户需求设定查看key的过期时长 127.0.0.1:6379&gt; TTL key1 五： 消息队列：消息队列主要分为两种，分别是生产者消费者模式和发布者订阅者模式，这两种模式Redis都支持 生产者消费者模式： 1.在生产者消费者(Producer/Consumer)模式下，上层应用接收到的外部请求后开始处理其当前步骤的操作，在执行完成后将已经完成的操作发送至指定的频道(channel)当中，并由其下层的应用监听该频道并继续下一步的操作，如果其处理完成后没有下一步的操作就直接返回数据给外部请求，如果还有下一步的操作就再将任务发布到另外一个频道，由另外一个消费者继续监听和处理。 2.模式介绍： 生产者消费者模式下，多个消费者同时监听一个队里，但是一个消息只能被最先抢到消息的消费者消费，即消息任务是一次性读取和处理，此模式在分布式业务架构中非常常用，比较常用的软件还有 RabbitMQ、Kafka、RocketMQ、ActiveMQ等 3.队列介绍： 队列当中的 消息由不同的生产者写入也会有不同的消费者取出进行消费处理，但是买一个消息一定是只能被取出一次也就是被消费一次。 12345678910111213141516171819202122232425262728293031323334353637383940生产者发布消息： [root@redis-s4 ~]# redis-cli 127.0.0.1:6379&gt; AUTH 123456 OK 127.0.0.1:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入 (integer) 1 127.0.0.1:6379&gt; LPUSH channel1 msg2 (integer) 2 127.0.0.1:6379&gt; LPUSH channel1 msg3 (integer) 3 127.0.0.1:6379&gt; LPUSH channel1 msg4 (integer) 4 127.0.0.1:6379&gt; LPUSH channel1 msg5 (integer) 5切换终端模拟消费者，查看队列所有消息：#（0，-1代表查看所有的消息） 127.0.0.1:6379&gt; LRANGE channel1 0 -1 #切换其他客户端查看则已经看不到此条消息队列，因为已经被当前客户端取走 1) "msg5" 2) "msg4" 3) "msg3" 4) "msg2" 5) "msg1"消费者消费消息： 127.0.0.1:6379&gt; RPOP channel1 #从管道的右侧消费 "msg1" 127.0.0.1:6379&gt; RPOP channel1 "msg2" 127.0.0.1:6379&gt; RPOP channel1 "msg3" 127.0.0.1:6379&gt; RPOP channel1 "msg4" 127.0.0.1:6379&gt; RPOP channel1 "msg5" 127.0.0.1:6379&gt; RPOP channel1 (nil)切换主机模拟消费者，再次验证队列消息： 127.0.0.1:6379&gt; LRANGE channel1 0 -1 (empty list or set) #队列中的消息已经被已全部消费完毕 发布者订阅模式： 1.模式简介： 在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容。 此模式常用语群聊天、群通知、群公告等场景。 Subscriber：订阅者 Publisher：发布者 Channel：频道 1234567891011121314151617181920212223242526订阅者监听频道： [root@redis-s4 ~]# redis-cli 127.0.0.1:6379&gt; AUTH 123456 OK 127.0.0.1:6379&gt; SUBSCRIBE channel1 #订阅者订阅指定的频道,也就是客户端监听服务端的频道，此时可以模拟多个客户端监听服务端的此频道 Reading messages... (press Ctrl-C to quit) 1) "subscribe" 2) "channel1" 3) (integer) 1发布者发布消息：#服务端在此频道发布消息，此时客户端监听在服务端的此频道，都会接受到消息 127.0.0.1:6379&gt; PUBLISH channel1 test1 #发布者发布消息 (integer) 2 127.0.0.1:6379&gt; PUBLISH channel1 test2 (integer) 2 127.0.0.1:6379&gt;订阅多个频道：订阅指定的多个频道 127.0.0.1:6379&gt; SUBSCRIBE channel1 channel2 订阅所有频道： 127.0.0.1:6379&gt; PSUBSCRIBE *订阅匹配的频道： 127.0.0.1:6379&gt; PSUBSCRIBE chann* #匹配订阅多个频道 六： redis其他命令：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859CONFIG： config 命令用于查看当前redis配置、以及不重启更改redis配置等 127.0.0.1:6379&gt;config get * #获取config的命令配置帮助,或当前配置更改最大内存： 127.0.0.1:6379&gt; CONFIG set maxmemory 8589934592 OK 127.0.0.1:6379&gt; CONFIG get maxmemory #获取此配置项的值 1) "maxmemory" 2) "8589934592"设置连接密码：(可以先修改配置文件再动态命令行设置，这样避免重启服务生效) 127.0.0.1:6379&gt; CONFIG SET requirepass 123456 OK #通过CONFIG设置密码后立即生效 重现连接测试 172.18.135.1:6379&gt; CONFIG SET requirepass 123456 OK 172.18.135.1:6379&gt; exit [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; keys * (error) NOAUTH Authentication required. 172.18.135.1:6379&gt; auth 123456 #auth认证连接 OK 172.18.135.1:6379&gt; keys * 1) "key1"编辑配置文件设置连接redis的密码永久生效 #可以先在redis动态控制台设置完再在配置文件中修改这样会避免重启服务器代来不必要的损失 [root@centos7 ~]# vim /usr/local/redis/etc/redis.conf 507行 requirepass 123456info：显示当前节点redis运行状态信息 172.18.135.1:6379&gt; info SELECT：切换数据库 172.18.135.1:6379&gt; keys:查看当前库下的所有key：#keys * 慎用，相当于将数据库中的所有数据拿出，如果数据较多全部显示则会把机器卡死BGSAVE：手动在后台执行RDB持久化操作 172.18.135.1:6379&gt; BGSAVEDBSIZE：返回当前库下的所有key 数量 172.18.135.1:6379&gt; DBSIZEFLUSHDB：强制清空当前库中的所有key 172.18.135.1:6379&gt; FLUSHDBFLUSHALL：强制清空当前redis服务器所有数据库中的所有key，即删除所有数据 172.18.135.1:6379&gt; FLUSHALL 七： redis高可用于集群——配置redis主从 虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用另外的技术来解决单点问题。 配置reids 主从： 主备模式，可以实现Redis数据的跨主机备份。 程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的IP地址设置。 Slave主要配置： Redis Slave 也要开启持久化（RDB\AOF）并设置和master同样的连接密码，因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。（最好将slave的配置于master相同，密码相同为了master宕机提升slave为新的主，如果开始同步，从节点上的原有的值则被清空，所以最好是要当从节点的服务器为干净的redis服务系统，后期如果将从节点强制和主节点断开的话则从节点的数据不会丢失） 一旦某个Slave成为一个master的slave，Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据。 命令行配置12345678910方法1：从节点命令行方式将称为主节点的slave 当前状态为master，需要转换为slave角色并指向master服务器的IP+PORT+Password 192.168.7.104:6379&gt; SLAVEOF 192.168.7.103 6379 OK 192.168.7.104:6379&gt; CONFIG SET masterauth 123456 OK 关闭从节点的从属性 127.0.0.1:6379&gt; SLAVEOF NO ONE 在终端配置文件主从选项在重启服务后失效 保存在配置文件中123456789方法2:此配置文件是编译安装的配置文件vim /usr/local/redis/etc/redis.conf replicaof 192.168.7.103 6379masterauth 123456 #master如果密码需要设置，这里设置的密码为主节点的密码从节点查看 重启服务查看 127.0.0.1:6379&gt; info 1234567891011验证slave数据：确定slave的数据是不是从主节点的数据同步来的，可以一致观察这从节点的日志 127.0.0.1:6379&gt; KEYS * 1) "num" 2) "hset1" 3) "key1" 4) "name1" 5) "zset2" 6) "key2" 7) "zset1" 8) "set2"slave 状态只读无法写入数据， 主从复制过程： Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的，其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存，然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。 主从同步优化： Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。repl-diskless-sync no #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认即为使用no，Master RDB文件不需要与磁盘交互。 repl-diskless-sync-delay 5 #Master准备好RDB文件后等等待传输时间 repl-ping-slave-period 10 #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间 repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性 repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：b repl-backlog-size = 允许从节点最大中断时长 主实例offset每秒写入量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb60秒=3840mb(3.8G)= repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。 #min-slaves-to-write 0 # #min-slaves-max-lag 10 #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。 \Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。 Slave同步过程日志：master同步日志： slave切换master：123456789101112131415161718192021222324252627282930313233当前状态： 从节点的状态信息 192.168.7.101:6379&gt; info Replication # Replication role:slave master_host:192.168.7.103 master_port:6379 master_link_status:up master_last_io_seconds_ago:8 master_sync_in_progress:0停止slave同步并查看当前状态： 192.168.7.101:6379&gt; SLAVEOF no one OK 192.168.7.101:6379&gt; info Replication # Replication role:master connected_slaves:0 master_replid:ac3475e5e4fae8c5f47711a643e465b9520c4182 master_replid2:8ee6bc1ac452fd4d2ccbaa660a219f78d218399a master_repl_offset:8840 second_repl_offset:8841 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:8547 repl_backlog_histlen:294测试能从节点否写入数据： 192.168.7.101:6379&gt; set key1 value1 #从节点停止主从结构时就是本机的自己的主，所以自然可以都自己的值进行写入 OK 192.168.7.101:6379&gt;虽然从节点脱离了主从结构，但是从节点的数据，依然保留着主节点同步时的数据。 Slave节点再有Slave： 在有slave的”master”查看状态： # Replication role:slave master_host:192.168.7.102 master_port:6379 master_link_status:up master_last_io_seconds_ago:9 #最近一次与master通信已经过去多少秒。 master_sync_in_progress:0 #是否正在与master通信。 slave_repl_offset:5334 #当前同步的偏移量。 slave_priority:100 #slave优先级，master故障后值越小越优先同步，一半设置相同的数值让它同时同步。 slave_read_only:1 connected_slaves:1 slave0:ip=192.168.7.104,port=6379,state=online, offset=5334,lag=1 master_replid:0f0318c25a022add7fd51d4438c470cf608631f9 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:5334 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:5334 常见问题汇总： master密码不对： 即配置的master密码不对，导致验证不通过而无法建立主从同步关系。 Redis版本不一致： 不同的redis 版本之间存在兼容性问题，因此各master和slave之间必须保持版本一致。 无法远程连接： 在开启了安全模式情况下，没有设置bind地址和密码]]></content>
      <categories>
        <category>linux服务</category>
      </categories>
      <tags>
        <tag>redis缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM.virsh命令使用入门]]></title>
    <url>%2F2018%2F12%2F25%2FKVM-virsh%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[KVM-virsh命令使用入门 虚拟化技术 主机级虚拟化：infrastructure 容器级虚拟化（用户空间虚拟化即容器）：Container 内核名称空间： NET Mount PID UTS IPC User 程序级虚拟化： JVM PVM 云计算环境： SaaS：软件即服务 CaaS:容器即服务 FWaaS:防火墙即服务 LBaaS:负载均衡即服务 DBaaS:数据库即服务 IaaS:基础设施即服务 PaaS:平台即服务 虚拟主机通讯： 物理桥：主机过多，主机间交换报文发生瓶颈 隧道、叠加网络 virsh家族的虚拟机创建后，即使物理机重启了虚拟机也还在。 12345678910- 所有的虚拟机创建完成后，/etc/libvirt作为的配置文件的工作目录 [root@centos7 ~]# ls /etc/libvirt/ libvirt-admin.conf lxc.conf qemu.conf storage libvirt.conf nwfilter qemu-lockd.conf virtlockd.conf libvirtd.conf qemu secrets virtlogd.conf使用qemu+kvm创建虚拟服务时，配置文件保存在qemu文件中（每个创建的虚拟机都表现为一个.xml文件，立案包含了所有创建虚拟机的所有的相关配置） [root@centos7 vms]# ls /etc/libvirt/qemu altlinux7.0.xml 虚拟的主机中虚拟cpu核心，仅表现为宿主机中线程 virsh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122列创建的虚拟机 [root@centos7 vms]# virsh list Id Name State ---------------------------------------------------- 12 altlinux7.0 running## virsh list帮助 [root@centos7 vms]# virsh list --help OPTIONS --inactive 列出不活跃的域 --all 不活跃和活跃的域列表 --transient 列出临时域 --persistent 列出持久域 --with-snapshot 列出现有的快照的域 --without-snapshot 列出没有快照的域 --state-running 运行状态的域列表 --state-paused 列出暂停状态的域 --state-shutoff 列出关闭状态的域 --state-other 列出其他状态的域 --autostart 列出启用antostart的域 --no-autostart 列出禁用antostart的域 --with-managed-save 列出有管理的保存状态的域 --without-managed-save 列出没有管理的保存状态的域 --uuid 只列出 uuid --name 只列出域名 --table 列出表格（默认） --managed-save 标记有管理的保存状态的域 --title show domain title [root@centos7 vms]# virsh list --all Id Name State ---------------------------------------------------- 12 altlinux7.0 running [root@centos7 vms]# virsh list --name altlinux7.0查看虚拟机的详细信息（实际上看的就是此虚拟机的xml的配置文件） [root@centos7 vms]# virsh dumpxml altlinux7.0可以将查看虚拟机的详细信息保存在/etc/libvirt作为的配置文件的工作目录中，加以修改实现创建一台新的虚拟系统 [root@centos7 ~]# virsh dumpxml altlinux7.0 &gt; /etc/libvirt/qemu/c1.xml 编辑c1.xml 必须修改项（行）： 2：名字 3：删除uuid，启动自动生成 38：修改本地对应镜像文件 71：网卡MAC创建虚拟机（此实现的前提时建立在上一章kvm虚拟机基础应用的实验的，下一执行命令是在kvm服务器上） virsh help create :查看创建虚拟机并且启动的帮助 virsh help define :查看仅创建但不启动的帮助 virsh help start :查看启动的帮助 virsh define &lt;xmlfile&gt; --validate : 检查xml文件格式是否有误 启动虚拟机，并指顶xml文件 检查语法 [root@centos7 ~]# virsh define /etc/libvirt/qemu/c1.xml --validate Domain c1 defined from /etc/libvirt/qemu/c1.xml 创建 [root@centos7 ~]# virsh define /etc/libvirt/qemu/c1.xml Domain c1 defined from /etc/libvirt/qemu/c1.xml 查看是否创建成功 [root@centos7 ~]# virsh list --all Id Name State ---------------------------------------------------- 12 altlinux7.0 running - c1 shut off 启动 [root@centos7 ~]# virsh start c1 Domain c1 started [root@centos7 ~]# virsh list Id Name State ---------------------------------------------------- 12 altlinux7.0 running 13 c1 running 查看创建的虚拟机的地址 [root@centos7 ~]# virsh domifaddr c1 ## 查看virsh控制台 virsh help console 使用连接控制台连接虚拟机 [root@centos7 ~]# virsh console c1 login as 'cirros' user. default password: 'cubswin:)'. use 'sudo' for root. 退出当前连接 ctrl + ] kvm虚拟机的暂停：所有的占用内存，仍然在内存中，只是不响应任何请求。定在内存中，如果宿主机掉电，则虚拟机的所有数据将会丢失 kvm虚拟机的挂起:是将宿主机上的所有的虚拟机的使用内存抽取掉，保存成二进制文件，放在磁盘上，下次再次开启虚拟机可以将磁盘中的二进制文件读出来恢复至内存中 暂停kvm虚拟机c1 [root@centos7 vms]# virsh suspend c1 恢复kvm虚拟机c1 [root@centos7 vms]# virsh resume c1 挂起kvm虚拟机c1（建议挂起虚拟机的时候将虚拟机先暂停） [root@centos7 vms]# virsh save c1 /tmp/c1.bin --paused 取消挂起kvm虚拟机c1 [root@centos7 vms]# virsh restore /tmp/c1.bin --running 重启kvm虚拟机c1（热重启） virsh reboot c1 重启kvm虚拟机c1（冷重启,如同使用电源按钮重新设定目标） virsh reset c1 关机 virsh shutdown c1 /相当于在主虚拟机内部shutdown -0 暴力拨电，销毁虚拟机的运行状态(销毁的只是虚拟机的运行状态并非是虚拟机的系统程序文件) virsh destroy c1 删除虚拟机（取消定义一个域或者持久转换为临时） vrish undefine c1 将虚拟机设置为随宿主机启动开启 [root@centos7 vms]# virsh autostart c1]]></content>
      <categories>
        <category>linux服务</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm虚拟机基础应用]]></title>
    <url>%2F2018%2F12%2F25%2Fkvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[kvm虚拟机基础应用 kvm: Kernel-based Virtual Machine Qumranet公司 –&gt; RedHat (1) X86_64 (2) HVM: Intel VT AMD AMD-v KVM的组件： 两类组件： (kvm.ko)/dev/kvm：工作为hypervisor，在用户空间可通过系统调用ioctl()与内核中的kvm模块交互，从而完成虚拟机的创建、启动、停止、删除等各种管理功能； qemu-kvm进程：工作于用户空间，用于实现IO设备模拟；用于实现一个虚拟机实例； KVM模块load进内存之后，系统的运行模式： 内核模式：GuestOS执行IO类的操作时，或其它的特殊指令操作时的模式；它也被称为“Guest-Kernel”模式；用户模式：Host OS的用户空间，用于代为GuestOS发出IO请求； 来宾模式：GuestOS的用户模式；所有的非IO类请求； 运行中的一个kvm虚拟机就是一个qemu-kvm进程，运行qemu-kvm程序并传递给它合适的选项及参数即能完成虚拟机启动，终止此进程即能关闭虚拟机； 安装使用KVM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131安装kvm的主机上：判断CPU是否支持硬件虚拟化： [root@centos7 ~]# grep -i -E '(vmx|svm|lm)' /proc/cpuinfo cpu型号： vmx：Intel VT-x svm：AMD AMD-v lm:64位cpu加载kvm模块使得内核支持kvm,并判断是否成功加载此模块 [root@centos7 ~]# modprobe kvm [root@centos7 ~]# lsmod | grep kvm kvm_intel 174841 0 kvm 578518 1 kvm_intel irqbypass 13503 1 kvm [root@centos7 ~]# file /dev/kvm （字符设备） /dev/kvm: character special安装qemu-kvm,使用户空间具有控制工具 [root@centos7 ~]# yum install qemu-kvm -y [root@centos7 ~]# rpm -ql qemu-kvm /usr/libexec/qemu-kvm 命令行工具被放在了非PATH变量中，红帽防止用户手动创建虚拟主机。此工具很底层使用virt-manager管理kvm(libvirt-daemon-kvm守护进程工具 qemu-kvm virt-manager图形化工具 libvirt库) [root@centos7 ~]# yum install libvirt-daemon-kvm qemu-kvm virt-manager libvirt -y （因为已经安装图形化界面的管理工具，确保宿主机上已经安装图像化相关的库 yum groupinstall GNOME Desktop）如果宿主机上已经安装有图像化相关的库则启动libvirt守护进程 [root@centos7 ~]# systemctl start libvirtdlibvirtd安装好默认仅提供了一个net网络创建桥接网络 将物理网卡当交换及使用 将软交换机当物理网卡使用创建物理桥（交换机） [root@centos7 ~]# cd /etc/sysconfig/network-scripts/ [root@centos7 network-scripts]# cp ifcfg-ens37 ifcfg-br0配置网卡的配置文件，使br0当网卡使用，将ens37当交换机使用 [root@centos7 network-scripts]# vim ifcfg-ens37 HWADDR=00:0C:29:14:4D:6C TYPE=Ethernet BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens37 DEVICE=ens37 BRIDGE=br0 ONBOOT=yes [root@centos7 network-scripts]# vim ifcfg-br0 NAME=br0 DEVICE=br0 TYPE=Bridge PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none IPADDR=172.18.135.1 PREFIX=24 GATEWAY=172.18.0.1 DNS1=8.8.8.8 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6_FAILURE_FATAL=no IPV6_PRIVACY=no ONBOOT=yes [root@centos7 network-scripts]# systemctl restart network 此时br0已经是网卡了，ens37变成了交换机 [root@centos7 network-scripts]# ifconfig br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.18.135.1 netmask 255.255.255.0 broadcast 172.18.135.255 inet6 fe80::20c:29ff:fe14:4d6c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 590 bytes 75531 (73.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 53 bytes 8801 (8.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens37: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 7333 bytes 809500 (790.5 KiB) RX errors 0 dropped 2 overruns 0 frame 0 TX packets 1275 bytes 194949 (190.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0------------------------------------------------------------------------------------------------------------------------远程连接安装kvm的主机一下操作在远程连接的主机上操作 查看网卡已经多了一个virbr0b设备，次接口是libvirtd自动生成的net模式类型的接口 [root@centos7 ~]# ssh -X 安装kvm的主机地址 [root@centos7 ~]# systemctl start libvirtd [root@centos7 ~]# ifconfig br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.18.135.1 netmask 255.255.255.0 broadcast 172.18.135.255 inet6 fe80::20c:29ff:fe14:4d6c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 3006 bytes 1312927 (1.2 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 412 bytes 58640 (57.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens37: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 18644 bytes 3281398 (3.1 MiB) RX errors 0 dropped 28 overruns 0 frame 0 TX packets 1827 bytes 281257 (274.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 312 bytes 32472 (31.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 312 bytes 32472 (31.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 192.168.122.1 netmask 255.255.255.0 broadcast 192.168.122.255 ether 52:54:00:ff:0b:1f txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0检查libvirtd程序是否启动，级运行virt-manager图形化 [root@centos7 ~]# systemctl status libvirtd [root@centos7 ~]# virt-manager 以下操作在远程远程连接的主机上使用pxe安装环境 使用本地的镜像（导入现有磁盘映像）123456789[root@centos7 ~]# lscirros-0.3.0-x86_64-disk.img[root@centos7 ~]# mkdir /vms[root@centos7 ~]# mv cirros-0.3.0-x86_64-disk.img /vms/[root@centos7 ~]# cd /vms/[root@centos7 vms]# lscirros-0.3.0-x86_64-disk.img[root@centos7 vms]# cp cirros-0.3.0-x86_64-disk.img pc1.img[root@centos7 vms]# cp cirros-0.3.0-x86_64-disk.img pc2.img 点击Browse Local本地浏览 本机客户端访问外部网络 SNAT源地址转换适用于隐藏客户端地址 主要原因是ipv4地址不够用，私网的地址在互联网没办法被路由。 本机服务端，放在互联网被客户访问。 DNET目标地址转换，仅考虑请求报文，不考虑响应报文，适用于隐藏服务端的地址]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>kvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础架构]]></title>
    <url>%2F2018%2F12%2F22%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[企业网络架构介绍 网络: 多个终端设备 网络传输介质设备实现通讯 局域网：最小的网络、本地、公司 广域网：不通的局域网连接 城域网：比广域网小，例如：一个城市 无线网（AP） CCNA CCNP 企业网络远程互联 企业网络组网不受地域限制，可以通过各种远程互联技术把分布在不同的地域的网络的网络连接在一起 ipsu mpls vpn 专线 广域网：逻辑的层次划分 小型企业组网：扁平 大型网络组网：层次 思想： 业务 冗余 层次-安全 传输介质介绍 通讯网络除了包含通讯设备的本身之外，还包含连接这些设备的传输介质，如同线缆、双绞线、和光纤等，不同的传输介质具有不用的特征，这些特性直接影响到通讯诸多方面，如线路编码方式、传输速度和传输距离等。 路由 交换机 传输介质：连接设备的线缆 网线 光线 两个终端，用一条能承载数据传输的物理介质（也成为传输介质），连接起来，组成了一个最简单的网络。 介质 光猫：光纤设置转换为网络设备进入网络 白色：单模光纤 黄色：多模光纤 共享式网络中可能会出现信号冲突现象 CSMA/CD: 载波侦听多路访问/冲突检测技术 工作原理：先听先发，边听边发，冲突避让，等待重发。 以太网的最大包长和最小包长 最大包长1518byte,其中三层数据1500byte（称为MTU）只是一个规定而言 最小包长64byte 原因：如果A主机发送的帧很小，很快完成帧的发送，而两台冲突主机相差很远，在主机A发送的帧传输到B的前一刻，B开始发送帧，这样，当A的帧到达B时，B检测到冲突，于是发送冲突信号。假如在B冲突信号传输到A之前，A的帧已经发送完毕，那么A将检测不到冲突而误认为已经发送成功，因此必须有最小包长的限制。 两种双工模式都支持双向数据传输 冲突与：半双工模式 分层模型及以太网帧结构 不同的协议栈用于定义和管理不同的网络的数据转发规则 什么是协议 为了使数据可以在网络上从源传递到目标地址，网络上所有设备需要“讲”相同的语言 数据通讯协议的定义 决定数据的格式和传输的一组规则和一组惯例 网络通讯的过程很复杂 数据以电子信号的形式穿越介质到达正确的计算机，然后转换为最初的形式，以便接收者可以阅读 为了降低网络设计的复杂性，将协议进行了分层设计 分层设计的意义 通讯服务层的模块设计可相对独立于具有的通讯路线和通讯接口的差别 而通信服务层的模块设计又可相对独立具体用户应用的要求不同 简化了相关的网络操作，提供了不不同的厂商之间的兼容性；促进了标准化工作，结构上进行了分层；易于学习和操作 各个层次独立，一层的变化不会影响到邻层 OSI参考模型 国际标准化组织ISO于1984年提出了OSI RM 。OSI参考模型很快成了计算机网络的基础模型 OSI参考模型具有的优点：简化了相关的网络操作，提供了不同的厂商之间的兼容性；促进了标准化工作；结构上进行了分层；易于学习和操作 OSI参考模型各个层次的功能如下： 网络层：在设备之间传输比特流，规定了电平、速度和断缆针脚 数据链路层：将比特流组合成了字节，再将字节组合成帧，使用链路层地址（以太网使用MAC地址）来访问介质，并进行排差错检测 网络层：提供逻辑地址，供路由确定路径 传输层：提供面向连接或者非面向连接的数据传递以及进行排差错检测 会话层：负责建、管理和终止表示层实体之间的通讯会话。该层的通信由不同的设备中的应用程序之间的服务请求和响应组成（通信设备可能存在多个会话） 表示层：提供各种用于应用层数据的编码和转换功能，确保一个系统的应用层发送的数据能够被另一个系统的应用层识别（数据表、加密、图片、文档、文字） 应用层：OSI参考模型中最靠近用户的一层，为应用程序提供网络服务 OSI层次设计的理念 建立七层模型的主要目的使为解决异种网络互连时所遇到的兼容性问题 它的优点：将服务、接口和协议这三个概念明确地区分开来 服务：某一层为上一层提供什么功能 接口：上层如何使用下层的服务 协议：如何实现本层的服务 这样各层之间具有很强的独立性，互联网络中各尸体采用什么样的协议时没有限制的，只要向上提供形同的服务并且不改变相邻层的接口就可以了]]></content>
      <categories>
        <category>网络基础架构</category>
      </categories>
      <tags>
        <tag>网络基础架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS服务器]]></title>
    <url>%2F2018%2F12%2F19%2Fnfs%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[NFS服务器 NFSNFS：Network File System 网络文件系统，基于内核的文件系统。Sun公司 开发，通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的 文件，基于RPC（Remote Procedure Call Protocol远程过程调用）实现 RPC采用C/S模式。客户机请求程序调用进程发送一个有进程参数的调用信息 到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用 信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发 送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信 息，获得进程结果，然后调用执行继续进行 NFS优势：节省本地存储空间，将常用的数据,如home目录,存放在NFS服务 器上且可以通过网络访问，本地终端将可减少自身存储空间的使用 12345678910111213常用系统的驱动查看模块[root@centos7 ~]# locate xfs.ko/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/xfs/xfs.ko.xz[root@centos7 ~]# ls /usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/binfmt_misc.ko.xz cifs ext4 gfs2 mbcache.ko.xz nls udfbtrfs cramfs fat isofs nfs overlayfs xfscachefiles dlm fscache jbd2 nfs_common pstoreceph exofs fuse lockd nfsd squashfslinux内核默认已经安装nfs文件系统，已经加载驱动模块[root@centos7 ~]# locate nfs.ko/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/drivers/xen/xenfs/xenfs.ko.xz/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/nfs/nfs.ko.xz NFS文件系统 NFS工作原理 NFS各个版本的对比s NFS服务介绍软件包：nfs-utils（并非服务器包时文件系统即工具）Kernel支持:nfs.ko端口：2049(nfsd), 其它端口由portmap(111)分配配置文件：/etc/exports,/etc/exports.d/*.exportsCentOS7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同相关软件包:rpcbind（必须rpcbind， 服务如果不可用则nfs服务也不可用），tcp_wrappersCentOS6开始portmap进程由rpcbind代替NFS服务主要进程：&ensp;&ensp;rpc.nfsd 最主要的NFS进程，管理客户端是否可登录&ensp;&ensp;rpc.mountd 挂载和卸载NFS文件系统，包括权限管理&ensp;&ensp;rpc.lockd 非必要，管理文件锁，避免同时写出错&ensp;&ensp;rpc.statd 非必要，检查文件一致性，可修复文件日志：/var/lib/nfs/ 范例：查看nfs对应的端口123456[root@centos7 ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper此服务使用的随机端口比较多，所以此服务一般不会跨网络使用，最好在局域网内使用 范例：配置防火墙，将随机端口绑死，实现跨网络12345678910配置防火墙，开放NFS服务 配置NFS使用固定端口 vim /etc/sysconfig/nfs RQUOTAD_PORT=875 LOCKD_TCPPORT=32803 LOCKD_UDPPORT=32769 MOUNTD_PORT=892 STATD_PORT=662 STATD_OUTGOING_PORT=2020 防火墙除开放上述端口，还需开放TCP和UDP的111和2049共4个端 范例：实现共享文件夹1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677服务端：创建共享的目录 [root@centos7 ~]# mkdir /data/a [root@centos7 ~]# mkdir /data/b编辑服务器的配置文件（此配置配置文件是系统的基本文件，此文件可以定义共享的目录的策略） [root@centos7 ~]# rpm -qf /etc/exports setup-2.8.71-9.el7.noarch [root@centos7 ~]# vim /etc/exports （*代表所有人可以访问） /data/a * 生效配置文件（提示我们没有配置策略使用默认的配置策略，sync直接写磁盘，不放buffer） [root@centos7 ~]# exportfs -r exportfs: No options for /data/a *: suggest *(sync) to avoid warning客户端： 创建挂载点，使用服务端共享的目录进行挂载 [root@centos7 ~]# mkdir /data/nfs1 /data/nfs2 [root@centos7 ~]# showmount -e 192.168.52.179 Export list for 192.168.52.179: /data/a * 挂载指向服务端的地址 [root@centos7 ~]# mount 192.168.52.179:/data/a /data/nfs1 [root@centos7 ~]# df 192.168.52.179:/data/a 20961280 33024 20928256 1% /data/nfs1服务端在共享的目录中创建文件，客户端查看是否同步 [root@centos7 ~]# touch /data/a/a.txt [root@centos7 ~]# ls /data/nfs1/ a.txt 查看共享默认的权限：只读属性 [root@centos7 ~]# touch /data/nfs1/b.txt touch: cannot touch ‘/data/nfs1/b.txt’: Read-only file system 客户端查看挂载属性：默认使用的挂载版本为vers=4 [root@centos7 ~]# mount 192.168.52.179:/data/a on /data/nfs1 type nfs4 (rw,relatime,vers=4.1,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.52.179,local_lock=none,addr=192.168.52.179) 客户端挂载指定版本挂载 [root@centos7 ~]# mount -o vers=3 192.168.52.179:/data/a /data/nfs1 [root@centos7 ~]# mount | tail -n1 192.168.52.179:/data/a on /data/nfs1 type nfs (rw,relatime,vers=3,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=192.168.52.179,mountvers=3,mountport=20048,mountproto=udp,local_lock=none,addr=192.168.52.179)服务端修改挂载的目录权限 [root@centos7 ~]# vim /etc/exports /data/a *(sync,ro) 同步，只读 /data/b *(rw) 可读可写 生效并查看权限 [root@centos7 ~]# exportfs -r [root@centos7 ~]# exportfs -v （root_squash压榨root权限 no_all_squash普通用户不压榨） /data/a &lt;world&gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) /data/b &lt;world&gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash)客户端挂载:挂载也是有读写权限的但是还是不可以创建文件 [root@centos7 ~]# mkdir /data/nfs2/ [root@centos7 ~]# mount 192.168.52.179:/data/b /data/nfs2/ [root@centos7 ~]# touch /data/nfs2/a.txt touch: cannot touch ‘/data/nfs2/a.txt’: Permission denied 因为客户端访问服务端的共享目录的身份默认的是以nfsnoboby身份服务端授权设置acl [root@centos7 ~]# setfacl -m u:nfsnobody:rwx /data/b/客户端测试 [root@centos7 ~]# touch /data/nfs2/a.txt [root@centos7 ~]# ll !$ ll /data/nfs2/a.txt -rw-r--r--. 1 nfsnobody nfsnobody 0 Dec 19 20:17 /data/nfs2/a.tx客户端使用客户端的普通用户，在服务端共享的目录中创建文件显示权限不足（因为客户端创建的用户为普通用户，如果有同名用户则显示相同的用户，如果没有则显示客户端的用户的id）(映射成id相同的人，普通用户不压榨) 导出的文件系统的格式：&ensp;&ensp;/dir 主机1(opt1,opt2) 主机2(opt1,opt2)… #开始为注释 主机格式：&ensp;&ensp;/单个主机：ipv4，ipv6，FQDN&ensp;&ensp;/IP networks：两种掩码格式均支持&ensp;&ensp;/&ensp;&ensp;/172.18.0.0/255.255.0.0&ensp;&ensp;/&ensp;&ensp;/172.18.0.0/16&ensp;&ensp;/wildcards：主机名通配，例如.magedu.com，IP不可以&ensp;&ensp;/netgroups：NIS域的主机组，@group_name&ensp;&ensp;/anonymous：表示使用通配所有客户端 nfs配置文件每个条目指定目录导出到的哪些主机，及相关的权限和选项&ensp;&ensp;默认选项：(ro,sync,root_squash,no_all_squash)&ensp;&ensp;ro,rw 只读和读写 • async 异步，数据变化后不立即写磁盘，性能高&ensp;&ensp;sync（1.0.0后为默认）同步，数据在请求时立即写入共享&ensp;&ensp;no_all_squash （默认）保留共享文件的UID和GID&ensp;&ensp;all_squash 所有远程用户(包括root)都变成nfsnobody&ensp;&ensp;root_squash （默认）远程root映射为nfsnobody,UID为65534，早期版本 是4294967294 (nfsnobody)&ensp;&ensp;no_root_squash 远程root映射成root用户&ensp;&ensp;anonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非 nfsnobody,可配合all_squash使用 1234567不压榨远程root用户的权限 [root@centos7 ~]# vim /etc/exports /data/a *(sync,ro) /data/b *(rw,no_root_squash) [root@centos7 ~]# exportfs -v /data/a &lt;world&gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) /data/b &lt;world&gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) NFS工具rpcinfo&ensp;&ensp;rpcinfo -p hostname&ensp;&ensp;rpcinfo –s hostname 查看RPC注册程序 exportfs&ensp;&ensp;–v 查看本机所有NFS共享&ensp;&ensp;–r 重读配置文件，并共享目录&ensp;&ensp;–a 输出本机所有共享&ensp;&ensp;–au 停止本机所有共享 showmount -e hostnamemount.nfs 挂载工具NFSv4支持通过挂载NFS服务器的共享“根”，从而浏览NFS服务器上的共享 目录列表&ensp;&ensp;mount nfsserver:/ /mnt/nfs 客户端NFS挂载基于安全考虑，建议使用nosuid,nodev,noexec挂载选项NFS相关的挂载选项：&ensp;&ensp;fg（默认）前台挂载，bg后台挂载&ensp;&ensp;hard（默认）持续请求，soft 非持续请求&ensp;&ensp;intr 和hard配合，请求可中断&ensp;&ensp;rsize和wsize 一次读和写数据最大字节数，rsize=32768&ensp;&ensp;_netdev 无网络不挂载示例：&ensp;&ensp;mount -o rw,nosuid,fg,hard,intr 172.16.0.1:/testdir /mnt/nfs/开机挂载:/etc/fstab&ensp;&ensp;172.16.0.1:/public /mnt/nfs nfs defaults 0 0 自动挂载可使用autofs按需要挂载NFS共享，在空闲时自动卸载由autofs包提供系统管理器指定由/etc/auto.master自动挂载器守护进程控制的挂载点自动挂载监视器访问这些目录并按要求挂载文件系统文件系统在失活的指定间隔5分钟后会自动卸载为所有导出到网络中的NFS启用特殊匹配 -host 至“browse”参看帮助：man 5 autofs支持含通配符的目录名&ensp;&ensp;* server:/export/&amp; 直接匹配直接匹配包括绝对路径名称不会影响本地目录结构示例：&ensp;&ensp;/etc/auto.master:&ensp;&ensp;/- /etc/auto.direct &ensp;&ensp;/etc/auto.direct:&ensp;&ensp;/foo server1:/export/foo&ensp;&ensp;/user/local/ server1:/usr/local]]></content>
      <categories>
        <category>NFS服务器</category>
      </categories>
      <tags>
        <tag>NFS服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux防火墙]]></title>
    <url>%2F2018%2F03%2F06%2Flinux%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[linux防火墙 本章内容安全技术 入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式 防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略(防范非授权网络) linux操作系统的空间：内核空间和用户空间端口：进程地址 防火墙的分类防火墙的分类 主机防火墙：服务范围为当前主机 网络防火墙：服务范围为防火墙一侧的局域网 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件 实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件 网络层防火墙：OSI模型下四层 应用层防火墙/代理服务器：代理网关，OSI模型七层 网络型防火墙网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制 列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议 状态等因素，或他们的组合来确定是否允许该数据包通过 优点：对用户来说透明，处理速度快且易于维护 缺点：无法检查应用层数据，如病毒等 应用层防火墙应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载 现实生产环境中所使用的防火墙一般都是二者结合体&ensp;&ensp;即先检查网络数据，通过之后再送到应用层去检查 iptables的基本认识Netfilter组件&ensp;&ensp;内核空间，集成在linux内核中&ensp;&ensp;扩展各种网络服务的结构化底层框架&ensp;&ensp;内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、 FORWARD、PREROUTING、POSTROUTING)，而这五个hook function 向用户开放，用户可以通过一个命令工具（iptables）向其写入规则&ensp;&ensp;由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则 被分组放在链（chain）上 三种报文流向：netfilter内核级别的框架，，人是不可和内核打交道，使用用户空间的工具iptables，规则编辑器，内核级的系统级别netfilter的调用接口，将写的规则送到内核中的钩子hook上直接生效，直接送到内存中，说明主机关机则规则就没有了，所以想永久生效，可以放在内核启动时初始化时读取到的文件中，或者在或者启动完后，自动执行某个命令或者启动某个服务来调用（即刻生效，但是不会永久有效）路由前：PREROUTING流入：INPUT流出：OUTPUT转发：FORWARD路由后：POSTROUTING &ensp;&ensp;流入本机：PREROUTING --&gt; INPUT--&gt;用户空间进程&ensp;&ensp;流出本机：用户空间进程 --&gt;OUTPUT--&gt; POSTROUTING&ensp;&ensp;转发：PREROUTING --&gt; FORWARD --&gt; POSTROUTING linux早期没有防火墙的，仿照unix的发行版的OpenBSD，著名的以安全为目标的发行版OpenBSD：纯软件，内核级只负责传输层一下级检测实现，进行工作和防护 定制防火墙规则：黑名单、白名单&ensp;&ensp;黑名单适用于知道改拒绝谁&ensp;&ensp;百名单高效的仅授权可以连接的 iptables的基本认识防火墙工具iptables&ensp;&ensp;命令行工具，工作在用户空间&ensp;&ensp;用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包 firewalld&ensp;&ensp;CentOS 7 引入了新的前端管理工具&ensp;&ensp;管理工具：&ensp;&ensp;&ensp;&ensp;firewall-cmd 命令行&ensp;&ensp;&ensp;&ensp;firewall-config 图形 历史ipfw -&gt; ipchains -&gt; iptables -&gt; nftables(rhel8) 主机级别防火墙：INPUT---OUTPUTS网络级别防火墙：FROWARD NAT：网络地址转换 iptables： 四个功能：table filter:过滤 nat:地址转换 mangle:报文修改，fwmark raw:关闭连接追踪 Centos：使用iptables的方式 netfilter:内核框架（framework） syscall:系统调用接口，iptables命令行工具，管理规则（服务化的管理工具） firewalld:守护进程，firewall-cmd(默认安装，但是尽量不使用) 禁用firewalld123456[root@centos7 ~]# systemctl stop firewalld[root@centos7 ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.[root@centos7 ~]# systemctl is-enabled firewallddisabled 报文流向： 到本机内部：prerouting–&gt;input 由本机发现：output–&gt;postrouting 转发：prerouting –&gt;forward–&gt;postrouting tables&lt;--&gt;CHANS链: filter: INPUT,PORWARD,OUTPUT nat: PREROUTING,INPUT,OUTPUT,POSTROUTING mangle: PREROUTING,INPUT,FOREARD,OUTPUT,POSTROUIING raw: PREROUTING,OUTPUT 查看各表中的链的规则：123456789[root@centos7 ~]# iptables -t filter -nLChain INPUT (policy ACCEPT)target prot opt source destination Chain FORWARD (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination Netfilter表和链对应的关系 数据包过滤匹配流程 命令的使用格式123456789101112131415161718192021222324252627282930SYNOPSIS iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specification ip6tables [-t table] &#123;-A|-C|-D&#125; chain rule-specification iptables [-t table] -I chain [rulenum] rule-specifica‐ tion iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches...] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] iptables [-t tables,如果不指定则代表使用默认的filter] SUBCMMAND子命令 chain [rulenum规则号码] [rule-spce] rule-specification=[matches匹配条件][-j target处理动作] CRUD:增删改查（指定多个规则隐含的是与关系，符合所有的条件才是满足定义的条件的） 子命令： 管理规则： -A ：append,尾部追加 -I ：inset,插入 -D ：删除 -R ：替换 管理链 -N ：new,新增加一条链 -X : 删除一条自定义、空的，不可有规则、引用计数为0的链 -E : rename 改自定义引用技术为0的链 -P ： policy,设置链的默认策略 -F ： flush,清空 -Z ： zero,置零，计数器归零 iptables的每条规则和每个链都有专用的两个计数器：pkts规则匹配到的报个数计数器，bytes报文体积计数器kbytes 查看 -L -n : 以数字显示主机的地址和端口 -v : -vv : 显示详细的信息 -x : exact，避免单位的换算显示精准的信息 –line-numbers : 显示行号 链 内置链 自定义链 匹配条件 检查报文 TCP或UDP首部：源端口，目标端口 FSM:有限状态机 IP首部：sip,dip（源ip和目标ip） MAC首部:MAC地址 匹配条件 通用匹配 [!] -s,–sip,–spurce-ip:报文的源地址,其值可以是ip或者是网络地址，不可使离散的网络（!为取反） [!] -d,–dip,–destination:报文的目标地址 -i,–in-interface : 表示从哪个网卡进入（PREROUTING，INPUT,FORWARD） -o,–out-interface : 表示从哪个网卡出去(,OUTPUT,POSTRUTING,FORWARD) -p protocol:四层协议，tcp,udp,icmp 扩展匹配 隐式扩展 -p tcp :隐含 -m tcp [!] –source-port ,–sport port [:port] : 匹配报文中的传输层的源端口,连续的端口范围，22，21：22 [!] –destination-port ,–dport poet [:port] :匹配报文中传输层的目标端口 [!] –tcp-flags mask comp SYN,ACK,RST,，FIN,URG,PSH mask:需要检查的标志位列表，以逗号分隔； comp:必须为1的标志列表，余下的出现在mask列表中的标志位则必须为0 范例:-tcp-flags SYN,ACK,FIN,RST SYN 表示检查报文tcp首部，syn为1，其余的为0，代表只检查源报文来的第一次握手 [!] –syn : tcp发送报文三次握手的第一次（相当于：–tcp-flags SYN,SCK,FINRST SYN） -p udp : 隐含了-m udp: [!] –source-port ,–sport port[:port] :匹配报文中传输层的源端口 [!] –destination-port,–dport port[:port] :匹配报文中传输层的目标端口 -p icmp(互联网控制协议) ： 隐含了-m udp: [!] –lcmp-type {type[/code]|typename} 8 : echo-request回显请求 0 : echo-reply 回显应答 显示扩展 ； 必须使用-m选项指出matchname(模块),有的match可能存在专用的选项 1.matchname扩展 以离散的或连续的方式定义多端口匹配条件 [!] –source-ports,–sports port[,port|,port:port]…:指定多个源端口,逗号隔开最多制定15个 [!] –destnation-ports,–dports port[,port|,port:port]…:制定多个目标端口 [!] –ports port[,port|,port:port]…:指定多个端口 2.iprange扩展 以连续的ip地址范围指明连续的多地址匹配条件 3.set扩展 依赖于ipset命令行工具 set存在的类型： hash:net : 网络地址的集合 hash:ip ：目标ip地址 使用方式： 先创建集合 ：ipset create NAMETYPE 向集合中添加元素 ：ipset add NAMETYPE 4.string扩展 对报文的应用层数据做字符串匹配检测 [!] –string pattern : 要检测的字符串模式 [!] –hex-string pattern : 要检测的字符串模式，16进制编码 –algo {bm|kmp} 5.time扩展 根据报文到达的时间与指定的时间范围进行匹配度检测 –datestart YYYY[-MM[-DD]Thh[:mm]:ss]]]]] : 起始日期时间 –datestop YYYY[-MM[-DD]Thh[:mm]:ss]]]]] : 结束日期时间 –timestart hh:mm[:ss] –timestop hh:mm[:ss] [!] –monthdays day[,day…] ： 每月几号的时间 [!] –weekdays day[,day…] ： 每周几的时间 –kerneltz : 使用内核中的配置的时区 6、connlimit扩展 根据每客户端IP做并发连接数匹配； –connlimit-upto n：连接数数量小于等于n，此时应该允许； –connlimit-above n：连接数数量大于n，此时应该拒绝； ~]# iptables -A INPUT -d 172.16.100.67 -p tcp –dport 23 -m connlimit –connlimit-upto 2 -j ACCEPT 7、limit扩展 基于收发报文的速率进行匹配； –limit rate[/second|/minute|/hour|/day]：平均速率 –limit-burst number：峰值速率 8、state扩展 状态检测；连接追踪机制（conntrack）； INVALID：无法识别的状态； ESTABLISHED：已建立的连接； NEW：新连接； RELATED：相关联的连接； UNTRACKED：未追踪的连接； nf_conntrack内核模块； 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，建议必要时调整到足够大； 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ [!] –state STATE 如何开放被模式的ftp服务： (1) 装载追踪ftp协议的模块； # modprobe nf_conntrack_ftp - (2) 放行命令连接 - ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT - ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT - (3) 放行数据连接 - ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作target DROP : 丢弃 REJECT : 拒绝 ACCEPT : 接受 RETURN : 无匹配的链的时候自动调回 REDIRECT : 重定向 SANT : 源地址转换 DNAT: 目标地址转换 MASQUERADE : 地址伪装 LOG : 日志 自定义链 管理机制 ： 两不兼容，最好不要并行 firewalld : firewalld-cmd iptables ： iptables-save,iptables-restore yum install iptables-services1234567891011每一个内核就是一个扩展 xt开头[root@centos7 ~]# cd /lib/modules/3.10.0-862.el7.x86_64/kernel/net/netfilter/[root@centos7 netfilter]# lsipset xt_connlimit.ko.xzipvs xt_connmark.ko.xznf_conntrack_amanda.ko.xz xt_CONNSECMARK.ko.xznf_conntrack_broadcast.ko.xz xt_conntrack.ko.xznf_conntrack_ftp.ko.xz xt_cpu.ko.xznf_conntrack_h323.ko.xz xt_CT.ko.xznf_conntrack_irc.ko.xz xt_dccp.ko.xznf_conntrack.ko.xz xt_devgroup.ko.xz 1234567891011121314151617181920212223242526272829查看某表中的规则[root@centos7 ~]# iptables -t filter -vnL将某表中的INPUT链计数器置零[root@centos7 ~]# iptables -t filter -Z INPUT规则显示详情[root@centos7 ~]# iptables -t filter -vnL pkts(报文数) bytes(字节数) target（目标） prot（协议） opt（选项） in（报文流入的接口） out（报文流出的接口） source（源地址） destination（目标地址） 显示iptables表的本文和自己的精确的显示以及行号的显示[root@centos7 ~]# iptables -t filter -vxnL --line-numbers-N 自定义规则链（见名知意）[root@centos7 ~]# iptables -N web_rules[root@centos7 ~]# iptables -vnLChain web_rules (0 references) 0个引用 pkts bytes target prot opt in out source destination -E 修改自定义的规则链名称（改名通常适用于修改自定义规则连0引用的规则链）[root@centos7 ~]# iptables -E web_rules cifs_rules-X 删除自定义的规则链：计数为0，若不为0 可以将主链中的调用删除再进行清空删除[root@centos7 ~]# iptables -F cifs_rules[root@centos7 ~]# iptables -X cifs_rules内部规则： Chain OUTPUT (policy ACCEPT 1 packets, 356 bytes)具有规则链和接收器 范例：使得iptables定义的规则永久有效12345678命令：内核中定义的规则标准输出至屏幕 [root@centos7 ~]# iptables-save 将标准的输入重定向到文件中 [root@centos7 ~]# iptables-save &gt; /data/iptables.txt 模拟清空防火墙规则 [root@centos7 ~]# iptables -F 还原防火墙的规则 [root@centos7 ~]# iptables-restore /data/iptables.txt 范例：如何将定义的防火墙规则开机自动生效123456yum install iptables-services -y服务方式管理的iptables[root@centos7 ~]# /usr/libexec/iptables/iptables.init restrtUsage: iptables &#123;start|stop|reload|restart|condrestart|status|panic|save&#125; 显示扩展1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461：multiport显示扩展：匹配多个源、目标端口 定义入栈规则 [root@centos7 ~]# iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 定义出栈规则 [root@centos7 ~]# iptables -I OUTPUT -p tcp -m multiport --sports 21:22,80,139,445 删除入栈规则的第#条 [root@centos7 ~]# iptables -D INPUT #2：iprange扩展：匹配ip地址的连续范围（仅开放给有限的地址去怕ping） 入栈 [root@centos7 ~]# iptables -I INPUT 4 -p icmp --icmp-type 8 -m iprange --src-range 192.168.10.10-192.168.10.20 -j ACCEPT 出栈 [root@centos7 ~]# iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.10.10-192.168.10.20 -j ACCEPT3：set扩展:非连续的ip地址，人为定义ip地址集后续调用 安装 [root@centos7 ~]# yum install ipset -y 查看帮助用法 ipset -h 创建集合ip哈希表 [root@centos7 ~]# ipset create pinghosts hash:ip (如果为多个网段hash:net) [root@centos7 ~]# ipset list Name: pinghosts Type: hash:ip Revision: 1 Header: family inet hashsize 1024 maxelem 65536 Size in memory: 16528 References: 0 Members: 向集合中添加允许的主机地址 [root@centos7 ~]# ipset add pinghosts 192.168.10.10 [root@centos7 ~]# ipset add pinghosts 192.168.10.20 [root@centos7 ~]# ipset list Name: pinghosts Type: hash:ip Revision: 1 Header: family inet hashsize 1024 maxelem 65536 Size in memory: 16560 References: 0 Members: 192.168.10.20 192.168.10.10 设置规则允许集合表中的主机对本机进行ping 入栈 [root@centos7 ~]# iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set pinghosts src -j ACCEPT 出栈 [root@centos7 ~]# iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set pinghosts dst -j ACCEPT [root@centos7 ~]# iptables -vnL4：string扩展：对报文的应用层数据做字符串匹配检测 假设web网页中的敏感字体进行字符串匹配检测 入栈 [root@centos7 ~]# iptables -I INPUT -m string --string "敏感字" --algo bm -j REJECT 出栈 [root@centos7 ~]# iptables -I OUTPUT -m srting --string "敏感字" --algo bm -j REJECT多个扩展可一起使用，与的关系，满足所有的条件time扩展 ： 根据报文到达的时间与指定的时间范围进行匹配度检测 [root@centos7 ~]# iptables -I INPUT 5 -p icmp --icmp-type 8 -m set --match-set pinghosts src -m time --timestart 08:00:00 --timestop 14:00:00 --weekdays Tue,Thu,Sat --kerneltz -j ACCEPT5：connlimit扩展：并发连接数限制 根据每个客户端ip做并发连接数数量匹配，可防止CC攻击。 --connlimit-upto # :连接的数量小于等于#时匹配 --connlimit-above # : 连接的数量大于#时匹配 通常分别与默认的拒绝或允许策略配合使用（默认的意思并非默认规则，而是定义的规则已经有允许，在此基础上做连接数量限制，定义在已经有的允许的规则之前） 限制ssh连接本机的连接数限制 [root@centos7 ~]# iptables -I INPUT 2 -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT6：limit扩展 基于收发报文的速度做匹配(报文传输速率限制) 令牌桶过滤器 --limit # [/second|/minute|/hour|/day] --limit-burst number 允许别人ping自己仅能按照特定的速率进行ping 出去的速率无需控制，仅控制本机进来的速率 限制ping速率为每3秒钟一个，限制突发速率为5个 [root@centos7 ~]# iptables -I INPUT -p icmp --icmmp-type 8 -s 192.168.52.177 -d 192.168.52.182 -m limit --limit 20/minute --limit-burst 5 -j ACCEPT7：state状态扩展 根据“连续追踪机制”去检查连接的状态，较消耗资源 - conntrack机制：追踪本机上的请求和响应之间的关系 状态有如下几种： - NEW：新发出的请求，连接追踪信息库中不存在此链接的相关信息条目，因此，将其识别为第一次触发的请求（新人） - ESTABLISHED:NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通讯状态（熟人） - RELATED:新发起的但与已有连接相关的连接，如：ftp协议中的数据连接与命令连接之间的关系（熟人的熟人） - INVALID:无效的连接，如flag标记不正确（识别不出的连接） - UNTRACKED:未进行的追踪的连接，如raw表中关闭追踪（未追踪的） - SNAT:源地址转换 - DNAT:目标地址转换 示例： iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 /proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 /proc/sys/net/nf_conntrack_max 永久生效修改的所能够容纳的最大的连接数量 [root@centos7 ~]# vim /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 10000000 [root@centos7 ~]# sysctl -p /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 100000 [root@centos7 ~]# cat /proc/sys/net/nf_conntrack_max 100000 不同的协议的连接追踪时长 /proc/sys/net/netfilter/ 注意：CentOS7 需要加载模块： modprobe nf_conntrack范例： 允许所有已经连结果的请求入栈出栈 [root@centos7 ~]# iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT [root@centos7 ~]# iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT [root@centos7 ~]# iptables -A INPUT -p tcp -m multiport --dports 21:22,80 -m state --state NEW -j ACCEPT [root@centos7 ~]# iptables -A OUTPUT ! -i lo -j REJECT [root@centos7 ~]# iptables -A OUTPUT ! -o lo -j REJECT 服务端开放客户端ftp服务，客户端主动访问服务端，服务端数据端口为随机端口，在客户端添加规则 [root@centos7 ~]# iptables -I INPUT 2 -p tcp -m state --state RELATED -j ACCEPT 实现ftp RELATED 需要手动载入一个模块 [root@centos7 ~]# modprobe nf_conntrack [root@centos7 ~]# modinfo nf_conntrack [root@centos7 ~]# lsmod | grep nf_conntrack 手动载入的模块，重启后失效，大量的ftp服务就会被肆意的放行，如何让ftp连接状态iptabless开机继续生效（自动装入模块） 方法1： [root@centos7 ~]# vim /etc/sysconfig/iptables-config 第六行 IPTABLES_MODULES="nf-conntrack_ftp" 方法2： [root@centos7 ~]# vim /etc/sysconfig/modules/nf_conntrack.mudules #!/bin/bash /sbin/modprobe nf_conntrack_ftp [root@centos7 ~]# chmod +x /etc/sysconfig/modules/nf_conntrack.mudules 前提是已经安装启动iptables.services [root@centos7 ~]# systemctl restart iptables [root@centos7 ~]# systemctl enable iptables]]></content>
      <categories>
        <category>iptables防火墙</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旧事-大好河山]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. U2FsdGVkX1/Ey8g6YNMzq7gXei6Et7nQxyxh4eqgU8GmklOInmOm0qV931+iGuLluRiYk6EOdZRAkXBlEvrfBILCVROWCScR2NOS+vq+UoWbKSTDrHsVmvr3cZm4f5Gb0Xh8Be4BSeyLXhBfXDs6dfB8TOTQyxXr+d2N1+DNLoIjfa0f8xcNzwbVUBWuBvxjFtnAY2/YOPeO5/5VOwyR9e1aosyWq+gOhQCwhN7XiqWLsvJJWOXNYcuij36E4+R/Qs3R5PxPjWyrJ04WR2sibqxWIgxPDWPg/EbnUcH7b3GBiGaQphd7p88rWglq0vl0jaYtn0YWW46DN02YSqv9NOv6ddZXW9Ce37tZiLx2m9pkht0xZGmls1QC0uwnsl2f]]></content>
      <categories>
        <category>旧事，杂记</category>
      </categories>
      <tags>
        <tag>旧事，杂记</tag>
      </tags>
  </entry>
</search>
