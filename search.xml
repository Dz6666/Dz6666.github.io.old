<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[keepalived及haproxy生产负载和高可用应用（编译安装）]]></title>
    <url>%2F2019%2F03%2F09%2Fkeepalived%E5%8F%8Ahaproxy%E7%94%9F%E4%BA%A7%E8%B4%9F%E8%BD%BD%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8%E5%BA%94%E7%94%A8%EF%BC%88%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%EF%BC%89%2F</url>
    <content type="text"><![CDATA[keepalived配置多vip及实现双主模式 一：在生产环境中haproxy广泛用于四层和七层的反向负载，haproxy则通过VRRP技术实现虚拟IP高可用从而实现haproxy的高可用，本文将侧重于介绍keepalived方面的知识及相关配置介绍，haproxy只用于测试web代理，具体如下： 1.1：安装haproxy： 1.1.1：编译安装haproxy：12345678[root@linux-node137 ~]# cd /usr/local/src/[root@linux-node137 src]# wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.3.tar.gz[root@linux-node137 src]# tar xvf haproxy-1.7.3.tar.gz[root@linux-node137 src]# cd haproxy-1.7.3/[root@linux-node137 haproxy-1.7.3]# yum install gcc pcre pcre-devel openssl openssl-devel -y[root@linux-node137 haproxy-1.7.3]# vim README #安装文档及相关帮助信息[root@linux-node137 haproxy-1.7.3]# make TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 PREFIX=/usr/local/haproxy[root@linux-node137 haproxy-1.7.3]# make install PREFIX=/usr/local/haproxy 1.1.2：准备启动脚本文件：123456789101112[root@linux-node137 haproxy-1.7.3]# vim /usr/lib/systemd/system/haproxy.service[Unit]Description=HAProxy Load BalancerAfter=syslog.target network.target[Service]EnvironmentFile=/etc/sysconfig/haproxyExecStart=/usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid $OPTIONSExecReload=/bin/kill -USR2 $MAINPID[Install]WantedBy=multi-user.target 1.1.3：复制启动脚本：12[root@linux-node137 haproxy-1.7.3]# cp haproxy-systemd-wrapper /usr/sbin/haproxy-systemd-wrapper[root@linux-node137 haproxy-1.7.3]# cp haproxy /usr/sbin/haproxy 1.1.4：准备sysconfig配置文件：12345[root@linux-node137 haproxy-1.7.3]# vim /etc/sysconfig/haproxy# Add extra options to the haproxy daemon here. This can be useful for# specifying multiple configuration files with multiple -f options.# See haproxy(1) for a complete list of options.OPTIONS="" 1.1.5：主备配置文件，简单配置，后续完善：12345678910111213141516171819202122232425262728293031323334[root@linux-node137 haproxy-1.7.3]# mkdir /etc/haproxy[root@linux-node137 haproxy-1.7.3]# vim /etc/haproxy/haproxy.cfgglobalmaxconn 100000chroot /usr/local/haproxyuid 99gid 99daemonnbproc 1pidfile /usr/local/haproxy/run/haproxy.pidlog 127.0.0.1 local3 infodefaultsoption http-keep-aliveoption forwardformaxconn 100000mode httptimeout connect 300000mstimeout client 300000mstimeout server 300000mslisten stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4yslisten web_port bind 0.0.0.0:80 mode http log global server web1 172.10.1.238:80 check inter 3000 fall 2 rise 5 1.1.6：启动haproxy:1[root@linux-node137 haproxy-1.7.3]# systemctl restart haproxy 1.1.7：验证haproxy监听的端口： 1.1.8：后端web服务器安装http：123[root@aqdl ~]# yum install httpd[root@aqdl html]# echo "Haptoxy Page" &gt; /var/www/html/index.html[root@aqdl ~]# systemctl restart httpd 1.1.9：访问haproxy的80端口: 1.1.10：开启haproxy日志：1234[root@linux-node137 ~]# vim /etc/rsyslog.conf 15 $ModLoad imudp 16 $UDPServerRun 514 92 local3.* /var/log/haproxy.log #保存后的日志目录 1.1.11：重启rsyslog服务：1[root@linux-node137 ~]# systemctl restart rsyslog 1.1.12：配置haproxy调用rsyslog：123[root@linux-node137 ~]# vim /etc/haproxy/haproxy.cfg 9 log 127.0.0.1 local3 info[root@linux-node137 ~]# systemctl restart haproxy 1.1.13：访问web界面并验证haproxy日志目录：1234[root@linux-node137 ~]# tail /var/log/haproxy.log Mar 9 16:04:40 localhost haproxy[55688]: Proxy stats started.Mar 9 16:04:40 localhost haproxy[55688]: Proxy web_port started.Mar 9 16:06:45 localhost haproxy[55689]: Connect from 192.168.10.1:2623 to 192.168.10.137:80 (web_port/TCP) 二：keepalived安装及配置： 2.1：编译安装keepalived： 2.1.1：源码编译安装keepalived：123456789[root@linux-node137 ~]# cd /usr/local/src/[root@linux-node137 src]# wget http://www.keepalived.org/software/keepalived-1.3.4.tar.gz[root@linux-node137 src]# tar xvf keepalived-1.3.4.tar.gz[root@linux-node137 src]# cd keepalived-1.3.4/[root@linux-node137 keepalived-1.3.4]# yum install libnfnetlink-devel libnfnetlink ipvsadm libnl libnl-devel \libnl3 libnl3-devel lm_sensors-libs net-snmp-agent-libs net-snmp-libs openssh-server openssh-clients openssl \openssl-devel automake iproute [root@localhost keepalived-1.3.4]# ./configure --prefix=/usr/local/keepalived --disable-fwmark #传递参数关闭管理防火墙功能 1[root@linux-node137 keepalived-1.3.4]# make &amp;&amp; amke install 2.1.2：安装完成界面如下： 2.1.3：复制相关配置文件及启动脚本：123[root@linux-node137 keepalived-1.3.4]# cp /usr/local/src/keepalived-1.3.4/keepalived/etc/init.d/keepalived.rh.init /etc/sysconfig/keepalived.sysconfig[root@linux-node137 keepalived-1.3.4]# cp /usr/local/src/keepalived-1.3.4/keepalived/keepalived.service /usr/lib/systemd/system/[root@linux-node137 keepalived-1.3.4]# cp /usr/local/src/keepalived-1.3.4/bin/keepalived /usr/sbin/ 2.1.4：准备一个简单的配置文件：1234567891011121314151617181920212223242526272829303132333435[root@linux-node137 keepalived-1.3.4]# mkdir /etc/keepalived[root@linux-node137 keepalived-1.3.4]# vim /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 80 priority 100 advert_int 1 #unicast_src_ip 172.10.1.37 #unicast_peer &#123; # 172.10.1.38 #&#125; authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.10.15 dev eth0 label eth0:0 &#125;&#125; 2.1.5：测试keepalived能否正常启动并绑定VIP到本地网卡]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived配置多vip及实现双主模式]]></title>
    <url>%2F2019%2F03%2F09%2Fkeepalived%E9%85%8D%E7%BD%AE%E5%A4%9Avip%E5%8F%8A%E5%AE%9E%E7%8E%B0%E5%8F%8C%E4%B8%BB%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[keepalived配置多vip及实现双主模式 安装keepalived1：实验准备 各节点同步时时间 各节点关闭selinux 2：安装keepalived （本地yum源安装）12345678910~]# yum info keepalivedVersion : 1.3.5~]# yum install keepalived -y~]# rpm -ql keepalived/etc/keepalived/keepalived.conf #主配置文件/etc/sysconfig/keepalived #环境初始化的配置文件/usr/lib/systemd/system/keepalived.service #程序启动的脚本/usr/sbin/keepalived #可执行程序 3：keepalived配置文件解析 keepalived的所有的配置文件都在一个配置文件中设置，支持的配置项也比较多。但分为三类 1：全局配置（Global Configuration） 2: VRRP 配置 3：LVS配置 很明显，全局配置就是对整个keepalived起效的配置，不管是否使用LVS,VRRPD是keepalived的核心，LVS配置只在要使用的keepalived来配置和管理LVS时需要使用，如果仅使用Keepalived来做HA，LVS的配置完全是不需要的 配置文件都是以块（block）形式组织的，每隔块都在{和}包围的范围内，#和开头的行都是注释行 使用mailx发送邮件测试12~]# yum install mailx~]# echo "hellow" | mail -s "biaoti" 1284808408@qq.com 4：养成良好的习惯，编辑服务的配置文件之前就要备份配置文件及解析配置文件 配置文件1234567891011121314151617181920212223242526272829303132~]# cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18&#125;vrrp_instance VRRP-V1 &#123; state MASTER interface ens37 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 11111111 &#125; virtual_ipaddress &#123; 172.18.135.8 &#125;&#125; 解析配置文件 12345678910111213141516171819202122232425262728293031323334备份配置文件 ~]# cd /etc/keepalived/ keepalived]# cp keepalived.conf keepalived.conf.bak编辑配置文件 ! Configuration File for keepalived #提示注释的信息可以使用！/#添加注释信息 global_defs &#123; #全局配置段 notification_email &#123; #定义接收邮件的邮箱 1284808408@qq.com &#125; notification_email_from #定义通知邮箱发件人的地址 smtp_server 127.0.0.1 #定义邮件服务器的地址 smtp_connect_timeout 30 router_id #此处不用定义，默认为本机的主机名称 #vrrp_mcast_group4 224.0.0.18 #默认组播地址 224.0.0.0~239.255.255.255 vrrp_skip_check_adv_addr #如果收到的报文和上一个报文是同一个路由器则跳过检查报文中的源地址 vrrp_strict #严格遵守VRRP协议，不允许状态 ：1.没有VIP地址，2.单播邻居，3.在VRRP版本2中有IPV6地址 vrrp_garp_interval 0 #ARP报文发送延迟，一般设置为0表示不延迟 vrrp_gna_interval 0 #消息发送延迟一般设置为0表示不延迟&#125;vrrp_instance 自定义实例的名称 &#123; #VRRP相关的配置 state MASTER #当前的初始状态 MASTER | BACKUP 主/备份 interface eth0 #指定当前keepalived在启动以后监听的网卡，组播会从此网卡发出 virtual_router_id 51 #定义ID 地址范围为0-255 ID号不能冲突 priority 100 #定义优先级，数字越大优先级越高，一般master的优先级一定是高于backup的，会将VIP绑定在优先级比较高的keepalived服务器上，一般建议将master的优先级要高于backup50个数值，实际上高出一个数值就可以 advert_int 1 #探测信息，默认一秒发送一个广播包，此包是发送到组播中的 authentication &#123; #定义认证的方式（PASS|AH） auth_type PASS #简单的密码认证 auth_pass 66666666 #指定认证的密码 ，默认的密码为1111，仅支持前8位密码 &#125; virtual_ipaddress &#123; #VIP相关的配置 ，定义的VIP地址一定是和指定interface 网卡在相同的网段中 172.18.135.8 &#125; &#125; 5：此节点上启动HA节点123456789101112131415161718192021222324启动节点的keepalived ~]# systemctl start keepalived ~]# systemctl enable keepalived查看进程的状态 ~]# ps -ef | grep keepalived root 6412 1 0 15:03 ? 00:00:00 /usr/sbin/keepalived -D root 6413 6412 0 15:03 ? 00:00:00 /usr/sbin/keepalived -D root 6414 6412 0 15:03 ? 00:00:00 /usr/sbin/keepalived -D root 6508 6466 0 15:06 pts/0 00:00:00 grep --color=auto keepalived 查看VIP ~] # ip addr ens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:14:4d:6c brd ff:ff:ff:ff:ff:ff inet 172.18.135.1/24 brd 172.18.135.255 scope global noprefixroute ens37 valid_lft forever preferred_lft forever inet 172.18.135.8/32 scope global ens37 valid_lft forever preferred_lft forever inet6 fe80::4587:5c47:4c05:570b/64 scope link noprefixroute valid_lft forever preferred_lft forever 6：启动keepalived会默认生成访问墙的规则12345678910~]# iptables -LChain INPUT (policy ACCEPT) #拒绝从任何地址到VIP地址的访问target prot opt source destination DROP all -- anywhere anywhere match-set keepalived dstChain FORWARD (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination 7：解决yum安装的keepalived启动时默认生成的防火墙额规则的123456789101112131415161718192021222324方法一： 直接清空防火墙 ~]# iptables -F 可以在keepalived启动时跳过生成防火墙的规则 编辑配置文件 global_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18 vrrp_iptables #不生成防火墙策略 &#125; .... 8：其他节点ping keepalived VIP地址测试12345~]# ping 172.18.135.8PING 172.18.135.8 (172.18.135.8) 56(84) bytes of data.64 bytes from 172.18.135.8: icmp_seq=1 ttl=64 time=0.077 ms64 bytes from 172.18.135.8: icmp_seq=2 ttl=64 time=0.106 ms64 bytes from 172.18.135.8: icmp_seq=3 ttl=64 time=0.090 ms 将VIP在HA主机上设置一个单独的子接口1：编辑keepalived的配置文件12345678910111213141516171819202122232425262728293031323334~]# cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18 vrrp_iptables&#125;vrrp_instance VRRP-V1 &#123; state MASTER interface ens37 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 11111111 &#125; virtual_ipaddress &#123; 172.18.135.8 dev ens37 label ens37:1 #定义lable，也可以在地址后面添加掩码 &#125;&#125; 2：重新启动查看网卡接口1~]# systemctl restart keepalived 高可用集群部署 1：node1配置123456789101112131415161718192021222324252627282930313233~]# cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18 vrrp_iptables&#125;vrrp_instance VRRP-V1 &#123; state MASTER #主 interface ens37 virtual_router_id 51 priority 100 #100优先级 advert_int 1 authentication &#123; auth_type PASS auth_pass 11111111 &#125; virtual_ipaddress &#123; 172.18.135.8/24 dev ens37 label ens37:01 &#125;&#125; 2：启动keepalived1~]# systemctl start keepalived 3：node2 配置123456789101112131415161718192021222324252627282930313233343536~]# yum install keepalived -y~]# vim /etc/keepalived/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18 vrrp_iptables&#125;vrrp_instance VRRP-V1 &#123; state BACKUP #备 interface ens37 virtual_router_id 51 priority 90 #90优先级要低于MASTER advert_int 1 authentication &#123; auth_type PASS auth_pass 11111111 &#125; virtual_ipaddress &#123; 172.18.135.8/24 dev ens37 label ens37:01 &#125;&#125; 4：node2 启动keepalived12~]# systemctl start keepalived~]# systemctl enable keepalived 5：测试在node1节点上ens37网卡断掉，是否会将vip飘到node2上(可以查看日志信息)123456789101112131415161718node1~]# ifconfig ens37 downnode2~]# ip addrens37: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:97:a5:a7 brd ff:ff:ff:ff:ff:ff inet 172.18.135.2/24 brd 172.18.135.255 scope global ens37 valid_lft forever preferred_lft forever inet 172.18.135.8/24 scope global secondary ens37:01 valid_lft forever preferred_lft forever inet6 fe80::8aad:e002:aea0:6f27/64 scope link valid_lft forever preferred_lft forever如果node1节点挂掉了，node2可以继续对外提供服务，但是node1的优先级要高于node2 如果node1恢复则vip会继续飘回node1上 指定当主节点VIP宕机时自动发送报警邮件信息1：编辑keepalived配置文件（node1 和node2 配置文件相同）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 notify_master #当前节点成为主节点时触发的脚本 notify_backup #当前节点转为备份节点时触发的脚本 notify_fault #当前节点转为“失败”状态时触发的脚本定义报警时触发的脚本~]# vim /etc/keepalived/notify.sh#!/bin/bash#contact='1284808408@qq.com'notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact &#125;case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;; esac~]# chmod +x /etc/keepalived/notify.sh 编辑keepalived配置文件调用脚本~]# cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 1284808408@qq.com &#125; notification_email_from root@example.com smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 #vrrp_mcast_group4 224.0.0.18 vrrp_iptables&#125;vrrp_instance VRRP-V1 &#123; state MASTER interface ens37 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 11111111 &#125; virtual_ipaddress &#123; 172.18.135.8/24 dev ens37 label ens37:01 #可配置多个VIP地址 172.18.135.9/24 dev ens37 label ens37:02 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125;重启服务 ~]# systemctl restart keepalived]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之filebeat多个文件日志收集]]></title>
    <url>%2F2019%2F03%2F06%2FELK%E4%B9%8Bfilebeat%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[ELK之filebeat多个文件日志收集 filebeat日志收集实战： 架构规划： 在下面的图当中从左向右看，当要访问ELK日志统计平台的时候，首先访问的是两台nginx+keepalived做的负载高可用，访问的地址是keepalived的IP，当一台nginx代理服务器挂掉之后也不影响访问，然后nginx将请求转发到kibana，kibana再去elasticsearch获取数据，elasticsearch是两台做的集群，数据会随机保存在任意一台elasticsearch服务器，redis服务器做数据的临时保存，避免web服务器日志量过大的时候造成的数据收集与保存不一致导致的日志丢失，可以临时保存到redis，redis可以是集群，然后再由logstash服务器在非高峰时期从redis持续的取出即可，另外有一台mysql数据库服务器，用于持久化保存特定的数据，web服务器的日志由filebeat收集之后发送给另外的一台logstash，再有其写入到redis即可完成日志的收集，从图中可以看出，redis服务器处于前端结合的最中间，其左右都要依赖于redis的正常运行，web服务删个日志经过filebeat收集之后通过日志转发层的logstash写入到redis不同的key当中，然后提取层logstash再从redis将数据提取并安按照不同的类型写入到elasticsearch的不同index当中，用户最终通过nginx代理的kibana查看到收集到的日志的具体内容： 1：filebeat收集日志转发至logstash(基于beats模块) 官方文档：https://www.elastic.co/guide/en/beats/filebeat/current/logstash-output.html 目前只收集了系统日志，下面将tomcat的访问日志和启动时生成的catalina.txt文件的日志进行收集，另外测试多行匹配，并将输出改为logstash进根据日志类型判断写入到不同的redis key当中，在一个filebeat服务上面同时收集不同类型的日志，比如收集系统日志的时候还要收集tomcat的访问日志，那么直接带来的问题就是要在写入至redis的时候要根据不同的日志类型写入到reids不通的key当中，首先通过logstash监听一个端口，并做标准输出测试，具体配置为： 配置Logstash配置文件123456789101112131415~]# cd /etc/logstash/conf.d/conf.d]# cat beats-test.conf input &#123; beats &#123; port =&gt; 5044 codec =&gt; "json" #指定编码格式 &#125;&#125;#将输出改为文件进行临时输出测试output &#123; file &#123; path =&gt; "/tmp/filebeat.txt" &#125;&#125; logstash配置文件测试语法12conf.d]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/beats-test.conf -tconf.d]# systemctl restart logstash #重启服务 2：更改web服务器的filebeat配置123456789101112131415161718#配置filebeat配置文件，配置收集nginx的访问日志，标准输出至Logstash中~]# vim /etc/filebeat/filebeat.yml 12 filebeat.prospectors:18 - input_type: log21 paths:22 - /var/log/nginx/access.log39 fields:40 type: nginx-accesslog116 output.logstash:117 hosts: ["172.18.135.2:5044"] #logstash 服务器地址，可以是多个118 enabled: true #是否开启输出至logstash，默认即为true119 worker: 1 #工作线程数120 #compression_level: 3 #压缩级别，数值越大，压缩比越高（1~9），一般情况下不使用，因为会占用cpu资源121 #loadbalance: true #多个输出的时候开启负载,在输出到多个logstash时开启此项 重启filebeat1~]# systemctl restart filebeat 3：客户端模拟访问web服务器，logstash查看是记录日志文件 4：Logstash中配置将filebeat发送来的日志发送到redis123456789101112131415161718192021222324252627前面配置logstash是将filebeat发来的日志信息，存储到本地的文件中编辑logstahs配置文件~]# cd /etc/logstash/conf.d/conf.d]# cat beats-test.conf input &#123; beats &#123; port =&gt; 5044 codec =&gt; "json" #指定编码格式 &#125;&#125;#将输出改为文件进行临时输出测试output &#123; if [fields] [type] == "nginx-accesslog" &#123; redis &#123; host =&gt; "172.18.135.2" #redis服务器的地址 prot =&gt; "6379" password =&gt; "123456" data_type =&gt; "list" key =&gt; "nginx-accesslog" #日志数据存储到redis时的key的名称 db =&gt; 1 codec =&gt; "json" &#125; &#125;&#125; logstash配置文件测试语法12conf.d]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/beats-test.conf -tconf.d]# systemctl restart logstash #重启服务 5：在redis上查看是否已经存入1库中 6：配置logstash从redis中读取键值并存储到ES集群中做日志收集1234567891011121314151617181920212223~]# vim /etc/logstash/conf.d/redis-systemlog-es.conf input &#123; redis &#123; host =&gt; "172.18.135.2" #redis主机地址 password =&gt; "123456" port =&gt; "6379" db =&gt; "1" key =&gt; "nginx-accesslog" data_type =&gt; "list" codec =&gt; "json" &#125;&#125;output &#123; if [fields][type] == "nginx-accesslog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] #ES集群主机地址 index =&gt; "nginx-log-135-1-%&#123;+YYYY.MM.dd&#125;" codec =&gt; "json"&#125;&#125;&#125; 语法检测并启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-systemlog-es.conf -t~]# systemctl restart logstash 7：ES主机上head插件查看日志索引是否存储 8：kibana根据定义的索引展示日志记录 filebeat收集多类型的日志文件1：编辑用来收集日志的filebeat配置文件，收集本机的多个日子文件(收集本机上的nginx的访问日志和本机的所有的文件)，发送到Logstash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152~]# grep -v "#" /etc/filebeat/filebeat.yml | grep -v "^$"filebeat.prospectors:- input_type: log paths: - /var/log/nginx/access.log fields: type: nginx-accesslog #标识nginx访问日志的类型（需要将nginx的日志类型改为json） - input_type: log paths: - /var/log/message fields: type: systemlog #标识message日志的类型output.logstash: hosts: ["172.18.135.1:5044"] enable: true worker: 1 compression_level: 52：编辑logstash配置文件，将filebeat发送来的日志信息，根据定义的type类型存储到redis中```bash~]# cd /etc/logstash/conf.d/conf.d]# cat beats-test.conf input &#123; beats &#123; port =&gt; 5044 codec =&gt; "json" #指定编码格式 &#125;&#125;#将输出改为文件进行临时输出测试output &#123; if [fields] [type] == "nginx-accesslog" &#123; redis &#123; host =&gt; "172.18.135.2" #redis服务器的地址 prot =&gt; "6379" password =&gt; "123456" data_type =&gt; "list" key =&gt; "nginx-accesslog" #日志数据存储到redis时的key的名称 db =&gt; 1 codec =&gt; "json" &#125;&#125; if [fields] [type] == "systemlog" &#123; redis &#123; host =&gt; "172.18.135.2" #redis服务器的地址 prot =&gt; "6379" password =&gt; "123456" data_type =&gt; "list" key =&gt; "systemlog" #日志数据存储到redis时的key的名称 db =&gt; 1 &#125;&#125;&#125; 语法检测并启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-systemlog-es.conf -t~]# systemctl restart logstash 3：在redis上查看是否已经存入1库中 4：编辑另一台logstash主机配置文件，从redis中服务日志键值，存储到后端的ES存储集群中，进行日志存储1234567891011121314151617181920212223242526272829303132333435363738~]# vim /etc/logstash/conf.d/redis-systemlog-es.conf input &#123; redis &#123; host =&gt; "172.18.135.2" #redis主机地址 password =&gt; "123456" port =&gt; "6379" db =&gt; "1" key =&gt; "nginx-accesslog" data_type =&gt; "list" codec =&gt; "json" &#125; redis &#123; host =&gt; "172.18.135.2" #redis主机地址 password =&gt; "123456" port =&gt; "6379" db =&gt; "1" key =&gt; "systemlog" data_type =&gt; "list" #codec =&gt; "json" &#125;&#125;output &#123; if [fields][type] == "nginx-accesslog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] #ES集群主机地址 index =&gt; "nginx-log-135-1-%&#123;+YYYY.MM.dd&#125;" codec =&gt; "json"&#125;&#125; if [fields][type] == "systemlog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] #ES集群主机地址 index =&gt; "message-log-135-1-%&#123;+YYYY.MM.dd&#125;" codec =&gt; "json"&#125;&#125;&#125; 语法检测并启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-systemlog-es.conf -t~]# systemctl restart logstash 5：ES主机上head插件查看日志索引是否存储 6：kibana根据定义的索引展示日志记录 脚本编写进行监控 依据判断logstash存储到redis数据的数据长度来判断存储redis数据的logstash程序是否已经宕机 实际环境当中，可能会出现reids当中堆积了大量的数据而logstash由于种种原因未能及时提取日志，此时会导致redis服务器的内存被大量使用，甚至出现如下内存即将被使用完毕的情景 1：查看reids中的日志队列长度发现有大量的日志堆积在redis 当中 2：在写入redis日志信息的logstash主机上编写python脚本（编写python脚本，获取redis中列表长度并返回值）1234567891011~] # cat redis-llen.py#!/usr/bin/env python#coding:utf-#Author Dai zheimport redisdef redis_conn(): pool=redis.ConnectionPool(host="Redis主机地址",port=6379,db=1,password=123456) conn = redis.Redis(connection_pool=pool) data = conn.llen('存储在redis的KEY名称') print(data)redis_conn() 3：安装管理模块12~]# yum install python-pip~]# pip install redis 4：执行脚本12~]# python redis-llen.py这里显示redia KEY对应的值的大小 脚本编写进行ES存储定期清理在ES主机上 关于elasticsearch存储index的定期删除，elasticsearch存储的日志较多的时候会影响搜索性能，因此建议定期清理，脚本如下，这次是shell脚本： 12345678910111213141516171819202122232425[root@els-s2 ~]# vim els_delete.sh#!/bin/bashDATE=`date -d "2 days ago" +%Y.%m.%d`LOG_NAME="api4-systemlog-7-103" #索引名称,定义的索引尽量使用含有日期格式的索引FILE_NAME=$&#123;LOG_NAME&#125;-$&#123;DATE&#125;curl -XDELETE http://ES主机地址:9200/$&#123;FILE_NAME&#125;echo "$&#123;FILE_NAME&#125; delete success"[root@els-s2 ~]# chmod a+x /root/els_delete.sh 测试执行：[root@els-s2 ~]# bash -x /root/els_delete.sh++ date -d '30 days ago' +%Y.%m.%d+ DATE=2016.08.05+ LOG_NAME=api4-systemlog+ FILE_NAME=api4-systemlog-2016.08.05+ curl -XDELETE http://hfelk.chinacloudapp.cn:9200/api4-systemlog-2016.08.05&#123;"acknowledged":true&#125;+ echo 'api4-systemlog-2016.08.05 delete success'api4-systemlog-2016.08.05 delete success6.2：添加任务计定期执行即可：[root@els-s2 ~]# crontab -e1 * * * * /root/els_delete.sh #每天凌晨一点清除一月之前的日志 备注： 千万不要直接去ES主机上删除数据 /data/esdata/]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之使用filebeat替换logstash]]></title>
    <url>%2F2019%2F03%2F03%2FELK%E4%B9%8B%E4%BD%BF%E7%94%A8filebeat%E6%9B%BF%E6%8D%A2logstash%2F</url>
    <content type="text"><![CDATA[ELK之使用filebeat替换logstash filebeat Filebeat是轻量级单用途的日志收集工具，用于在没有安装java的服务器上专门收集日志，可以将日志转发到logstash、elasticsearch或redis及kafka等场景中进行下一步处理。 官网下载地址：https://www.elastic.co/downloads/beats/filebeat 官方文档：https://www.elastic.co/guide/en/beats/filebeat/current/filebeat- 将本机的json格式的日志通过filebeat收集并标准输出至屏幕 确认日志格式为json格式：先访问web服务器，以产生一定的日志，然后确认是json格式，因为下面的课程中会使用到： 这里演示的本机的json日志格式为web服务器tomcat的访问日志格式 1：访问tomcat WEB站点，生成访问日志信息1~]# ab -n100 -c100 http://192.168.15.16:8080/web 2：确认日志格式，后续会用日志做统计123~]# tail /usr/local/tomcat/logs/localhost_access_log.2017-04-28.txt &#123;"clientip":"192.168.15.15","ClientUser":"-","authenticated":"-","AccessTime":"[28/Apr/2017:21:16:46 +0800]","method":"GET /webdir/ HTTP/1.0","status":"200","SendBytes":"12","Query?string":"","partner":"-","AgentVersion":"ApacheBench/2.3"&#125;&#123;"clientip":"192.168.15.15","ClientUser":"-","authenticated":"-","AccessTime":"[28/Apr/2017:21:16:46 +0800]","method":"GET /webdir/ HTTP/1.0","status":"200","SendBytes":"12","Query?string":"","partner":"-","AgentVersion":"ApacheBench/2.3"&#125; 3：安装配置filebeat1234 ~]# systemctl stop logstash #停止logstash服务(如果有安装) src]# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.3.2-x86_64.rpm src]# yum install filebeat-5.3.2-x86_64.rpm -y` 4：配置filebeat收集系统日志1234567891011121314151617 ~]# cd /etc/filebeat/ filebeat~]# cp filebeat.yml filebeat.yml.bak #备份源配置文件filebeat收集多个系统日志并输出到本地文件~]# grep -v "#" /etc/filebeat/filebeat.yml | grep -v "^$"filebeat.prospectors:- input_type: log paths: - /var/log/messages - /var/log/*.log exclude_lines: ["^DBG","^$"] #不收取的 #include_lines: ["^ERR", "^WARN"] #只收取的 document_type: system-log-1512 #类型，会在每条日志中插入标记output.file: path: "/tmp" filename: "filebeat.txt" 5：启动filebeat服务并验证本地文件是否有数据1filebeat]# systemctl start filebeat 使用Filebeat收集本机的Nginx的访问日志并存储到后端的ES主机上 Filebeat官方参考手册：https://www.elastic.co/products/beats 1：rpm包安装Filebeat123~]# lsfilebeat-5.6.13-x86_64.rpm~]# rpm -ivh filebeat-5.6.13-x86_64.rpm Filebeat配置文件解析123456789101112131415161718192021222324252627~]# vim /etc/filebeat/filebeat.yml #yml语法格式21 paths: #基于path参数，指定收集的哪个日志文件，支持模糊匹配22 - /var/log/*.log23 #- c:\programdata\elasticsearch\logs\* #windows收集windows日志文件语法27 #exclude_lines: ["^DBG"] #排除日志文件中开头以DBU开头的行不做收集31 #include_lines: ["^ERR", "^WARN"] #指定日志文件中只收集的行35 #exclude_files: [".gz$"] #排除文件，范例排除收集压缩的文件39 #fields: 40 # level: debug #在收集的每条日志中插入debug41 # review: 1## 多行合并49 #multiline.pattern: ^\[#================================ Outputs ================================ =====81 output.elasticsearch: #将收集的日志存储到ES主机上格式83 hosts: ["localhost:9200"]86 #protocol: "https" #支持安全认证机制87 #username: "elastic"88 #password: "changeme" 2：编辑配置文件修改nginx日志的格式1234567891011121314151617181920212223242526~]# vim /etc/nginx/nginx.confhttp &#123;# log_format main '$remote_addr - $remote_user [$time_local] "$request" '# '$status $body_bytes_sent "$http_referer" '# '"$http_user_agent" "$http_x_forwarded_for"';## access_log /var/log/nginx/access.log main;log_format access_json '&#123;"@timestamp":"$time_iso8601",' #定义日志的格式 '"host":"$server_addr",' '"clientip":"$remote_addr",' '"size":$body_bytes_sent,' '"responsetime":$request_time,' '"upstreamtime":"$upstream_response_time",' '"upstreamhost":"$upstream_addr",' '"http_host":"$host",' '"url":"$uri",' '"domain":"$host",' '"xff":"$http_x_forwarded_for",' '"referer":"$http_referer",' '"status":"$status"&#125;'; access_log /var/log/nginx/access.log access_json;~]# mkdir -p /var/log/nginx/~]# systemctl start nginx ~]# systemctl enable nginx 3：使用filebeat收集nginx访问日志，配置filebeat收集系统日志：1234567891011121314~]# cd /etc/filebeat/filebeat]# cp filebeat.yml filebeat.yml.bak #备份源配置文件~]# vim /etc/filebeat/filebeat.yml 21 paths:22 - /var/log/nginx/access.log39 fields: #定义type40 type: nginx-accesslog82 output.elasticsearch: #指定将filebeat收集来的日志存储在ES中83 # Array of hosts to connect to.84 hosts: ["172.18.135.1:9200"]85 index "filebeat-nginx-accesslog" #默认的index名称 filebeat-%&#123;+yyyy.MM.DD&#125; 4：启动filebeat12~]# systemctl start filebeat~]# systemctl enable filebeat 5：在ES主机上的head插件查看索引 6：在kinban展示日志 filebeat收集nginx访问日志并写入redis（nginx日志格式需要改为json格式）Filebeat支持将数据直接写入到redis服务器，本步骤为写入到redis当中的一个可以，另外filebeat还支持写入到elasticsearch、logstash等服务器。 1：filebeat配置1234567891011121314~]# vim /etc/filebeat/filebeat.yml 21 paths:22 - /var/log/nginx/access.log39 fields: #定义type，格式很重要40 type: nginx-accesslog116 output.redis: #将日志输出至redis117 hosts: ["172.18.135.5"] #redis地址118 password: "123456" #redis密码119 key: "system-log-5612" #KEY名称（自定义）120 db: 1 #存储到redis的库121 timeout: 5 #超时时长 2：启动filebeat12~]# systemctl start filebeat~]# systemctl enable filebeat 3：测试访问nginx 默认的web页面,验证日志的格式是否为json1234~]# curl 172.18.135.5:80 ~]# cat /var/log/nginx/access.log &#123;"@timestamp":"2019-03-03T16:38:24+08:00","host":"172.18.135.5","clientip":"172.18.135.5","size":3700,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"172.18.135.5","url":"/index.html","domain":"172.18.135.5","xff":"-","referer":"-","status":"200"&#125;&#123;"@timestamp":"2019-03-03T16:38:25+08:00","host":"172.18.135.5","clientip":"172.18.135.5","size":3700,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"172.18.135.5","url":"/index.html","domain":"172.18.135.5","xff":"-","referer":"-","status":"200"&#125; 3：验证redis是否有数据(指定查看对用的库) 4：查看redis中的日志数据123456注意选择的db是否和filebeat写入一致172.18.135.2:6379&gt; select 1OK172.18.135.2:6379[1]&gt; RPOP system-log-5612"&#123;\"@timestamp\":\"2019-03-03T10:04:39.966Z\",\"beat\":&#123;\"hostname\":\"centos77\",\"name\":\"centos77\",\"version\":\"5.6.13\"&#125;,\"fields\":&#123;\"type\":\"nginx-accesslog\"&#125;,\"input_type\":\"log\",\"message\":\"&#123;\\\"@timestamp\\\":\\\"2019-03-03T18:04:37+08:00\\\",\\\"host\\\":\\\"172.18.135.5\\\",\\\"clientip\\\":\\\"172.18.135.5\\\",\\\"size\\\":3700,\\\"responsetime\\\":0.000,\\\"upstreamtime\\\":\\\"-\\\",\\\"upstreamhost\\\":\\\"-\\\",\\\"http_host\\\":\\\"172.18.135.5\\\",\\\"url\\\":\\\"/index.html\\\",\\\"domain\\\":\\\"172.18.135.5\\\",\\\"xff\\\":\\\"-\\\",\\\"referer\\\":\\\"-\\\",\\\"status\\\":\\\"200\\\"&#125;\",\"offset\":9248,\"source\":\"/var/log/nginx/access.log\",\"type\":\"log\"&#125;" 截图补充：对应关系要对应好 5：配置logstash从redis读取上面的日志1234567891011121314151617181920212223~]# vim /etc/logstash/conf.d/redis-systemlog-es.conf input &#123; redis &#123; host =&gt; "192.168.15.12" #指定redis地址 port =&gt; "6379" password =&gt; "123456" #指定redis密码 db =&gt; "1" #从redis哪个库中取数据，需要和filebeat存储时指定的库序号保持一致 key =&gt; "system-log-1512" #从redis取出的KEY的名称，需要和filebeat存储仅redis时的KEY名称保持一致 data_type =&gt; "list" &#125;&#125;output &#123; if [fields][type] == "nginx-accesslog" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] #ES主机地址 index =&gt; "system-log-1512" #定义存储的索引名称 codec =&gt; "json"&#125;&#125;&#125;~]# systemctl restart logstash #重启logstash服务 6：查看logstash服务日志 7：查看redis中是否有数据 8：在ES的head插件验证索引是否创建 9：kibana界面添加索引 10：在kibana验证system日志 11：监控redis数据长度 实际环境当中，可能会出现reids当中堆积了大量的数据而logstash由于种种原因未能及时提取日志，此时会导致redis服务器的内存被大量使用，甚至出现如下内存即将被使用完毕的情景： 12：查看reids中的日志队列长度发现有大量的日志堆积在redis 当中]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper和kafka]]></title>
    <url>%2F2019%2F02%2F23%2FELK%E4%B9%8Bzookeeper%E5%92%8Ckafka%2F</url>
    <content type="text"><![CDATA[zookeeper和kafka kafka及zookeeper简介： Kafka （默认port：9092）被称为下一代分布式消息系统，是非营利性组织ASF(Apache Software Foundation，简称为ASF)基金会中的一个开源项目，比如HTTP Server、Hadoop、ActiveMQ、Tomcat等开源软件都属于Apache基金会的开源软件，类似的消息系统还有RbbitMQ、ActiveMQ、ZeroMQ，最主要的优势是其具备分布式功能、并且结合zookeeper可以实现动态扩容。 官方站点：http://www.infoq.com/cn/articles/apache-kafka ZooKeeper（默认port：2181）是一个分布式且开源的分布式应用程序协调服务。 zookeeper集群特性：整个集群中只要有超过集群数量一半的zookeeper工作是正常的，那么整个集群对外就是可用的，假如有2台服务器做了一个zookeeper集群，只要有任何一台故障或宕机，那么这个zookeeper集群就不可用了，因为剩下的一台没有超过集群一半的数量，但是假如有三台zookeeper组成一个集群，那么损坏一台就还剩两台，大于3台的一半，所以损坏一台还是可以正常运行的，但是再损坏一台就只剩一台集群就不可用了。那么要是4台组成一个zookeeper集群，损坏一台集群肯定是正常的，那么损坏两台就还剩两台，那么2台不大于集群数量的一半，所以3台的zookeeper集群和4台的zookeeper集群损坏两台的结果都是集群不可用，一次类推5台和6台以及7台和8台都是同理，所以这也就是为什么集群一般都是奇数的原因。 zookeeper集群部署安装zookeeper：三台服务器： 备注：也可以将ZK和KF集群安装在6台主机上各三台IP分别是：172.18.135.1 &ensp;&ensp; 172.18.135.2 &ensp;&ensp; 172.18.135.5 1：三台服务器分别配置hosts文件：123456cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.18.135.1 es1.com172.18.135.2 es2.com172.18.135.5 es5.com 2：zookeeper的安装是依赖java环境的,三台主机安装java，JDK1234~]# java -versionopenjdk version "1.8.0_161"OpenJDK Runtime Environment (build 1.8.0_161-b14)OpenJDK 64-Bit Server VM (build 25.161-b14, mixed mode) 3：下载安装并验证zookeeper：kafka下载地址：http://kafka.apache.org/downloads.html zookeeper 下载地址：http://zookeeper.apache.org/releases.html 4：三台主机安装zookeeper(需要依赖java环境)： ZooKeeper是一个分布式且开源的分布式应用程序协调服务。 zookeeper集群特性：整个集群中只要有超过集群数量一半的zookeeper工作是正常的，那么整个集群对外就是可用的，假如有2台服务器做了一个zookeeper集群，只要有任何一台故障或宕机，那么这个zookeeper集群就不可用了，因为剩下的一台没有超过集群一半的数量，但是假如有三台zookeeper组成一个集群，那么损坏一台就还剩两台，大于3台的一半，所以损坏一台还是可以正常运行的，但是再损坏一台就只剩一台集群就不可用了。那么要是4台组成一个zookeeper集群，损坏一台集群肯定是正常的，那么损坏两台就还剩两台，那么2台不大于集群数量的一半，所以3台的zookeeper集群和4台的zookeeper集群损坏两台的结果都是集群不可用，一次类推5台和6台以及7台和8台都是同理，所以这也就是为什么集群一般都是奇数的原因。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364三台主机都要编译安装zookeeper（配置相同，配置如下） ~]# cd /usr/local/src/ src]# ls zookeeper-3.4.13.tar.gz src]# tar xvf zookeeper-3.4.13.tar.gz 创建软连接方便下次升级 src]# ln -sv /usr/local/src/zookeeper-3.4.13 /usr/local/zookeeper三台主机配置zookeeper配置的文件 ~]# cp /usr/local/zookeeper/conf/zoo_sample.cfg /usr/local/zookeeper/conf/zoo.cfg ~]# grep "^[a-Z]" /usr/local/zookeeper/conf/zoo.cfg tickTime=2000 initLimit=10 syncLimit=5 dataDir=/usr/local/zookeeper/data clientPort=2181 maxClientCnxns=4096 autopurge.snapRetainCount=3 autopurge.purgeInterval=72 server.1=172.18.135.1:2888:3888 server.2=172.18.135.2:2888:3888 server.3=172.18.135.5:2888:3888三台主机创建zookeeper数据目录 ~]# mkdir /usr/local/zookeeper/data在三台主机上手动生成serverID172.18.135.1 ~]# echo "1" &gt; /usr/local/zookeeper/data/myid172。18.135.2 ~]# echo "2" &gt; /usr/local/zookeeper/data/myid172.18.135.5 ~]# echo "3" &gt; /usr/local/zookeeper/data/myid三台机器启动zookeeper ~]# ls /usr/local/zookeeper/bin/ zkServer.sh #启动服务端脚本 zkCli.sh #启动客户端脚本 ~]# /usr/local/zookeeper/bin/zkServer.sh start ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED查看各主机的端口是否监听 #启动zookeeper进程时，已经将角色身份分配好，如果为领导者端口为3888，2181，2888，如果身份为跟随者端口为2181，2888 ~]# ss -tnl ::ffff:172.18.135.2:3888 :::2181 ::ffff:172.18.135.2:2888 zookeeper配置文件详解1234567891011src]# grep "^[a-Z]" /usr/local/zookeeper/conf/zoo.cfg tickTime=2000 #服务器与服务器之间和客户端与服务器之间的单次心跳检测时间间隔，单位为毫秒initLimit=5 #集群中leader服务器与follower服务器初始连接心跳次数，即多少个2000毫秒syncLimit=5 # leader与follower之间连接完成之后，后期检测发送和应答的心跳次数，如果该follower 在设置的时间内(5*2000)不能与leader 进行通信，那么此 follower 将被视为不可用。clientPort=2181 #客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求dataDir=/usr/local/zookeeper/data #自定义的zookeeper保存数据的目录autopurge.snapRetainCount=3 #设置zookeeper保存保留多少次客户端连接的数据autopurge.purgeInterval=1 #设置zookeeper间隔多少小时清理一次保存的客户端数据（单位为小时，0为关闭自动清理）server.1=192.168.15.211:2888:3888 #服务器编号=服务器IP:LF数据同步端口:LF选举端口server.2=192.168.15.212:2888:3888server.3=192.168.15.213:2888:3888 5：查看各主机的zookeeper节点状态信息12345678910111213141516java程序往leader中写入数据，从follower中读取数据，此功能是基于底层的java库实现的 ~]# /usr/local/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: leader #角色：领导者/追随者 ~]# /usr/local/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: follower ~]# /usr/local/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg Mode: follower zookeeper简单操作测试6：连接到leader节点生成数据12345678客户端链接至领导者节点 ~]# /usr/local/zookeeper/bin/zkCli.sh -server 172.18.135.2:2181 #指定server端的节点地址和端口在/下创建消息 [zk: 172.18.135.2:2181(CONNECTED) 0] create /test "hello" Created /test 7：链接到follower节点查看消息是否同步leader节点12345678910111213141516客户端连接至跟随者节点查看消息 ~]# /usr/local/zookeeper/bin/zkCli.sh -server 172.18.135.1:2181 [zk: 172.18.135.1:2181(CONNECTED) 0] get /test hello cZxid = 0x100000004 ctime = Sat Feb 23 19:11:52 CST 2019 mZxid = 0x100000004 mtime = Sat Feb 23 19:11:52 CST 2019 pZxid = 0x100000004 cversion = 0 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 5 numChildren = 0 kafka 集群部署 kafka：（端口9092） Broker Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic 每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处） Partition parition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件 Producer 生产消息，负责发布消息到Kafka broker Consumer 消费消息。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。 1：在上面安装zookeeper的三台主机上安装kafka12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849安装解压 ~]# cd /usr/local/src/ src]# ls kafka_2.12-2.1.0.tgz src]# tar xvf kafka_2.12-2.1.0.tgz src]# ln -sv /usr/local/src/kafka_2.12-2.1.0 /usr/local/kafka ‘/usr/local/kafka’ -&gt; ‘/usr/local/src/kafka_2.12-2.1.0’编辑各配置文件 172.18.135.1 ~]# vim /usr/local/kafka/config/server.properties 21 broker.id=1 #设置每个代理全局唯一的整数ID 31 listeners=PLAINTEXT://172.18.135.1:9092 #指定kafka监听的本机地址 60 log.dirs=/usr/local/kafka/logs #指定kafka保存日志的位置 65 num.partitions=1 #kafka分区，一个数据仅保留一个分区 103 log.retention.hours=72 #保留指定小时的日志内容 123 zookeeper.connect=172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 #所有的zookeeper地址，让zookeeper注册在kafka中 创建日志存放的目录 ~]# mkdir -p /usr/local/kafka/logs 172.18.135.2 ~]# vim /usr/local/kafka/config/server.properties 21 broker.id=2 31 listeners=PLAINTEXT://172.18.135.2:9092 60 log.dirs=/usr/local/kafka/logs 65 num.partitions=1 103 log.retention.hours=72 123 zookeeper.connect=172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 创建日志存放的目录 ~]# mkdir -p /usr/local/kafka/logs 172.18.135.5 ~]# vim /usr/local/kafka/config/server.properties 21 broker.id=3 31 listeners=PLAINTEXT://172.18.135.5:9092 60 log.dirs=/usr/local/kafka/logs 65 num.partitions=1 103 log.retention.hours=72 123 zookeeper.connect=172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 创建日志存放的目录 ~]# mkdir -p /usr/local/kafka/logs 2：各主机启动kafka1234~]# /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties #以守护进程的方式启动~]# ss -tnl::ffff:172.18.135.2:9092 #kafka监听端口 将zookeeper和kafka加入开机启动项中将各主机的kafka和zookeeper程序设置为开机自启123456~]# vim /etc/rc.d/rc.local /usr/local/zookeeper/bin/zkServer.sh startsleep 20/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties~]# chmod +x /etc/rc.d/rc.local zookeeper命令测试1：验证kafka进程12345~]# jps26450 Jps1079 Elasticsearch10905 QuorumPeerMain19790 Kafka 2：测试zookeeper创建topic：创建名为logstashtest，partitions(分区)为3，replication(复制)为3的topic(主题)：在任意kafaka服务器操作：12~]# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 --partitions 3 --replication-factor 3 --topic logstashtestCreated topic "logstashtest". 3：测试zookeeper获取topic可以在任意一台kafka服务器进行测试：12345~]# /usr/local/kafka/bin/kafka-topics.sh --describe --zookeeper 172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 --topic logstashtestTopic:logstashtest PartitionCount:3 ReplicationFactor:3 Configs: Topic: logstashtest Partition: 0 Leader: 1 Replicas: 1,3,2 Isr: 1,2,3 Topic: logstashtest Partition: 1 Leader: 2 Replicas: 2,1,3 Isr: 2,1,3 Topic: logstashtest Partition: 2 Leader: 3 Replicas: 3,2,1 Isr: 3,2,1 状态说明：logstashtest有三个分区分别为0、1、2，分区0的leader是3（broker.id），分区0有三个副本，并且状态都为lsr（ln-sync，表示可以参加选举成为leader）。 4：获取所有topic12~]# /usr/local/kafka/bin/kafka-topics.sh --list --zookeeper 172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181logstashtest 5：删除topic1~]#/usr/local/kafka/bin/kafka-topics.sh --delete --zookeeper 172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 --topic logstashtest kafka命令测试消息发送1：创建topic12~]# /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper 172.18.135.1:2181,172.18.135.2:2181,172.18.135.5:2181 --partitions 3 --replication-factor 3 --topic messagetestCreated topic "messagetest". 2：发送消息1~]# /usr/local/kafka/bin/kafka-console-producer.sh --broker-list 172.18.135.1:9092,172.18.135.2:9092,172.18.135.3:9092 --topic messagetest 使用logstash测试向kafka写入数据 测试使用logstash测试向kafka写入数据logstash收集日志标准输出至kafka参考官方文档:https://www.elastic.co/guide/en/logstash/5.6/plugins-outputs-kafka.html 1：编辑logstash配置文件12345678910111213141516~]# vim /etc/logstash/conf.d/logstash-kafka.shinput &#123; #标准输入为收集桌面信息 stdin &#123;&#125;&#125;output &#123; #logstash收集日志写入kafka中 kafka &#123; codec =&gt; json topic_id =&gt; "messagetest" #指定写入的topic，如果指定的topic在kafka集群中不存在，则kafka自动创建此topic bootstrap_servers =&gt; "172.18.135.1:9092" #指定集群中任意kafka的地址 batch_size =&gt; 5 &#125; stdout &#123; #logstash收集的日志再在终端中打印一份 codec =&gt; rubydebug &#125;&#125; 2：检查logstash配置文件的语法格式并启动123456~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash-kafka.sh -tWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the consoleConfiguration OK~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash-kafka.sh 3：验证kafka收到logstash数据 3.1：logstash启动，标准输入为桌面12345678910111213141516171819~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash-kafka.sh[INFO ] 2019-03-02 18:44:19.332 [[main]-pipeline-manager] AppInfoParser - Kafka version : 0.10.0.1[INFO ] 2019-03-02 18:44:19.333 [[main]-pipeline-manager] AppInfoParser - Kafka commitId : a7a17cdec9eaa6c5The stdin plugin is now waiting for input:haha&#123; "@version" =&gt; "1", "host" =&gt; "es3.com", "@timestamp" =&gt; 2019-03-02T10:45:27.185Z, "message" =&gt; "haha"&#125;logstash&#123; "@version" =&gt; "1", "host" =&gt; "es3.com", "@timestamp" =&gt; 2019-03-02T10:49:07.782Z, "message" =&gt; "logstash"&#125; 3.2：kafka集群也监听的messagetest topic1234~]# /usr/local/kafka/bin/kafka-console-consumer.sh --topic messagetest --bootstrap-server 172.18.135.1:9092 --from-beginninghaha&#123;"@version":"1","host":"es3.com","@timestamp":"2019-03-02T10:45:27.185Z","message":"haha"&#125;&#123;"@version":"1","host":"es3.com","@timestamp":"2019-03-02T10:49:07.782Z","message":"logstash"&#125; 后端logstash收集单个Nginx日志文件缓存到zk和KF集群，ZK和KF集群上的logstash再取走存储到ES中1：编辑Logstash配置文件，收集nginx日志的logstash，再将收集的日志文件存储到ZK和KF集群中123456789101112131415161718192021222324~]# vim /etc/logstash/conf.d/nginx-kafka.conf input &#123; file &#123; path =&gt; "/var/log/nginx/access.log" start_position =&gt; "beginning" type =&gt; "nginx-accesslog-1512" codec =&gt; "json" #声明json编码格式 &#125;&#125;output &#123; if [type] == "nginx-accesslog-1512" &#123; kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" #任意kafka集群中服务器地址 topic_id =&gt; "nginx-accesslog-1512" #日志保存在KF中的topic主题名称 codec =&gt; "json" #指定日志编码格式 &#125; file &#123; path =&gt; "/tmp/nginx-jsog-log.txt" #将日志保存在本地文件中一份 &#125; &#125;&#125; 2：测试logstash配置文件语法格式，并启动logstash12345~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx-kafka.conf -tWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the consoleConfiguration OK~]# systemctl restart logstash 3:访问Nginx Web界面1~]# ab -n100 -c10 http://nginx地址/index.html 4：验证日志写入到/tmp 文件1~]# head /tmp/nginx-jsog-log.txt 5：配置logstash从kafka读取日志（logstash可以安装在ZK和KF集群中的任何一台主机上都可以）12345678910111213141516171819~]# vim /etc/logstash/conf.d/nginx-kafka.conf input &#123; #标准输入从KAFKA输入 kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" #任意kafka集群中服务器地址 topics =&gt; "nginx-accesslog-1512" #logstash从KF中取走topic的主题名称 codec =&gt; "json" consumer_threads =&gt; 1 #decorate_events =&gt; true &#125;&#125;output &#123; #输出至后端的ES中 if [type] == "nginx-accesslog-1512" &#123; elasticsearch &#123; hosts =&gt; ["ES主机地址:9200"] index =&gt; "nginx-accesslog-kafka-1512-%&#123;+YYYY.MM.dd&#125;" #指定索引格式 &#125;&#125;&#125; 6：测试语法并重启logstash12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-es.conf -t~]# systemctl restart logstash 7：在ES主机上head插件验证数据 8：kibana添加Nginx访问日志索引 9：kibana验证数据 使用logstash收集多日志文件并写入kafka：1：配置logstash收集message日志123456789101112131415161718192021222324252627282930313233343536 ~]# chmod 644 /var/log/messages conf.d]# cat nginx-kafka.conf input &#123; file &#123; path =&gt; "/var/log/nginx/access.log" start_position =&gt; "beginning" type =&gt; "nginx-accesslog-1512" codec =&gt; "json" &#125; file &#123; path =&gt; "/var/log/messages" start_position =&gt; "beginning" type =&gt; "system-log-1512" &#125;&#125;output &#123; if [type] == "nginx-accesslog-1512" &#123; kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" topic_id =&gt; "nginx-accesslog-1512" batch_size =&gt; 5 codec =&gt; "json" &#125; &#125; if [type] == "system-log-1512" &#123; kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" topic_id =&gt; "system-log-1512" batch_size =&gt; 5 codec =&gt; "json" #写入的时候使用json编码，因为logstash收集后会转换成json格式 &#125; file &#123; path =&gt; "/tmp/systemlog-1512-log.txt" &#125;&#125;&#125; 2：测试并重启logstash12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginx-kafka.conf -t~]# systemctl restart logstash 3：验证logstash启动完成 4：验证日志写入到目标文件 5：配置logstash从kafka读取系统日志123456789101112131415161718192021222324252627282930313233343536373839#此步骤如果没有从kafka正确收集日志或者将日志从kafka读取并写入到文件没有输出，可以使用/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-es.conf 进行标准输出测试。~]# cat /etc/logstash/conf.d/kafka-es.conf input &#123; kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" topics =&gt; "nginx-accesslog-1512" codec =&gt; "json" consumer_threads =&gt; 1 decorate_events =&gt; true &#125; kafka &#123; bootstrap_servers =&gt; "192.168.15.11:9092" topics =&gt; "system-log-1512" consumer_threads =&gt; 1 decorate_events =&gt; true codec =&gt; "json" &#125;&#125;output &#123; if [type] == "nginx-accesslog-1512" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "nginx-accesslog-1512-%&#123;+YYYY.MM.dd&#125;" &#125;&#125; if [type] == "system-log-1512" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.12:9200"] index =&gt; "system-log-1512-%&#123;+YYYY.MM.dd&#125;" &#125; stdout &#123; codec =&gt; "rubydebug" &#125; &#125;&#125; 6：验证配置并启动logstash12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-es.conf –t~]# systemctl start logstash 7：在head插件验证数据 8：在kibana添加索引 9：kibana验证数据 补充： 也可以将logstash开启两个进程去同时收集日志 /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-es.conf #systemcd 管理的进程去收集日志 /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/kafka-es.conf &amp; # 手动管理的进程去收集日志]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集日志并写入redis]]></title>
    <url>%2F2019%2F02%2F22%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97%E5%B9%B6%E5%86%99%E5%85%A5redis%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集日志并写入redis logstash收集日志并写入redis： 用一台服务器按照部署redis服务，专门用于日志缓存使用，用于web服务器产生大量日志的场景，例如下面的服务器内存即将被使用完毕，查看是因为redis服务保存了大量的数据没有被读取而占用了大量的内存空间。 Redis output plugin 官网解释：https://www.elastic.co/guide/en/logstash/current/plugins-outputs-redis.html 1：部署redis1~]# yum install redis -y 2：设置redis持久化及访问密码：12345678为安全考虑，生产环境必须设置reids连接密码：[root@linux-host2 redis]# redis-cli127.0.0.1:6379&gt; config set requirepass 12345678 #动态设置，重启后无效OK202~204 注释掉不需要做快照，改为 save "" #logstash从redis中将日志数据取走，数据则从redis消失，所以不做快照480 requirepass 123456 #redis.conf配置文件 3:启动并测试redis服务：1234redis]# redis-server /usr/local/redis/redis.conf #启动服务redis]# redis-cli 127.0.0.1:6379&gt; pingPONG 4：配置logstash服务器将日志写入至redis：将tomcat服务器的logstash收集之后的tomcat 访问日志写入到redis服务器，然后通过另外的logstash将redis服务器的数据取出在写入到elasticsearch服务器。 官方文档：https://www.elastic.co/guide/en/logstash/current/plugins-outputs-redis.html 1234567891011121314151617181920212223242526272829303132333435~]# cat /etc/logstash/conf.d/tomcat_tcp.confinput &#123; file &#123; path =&gt; "/usr/local/tomcat/logs/tomcat_access_log.*.log" type =&gt; "tomcat-accesslog-1512" start_position =&gt; "beginning" stat_interval =&gt; "2" &#125; tcp &#123; port =&gt; 7800 mode =&gt; "server" type =&gt; "tcplog-1512" &#125;&#125;output &#123; if [type] == "tomcat-accesslog-1512" &#123; redis &#123; data_type =&gt; "list" #以列表的方式写入 key =&gt; "tomcat-accesslog-1512" #日志写入redis的key名称 host =&gt; "192.168.15.12" #指定redis服务器地址 port =&gt; "6379" db =&gt; "0" #指定写入的库 password =&gt; "123456" #redis密码 &#125;&#125; if [type] == "tcplog-1512" &#123; redis &#123; data_type =&gt; "list" key =&gt; "tcplog-1512" host =&gt; "192.168.15.12" port =&gt; "6379" db =&gt; "1" password =&gt; "123456"&#125;&#125;&#125; 5：测试logstash配置文件语法是否正确1~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tomcat.conf 6:访问tomcat的web界面并生成系统日志1~]# echo "伪设备1" &gt; /dev/tcp/192.168.15.12/7800 7:验证redis是否有数据 8: 配置Redis主机上的logstash服务器从redis读取数据：配置专门logstash服务器从redis读取指定的key的数据，并写入到elasticsearch。123456789101112131415161718192021222324252627282930313233343536[root@linux-host3 ~]# cat /etc/logstash/conf.d/redis-to-els.conf [root@linux-host1 conf.d]# cat /etc/logstash/conf.d/redis-tomcat-es.confinput &#123; redis &#123; data_type =&gt; "list" key =&gt; "tomcat-accesslog-1512" host =&gt; "192.168.15.12" port =&gt; "6379" db =&gt; "0" password =&gt; "123456" codec =&gt; "json" #指定取出的日志格式 &#125; redis &#123; data_type =&gt; "list" key =&gt; "tcplog-1512" host =&gt; "192.168.15.12" port =&gt; "6379" db =&gt; "1" password =&gt; "123456" &#125;&#125;output &#123; if [type] == "tomcat-accesslog-1512" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "logstash-tomcat1512-accesslog-%&#123;+YYYY.MM.dd&#125;"&#125;&#125; if [type] == "tcplog-1512" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "logstash-tcplog1512-%&#123;+YYYY.MM.dd&#125;"&#125;&#125;&#125; 9：测试logstash及启动1conf.d]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/redis-to-els.conf 10：验证redis的数据是否被取出 11：在head插件验证数据 12：kibana添加tomcat访问日志索引 13：kibana添加tcp日志索引 14：kibana验证tomcat访问日志 15：kibana 验证tcp日志]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集rsyslog中记录的haproxy服务的日志]]></title>
    <url>%2F2019%2F02%2F21%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86rsyslog%E4%B8%AD%E8%AE%B0%E5%BD%95%E7%9A%84haproxy%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集rsyslog中记录的haproxy服务的日志 通过rsyslog收集haproxy日志： logstash和rsyslog可以不在同一台主机 ES和kibana也可以不在同一台主机运行 在centos 6及之前的版本叫做syslog，centos 7开始叫做rsyslog，根据官方的介绍，rsyslog(2013年版本)可以达到每秒转发百万条日志的级别，官方网址：http://www.rsyslog.com/，确认系统安装的版本命令如下： 1：安装rsyslog和haproxy1234567安装haproxy ~]# yum install haproxy -y安装rsyslog ~]# yum install rsyslog -y 2：编辑rsyslog服务配置文件，打开rsyslog服务用来保存haproxy的日志12345678910111213141516171819202122编辑rsyslog配置文件 ~]# vim /etc/rsyslog.conf 15 $ModLoad imudp 16 $UDPServerRun 514 19 $ModLoad imtcp 20 $InputTCPServerRun 514 74 local2.* /var/log/haproxy.log #自定义日志级别，将此日志级别的日志存放在本机的此文件中 75 local2.* @@本机地址:1514 #端口自定义不和其他服务冲突即可 #也将此日志的级别存放在本主机上，定义监听的端口为1514（使用本机的logstash主机监听此地址）#最后面一行添加，local2对应haproxy配置文件定义的local级别查看haproxy配置文件 #20~26行默认的配置文件解释：如果要设置将haproxy的日志记录在本机rsyslog服务器中就要在rsyslog配置文件中添加local2.* /var/log/haproxy.log # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 3：重新启动haproxy和rsyslog服务1234~]# systemctl start rsyslog~]# systemctl enable rsyslog~]# systemctl start haproxy~]# systemctl enable haproxy 测试标准输出至屏幕4：配置本机的logstash来监听此端口的日志—&gt;测试标准输出至屏幕123456789101112131415161718192021222324252627编辑配置文件 ~]# vim /etc/logstash/conf.d/rsyslog.conf input&#123; syslog &#123; type =&gt; "ststem-rsyslog" port =&gt; "1514" &#125;&#125; output&#123; stdout&#123; codec =&gt; rubydebug &#125;&#125;检测配置文件启动logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/rsyslog.conf -t ~]# systemctl restart logstash查看logstash收集rsyslogs日志的端口（rsyslog使用本机定义的端口，将haproxy的日志发送到本机logstash上做收集） ~]# ss -tnl :::1514 logstash监听（定义的rsyslog使用此端口将haproxy日志发送给本机的logstash中做收集） *:514 rsyslog端口 UDP协议 *:5000 haproxy端口 5：开启haproxy的状态页面 1234567891011121314151617~]# vim /etc/haproxy/haproxy.cfg 最后面定义list listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys重启haproxy ~]# systemctl restart haproxy ~]# ss -tnl 9999 #自定义haproxy开启的状态页监听端口 5000 6：客户端web界面访问haproxy状态页面 7:查看本机的命令行页面查看本机的logstash是否收集到rsyslog收集的haproxy日志 将logstash收集的rsyslog的日志输出至远端的ES集群中存储8：编辑logstash配置文件12345678910111213141516~]# vim /etc/logstash/conf.d/haproxy.conf input&#123; syslog &#123; type =&gt; "ststem-rsyslog" port =&gt; "1514"&#125;&#125;output&#123; if [type] == "syslog" &#123; elasticsearch &#123; hosts =&gt; "172.18.135.1:9200" #ES主机地址 index =&gt; "rsyslog-7-103-%&#123;+YYYY.MM&#125;"&#125;&#125;&#125; 9：检测logstash配置文件及启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/haproxy.conf -t~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/haproxy.conf 10：客户端web界面访问haproxy状态页面 11：head插件web界面访问haproxy以生成新日志： 12：kibana界面添加索引 13：kibana验证数据 OUTPUT输出中index查看支持的输出的索引的格式时间格式官方文档：https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-index https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集TCP和UDP日志]]></title>
    <url>%2F2019%2F02%2F21%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86TCP%E5%92%8CUDP%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集TCP和UDP日志 Logstash收集TCP和UDP日志 通过logstash的tcp/udp插件收集日志，通常用于在向elasticsearch日志补录丢失的部分日志，可以将丢失的日志写到一个文件，然后通过TCP日志收集方式直接发送给logstash然后再写入到elasticsearch服务器。 官方介绍：https://www.elastic.co/guide/en/logstash/5.6/input-plugins.html Logstash配置文件解释1234567891011121314151617logstash配置文件，先进行收集测试：[root@linux-host6 ~]# cat /etc/logstash/conf.d/tcp.conf input &#123; tcp &#123; #指定收集tcp的日志 port =&gt; 9889 host =&gt; "0.0.0.0" #指定监听的本机地址，如果不指定默认时0.0.0.0监听本机的所有可用的地址 type =&gt; "tcplog" #指定类型 mode =&gt; "server" #是定server或者client ，如果不指定默认的为server codec =&gt; json &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 标准输出测试（测试基于tcp收集日志，是否可以收到日志）1:logstash收集本机的tcp链接的日志文件，编辑logstash配置文件12345678910111213141516~]# cat /etc/logstash/conf.d/tcp.conf input &#123; tcp &#123; port =&gt; 12345 type =&gt; "tcplog" mode =&gt; "server" codec =&gt; json &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug &#125;&#125; 2：测试logstash配置文件并启动123456789101112测试配置文件语法 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcplog.cof -t前台启动logstash测试是否可以接收到tcp日志 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcplog.cof验证端口是否启动 ~]# ss -tnl :::12345 3：其他主机测试：在其他服务器安装nc命令：NetCat简称nc，在网络工具中有“瑞士军刀”美誉，其功能实用，是一个简单、可靠的网络工具，可通过TCP或UDP协议传输读写数据，另外还具有很多其他功能。1234567安装测试工具 ~]# yum instll nc –y发送tcp消息到logstash主机 ~]# echo "nc test" | nc 172.20.101.221(logstash主机地址) 12345 4：查看logstash主机是否接收到日志消息1234567891011121314~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcplog.cofWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console&#123; "@timestamp" =&gt; 2019-02-21T03:34:35.041Z, "port" =&gt; 43030, "@version" =&gt; "1", "host" =&gt; "172.20.0.1", "message" =&gt; "nc test", "type" =&gt; "tcplog", "tags" =&gt; [ [0] "_jsonparsefailure" ]&#125; 5:其他主机测试：通过nc命令发送一个文件12通过nc命令发送一个文件： ~]# nc 172.20.101.221 12345 &lt; /etc/passwd 6：logstash主机查看验证数据 7：其他主机测试：通过伪设备的方式发送消息：在类Unix操作系统中，块设备有硬盘、内存的硬件，但是还有设备节点并不一定要对应物理设备，我们把没有这种对应关系的设备是伪设备，比如/dev/null，/dev/zero，/dev/random以及/dev/tcp和/dev/upd等，Linux操作系统使用这些伪设备提供了多种不通的功能，tcp通信只是dev下面众多伪设备当中的一种设备。1~]# echo "伪设备" &gt; /dev/tcp/172.20.101.221/12345 8：logstash主机查看验证数据 Lgstash收集本机TCP日志将输出改为elasticsearch1：logstash收集本机的tcp链接的日志文件，编辑logstash配置文件12345678910111213141516171819 ~]# vim /etc/logstash/conf.d/tcplog.cof input &#123; tcp &#123; port =&gt; 12345 type =&gt; "tcplog" mode =&gt; "server" host =&gt; "0.0.0.0" codec =&gt; json &#125;&#125;output &#123; if [type] == "tcplog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] index =&gt; "logstash-tcplog-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;&#125; 2：测试logstash配置文件语法并启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tcplog.cof -t~]# systemctl restart logstash 3；通过nc命令或伪设备输入日志1~]# nc 172.20.101.221 12345 &lt; /etc/passwd 4：在kibana界面添加索引 5：kibana验证数据]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集Nginx日志]]></title>
    <url>%2F2019%2F02%2F20%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86Nginx%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集Nginx日志 收集nginx访问日志 1.安装nginx1234567891011121314编译安装 src]# pwd /usr/share/src src]# ls nginx-1.2.9.tar.gz src]# tar xzvf nginx-1.2.9.tar.gz nginx-1.2.9]# pwd /usr/share/src/nginx-1.2.9指定安装位置并编译安装 nginx-1.2.9]# ./configure --prefix=/usr/share/nginx &amp;&amp; make &amp;&amp; make install 2：修改nginx日志格式(将输出的日志格式修改为json格式的日志格式)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869~]# cat /usr/share/nginx/conf/nginx.conf#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; #注意定义的日志的位置log_format access_json '&#123;"@timestamp":"$time_iso8601",' #定义日志的格式 '"host":"$server_addr",' '"clientip":"$remote_addr",' '"size":$body_bytes_sent,' '"responsetime":$request_time,' '"upstreamtime":"$upstream_response_time",' '"upstreamhost":"$upstream_addr",' '"http_host":"$host",' '"url":"$uri",' '"domain":"$host",' '"xff":"$http_x_forwarded_for",' '"referer":"$http_referer",' '"status":"$status"&#125;'; access_log /var/log/nginx/access.log access_json; #调用此日志格式 sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125;创建对应的保存日志的目录 ~]# mkdir /var/log/nginx 3：启动nginx并访问默认页面查看日志格式123456789101112131415启动nginx ~]# /usr/share/nginx/sbin/nginx -t nginx: the configuration file /usr/share/nginx/conf/nginx.conf syntax is ok nginx: configuration file /usr/share/nginx/conf/nginx.conf test is successful ~]# /usr/share/nginx/sbin/nginx访问默认页面 ~]# curl 172.20.101.221:80查看日志格式 ~]# cat /var/log/nginx/access.log &#123;"@timestamp":"2019-02-21T10:44:15+08:00","host":"192.168.35.103","clientip":"172.20.101.221","size":612,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"172.20.101.221","url":"/index.html","domain":"172.20.101.221","xff":"-","referer":"-","status":"200"&#125; 4：配置本机上的logstash收集本机的nginx日志123456789101112131415161718~]# vim /etc/logstash/conf.d/nginxlog.confinput &#123; file &#123; path =&gt; "/var/log/nginx/access.log" start_position =&gt; "end" type =&gt; "nginx-accesslog" codec =&gt; json &#125;&#125;output &#123; if [type] == "nginx-accesslog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] index =&gt; "logstash-nginx-accesslog-1516-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;&#125; 5：logstash进行配置文件语法检测及重启服务123~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/nginxlog.conf -t~]# systemctl restart logstash 6：kibana界面添加索引 7：kibana界面验证数据]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集本机ES服务json类型日志]]></title>
    <url>%2F2019%2F02%2F20%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86%E6%9C%AC%E6%9C%BAES%E6%9C%8D%E5%8A%A1json%E7%B1%BB%E5%9E%8B%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集本机ES服务json类型日志 收集java日志： java日志的格式长度不统一，有的条日志很短而有的一条记录很长好几行 使用codec的multiline插件实现多行匹配，这是一个可以将多行进行合并的插件，而且可以使用what指定将匹配到的行与前面的行合并还是和后面的行合并 multiline（匹配多行输入官方解释）：https://www.elastic.co/guide/en/logstash/current/plugins-codecs-multiline.html 这里演示收集ES机器上的日志(ES程序的运行是要求部署JAVA环境的，射门生成的日志格式也是java格式类型,但是日志格式的开头都是以[开头)1: ES主机上安装收集日志的logstash程序123~]# lslogstash-5.6.13.rpm ~]# rpm -ivh logstash-5.6.13.rpm 收集ES日志语法测试2：配置ES主机上用来收集日志的logstash程序的配置文件解释123456789101112131415~]# cat /etc/logstash/conf.d/java.confinput &#123; stdin &#123; codec =&gt; multiline &#123; pattern =&gt; "^\[" #当遇到[开头的行时候将多行进行合并 negate =&gt; true #true为匹配成功进行操作，false为不成功进行操作 what =&gt; "previous" #与上面的行合并，如果是下面的行合并就是next &#125;&#125;&#125;filter &#123; #日志过滤，如果所有的日志都过滤就写这里，如果只针对某一个过滤就写在input里面的日志输入里面&#125;output &#123; stdout &#123; codec =&gt; rubydebug&#125;&#125; 配置文件1234567891011121314151617~]# cat /etc/logstash/conf.d/es.conf input &#123; stdin &#123; codec =&gt; multiline &#123; pattern =&gt; "^\[" negate =&gt; true what =&gt; "previous" &#125;&#125;&#125;filter &#123; &#125;output &#123; stdout &#123; codec =&gt; rubydebug&#125;&#125; 2：检测配置文件的语法格式并启动12~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/es.conf -t~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/es.conf 3：日志输入输出测试1234567891011121314151617181920212223242526272829~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/es.conf WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaultsCould not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the consoleThe stdin plugin is now waiting for input:111111224324324324324234234[v1&#123; "@version" =&gt; "1", "host" =&gt; "es1.com", "@timestamp" =&gt; 2019-02-20T12:54:38.873Z, "message" =&gt; "1111\n1122432\n4324324324\n234234", "tags" =&gt; [ [0] "multiline" ]&#125;[123&#123; "@version" =&gt; "1", "host" =&gt; "es1.com", "@timestamp" =&gt; 2019-02-20T12:54:42.617Z, "message" =&gt; "[v1"&#125; 搜集ES日志实战1：logstash配置文件标准输出至文件中 1234567891011121314151617181920212223[root@linux-host1 ~]# vim /etc/logstash/conf.d/java.confinput &#123; file &#123; path =&gt; "/data/eslogs/ES.log" type =&gt; "javalog" start_position =&gt; "beginning" codec =&gt; multiline &#123; pattern =&gt; "^\[" negate =&gt; true what =&gt; "previous" &#125;&#125;&#125;output &#123; if [type] == "javalog" &#123; stdout &#123; codec =&gt; rubydebug &#125; file &#123; path =&gt; "/tmp/m.txt" &#125;&#125;&#125; 2:语法验证：1[root@linux-host1 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/java.conf -t 3：将输出改为elasticsearch和本地的一个文件中：123456789101112131415161718192021222324252627更改后的内容如下：[root@linux-host1 ~]# cat /etc/logstash/conf.d/java.conf input &#123; file &#123; path =&gt; "/data/eslogs/ES.log" type =&gt; "javalog" start_position =&gt; "beginning" codec =&gt; multiline &#123; pattern =&gt; "^\[" negate =&gt; true what =&gt; "previous" &#125;&#125;&#125;output &#123; if [type] == "javalog" &#123; file &#123; path =&gt; "/tmp/java.txt" &#125; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "javalog-1511-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;&#125;[root@linux-host1 ~]# systemctl restart logstash 4:然后重启一下elasticsearch服务，目前是为了生成新的日志，以验证logstash能否自动收集新生成的日志。1[root@linux-host1 ~]# systemctl restart elasticsearch 5：kibana界面添加javalog-1511索引： 6：模拟生成数据查看kibana界面查看数据： 7：关于sincedb：12[root@linux-host1~]# cat /var/lib/logstash/plugins/inputs/file/.sincedb_1ced15cfacdbb0380466be84d620085a134219868 0 2064 29465 #记录了收集文件的inode信息]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之存储引擎和服务器配置]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E4%B9%8B%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysql之存储引擎和服务器配置 存储引擎：如何去管理数据库的数据文件 1234567891011121314151617查看当前数据库的存储引擎MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+10 rows in set (0.00 sec) 存储引擎MyISAM引擎特点：不支持事务表级锁定读写相互阻塞，写入不能读，读时不能写只缓存索引不支持外键约束不支持聚簇索引读取数据较快，占用资源较少不支持MVCC（多版本并发控制机制）高并发崩溃恢复性较差MySQL5.5.5前默认的数据库引擎 MyISAM存储引擎适用场景&ensp;&ensp;只读（或者写较少）、表较小（可以接受长时间进行修复操作）&ensp;&ensp;MyISAM引擎文件&ensp;&ensp;tbl_name.frm 表格式定义&ensp;&ensp;tbl_name.MYD 数据文件&ensp;&ensp;tbl_name.MYI 索引文件 InnoDB引擎特点行级锁支持事务，适合处理大量短期事务读写阻塞与事务隔离级别相关可缓存数据和索引支持聚簇索引崩溃恢复性更好支持MVCC高并发从MySQL5.5后支持全文索引从MySQL5.5.5开始为默认的数据库引擎 InnoDB数据库文件所有InnoDB表的数据和索引放置于同一个表空间中&ensp;&ensp;表空间文件：datadir定义的目录下&ensp;&ensp;数据文件：ibddata1, ibddata2, …每个表单独使用一个表空间存储表的数据和索引&ensp;&ensp;启用：innodb_file_per_table=ON&ensp;&ensp;参看：https://mariadb.com/kb/en/library/xtradbinnodb-serversystem-variables/#innodb_file_per_table ON (&gt;= MariaDB 5.5)两类文件放在数据库独立目录中&ensp;&ensp;数据文件(存储数据和索引)：tb_name.ibd&ensp;&ensp;表格式定义：tb_name.frm 1234567如果想让老版本的数据库创建的库以及表支持innodb搜索引擎需要编辑配置文件中添加[root@centos7 ~]# vim /etc/my.cnf[mysqld]default-storage-engine=innodb删除hellodb这个数据库mysql -e 'drop database hellodb' 其它存储引擎Performance_Schema：Performance_Schema数据库使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798MariaDB [(none)]&gt; use information_schemaReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [information_schema]&gt; show tables;(这些表都是基于此搜索引擎的)+---------------------------------------+| Tables_in_information_schema |+---------------------------------------+| CHARACTER_SETS || CLIENT_STATISTICS || COLLATIONS || COLLATION_CHARACTER_SET_APPLICABILITY || COLUMNS || COLUMN_PRIVILEGES || ENGINES || EVENTS || FILES || GLOBAL_STATUS || GLOBAL_VARIABLES || INDEX_STATISTICS || KEY_CACHES || KEY_COLUMN_USAGE || PARAMETERS || PARTITIONS || PLUGINS || PROCESSLIST || PROFILING || REFERENTIAL_CONSTRAINTS || ROUTINES || SCHEMATA || SCHEMA_PRIVILEGES || SESSION_STATUS || SESSION_VARIABLES || STATISTICS || TABLES || TABLESPACES || TABLE_CONSTRAINTS || TABLE_PRIVILEGES || TABLE_STATISTICS || TRIGGERS || USER_PRIVILEGES || USER_STATISTICS || VIEWS || INNODB_CMPMEM_RESET || INNODB_RSEG || INNODB_UNDO_LOGS || INNODB_CMPMEM || INNODB_SYS_TABLESTATS || INNODB_LOCK_WAITS || INNODB_INDEX_STATS || INNODB_CMP || INNODB_CMP_RESET || INNODB_CHANGED_PAGES || INNODB_BUFFER_POOL_PAGES || INNODB_TRX || INNODB_BUFFER_POOL_PAGES_INDEX || INNODB_LOCKS || INNODB_BUFFER_POOL_PAGES_BLOB || INNODB_SYS_TABLES || INNODB_SYS_FIELDS || INNODB_SYS_COLUMNS || INNODB_SYS_STATS || INNODB_SYS_FOREIGN || INNODB_SYS_INDEXES || XTRADB_ADMIN_COMMAND || INNODB_TABLE_STATS || INNODB_SYS_FOREIGN_COLS || INNODB_BUFFER_PAGE_LRU || INNODB_BUFFER_POOL_STATS || INNODB_BUFFER_PAGE |+---------------------------------------+62 rows in set (0.00 sec)MariaDB [information_schema]&gt; show table status from performance_schema;+----------------------------------------------+--------------------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+-------------+-------------+------------+-----------------+----------+----------------+---------+| Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment |+----------------------------------------------+--------------------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+-------------+-------------+------------+-----------------+----------+----------------+---------+| cond_instances | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_current | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_history | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_history_long | PERFORMANCE_SCHEMA | 10 | Dynamic | 10000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_summary_by_instance | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_summary_by_thread_by_event_name | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || events_waits_summary_global_by_event_name | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || file_instances | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || file_summary_by_event_name | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || file_summary_by_instance | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || mutex_instances | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || performance_timers | PERFORMANCE_SCHEMA | 10 | Fixed | 5 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || rwlock_instances | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || setup_consumers | PERFORMANCE_SCHEMA | 10 | Dynamic | 8 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || setup_instruments | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || setup_timers | PERFORMANCE_SCHEMA | 10 | Dynamic | 1 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | || threads | PERFORMANCE_SCHEMA | 10 | Dynamic | 1000 | 0 | 0 | 0 | 0 | 0 | NULL | NULL | NULL | NULL | utf8_general_ci | NULL | | |+----------------------------------------------+--------------------+---------+------------+-------+----------------+-------------+-----------------+--------------+-----------+----------------+-------------+-------------+------------+-----------------+----------+----------------+---------+17 rows in set (0.00 sec)该数据库是存储性能相关 Memory ：将所有数据存储在RAM（内存）中，以便在需要快速查找参考和其他类似 数据的环境中进行快速访问。适用存放临时数据。引擎以前被称为HEAP引擎 MRG_MyISAM：使MySQL DBA或开发人员能够对一系列相同的 MyISAM表 进行逻辑分组，并将它们作为一个对象引用。适用于VLDB(Very Large Data Base)环境，如数据仓库 Archive ：为存储和检索大量很少参考的存档或安全审核信息，只支持 SELECT和INSERT操作；支持行级锁和专用缓存区 Federated联合：用于访问其它远程MySQL服务器一个代理，它通过创建一 个到远程MySQL服务器的客户端连接，并将查询传输到远程服务器执行，而 后完成数据存取，提供链接单独MySQL服务器的能力，以便从多个物理服务 器创建一个逻辑数据库。非常适合分布式或数据集市环境 BDB：可替代InnoDB的事务引擎，支持COMMIT、ROLLBACK和其他事务特性Cluster/NDB：MySQL的簇式数据库引擎，尤其适合于具有高性能查找要求的 应用程序，这类查找需求还要求具有最高的正常工作时间和可用性 CSV：CSV存储引擎使用逗号分隔值格式将数据存储在文本文件中。可以使用 CSV引擎以CSV格式导入和导出其他软件和应用程序之间的数据交换 BLACKHOLE ：黑洞存储引擎接受但不存储数据，检索总是返回一个空集。该功 能可用于分布式数据库设计，数据自动复制，但不是本地存储 example：“stub”引擎，它什么都不做。可以使用此引擎创建表，但不能将数 据存储在其中或从中检索。目的是作为例子来说明如何开始编写新的存储引擎 MariaDB支持的其它存储引擎：OQGraphSphinxSETokuDBCassandraCONNECTSQUENCE 查看mysql支持的存储引擎show engines;查看当前默认的存储引擎show variables like ‘%storage_engine%’;设置默认的存储引擎vim /etc/my.conf [mysqld]default_storage_engine= InnoDB查看库中所有表使用的存储引擎show table status from db_name;查看库中指定表的存储引擎show table status like ‘ tb_name ‘;show create table tb_name;设置表的存储引擎：CREATE TABLE tb_name(… ) ENGINE=InnoDB;ALTER TABLE tb_name ENGINE=InnoDB; MySQL中的系统数据库mysql数据库是mysql的核心数据库，类似于Sql Server中的master库，主要负责存储数据 库的用户、权限设置、关键字等mysql自己需要使用的控制和管理信息performance_schema数据库MySQL 5.5开始新增的数据库，主要用于收集数据库服务器性能参数,库里表的 存储引擎均为PERFORMANCE_SCHEMA，用户不能创建存储引擎为 PERFORMANCE_SCHEMA的表information_schema数据库MySQL 5.0之后产生的，一个虚拟数据库，物理上并不存在 information_schema数据库类似与“数据字典”，提供了访问数据库元数据的 方式，即数据的数据。比如数据库名或表名，列类型，访问权限（更加细化的 访问方式） 服务器配置mysqld选项cmd-line和option file(可以写在配置文件中即服务器选项) 服务器系统变量 system var（服务器在内存中存放的状态，登陆服务器之后，show variables like &#39;变量名&#39; 可以看到的） 服务器状态变量 status var（只读性的变量，当前数据库的状态）&ensp;&ensp;https://dev.mysql.com/doc/refman/5.7/en/mysqld-optiontables.html&ensp;&ensp;https://mariadb. com/kb/en/library/full-list-of-mariadb-optionssystem-and-status-variables/注意：其中有些参数支持运行时修改，会立即生效；有些参数不支持，且 只能通过修改配置文件，并重启服务器程序生效；有些参数作用域是全局 的，且不可改变；有些可以为每个用户提供单独（会话）的设置 获取mysqld的可用选项列表：服务器选项&ensp;&ensp;mysqld --help --verbose&ensp;&ensp;mysqld --print-defaults 获取默认设置 服务器配置服务器系统变量：分全局和会话两种服务器状态变量：分全局和会话两种获取运行中的mysql进程使用各服务器参数及其值&ensp;&ensp;mysql&gt; SHOW GLOBAL VARIABLES;&ensp;&ensp;mysql&gt; SHOW [SESSION] VARIABLES;设置服务器选项方法：&ensp;&ensp;在命令行中设置&ensp;&ensp;&ensp;&ensp;shell&gt; ./mysqld_safe –skip-name-resolve=1&ensp;&ensp;在配置文件my.cnf中设置&ensp;&ensp;&ensp;&ensp;skip_name_resolve=1 服务器端设置服务器系统变量：分全局和会话两种获取系统变量：&ensp;&ensp;mysql&gt; show global variables; 显示所有的全局变量&ensp;&ensp;mysql&gt; show [session] variables; 显示所有的会话变量&ensp;&ensp;mysql&gt; select @@varriables; 显示系统变量 修改服务器变量的值：&ensp;&ensp;mysql&gt; help SET修改全局变量：仅对修改后新创建的会话有效；对已经建立的会话无效&ensp;&ensp;mysql&gt; SET GLOBAL system_var_name=value;&ensp;&ensp;mysql&gt; SET @@global.system_var_name=value;修改会话变量：&ensp;&ensp;mysql&gt; SET [SESSION] system_var_name=value;&ensp;&ensp;mysql&gt; SET @@[session.]system_var_name=value;状态变量（只读）：用于保存mysqld运行中的统计数据的变量，不可更改&ensp;&ensp;mysql&gt; SHOW GLOBAL STATUS;&ensp;&ensp;mysql&gt; SHOW [SESSION] STATUS; 服务器变量SQL_MODESQL_MODE：对其设置可以完成一些约束检查的工作,可分别进行全局的设置或当前会 话的设置，参看：https://mariadb.com/kb/en/library/sql-mode/常见MODE:&ensp;&ensp;NO_AUTO_CREATE_USER&ensp;&ensp;&ensp;&ensp;禁止GRANT创建密码为空的用户&ensp;&ensp;NO_ZERO_DATE&ensp;&ensp;&ensp;&ensp;在严格模式，不允许使用‘0000-00-00’的时间&ensp;&ensp;ONLY_FULL_GROUP_BY&ensp;&ensp;&ensp;&ensp;对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么 将认为这个SQL是不合法的&ensp;&ensp;NO_BACKSLASH_ESCAPES&ensp;&ensp;&ensp;&ensp;反斜杠“\”作为普通字符而非转义字符&ensp;&ensp;PIPES_AS_CONCAT&ensp;&ensp;&ensp;&ensp;将”||”视为连接操作符而非“或运算符 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182主要影响对数据库的操作查看sql_mode值MariaDB [hellodb]&gt; show variables like 'sql_mode';+---------------+-------+| Variable_name | Value |+---------------+-------+| sql_mode | |+---------------+-------+1 row in set (0.00 sec)创建一个表，限制输入的name记录的字段的字符长度为3个字符MariaDB [hellodb]&gt; create table test (id int,name char(3));Query OK, 0 rows affected (0.02 sec)MariaDB [hellodb]&gt; show create table test\G*************************** 1. row *************************** Table: testCreate Table: CREATE TABLE `test` ( `id` int(11) DEFAULT NULL, `name` char(3) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf81 row in set (0.00 sec)添加长字段测试，添加字段未被限制不让添加仅仅是报警MariaDB [hellodb]&gt; insert test value (2,'abcde');Query OK, 1 row affected, 1 warning (0.00 sec)查看报警信息MariaDB [hellodb]&gt; show warnings;+---------+------+-------------------------------------------+| Level | Code | Message |+---------+------+-------------------------------------------+| Warning | 1265 | Data truncated for column 'name' at row 1 |+---------+------+-------------------------------------------+1 row in set (0.00 sec)查看表中的所有的字段，虽然添加超过限制的字段，但是录入了在限制内的字段，显示的字段为3个所以留下了三个字段MariaDB [hellodb]&gt; select * from test;+------+------+| id | name |+------+------+| 1 | abc || 2 | abc |+------+------+2 rows in set (0.00 sec)修改sql_mode变量 5.5版本的数据库默认sql_mod的值为空MariaDB [hellodb]&gt; show variables like 'sql_mode';+---------------+-------+| Variable_name | Value |+---------------+-------+| sql_mode | |+---------------+-------+1 row in set (0.00 sec)修改sql_mode值限制在添加字段的时候的值不能超长，未修改之前只是报警，截取可以限制的长度内的字段则被记录MariaDB [hellodb]&gt; set sql_mode='traditional';Query OK, 0 rows affected (0.00 sec)MariaDB [hellodb]&gt; show variables like 'sql_mode';+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------+| Variable_name | Value |+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------+| sql_mode | STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |+---------------+------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)再次添加超长字段测试：直接不是报警了，直接报错MariaDB [hellodb]&gt; insert test value (3,'abcdeddd');ERROR 1406 (22001): Data too long for column 'name' at row 1查看添加的记录是否添加进入：未被添加进去MariaDB [hellodb]&gt; select * from test;+------+------+| id | name |+------+------+| 1 | abc || 2 | abc |+------+------+2 rows in set (0.00 sec) 在命令外显示系统自带的变量：数据库的状态信息12345678910111213141516171819202122232425262728293031323334353637[root@centos7 ~]# mysql -e 'show status' | grep select Com_insert_select 0Com_replace_select 0Com_select 1 查询的次数MariaDB [(none)]&gt; use hellodb;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [hellodb]&gt; show status like 'com_select';+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_select | 2 |+---------------+-------+1 row in set (0.00 sec)再次查询查看是否会增长MariaDB [hellodb]&gt; select * from test;+------+------+| id | name |+------+------+| 1 | abc || 2 | abc |+------+------+2 rows in set (0.00 sec)MariaDB [hellodb]&gt; show status like 'com_select';+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_select | 3 | 记录执行查询命令的次数+---------------+-------+1 row in set (0.01 sec)状态变量不可使用set修改]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之数据库用户和权限管理]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E7%94%A8%E6%88%B7%E5%92%8C%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql之数据库用户和权限管理 MySQL用户和权限管理元数据数据库：mysql&ensp;&ensp;系统授权表：&ensp;&ensp;db, host, user&ensp;&ensp;columns_priv, tables_priv, procs_priv, proxies_priv用户账号：&ensp;&ensp;‘USERNAME‘@’HOST’ &ensp;&ensp; 用户名@允许从哪台主机登陆&ensp;&ensp;@’HOST’:&ensp;&ensp;主机名&ensp;&ensp;IP地址或Network&ensp;&ensp;通配符： % _&ensp;&ensp;示例：172.16.%.% 用户管理创建用户：CREATE USER&ensp;&ensp;CREATE USER ‘USERNAME‘@’HOST’ [IDENTIFIED BY ‘password’]；&ensp;&ensp;默认权限：USAGE用户重命名：RENAME USER&ensp;&ensp;RENAME USER old_user_name TO new_user_name;删除用户：&ensp;&ensp;DROP USER ‘USERNAME‘@’HOST‘&ensp;&ensp;示例：删除默认的空用户&ensp;&ensp;DROP USER ‘‘@’localhost’;修改密码：&ensp;&ensp;mysql&gt;SET PASSWORD FOR ‘user‘@’host’ = PASSWORD(‘password’);&ensp;&ensp;mysql&gt;UPDATE mysql.user SET password=PASSWORD(‘password’) WHERE clause; （直接修改表，不会立即生效，配合下面的命令）&ensp;&ensp;&ensp;&ensp;此方法需要执行下面指令才能生效：&ensp;&ensp;&ensp;&ensp;mysql&gt; FLUSH PRIVILEGES;&ensp;&ensp;#mysqladmin -u root -poldpass password ‘newpass’忘记管理员密码的解决办法：&ensp;&ensp;启动mysqld进程时，为其使用如下选项：&ensp;&ensp;&ensp;&ensp;–skip-grant-tables&ensp;&ensp;&ensp;&ensp;–skip-networking (禁止数据库有网络功能，防止破解口令的同时其他人利用此特性盗取数据)&ensp;&ensp;使用UPDATE命令修改管理员密码&ensp;&ensp;关闭mysqld进程，移除上述两个选项，重启mysqld12345678910111213141516171819202122232425262728293031323334353637383940414243444546查看mysql数据库中的用户信息系统表MariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.01 sec)查询当前数据库服务器中的用户MariaDB [mysql]&gt; select user,host from user;+------+-------------+| user | host |+------+-------------+| root | 127.0.0.1 || root | ::1 || | centos7.com || root | centos7.com || | localhost || root | localhost |+------+-------------+6 rows in set (0.00 sec) 创建账号12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485创建账号，授权允许此用户可以在那台主机上登陆数据库 创建test这个用户可以在172.18.133. 这个网段的连接此服务器，并且设置口令为centosMariaDB [mysql]&gt; create user test@'172.18.133.%' identified by 'centos';Query OK, 0 rows affected (0.00 sec)查看是否创建MariaDB [mysql]&gt; select user,host from user;+------+--------------+| user | host |+------+--------------+| root | 127.0.0.1 | 系统自带的管理员| test | 172.18.133.% | | root | ::1 | 系统自带的管理员| | centos7.com | 匿名账号| root | centos7.com | 系统自带的管理员| | localhost | 匿名账号| root | localhost |+------+--------------+7 rows in set (0.00 sec)使用此账号远程登陆 -h 指定服务器端的ip地址[root@centos7 ~]# mysql -utest -pcentos -h172.18.133.162Welcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 11Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; 查看当前连接的用户名：使用user函数查看MariaDB [(none)]&gt; select user();+---------------------+| user() |+---------------------+| test@172.18.133.162 |+---------------------+1 row in set (0.00 sec)使用create user 创建的账号，登陆上来之后查看当前数据库的数据库仅能看到两个，因为创建的账号没有权限 使用create user创建好账号登陆MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test |+--------------------+2 rows in set (0.00 sec)删除用户 范例为：删除匿名用户MariaDB [mysql]&gt; select user,host from user;+------+--------------+| user | host |+------+--------------+| root | 127.0.0.1 || test | 172.18.133.% || root | ::1 || | centos7.com | 匿名账号| root | centos7.com || | localhost | 匿名账号| root | localhost |+------+--------------+7 rows in set (0.00 sec) 删除匿名用户：没有用户名就时空，用单引号引起来MariaDB [mysql]&gt; drop user ''@centos7.com -&gt; ;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; drop user ''@localhost;Query OK, 0 rows affected (0.00 sec)再次查询当前数据库的账号MariaDB [mysql]&gt; select user,host from user;+------+--------------+| user | host |+------+--------------+| root | 127.0.0.1 || test | 172.18.133.% || root | ::1 || root | centos7.com || root | localhost |+------+--------------+5 rows in set (0.00 sec) 修改用户口令，设置密码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071修改用户口令 ： password函数生成加密口令 查看当前的账号信息以及密码MariaDB [mysql]&gt; select user,host,password from user;+------+--------------+-------------------------------------------+| user | host | password |+------+--------------+-------------------------------------------+| root | localhost | || root | centos7.com | || root | 127.0.0.1 | || root | ::1 | || test | 172.18.133.% | *128977E278358FF80A246B5046F51043A2B1FCED |+------+--------------+-------------------------------------------+5 rows in set (0.00 sec) 使用password 可以将你要设置的字符串设置加密MariaDB [mysql]&gt; select password('dai');+-------------------------------------------+| password('dai') |+-------------------------------------------+| *CE886B6974FB59FB743ADF5DB78FDA6B25649F5C |+-------------------------------------------+1 row in set (0.00 sec)修改用户的口令：对test用户修改口令，将原有的centos口令修改为daizheMariaDB [mysql]&gt; set password for test@'172.18.133.%'=password('daizhe');Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; select user,host,password from user;+------+--------------+-------------------------------------------+| user | host | password |+------+--------------+-------------------------------------------+| root | localhost | || root | centos7.com | || root | 127.0.0.1 | || root | ::1 | || test | 172.18.133.% | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 |+------+--------------+-------------------------------------------+5 rows in set (0.00 sec)使用新口令登陆[root@centos7 ~]# mysql -utest -pdaizhe -h172.18.133.162Welcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 6将数据库系统自带的管理员用户添加密码：设置密码为daizhe （mysql数据库的缺点就是设置相同口令的密码会看的出来，因为没有加盐 sort）MariaDB [mysql]&gt; update user set password=password('daizhe') where user='root';Query OK, 4 rows affected (0.00 sec)Rows matched: 4 Changed: 4 Warnings: 0MariaDB [mysql]&gt; select user,host,password from user;+------+--------------+-------------------------------------------+| user | host | password |+------+--------------+-------------------------------------------+| root | localhost | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | centos7.com | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | 127.0.0.1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | ::1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || test | 172.18.133.% | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 |+------+--------------+-------------------------------------------+5 rows in set (0.00 sec) 此时不会立即生效:执行生效命令MariaDB [mysql]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)测试密码是否已经被更改[root@centos7 ~]# mysql ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)[root@centos7 ~]# mysql -pdaizheWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 9Server version: 5.5.60-MariaDB MariaDB Server 范例：假设root口令忘记了123456789101112131415 如果是测试环境，可以最直接的方法，删除数据库的数据目录，因为数据库的所有数据都存放在数据库的数据目录中rm -rf /var/lib/mysql/*systemctl restart mariadb破解root密码并且保存数据库的所有数据编辑数据的配置文件（使得数据库登陆时忽略授权表）[root@centos7 ~]# vim /etc/my.cnf[mysqld]skip-grant-tables[root@centos7 ~]# systemctl restart mariadb[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.60-MariaDB MariaDB Server MySQL权限管理权限类别：&ensp;&ensp;管理类&ensp;&ensp;程序类&ensp;&ensp;数据库级别&ensp;&ensp;表级别&ensp;&ensp;字段级别 MySQL用户和权限管理管理类：&ensp;&ensp;CREATE TEMPORARY TABLES&ensp;&ensp;CREATE USER&ensp;&ensp;FILE&ensp;&ensp;SUPER&ensp;&ensp;SHOW DATABASES&ensp;&ensp;RELOAD&ensp;&ensp;SHUTDOWN&ensp;&ensp;REPLICATION SLAVE&ensp;&ensp;REPLICATION CLIENT&ensp;&ensp;LOCK TABLES&ensp;&ensp;PROCESS程序类： FUNCTION、PROCEDURE、TRIGGER 函数、存储过程、触发器&ensp;&ensp;CREATE&ensp;&ensp;ALTER&ensp;&ensp;DROP&ensp;&ensp;EXCUTE库和表级别：DATABASE、TABLE 数据库、表&ensp;&ensp;ALTER&ensp;&ensp;CREATE&ensp;&ensp;CREATE VIEW&ensp;&ensp;DROP&ensp;&ensp;INDEX&ensp;&ensp;SHOW VIEW&ensp;&ensp;GRANT OPTION：能将自己获得的权限转赠给其他用户 （让权限具有传递性）数据操作： 增删改查&ensp;&ensp;SELECT&ensp;&ensp;INSERT&ensp;&ensp;DELETE&ensp;&ensp;UPDATE字段级别： 精确到字段的增删改查&ensp;&ensp;SELECT(col1,col2,…)&ensp;&ensp;UPDATE(col1,col2,…)&ensp;&ensp;INSERT(col1,col2,…)所有权限：ALL PRIVILEGES 或 ALL 授权授权参考：https://dev.mysql.com/doc/refman/5.7/en/grant.html&ensp;&ensp;GRANT priv_type [(column_list)],… ON [object_type] priv_level TO ‘user‘@’host’ [IDENTIFIED BY ‘password’] [WITH GRANT OPTION];&ensp;&ensp;priv_type: ALL [PRIVILEGES]&ensp;&ensp;object_type:TABLE | FUNCTION | PROCEDURE&ensp;&ensp;priv_level: (所有库) | . | db_name. | db_name.tbl_name | tbl_name(当前库 的表) | db_name.routine_name(指定库的函数,存储过程,触发器)with_option: GRANT OPTION&ensp;&ensp;| MAX_QUERIES_PER_HOUR count&ensp;&ensp;| MAX_UPDATES_PER_HOUR count&ensp;&ensp;| MAX_CONNECTIONS_PER_HOUR count&ensp;&ensp;| MAX_USER_CONNECTIONS count示例：GRANT SELECT (col1), INSERT (col1,col2) ON mydb.mytbl TO ‘someuser‘@’somehost‘; 回收授权回收授权：REVOKE priv_type [(column_list)] [, priv_type [(column_list)]] … ON [object_type] priv_level FROM user [, user] …示例： REVOKE DELETE ON testdb.* FROM ‘testuser‘@‘172.16.0.%’; 查看指定用户获得的授权：&ensp;&ensp;Help SHOW GRANTS&ensp;&ensp;SHOW GRANTS FOR ‘user‘@’host’;&ensp;&ensp;SHOW GRANTS FOR CURRENT_USER[()];注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存&ensp;&ensp;(1) GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进 程通常会自动重读授权表，使之生效&ensp;&ensp;(2) 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程 重读授权表：mysql&gt; FLUSH PRIVILEGES; 范例：实现用户的权限授权1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162创建一个账号MariaDB [mysql]&gt; create user daizhe@'172.18.133.%' identified by 'daizhe';Query OK, 0 rows affected (0.00 sec)授权创建的daizhe 这个账号权限 多这个账号授权所有权限，在hollodb中的所有表MariaDB [mysql]&gt; grant all on hellodb.* to daizhe@'172.18.133.%';Query OK, 0 rows affected (0.01 sec)使用此账号，远程连接查看是否已经授权[root@centos7 ~]# mysql -udaizhe -pdaizhe -h172.18.133.162Welcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 9Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || hellodb || test |+--------------------+3 rows in set (0.00 sec)使用grant 创建用户、授权、设置密码 创建test2这个用户，针对hellodb这个库中的表， 仅能针对特定的字段来查询，MariaDB [(none)]&gt; grant select(name,age) on hellodb.students to test2@'172.18.133.%' identified by 'daizhe';Query OK, 0 rows affected (0.00 sec)查看授权完的用户的权限MariaDB [(none)]&gt; show grants for test2@'172.18.133.%'\G*************************** 1. row ***************************Grants for test2@172.18.133.%: GRANT USAGE ON *.* TO 'test2'@'172.18.133.%' IDENTIFIED BY PASSWORD '*0E04F27C8B21547FD069D6E8519AE49B7ECE8E94'*************************** 2. row ***************************Grants for test2@172.18.133.%: GRANT SELECT (age, name) ON `hellodb`.`students` TO 'test2'@'172.18.133.%'2 rows in set (0.00 sec)取消回收权限 revoke 创建一个用户给与针对于所有库的所有权限MariaDB [(none)]&gt; grant all on *.* to test3@'172.18.133.%' identified by 'daizhe';Query OK, 0 rows affected (0.00 sec)取消这个用户的select 查询权限MariaDB [(none)]&gt; revoke select on *.* from test3@'172.18.133.%';Query OK, 0 rows affected (0.00 sec)查看test3用户的权限MariaDB [(none)]&gt; show grants for test3@'172.18.133.%'\G*************************** 1. row ***************************Grants for test3@172.18.133.%: GRANT INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE ON *.* TO 'test3'@'172.18.133.%' IDENTIFIED BY PASSWORD '*0E04F27C8B21547FD069D6E8519AE49B7ECE8E94'1 row in set (0.00 sec)查看当前用户的权限MariaDB [(none)]&gt; show grants for current_user()\G*************************** 1. row ***************************Grants for root@localhost: GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' IDENTIFIED BY PASSWORD '*0E04F27C8B21547FD069D6E8519AE49B7ECE8E94' WITH GRANT OPTION*************************** 2. row ***************************Grants for root@localhost: GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION2 rows in set (0.00 sec)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之数据库DML语言]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%BA%93DML%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[mysql之数据库DML语言 DML语言 增加insert12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788 DML语句 DML: INSERT增加, DELETE删除, UPDATE 改 增加insert查看帮助：MariaDB [studentdb]&gt; help insert查询当前数据库中的表信息MariaDB [studentdb]&gt; select * from student;Empty set (0.00 sec) （为空）查询当前表中的记录数 （count 为函数）MariaDB [studentdb]&gt; select count(*) from student;+----------+| count(*) |+----------+| 0 |+----------+1 row in set (0.00 sec) （为空）在当前使用的表中添加纪录首先查看表的结构，查看有哪些字段MariaDB [studentdb]&gt; desc student;+---------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(10) | NO | | NULL | || sex | enum('f','m') | YES | | m | || age | tinyint(3) unsigned | YES | | NULL | || phone | char(11) | YES | | NULL | || address | varchar(50) | YES | | NULL | |+---------+---------------------+------+-----+---------+----------------+6 rows in set (0.00 sec)在表中添加纪录（赋值字段对应的字段，相对应的值，顺序不可变）（值和字段必须相同）MariaDB [studentdb]&gt; insert into student (name,age,phone,address) values ('mage',30,10086,'beijing'), ('daizhe',20,10010,'tangshan');Query OK, 2 rows affected (0.00 sec)Records: 2 Duplicates: 0 Warnings: 0查询表中的纪录MariaDB [studentdb]&gt; select * from student;+----+--------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+----------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan |+----+--------+------+------+-------+----------+2 rows in set (0.00 sec)MariaDB [studentdb]&gt; select count(*) from student;+----------+| count(*) |+----------+| 2 |+----------+1 row in set (0.00 sec)假如上述赋值时手机号忘记了怎么赋值（空值设置方法）MariaDB [studentdb]&gt; insert into student (age,name,phone,address) values (20,'ma',null,'shijiahuang');Query OK, 1 row affected (0.00 sec)MariaDB [studentdb]&gt; select * from student;+----+--------+------+------+-------+-------------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+-------------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | dehua | m | 22 | NULL | tianjin || 4 | ma | m | 20 | NULL | shijiahuang |+----+--------+------+------+-------+-------------+4 rows in set (0.00 sec)单独挑出字段来赋值MariaDB [studentdb]&gt; insert student set name='dehua',age=22,address='tianjin';Query OK, 1 row affected (0.01 sec)MariaDB [studentdb]&gt; select * from student;+----+--------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+----------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | dehua | m | 22 | NULL | tianjin |+----+--------+------+------+-------+----------+3 rows in set (0.00 sec) 克隆表结构，并且纪录也被克隆12345678910111213141516171819202122232425262728克隆表结构MariaDB [studentdb]&gt; create table employee select * from student;Query OK, 2 rows affected (0.01 sec)Records: 2 Duplicates: 0 Warnings: 0查看克隆生成的表的结构MariaDB [studentdb]&gt; desc employee;+---------+---------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+-------+| id | int(10) unsigned | NO | | 0 | || name | varchar(10) | NO | | NULL | || sex | enum('f','m') | YES | | m | || age | tinyint(3) unsigned | YES | | NULL | || phone | char(11) | YES | | NULL | || address | varchar(50) | YES | | NULL | |+---------+---------------------+------+-----+---------+-------+6 rows in set (0.01 sec)查看数据是否也被克隆，被克隆MariaDB [studentdb]&gt; select * from employee;+----+--------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+----------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan |+----+--------+------+------+-------+----------+2 rows in set (0.00 sec) 克隆表结构，并且纪录不被克隆12345678910111213141516171819MariaDB [studentdb]&gt; create table haha like student;Query OK, 0 rows affected (0.01 sec)MariaDB [studentdb]&gt; desc haha;+---------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(10) | NO | | NULL | || sex | enum('f','m') | YES | | m | || age | tinyint(3) unsigned | YES | | NULL | || phone | char(11) | YES | | NULL | || address | varchar(50) | YES | | NULL | |+---------+---------------------+------+-----+---------+----------------+6 rows in set (0.00 sec)MariaDB [studentdb]&gt; select * from haha -&gt; ;Empty set (0.00 sec) 将相同表结构的数据合并123456MariaDB [studentdb]&gt; select * from haha;Empty set (0.00 sec)MariaDB [studentdb]&gt; insert haha select * from student; (将student中的数据导入到haha表中，前提是两张表的表结构是相同的)Query OK, 4 rows affected (0.01 sec)Records: 4 Duplicates: 0 Warnings: 0 在表的纪录的数据中添加汉字123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127添加中文件字段MariaDB [studentdb]&gt; insert into student (age,name,phone,address) values (19,'星星',114114,'河北');结果显示为乱码MariaDB [studentdb]&gt; select * from student;+----+--------+------+------+--------+-------------+| id | name | sex | age | phone | address |+----+--------+------+------+--------+-------------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | dehua | m | 22 | NULL | tianjin || 4 | ma | m | 20 | NULL | shijiahuang || 5 | ?? | m | 19 | 114114 | ?? |+----+--------+------+------+--------+-------------+5 rows in set (0.00 sec)乱码原因当初创建表的时候，用的为在字符集不支持汉字MariaDB [studentdb]&gt; show create table student;| student | CREATE TABLE `student` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) NOT NULL, `sex` enum('f','m') DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `phone` char(11) DEFAULT NULL, `address` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=latin1 |创建一个utf8mb4的数据库MariaDB [studentdb]&gt; create database db_utf8mb4 character set=utf8mb4;Query OK, 1 row affected (0.00 sec)MariaDB [studentdb]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db_utf8mb4 || mysql || performance_schema || studentdb || test |+--------------------+6 rows in set (0.00 sec)克隆一张，studentdb库中的表student 倒 db_utf8mb4库中，仅克隆表结构（跨库导入表，库于表之间需要加点）MariaDB [studentdb]&gt; use db_utf8mb4;Database changedMariaDB [db_utf8mb4]&gt; 跨库克隆MariaDB [db_utf8mb4]&gt; create table student like studentdb.student -&gt; ;Query OK, 0 rows affected (0.01 sec)查看克隆过来的表的字符集MariaDB [db_utf8mb4]&gt; show create table student;| student | CREATE TABLE `student` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) NOT NULL, `sex` enum('f','m') DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `phone` char(11) DEFAULT NULL, `address` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1 | 此表为latin1也不支持中文，修改表的字符集MariaDB [db_utf8mb4]&gt; alter table student character set = utf8mb4 -&gt; ;Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0MariaDB [db_utf8mb4]&gt; show create table student;| student | CREATE TABLE `student` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) CHARACTER SET latin1 NOT NULL, `sex` enum('f','m') CHARACTER SET latin1 DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `phone` char(11) CHARACTER SET latin1 DEFAULT NULL, `address` varchar(50) CHARACTER SET latin1 DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 |在此表中手动添加纪录MariaDB [db_utf8mb4]&gt; insert student (name,age,address) values ('nana',22,'石家庄');Query OK, 1 row affected (0.01 sec)MariaDB [db_utf8mb4]&gt; select * from status;ERROR 1146 (42S02): Table 'db_utf8mb4.status' doesn't existMariaDB [db_utf8mb4]&gt; select * from student;+----+------+------+------+-------+---------+| id | name | sex | age | phone | address |+----+------+------+------+-------+---------+| 1 | nana | m | 22 | NULL | ？？？ |+----+------+------+------+-------+---------+1 row in set (0.00 sec)结果还是乱码查看此库的信息，显示编码不一致（结论客户端和服务端都应该统一编码）MariaDB [db_utf8mb4]&gt; status--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 2Current database: db_utf8mb4Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketInsert id: 1Server characterset: latin1Db characterset: utf8mb4Client characterset: utf8Conn. characterset: utf8UNIX socket: /var/lib/mysql/mysql.sockUptime: 3 min 21 secThreads: 1 Questions: 14 Slow queries: 0 Opens: 1 Flush tables: 2 Open tables: 27 Queries per second avg: 0.069 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114设置所有的编码都进行统一 设定之前查看当前数据库字符集，目前客户端和服务端都不一致 MariaDB [(none)]&gt; status--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 3Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1Db characterset: latin1Client characterset: utf8Conn. characterset: utf8UNIX socket: /var/lib/mysql/mysql.sockUptime: 1 min 5 secThreads: 1 Questions: 9 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 26 Queries per second avg: 0.138编辑配置文件[root@centos7 ~]# vim /etc/my.cnf[mysqld] （服务端添加一行）character-set-server=utf8mb4[root@centos7 ~]# vim /etc/my.cnf.d/mysql-clients.cnf [mysql] （客户端添加）default-character-set=utf8mb4[root@centos7 ~]# systemctl restart mariadb查看更改完的字符集MariaDB [(none)]&gt; status--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 2Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketServer characterset: utf8mb4Db characterset: utf8mb4Client characterset: utf8mb4Conn. characterset: utf8mb4UNIX socket: /var/lib/mysql/mysql.sockUptime: 42 secThreads: 1 Questions: 5 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 26 Queries per second avg: 0.119此时再次可以新创建一个数据库，添加新表，写入字段，添加纪录，则此时已经支持了汉字，创库之前就要统一编码机制备份时，系统用什么字符集，备份就用相同的字符集建议使用utf8mb4修改统一的字符集，并创建新表MariaDB [xinbiao2]&gt; create database db2;Query OK, 1 row affected (0.00 sec)MariaDB [xinbiao2]&gt; show create database db2;+----------+-----------------------------------------------------------------+| Database | Create Database |+----------+-----------------------------------------------------------------+| db2 | CREATE DATABASE `db2` /*!40100 DEFAULT CHARACTER SET utf8mb4 */ |+----------+-----------------------------------------------------------------+1 row in set (0.00 sec)MariaDB [xinbiao2]&gt; use db2;Database changedMariaDB [db2]&gt; create table biao (id int,name char(3));Query OK, 0 rows affected (0.00 sec)MariaDB [db2]&gt; show create table biao;+-------+--------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------+| biao | CREATE TABLE `biao` ( `id` int(11) DEFAULT NULL, `name` char(3) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 |+-------+--------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)MariaDB [db2]&gt; desc biao;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || name | char(3) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.00 sec)全部字段赋值MariaDB [db2]&gt; insert biao value(1,'星星');Query OK, 1 row affected (0.01 sec)MariaDB [db2]&gt; select * from biao;+------+--------+| id | name |+------+--------+| 1 | 星星 |+------+--------+1 row in set (0.00 sec)已经支持汉字 字符集：实例可以自己指定，表结构可以指定，字段可以指定（最好统一）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647查看以前创建的表的创建规则，生成一个新字符集的表MariaDB [db2]&gt; show create table studentdb.student;| student | CREATE TABLE `student` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) NOT NULL, `sex` enum('f','m') DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `phone` char(11) DEFAULT NULL, `address` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=latin1 |仿照上一个的创建信息，创建一张新的表，默认的字符集为上面设置的。MariaDB [db2]&gt; CREATE TABLE `t2` ( -&gt; `id` int(10) unsigned NOT NULL DEFAULT '0', -&gt; `name` varchar(10) NOT NULL, -&gt; `sex` enum('f','m') DEFAULT 'm', -&gt; `age` tinyint(3) unsigned DEFAULT NULL, -&gt; `mobile` char(11) DEFAULT NULL, -&gt; `address` varchar(50) DEFAULT NULL -&gt; ) ENGINE=InnoDB;Query OK, 0 rows affected (0.01 sec)查看创建信息，在创建时未指定表结构，使用默认的表结构utf8mb4MariaDB [db2]&gt; show create table t2;| t2 | CREATE TABLE `t2` ( `id` int(10) unsigned NOT NULL DEFAULT '0', `name` varchar(10) NOT NULL, `sex` enum('f','m') DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `mobile` char(11) DEFAULT NULL, `address` varchar(50) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 |在表中插入记录，挑选字段插入MariaDB [db2]&gt; insert t2 (name,age,address) values('代哲',21,'唐山');Query OK, 1 row affected (0.01 sec)MariaDB [db2]&gt; select * from t2;+----+--------+------+------+--------+---------+| id | name | sex | age | mobile | address |+----+--------+------+------+--------+---------+| 0 | 代哲 | m | 21 | NULL | 唐山 |+----+--------+------+------+--------+---------+1 row in set (0.00 sec) DML 语言 删除 delete1234567891011121314151617181920212223删库：drop database 库名删表：drop table 表名删除数据库中的表数据，但不删除表结构，而且不记录日志，效率高，慎用：truncate table 表全部删除表中所有内容：MariaDB [studentdb]&gt; delete from 表名;使用delete删除指定删除的条件，使用where指定条件删除表中的单条记录 查看表中的内容MariaDB [studentdb]&gt; select * from student;+----+---------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+---------+------+------+-------+----------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | laowang | m | 18 | NULL | tangshan |+----+---------+------+------+-------+----------+3 rows in set (0.00 sec) 删除表中的字段，需要定义查询条件 范例：删除id为3号和三号以后的字段MariaDB [studentdb]&gt; delete from student where id &gt;= 3; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960高版本的数据库版本[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 8Server version: 10.3.11-MariaDB MariaDB ServerMariaDB [(none)]&gt; create database b1;Query OK, 1 row affected (0.001 sec)MariaDB [(none)]&gt; use b1;Database changedMariaDB [b1]&gt; create table t1(id int,name char(3));Query OK, 0 rows affected (0.007 sec)当在高版本的数据库中创建一个库，再创建一个表，查看数据库数据目录[root@centos7 ~]# ls /var/lib/mysql/b1/db.opt t1.frm t1.ibd低版本的数据库[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 4Server version: 5.5.60-MariaDB MariaDB Server当在低版本的数据库中创建一个库，再创建一个表，查看数据库数据目录[root@centos7 ~]# ls /var/lib/mysql/studentdb/db.opt student.frm xinbiao1.frm xinbiao.frmfrm文件存放表结构缺少ibd文件，存放用户的数据，老版本的数据放置再/var/lib/mysql/ibdata1（所有数据库，以及所有表的数据放在这个文件中）可以再老版本中添加选项使得和新版本一样，使得每个数据单独放置 可以在数据库程序使用系统函数查看老版本为关闭状态MariaDB [(none)]&gt; show variables like '%per_table%';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | OFF |+-----------------------+-------+1 row in set (0.00 sec)新版本为开启状态MariaDB [b1]&gt; show variables like '%per_table%';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| innodb_file_per_table | ON |+-----------------------+-------+1 row in set (0.002 sec)可以再老版本的配置文件中加以定义，添加一行，重启服务重启后，只有再次创建的新 表才会遵循此规则[root@centos7 ~]# vim /etc/my.cnf[mysqld]innodb_file_per_table DML 语言 更改 update1234567891011121314151617181920212223242526272829303132333435363738394041update 进行数据更改时也要使用where进行条件匹配如果不加条件匹配则修改所有的字段更改表内容 先查看下表内容MariaDB [studentdb]&gt; select * from student;+----+---------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+---------+------+------+-------+----------+| 1 | mage | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | laowang | m | 18 | NULL | tangshan |+----+---------+------+------+-------+----------+3 rows in set (0.00 sec)将一号的姓名进行更改MariaDB [studentdb]&gt; update student set name='aaaa' where id=1;MariaDB [studentdb]&gt; select * from student;+----+---------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+---------+------+------+-------+----------+| 1 | aaaa | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | laowang | m | 18 | NULL | tangshan |+----+---------+------+------+-------+----------+防止忘记使用where条件判断语句，可以使用方法1：mysql选项： -U | --safe-updates [root@centos7 ~]# mysql -UMariaDB [studentdb]&gt; update student set name='aaaa';ERROR 1175 (HY000): You are using safe update mode and you tried to update a table without a WHERE that uses a KEY column提示说你使用的是安装更新模式方法2：可以修改配置文件，追加[root@centos7 ~]# vim /etc/my.cnf.d/mysql-clients.cnf [mysql]safe-updates 字符集更改12345678910数据库级的更改alter database studentdb character set utf8;表整个所有字段的字符集更改(仅能影响表中后增加的字段)alter table student character set utf8;原来的字段想被修改alter table student chage 原字段name 新字段name varchar(20) character set utf8;尽量设计表之前就要将客户端和服务端的字符集就要设计好，后期尽量不要修改]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之select多表操作]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E4%B9%8Bselect%E5%A4%9A%E8%A1%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[mysql之select多表操作 DQL语句 select 查询 范例中的两张表123456789101112MariaDB [hellodb]&gt; show tables;+-------------------+| Tables_in_hellodb |+-------------------+| students || teachers |+-------------------+两张表组合查询：两种情况：两张表纵向合并，和两张表横向合并纵向合并：前提是字段相同，如果不同，可以挑选出相同的字段来显示横向合并：笛卡尔乘积:交叉连接：cross join:互相两张表互相每条记录组合一变 纵向合并123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155首先查看两张表的字段信息学生表MariaDB [hellodb]&gt; select * from students;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 3 | Xie Yanke | 53 | M | 2 | 16 || 4 | Ding Dian | 32 | M | 4 | 4 || 5 | Yu Yutong | 26 | M | 3 | 1 || 6 | Shi Qing | 46 | M | 5 | NULL || 7 | Xi Ren | 19 | F | 3 | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL || 15 | Duan Yu | 19 | M | 4 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL || 20 | Diao Chan | 19 | F | 7 | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL || 23 | Ma Chao | 23 | M | 4 | NULL || 24 | Xu Xian | 27 | M | NULL | NULL || 25 | Sun Dasheng | 100 | M | NULL | NULL |+-------+---------------+-----+--------+---------+-----------+讲师表MariaDB [hellodb]&gt; select * from teachers -&gt; ;+-----+---------------+-----+--------+| TID | Name | Age | Gender |+-----+---------------+-----+--------+| 1 | Song Jiang | 45 | M || 2 | Zhang Sanfeng | 94 | M || 3 | Miejue Shitai | 77 | F || 4 | Lin Chaoying | 93 | F |+-----+---------------+-----+--------+4 rows in set (0.00 sec)如果纵向显示可以挑选出字段想多的信息来显示挑选学生表的字段MariaDB [hellodb]&gt; select stuid,name,age,gender from students;+-------+---------------+-----+--------+| stuid | name | age | gender |+-------+---------------+-----+--------+| 1 | Shi Zhongyu | 22 | M || 2 | Shi Potian | 22 | M || 3 | Xie Yanke | 53 | M || 4 | Ding Dian | 32 | M || 5 | Yu Yutong | 26 | M || 6 | Shi Qing | 46 | M || 7 | Xi Ren | 19 | F || 8 | Lin Daiyu | 17 | F |........已经挑选了相同的字段，现在进行两表纵向合并显示关键字union合并显示、联合（并非真实的合并，仅仅是显示结果的合并）字段的标题是由前面定义的显示的字段决定的，显示结果如下，如果想定义自己想看到的字段，可以在前面匹配第一张表显示的字段上加以别名显示MariaDB [hellodb]&gt; select stuid,name,age,gender from students -&gt; union -&gt; select * from teachers;+-------+---------------+-----+--------+| stuid | name | age | gender |+-------+---------------+-----+--------+| 1 | Shi Zhongyu | 22 | M || 2 | Shi Potian | 22 | M || 3 | Xie Yanke | 53 | M || 4 | Ding Dian | 32 | M || 5 | Yu Yutong | 26 | M || 6 | Shi Qing | 46 | M || 7 | Xi Ren | 19 | F || 8 | Lin Daiyu | 17 | F || 9 | Ren Yingying | 20 | F || 10 | Yue Lingshan | 19 | F || 11 | Yuan Chengzhi | 23 | M || 12 | Wen Qingqing | 19 | F || 13 | Tian Boguang | 33 | M || 14 | Lu Wushuang | 17 | F || 15 | Duan Yu | 19 | M || 16 | Xu Zhu | 21 | M || 17 | Lin Chong | 25 | M || 18 | Hua Rong | 23 | M || 19 | Xue Baochai | 18 | F || 20 | Diao Chan | 19 | F || 21 | Huang Yueying | 22 | F || 22 | Xiao Qiao | 20 | F || 23 | Ma Chao | 23 | M || 24 | Xu Xian | 27 | M || 25 | Sun Dasheng | 100 | M || 1 | Song Jiang | 45 | M || 2 | Zhang Sanfeng | 94 | M || 3 | Miejue Shitai | 77 | F || 4 | Lin Chaoying | 93 | F |+-------+---------------+-----+--------+挑选两张表相同的字段来显示MariaDB [hellodb]&gt; select stuid,name from students union select tid,name from teachers;+-------+---------------+| stuid | name |+-------+---------------+| 1 | Shi Zhongyu || 2 | Shi Potian || 3 | Xie Yanke || 4 | Ding Dian || 5 | Yu Yutong || 6 | Shi Qing || 7 | Xi Ren || 8 | Lin Daiyu || 9 | Ren Yingying || 10 | Yue Lingshan || 11 | Yuan Chengzhi || 12 | Wen Qingqing || 13 | Tian Boguang || 14 | Lu Wushuang || 15 | Duan Yu || 16 | Xu Zhu || 17 | Lin Chong || 18 | Hua Rong || 19 | Xue Baochai || 20 | Diao Chan || 21 | Huang Yueying || 22 | Xiao Qiao || 23 | Ma Chao || 24 | Xu Xian || 25 | Sun Dasheng || 1 | Song Jiang || 2 | Zhang Sanfeng || 3 | Miejue Shitai || 4 | Lin Chaoying |+-------+---------------+29 rows in set (0.00 sec)显示自己想要显示的字段，加以别名显示MariaDB [hellodb]&gt; select stuid as 编号,name as 名字 from students union select tid,name from teachers;+--------+---------------+| 编号 | 名字 |+--------+---------------+| 1 | Shi Zhongyu || 2 | Shi Potian |如果两张表合并时，显示的字段相同，且有相同的记录信息，则不仅显示一条，因为select语句有重复的记录，union会去重去重小技巧：将同一个表中的相同字段去重方法1：自己和自己合并去重select * from 表 union select * from 表方法2：使用distinct,取唯一值select distinct * from 表 横向合并cross join123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109cross join 横向合并：笛卡尔乘积MariaDB [hellodb]&gt; select * from students cross join teachers;+-------+---------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+---------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 | 1 | Song Jiang | 45 | M || 1 | Shi Zhongyu | 22 | M | 2 | 3 | 2 | Zhang Sanfeng | 94 | M || 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 1 | Shi Zhongyu | 22 | M | 2 | 3 | 4 | Lin Chaoying | 93 | F || 2 | Shi Potian | 22 | M | 1 | 7 | 1 | Song Jiang | 45 | M || 2 | Shi Potian | 22 | M | 1 | 7 | 2 | Zhang Sanfeng | 94 | M || 2 | Shi Potian | 22 | M | 1 | 7 | 3 | Miejue Shitai | 77 | F || 2 | Shi Potian | 22 | M | 1 | 7 | 4 | Lin Chaoying | 93 | F || 3 | Xie Yanke | 53 | M | 2 | 16 | 1 | Song Jiang | 45 | M || 3 | Xie Yanke | 53 | M | 2 | 16 | 2 | Zhang Sanfeng | 94 | M || 3 | Xie Yanke | 53 | M | 2 | 16 | 3 | Miejue Shitai | 77 | F || 3 | Xie Yanke | 53 | M | 2 | 16 | 4 | Lin Chaoying | 93 | F || 4 | Ding Dian | 32 | M | 4 | 4 | 1 | Song Jiang | 45 | M || 4 | Ding Dian | 32 | M | 4 | 4 | 2 | Zhang Sanfeng | 94 | M || 4 | Ding Dian | 32 | M | 4 | 4 | 3 | Miejue Shitai | 77 | F || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F || 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 5 | Yu Yutong | 26 | M | 3 | 1 | 2 | Zhang Sanfeng | 94 | M || 5 | Yu Yutong | 26 | M | 3 | 1 | 3 | Miejue Shitai | 77 | F || 5 | Yu Yutong | 26 | M | 3 | 1 | 4 | Lin Chaoying | 93 | F || 6 | Shi Qing | 46 | M | 5 | NULL | 1 | Song Jiang | 45 | M || 6 | Shi Qing | 46 | M | 5 | NULL | 2 | Zhang Sanfeng | 94 | M || 6 | Shi Qing | 46 | M | 5 | NULL | 3 | Miejue Shitai | 77 | F || 6 | Shi Qing | 46 | M | 5 | NULL | 4 | Lin Chaoying | 93 | F || 7 | Xi Ren | 19 | F | 3 | NULL | 1 | Song Jiang | 45 | M || 7 | Xi Ren | 19 | F | 3 | NULL | 2 | Zhang Sanfeng | 94 | M || 7 | Xi Ren | 19 | F | 3 | NULL | 3 | Miejue Shitai | 77 | F || 7 | Xi Ren | 19 | F | 3 | NULL | 4 | Lin Chaoying | 93 | F || 8 | Lin Daiyu | 17 | F | 7 | NULL | 1 | Song Jiang | 45 | M || 8 | Lin Daiyu | 17 | F | 7 | NULL | 2 | Zhang Sanfeng | 94 | M || 8 | Lin Daiyu | 17 | F | 7 | NULL | 3 | Miejue Shitai | 77 | F || 8 | Lin Daiyu | 17 | F | 7 | NULL | 4 | Lin Chaoying | 93 | F || 9 | Ren Yingying | 20 | F | 6 | NULL | 1 | Song Jiang | 45 | M || 9 | Ren Yingying | 20 | F | 6 | NULL | 2 | Zhang Sanfeng | 94 | M || 9 | Ren Yingying | 20 | F | 6 | NULL | 3 | Miejue Shitai | 77 | F || 9 | Ren Yingying | 20 | F | 6 | NULL | 4 | Lin Chaoying | 93 | F || 10 | Yue Lingshan | 19 | F | 3 | NULL | 1 | Song Jiang | 45 | M || 10 | Yue Lingshan | 19 | F | 3 | NULL | 2 | Zhang Sanfeng | 94 | M || 10 | Yue Lingshan | 19 | F | 3 | NULL | 3 | Miejue Shitai | 77 | F || 10 | Yue Lingshan | 19 | F | 3 | NULL | 4 | Lin Chaoying | 93 | F || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | 1 | Song Jiang | 45 | M || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | 2 | Zhang Sanfeng | 94 | M || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | 3 | Miejue Shitai | 77 | F || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | 4 | Lin Chaoying | 93 | F || 12 | Wen Qingqing | 19 | F | 1 | NULL | 1 | Song Jiang | 45 | M || 12 | Wen Qingqing | 19 | F | 1 | NULL | 2 | Zhang Sanfeng | 94 | M || 12 | Wen Qingqing | 19 | F | 1 | NULL | 3 | Miejue Shitai | 77 | F || 12 | Wen Qingqing | 19 | F | 1 | NULL | 4 | Lin Chaoying | 93 | F || 13 | Tian Boguang | 33 | M | 2 | NULL | 1 | Song Jiang | 45 | M || 13 | Tian Boguang | 33 | M | 2 | NULL | 2 | Zhang Sanfeng | 94 | M || 13 | Tian Boguang | 33 | M | 2 | NULL | 3 | Miejue Shitai | 77 | F || 13 | Tian Boguang | 33 | M | 2 | NULL | 4 | Lin Chaoying | 93 | F || 14 | Lu Wushuang | 17 | F | 3 | NULL | 1 | Song Jiang | 45 | M || 14 | Lu Wushuang | 17 | F | 3 | NULL | 2 | Zhang Sanfeng | 94 | M || 14 | Lu Wushuang | 17 | F | 3 | NULL | 3 | Miejue Shitai | 77 | F || 14 | Lu Wushuang | 17 | F | 3 | NULL | 4 | Lin Chaoying | 93 | F || 15 | Duan Yu | 19 | M | 4 | NULL | 1 | Song Jiang | 45 | M || 15 | Duan Yu | 19 | M | 4 | NULL | 2 | Zhang Sanfeng | 94 | M || 15 | Duan Yu | 19 | M | 4 | NULL | 3 | Miejue Shitai | 77 | F || 15 | Duan Yu | 19 | M | 4 | NULL | 4 | Lin Chaoying | 93 | F || 16 | Xu Zhu | 21 | M | 1 | NULL | 1 | Song Jiang | 45 | M || 16 | Xu Zhu | 21 | M | 1 | NULL | 2 | Zhang Sanfeng | 94 | M || 16 | Xu Zhu | 21 | M | 1 | NULL | 3 | Miejue Shitai | 77 | F || 16 | Xu Zhu | 21 | M | 1 | NULL | 4 | Lin Chaoying | 93 | F || 17 | Lin Chong | 25 | M | 4 | NULL | 1 | Song Jiang | 45 | M || 17 | Lin Chong | 25 | M | 4 | NULL | 2 | Zhang Sanfeng | 94 | M || 17 | Lin Chong | 25 | M | 4 | NULL | 3 | Miejue Shitai | 77 | F || 17 | Lin Chong | 25 | M | 4 | NULL | 4 | Lin Chaoying | 93 | F || 18 | Hua Rong | 23 | M | 7 | NULL | 1 | Song Jiang | 45 | M || 18 | Hua Rong | 23 | M | 7 | NULL | 2 | Zhang Sanfeng | 94 | M || 18 | Hua Rong | 23 | M | 7 | NULL | 3 | Miejue Shitai | 77 | F || 18 | Hua Rong | 23 | M | 7 | NULL | 4 | Lin Chaoying | 93 | F || 19 | Xue Baochai | 18 | F | 6 | NULL | 1 | Song Jiang | 45 | M || 19 | Xue Baochai | 18 | F | 6 | NULL | 2 | Zhang Sanfeng | 94 | M || 19 | Xue Baochai | 18 | F | 6 | NULL | 3 | Miejue Shitai | 77 | F || 19 | Xue Baochai | 18 | F | 6 | NULL | 4 | Lin Chaoying | 93 | F || 20 | Diao Chan | 19 | F | 7 | NULL | 1 | Song Jiang | 45 | M || 20 | Diao Chan | 19 | F | 7 | NULL | 2 | Zhang Sanfeng | 94 | M || 20 | Diao Chan | 19 | F | 7 | NULL | 3 | Miejue Shitai | 77 | F || 20 | Diao Chan | 19 | F | 7 | NULL | 4 | Lin Chaoying | 93 | F || 21 | Huang Yueying | 22 | F | 6 | NULL | 1 | Song Jiang | 45 | M || 21 | Huang Yueying | 22 | F | 6 | NULL | 2 | Zhang Sanfeng | 94 | M || 21 | Huang Yueying | 22 | F | 6 | NULL | 3 | Miejue Shitai | 77 | F || 21 | Huang Yueying | 22 | F | 6 | NULL | 4 | Lin Chaoying | 93 | F || 22 | Xiao Qiao | 20 | F | 1 | NULL | 1 | Song Jiang | 45 | M || 22 | Xiao Qiao | 20 | F | 1 | NULL | 2 | Zhang Sanfeng | 94 | M || 22 | Xiao Qiao | 20 | F | 1 | NULL | 3 | Miejue Shitai | 77 | F || 22 | Xiao Qiao | 20 | F | 1 | NULL | 4 | Lin Chaoying | 93 | F || 23 | Ma Chao | 23 | M | 4 | NULL | 1 | Song Jiang | 45 | M || 23 | Ma Chao | 23 | M | 4 | NULL | 2 | Zhang Sanfeng | 94 | M || 23 | Ma Chao | 23 | M | 4 | NULL | 3 | Miejue Shitai | 77 | F || 23 | Ma Chao | 23 | M | 4 | NULL | 4 | Lin Chaoying | 93 | F || 24 | Xu Xian | 27 | M | NULL | NULL | 1 | Song Jiang | 45 | M || 24 | Xu Xian | 27 | M | NULL | NULL | 2 | Zhang Sanfeng | 94 | M || 24 | Xu Xian | 27 | M | NULL | NULL | 3 | Miejue Shitai | 77 | F || 24 | Xu Xian | 27 | M | NULL | NULL | 4 | Lin Chaoying | 93 | F || 25 | Sun Dasheng | 100 | M | NULL | NULL | 1 | Song Jiang | 45 | M || 25 | Sun Dasheng | 100 | M | NULL | NULL | 2 | Zhang Sanfeng | 94 | M || 25 | Sun Dasheng | 100 | M | NULL | NULL | 3 | Miejue Shitai | 77 | F || 25 | Sun Dasheng | 100 | M | NULL | NULL | 4 | Lin Chaoying | 93 | F |+-------+---------------+-----+--------+---------+-----------+-----+---------------+-----+--------+100 rows in set (0.00 sec)意义不大：生产一般不用 两表交集内连接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105先查看两表的记录 学生表MariaDB [hellodb]&gt; select * from students;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 3 | Xie Yanke | 53 | M | 2 | 16 || 4 | Ding Dian | 32 | M | 4 | 4 || 5 | Yu Yutong | 26 | M | 3 | 1 || 6 | Shi Qing | 46 | M | 5 | NULL || 7 | Xi Ren | 19 | F | 3 | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL || 15 | Duan Yu | 19 | M | 4 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL || 20 | Diao Chan | 19 | F | 7 | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL || 23 | Ma Chao | 23 | M | 4 | NULL || 24 | Xu Xian | 27 | M | NULL | NULL || 25 | Sun Dasheng | 100 | M | NULL | NULL |+-------+---------------+-----+--------+---------+-----------+25 rows in set (0.00 sec) 讲师表MariaDB [hellodb]&gt; select * from teachers;+-----+---------------+-----+--------+| TID | Name | Age | Gender |+-----+---------------+-----+--------+| 1 | Song Jiang | 45 | M || 2 | Zhang Sanfeng | 94 | M || 3 | Miejue Shitai | 77 | F || 4 | Lin Chaoying | 93 | F |+-----+---------------+-----+--------+4 rows in set (0.00 sec)学生表中的TeacherID和讲师表中的TID，可以作为交集的相等记录语法1：MariaDB [hellodb]&gt; select * from students,teachers where students.teacherid=teachers.tid;+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F |+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+3 rows in set (0.00 sec)语法2：内连接inner join ..onMariaDB [hellodb]&gt; select * from students inner join teachers on students.teacherid=teachers.tid;+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+| 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 25 | Sun Dasheng | 100 | M | NULL | 1 | 1 | Song Jiang | 45 | M || 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F |+-------+-------------+-----+--------+---------+-----------+-----+---------------+-----+--------+4 rows in set (0.01 sec)可以将内连接后的查询结果再次进行查询（name 在此句中出现了两次，要指定表名）MariaDB [hellodb]&gt; select stuid,students.name,tid,teachers.name from students inner join teachers on students.teacherid=teachers.tid;+-------+-------------+-----+---------------+| stuid | name | tid | name |+-------+-------------+-----+---------------+| 5 | Yu Yutong | 1 | Song Jiang || 25 | Sun Dasheng | 1 | Song Jiang || 1 | Shi Zhongyu | 3 | Miejue Shitai || 4 | Ding Dian | 4 | Lin Chaoying |+-------+-------------+-----+---------------+4 rows in set (0.00 sec)此时虽然已经查询到了，但是为了区分name的含义，可以考虑添加别名MariaDB [hellodb]&gt; select stuid,students.name as 学生姓名,tid,teachers.name as 老师名字 from students inner join teachers on students.teacherid=teachers.tid;+-------+--------------+-----+---------------+| stuid | 学生姓名 | tid | 老师名字 |+-------+--------------+-----+---------------+| 5 | Yu Yutong | 1 | Song Jiang || 25 | Sun Dasheng | 1 | Song Jiang || 1 | Shi Zhongyu | 3 | Miejue Shitai || 4 | Ding Dian | 4 | Lin Chaoying |+-------+--------------+-----+---------------+4 rows in set (0.00 sec)为了简化也可以给表起别名MariaDB [hellodb]&gt; select stuid,s.name as student_name,tid,t.name teacher_name from students as s inner join teachers t on s.teacherid=t.tid;+-------+--------------+-----+---------------+| stuid | student_name | tid | teacher_name |+-------+--------------+-----+---------------+| 5 | Yu Yutong | 1 | Song Jiang || 25 | Sun Dasheng | 1 | Song Jiang || 1 | Shi Zhongyu | 3 | Miejue Shitai || 4 | Ding Dian | 4 | Lin Chaoying |+-------+--------------+-----+---------------+4 rows in set (0.00 sec) 取a表的所有记录，b表取于a表相同条件的记录 外连接1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950左外连接left outer join MariaDB [hellodb]&gt; select * from students as s left outer join teachers t on s.teacherid=t.tid;+-------+---------------+-----+--------+---------+-----------+------+---------------+------+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+---------------+-----+--------+---------+-----------+------+---------------+------+--------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 2 | Shi Potian | 22 | M | 1 | 7 | NULL | NULL | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 | NULL | NULL | NULL | NULL || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F || 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 6 | Shi Qing | 46 | M | 5 | NULL | NULL | NULL | NULL | NULL || 7 | Xi Ren | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL | NULL | NULL | NULL | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL | NULL | NULL | NULL | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | NULL | NULL | NULL | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL | NULL | NULL | NULL | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL | NULL | NULL | NULL | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL | NULL | NULL | NULL | NULL || 15 | Duan Yu | 19 | M | 4 | NULL | NULL | NULL | NULL | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL | NULL | NULL | NULL | NULL || 17 | Lin Chong | 25 | M | 4 | NULL | NULL | NULL | NULL | NULL || 18 | Hua Rong | 23 | M | 7 | NULL | NULL | NULL | NULL | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL | NULL | NULL | NULL | NULL || 20 | Diao Chan | 19 | F | 7 | NULL | NULL | NULL | NULL | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL | NULL | NULL | NULL | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL | NULL | NULL | NULL | NULL || 23 | Ma Chao | 23 | M | 4 | NULL | NULL | NULL | NULL | NULL || 24 | Xu Xian | 27 | M | NULL | NULL | NULL | NULL | NULL | NULL || 25 | Sun Dasheng | 100 | M | NULL | 1 | 1 | Song Jiang | 45 | M |+-------+---------------+-----+--------+---------+-----------+------+---------------+------+--------+25 rows in set (0.00 sec)右外链接right outer joinMariaDB [hellodb]&gt; select * from students as s right outer join teachers t on s.teacherid=t.tid;+-------+-------------+------+--------+---------+-----------+-----+---------------+-----+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+-------------+------+--------+---------+-----------+-----+---------------+-----+--------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F || 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 25 | Sun Dasheng | 100 | M | NULL | 1 | 1 | Song Jiang | 45 | M || NULL | NULL | NULL | NULL | NULL | NULL | 2 | Zhang Sanfeng | 94 | M |+-------+-------------+------+--------+---------+-----------+-----+---------------+-----+--------+5 rows in set (0.00 sec)左外连接和右外连接 ，表的左右顺序很重要 左外连接 变种：排除交集和b表将右边的表全部不显示，仅显示a表中和b表不相同的记录123456789101112131415161718192021222324252627282930313233343536MariaDB [hellodb]&gt; select * from students as s left outer join teachers t on s.teacherid=t.tid where t.tid is null;+-------+---------------+-----+--------+---------+-----------+------+------+------+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+---------------+-----+--------+---------+-----------+------+------+------+--------+| 2 | Shi Potian | 22 | M | 1 | 7 | NULL | NULL | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 | NULL | NULL | NULL | NULL || 6 | Shi Qing | 46 | M | 5 | NULL | NULL | NULL | NULL | NULL || 7 | Xi Ren | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL | NULL | NULL | NULL | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL | NULL | NULL | NULL | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | NULL | NULL | NULL | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL | NULL | NULL | NULL | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL | NULL | NULL | NULL | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL | NULL | NULL | NULL | NULL || 15 | Duan Yu | 19 | M | 4 | NULL | NULL | NULL | NULL | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL | NULL | NULL | NULL | NULL || 17 | Lin Chong | 25 | M | 4 | NULL | NULL | NULL | NULL | NULL || 18 | Hua Rong | 23 | M | 7 | NULL | NULL | NULL | NULL | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL | NULL | NULL | NULL | NULL || 20 | Diao Chan | 19 | F | 7 | NULL | NULL | NULL | NULL | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL | NULL | NULL | NULL | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL | NULL | NULL | NULL | NULL || 23 | Ma Chao | 23 | M | 4 | NULL | NULL | NULL | NULL | NULL || 24 | Xu Xian | 27 | M | NULL | NULL | NULL | NULL | NULL | NULL |+-------+---------------+-----+--------+---------+-----------+------+------+------+--------+21 rows in set (0.01 sec)右外连接的 变种MariaDB [hellodb]&gt; select * from students as s right outer join teachers t on s.teacherid=t.tid where s.teacherid is null;+-------+------+------+--------+---------+-----------+-----+---------------+-----+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+------+------+--------+---------+-----------+-----+---------------+-----+--------+| NULL | NULL | NULL | NULL | NULL | NULL | 2 | Zhang Sanfeng | 94 | M |+-------+------+------+--------+---------+-----------+-----+---------------+-----+--------+1 row in set (0.00 sec) 子查询查询语句中嵌入另外的语句查询123456789101112131415161718192021222324252627282930313233范例：查询老师年龄大于学生平均年龄的老师列表 查询学生的平均年龄MariaDB [hellodb]&gt; select avg(age) from students;+----------+| avg(age) |+----------+| 27.4000 |+----------+1 row in set (0.00 sec)查看老师的表MariaDB [hellodb]&gt; select * from teachers;+-----+---------------+-----+--------+| TID | Name | Age | Gender |+-----+---------------+-----+--------+| 1 | Song Jiang | 45 | M || 2 | Zhang Sanfeng | 94 | M || 3 | Miejue Shitai | 77 | F || 4 | Lin Chaoying | 93 | F |+-----+---------------+-----+--------+4 rows in set (0.00 sec)查询老师年龄大于学生平均年龄的老师列表MariaDB [hellodb]&gt; select * from teachers where age &gt; (select avg(age) from students);+-----+---------------+-----+--------+| TID | Name | Age | Gender |+-----+---------------+-----+--------+| 1 | Song Jiang | 45 | M || 2 | Zhang Sanfeng | 94 | M || 3 | Miejue Shitai | 77 | F || 4 | Lin Chaoying | 93 | F |+-----+---------------+-----+--------+4 rows in set (0.00 sec) 完全外连接12345678910111213141516171819202122232425262728293031323334353637383940full outer joinmysql数据库不支持变相逻辑实现使用左外连接和右外连接实现MariaDB [hellodb]&gt; select * from students as s left outer join teachers t on s.teacherid=t.tid -&gt; union -&gt; select * from students as s right outer join teachers t on s.teacherid=t.tid;+-------+---------------+------+--------+---------+-----------+------+---------------+------+--------+| StuID | Name | Age | Gender | ClassID | TeacherID | TID | Name | Age | Gender |+-------+---------------+------+--------+---------+-----------+------+---------------+------+--------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 | 3 | Miejue Shitai | 77 | F || 2 | Shi Potian | 22 | M | 1 | 7 | NULL | NULL | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 | NULL | NULL | NULL | NULL || 4 | Ding Dian | 32 | M | 4 | 4 | 4 | Lin Chaoying | 93 | F || 5 | Yu Yutong | 26 | M | 3 | 1 | 1 | Song Jiang | 45 | M || 6 | Shi Qing | 46 | M | 5 | NULL | NULL | NULL | NULL | NULL || 7 | Xi Ren | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL | NULL | NULL | NULL | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL | NULL | NULL | NULL | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | NULL | NULL | NULL | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL | NULL | NULL | NULL | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL | NULL | NULL | NULL | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL | NULL | NULL | NULL | NULL || 15 | Duan Yu | 19 | M | 4 | NULL | NULL | NULL | NULL | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL | NULL | NULL | NULL | NULL || 17 | Lin Chong | 25 | M | 4 | NULL | NULL | NULL | NULL | NULL || 18 | Hua Rong | 23 | M | 7 | NULL | NULL | NULL | NULL | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL | NULL | NULL | NULL | NULL || 20 | Diao Chan | 19 | F | 7 | NULL | NULL | NULL | NULL | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL | NULL | NULL | NULL | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL | NULL | NULL | NULL | NULL || 23 | Ma Chao | 23 | M | 4 | NULL | NULL | NULL | NULL | NULL || 24 | Xu Xian | 27 | M | NULL | NULL | NULL | NULL | NULL | NULL || 25 | Sun Dasheng | 100 | M | NULL | 1 | 1 | Song Jiang | 45 | M || NULL | NULL | NULL | NULL | NULL | NULL | 2 | Zhang Sanfeng | 94 | M |+-------+---------------+------+--------+---------+-----------+------+---------------+------+--------+26 rows in set (0.00 sec) 仅去除交集:两个都有的去除123456789101112131415161718192021222324252627282930313233MariaDB [hellodb]&gt; select * from (select stuid,s.name as student_name,s.age as student_age,s.gender as student_gender ,classid,teacherid,tid,t.name as teacher_name,t.age as teacher_age,t.gender as teacher_gedner -&gt; from students as s left outer join teachers t on s.teacherid=t.tid -&gt; union -&gt; select stuid,s.name,s.age,s.gender,classid,teacherid,tid,t.name,t.age,t.gender -&gt; from students as s right outer join teachers t on s.teacherid=t.tid) -&gt; as f where f.teacherid is null or f.tid is null;+-------+---------------+-------------+----------------+---------+-----------+------+---------------+-------------+----------------+| stuid | student_name | student_age | student_gender | classid | teacherid | tid | teacher_name | teacher_age | teacher_gedner |+-------+---------------+-------------+----------------+---------+-----------+------+---------------+-------------+----------------+| 2 | Shi Potian | 22 | M | 1 | 7 | NULL | NULL | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 | NULL | NULL | NULL | NULL || 6 | Shi Qing | 46 | M | 5 | NULL | NULL | NULL | NULL | NULL || 7 | Xi Ren | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 8 | Lin Daiyu | 17 | F | 7 | NULL | NULL | NULL | NULL | NULL || 9 | Ren Yingying | 20 | F | 6 | NULL | NULL | NULL | NULL | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL | NULL | NULL | NULL | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL | NULL | NULL | NULL | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL | NULL | NULL | NULL | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL | NULL | NULL | NULL | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL | NULL | NULL | NULL | NULL || 15 | Duan Yu | 19 | M | 4 | NULL | NULL | NULL | NULL | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL | NULL | NULL | NULL | NULL || 17 | Lin Chong | 25 | M | 4 | NULL | NULL | NULL | NULL | NULL || 18 | Hua Rong | 23 | M | 7 | NULL | NULL | NULL | NULL | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL | NULL | NULL | NULL | NULL || 20 | Diao Chan | 19 | F | 7 | NULL | NULL | NULL | NULL | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL | NULL | NULL | NULL | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL | NULL | NULL | NULL | NULL || 23 | Ma Chao | 23 | M | 4 | NULL | NULL | NULL | NULL | NULL || 24 | Xu Xian | 27 | M | NULL | NULL | NULL | NULL | NULL | NULL || NULL | NULL | NULL | NULL | NULL | NULL | 2 | Zhang Sanfeng | 94 | M |+-------+---------------+-------------+----------------+---------+-----------+------+---------------+-------------+----------------+22 rows in set (0.00 sec) 定义的char(3) 是三个字符的意思，非字节 不同的字符所占的字节是不同的。 ASCII码： 一个英文字母（不分大小写）占一个字节的空间，一个中文汉字占两个字节的空间。一个二进制数字序列，在计算机中作为一个数字单元，一般为8位二进制数，换算为十进制。最小值0，最大值255。如一个ASCII码就是一个字节。 UTF-8编码： 一个英文字符等于一个字节，一个中文（含繁体）等于三个字节。 Unicode编码： 一个英文等于两个字节，一个中文（含繁体）等于两个字节。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之select单表操作]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E4%B9%8Bselect%E5%8D%95%E8%A1%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[mysql之select单表操作 DQL语句 select 查询挑选字段来显示列的过滤12345678910111213141516171819202122232425查询所有的字段信息：代表从student这个表中查询所有字段select * from student;挑选字段显示（定义显示的顺序由自己定义）MariaDB [studentdb]&gt; select id,name,age from student;+----+---------+------+| id | name | age |+----+---------+------+| 1 | aaaa | 30 || 2 | daizhe | 20 || 3 | laowang | 18 |+----+---------+------+3 rows in set (0.00 sec)将显示的字段名称加以别名：此场景适用于挑选的字段过长，或者将字母转换为中文显示MariaDB [studentdb]&gt; select name as 姓名,age from student;+---------+------+| 姓名 | age |+---------+------+| aaaa | 30 || daizhe | 20 || laowang | 18 |+---------+------+3 rows in set (0.01 sec) 挑选特定的行来显示行的过滤123456789101112131415161718192021222324252627282930313233343536范例：查看年龄为25岁以上的学员信息MariaDB [studentdb]&gt; select * from student where age &gt; 25;+----+------+------+------+-------+---------+| id | name | sex | age | phone | address |+----+------+------+------+-------+---------+| 1 | aaaa | m | 30 | 10086 | beijing |+----+------+------+------+-------+---------+1 row in set (0.00 sec)范例：查看年龄大于等于25 小于等于28方法1：MariaDB [studentdb]&gt; select * from student where age &gt;= 25 and age &lt;= 28;方法2：between 在什么之间MariaDB [studentdb]&gt; select * from student where age between 25 and 28;范例：查询年龄等于20 和等于30的人MariaDB [studentdb]&gt; select * from student where age in (20,30);+----+--------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+----------+| 1 | aaaa | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan |+----+--------+------+------+-------+----------+2 rows in set (0.00 sec)范例：查询班级表中手机号未知的人MariaDB [studentdb]&gt; select * from student where phone is null;范例：查询班级手机号不为空的人MariaDB [studentdb]&gt; select * from student where phone is not null;+----+--------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+--------+------+------+-------+----------+| 1 | aaaa | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan |+----+--------+------+------+-------+----------+ 模糊匹配12345678910111213范例：包含a字母的人的姓名MariaDB [studentdb]&gt; select * from student where name like '%a%';+----+---------+------+------+-------+----------+| id | name | sex | age | phone | address |+----+---------+------+------+-------+----------+| 1 | aaaa | m | 30 | 10086 | beijing || 2 | daizhe | m | 20 | 10010 | tangshan || 3 | laowang | m | 18 | NULL | tangshan |+----+---------+------+------+-------+----------+3 rows in set (0.00 sec)范例：以a开头的人的姓名MariaDB [studentdb]&gt; select * from student where name like 'a%'; 正则表达式rlike:正则表达式，索引失效，不建议使用12345678范例：使用正则表达式，匹配以a开头的人姓名MariaDB [studentdb]&gt; select * from student where name rlike '^a';+----+------+------+------+-------+---------+| id | name | sex | age | phone | address |+----+------+------+------+-------+---------+| 1 | aaaa | m | 30 | 10086 | beijing |+----+------+------+------+-------+---------+1 row in set (0.00 sec) 如果执行结果由报警可以执行show warnings; 查看报警信息 去重distinct12345678范例：显示所有的性别，但不显示重复的性别信息MariaDB [studentdb]&gt; select distinct sex from student;+------+| sex |+------+| m |+------+1 row in set (0.00 sec) 范例：将范例数据信息导入数据库12345678910111213141516171819[root@centos7 ~]# mysql &lt; hellodb_innodb.sql MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| hellodb |MariaDB [hellodb]&gt; show tables;+-------------------+| Tables_in_hellodb |+-------------------+| classes || coc || courses || scores || students || teachers || toc |+-------------------+ group分组1234567891011121314151617181920212223242526272829范例：统计一下班内所有的男生的平均年龄和女生的平均年龄 按性别分组 显示整个表有多少条记录MariaDB [hellodb]&gt; select count(*) from students;+----------+| count(*) |+----------+| 25 |+----------+ 按性别统计男生的个数和女生的个数 (gender是字段性别的意思)MariaDB [hellodb]&gt; select gender as 性别,count(*) as 人数 from students group by gender;+--------+--------+| 性别 | 人数 |+--------+--------+| F | 10 || M | 15 |+--------+--------+统计平均年龄：函数 avgMariaDB [hellodb]&gt; select gender,avg(age) from students group by gender;+--------+----------+| gender | avg(age) |+--------+----------+| F | 19.0000 || M | 33.0000 |+--------+----------+注意：后面 跟了group by 子句 ，在select 后面仅能出现两种内容，分组字段本身和聚合函数 having123456789101112131415161718仅统计男生的平均年龄（在group by 后面加条件不能使用where 要使用having 来判断条件） 先分组再过滤（先分完组再进行过滤）MariaDB [hellodb]&gt; select gender,avg(age) from students group by gender having gender = 'M';+--------+----------+| gender | avg(age) |+--------+----------+| M | 33.0000 |+--------+----------+1 row in set (0.00 sec) 先过滤再分组(从过滤出的结果中再分组)MariaDB [hellodb]&gt; select gender,avg(age) from students where gender= 'M' group by gender;+--------+----------+| gender | avg(age) |+--------+----------+| M | 33.0000 |+--------+----------+1 row in set (0.00 sec) 多次分组12345678910111213141516171819202122范例：针对不同性别不班级分别统计，每个班不同性别的最大年龄比如：一般的男生最大年龄，一般的女生的最大年龄，二班的男生的最大年龄和最大女生的年龄...max（）函数MariaDB [hellodb]&gt; select classid,gender,max(age) from students group by classid,gender;+---------+--------+----------+| classid | gender | max(age) |+---------+--------+----------+| NULL | M | 100 || 1 | F | 20 || 1 | M | 22 || 2 | M | 53 || 3 | F | 19 || 3 | M | 26 || 4 | M | 32 || 5 | M | 46 || 6 | F | 22 || 6 | M | 23 || 7 | F | 19 || 7 | M | 23 |+---------+--------+----------+ order by根据指定的字段对查询结果进行排序1234567891011121314151617181920212223242526272829303132333435363738394041排序：默认为从小到大排序范例：拿学生的年龄进行排序MariaDB [hellodb]&gt; select * from students order by age;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 8 | Lin Daiyu | 17 | F | 7 | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL |倒序排：从大到小排序MariaDB [hellodb]&gt; select * from students order by age desc;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 25 | Sun Dasheng | 100 | M | NULL | NULL || 3 | Xie Yanke | 53 | M | 2 | 16 || 6 | Shi Qing | 46 | M | 5 | NULL || 13 | Tian Boguang | 33 | M | 2 | NULL |排序完可以查看年龄最小的3个MariaDB [hellodb]&gt; select * from students order by age limit 3;+-------+-------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+-------------+-----+--------+---------+-----------+| 8 | Lin Daiyu | 17 | F | 7 | NULL || 14 | Lu Wushuang | 17 | F | 3 | NULL || 19 | Xue Baochai | 18 | F | 6 | NULL |+-------+-------------+-----+--------+---------+-----------+跳过前第3个取后续4个ariaDB [hellodb]&gt; select * from students order by age limit 3,4;+-------+--------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+--------------+-----+--------+---------+-----------+| 12 | Wen Qingqing | 19 | F | 1 | NULL || 10 | Yue Lingshan | 19 | F | 3 | NULL || 7 | Xi Ren | 19 | F | 3 | NULL || 15 | Duan Yu | 19 | M | 4 | NULL |+-------+--------------+-----+--------+---------+-----------+ 多列排序12345678910111213141516171819202122232425范例：先按班级排序，如果同一个班，再班级相同的情况下，在对年龄排序（班级为正序，年龄为倒序）MariaDB [hellodb]&gt; select * from students order by classid ,age desc;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 25 | Sun Dasheng | 100 | M | NULL | NULL || 24 | Xu Xian | 27 | M | NULL | NULL || 2 | Shi Potian | 22 | M | 1 | 7 || 16 | Xu Zhu | 21 | M | 1 | NULL || 22 | Xiao Qiao | 20 | F | 1 | NULL | 空值的优先级高，可以使得null值，放到最后MariaDB [hellodb]&gt; select * from students order by -classid desc;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 2 | Shi Potian | 22 | M | 1 | 7 || 22 | Xiao Qiao | 20 | F | 1 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 12 | Wen Qingqing | 19 | F | 1 | NULL |.......| 8 | Lin Daiyu | 17 | F | 7 | NULL || 24 | Xu Xian | 27 | M | NULL | NULL || 25 | Sun Dasheng | 100 | M | NULL | NULL |+-------+---------------+-----+--------+---------+-----------+ 练习：12345678910111213141516171819202122232425262728293031323334353637(2) 以ClassID为分组依据，显示每组的平均年龄 (3) 显示第2题中平均年龄大于30的分组及平均年龄 MariaDB [hellodb]&gt; select classid,avg(age) from students group by classd having avg(age) &gt; 30;+---------+----------+| classid | avg(age) |+---------+----------+| NULL | 63.5000 || 2 | 36.0000 || 5 | 46.0000 |+---------+----------+3 rows in set (0.00 sec)(7) 查询年龄大于等于20岁，小于等于25岁的同学的信方法1：MariaDB [hellodb]&gt; select * from students where age between 20 and 25;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 9 | Ren Yingying | 20 | F | 6 | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL || 21 | Huang Yueying | 22 | F | 6 | NULL |方法2：MariaDB [hellodb]&gt; select * from students where age &gt;=20 and age &lt;=25;+-------+---------------+-----+--------+---------+-----------+| StuID | Name | Age | Gender | ClassID | TeacherID |+-------+---------------+-----+--------+---------+-----------+| 1 | Shi Zhongyu | 22 | M | 2 | 3 || 2 | Shi Potian | 22 | M | 1 | 7 || 9 | Ren Yingying | 20 | F | 6 | NULL || 11 | Yuan Chengzhi | 23 | M | 6 | NULL || 16 | Xu Zhu | 21 | M | 1 | NULL || 17 | Lin Chong | 25 | M | 4 | NULL || 18 | Hua Rong | 23 | M | 7 | NULL |]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库和表管理理论及实操]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E8%A1%A8%E7%AE%A1%E7%90%86%E7%90%86%E8%AE%BA%E5%8F%8A%E5%AE%9E%E6%93%8D%2F</url>
    <content type="text"><![CDATA[mysql数据库和表管理理论及实操 理论数据库操作创建数据库：&ensp;&ensp;CREATE DATABASE|SCHEMA [IF NOT EXISTS] ‘DB_NAME’;&ensp;&ensp;CHARACTER SET ‘character set name’&ensp;&ensp;COLLATE ‘collate name’删除数据库&ensp;&ensp;DROP DATABASE|SCHEMA [IF EXISTS] ‘DB_NAME’;查看支持所有字符集：&ensp;&ensp;SHOW CHARACTER SET;查看支持所有排序规则：&ensp;&ensp;SHOW COLLATION;获取命令使用帮助：&ensp;&ensp;mysql&gt; HELP KEYWORD;查看数据库列表：&ensp;&ensp;mysql&gt; SHOW DATABASES; 表表：二维关系设计表：遵循规范定义：字段，索引&ensp;&ensp;字段：字段名，字段数据类型，修饰符&ensp;&ensp;约束，索引：应该创建在经常用作查询条件的字段上 创建表创建表：CREATE TABLE(1) 直接创建(2) 通过查询现存表创建；新表会被直接插入查询而来的数据&ensp;&ensp;CREATE [TEMPORARY临时表] TABLE [IF NOT EXISTS存在则不创建] tbl_name [(create_definition,…)创建表的定义] [table_options] [partition_options] select_statement(3) 通过复制现存的表的表结构创建，但不复制数据&ensp;&ensp;CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name { LIKE old_tbl_name | (LIKE old_tbl_name) }注意：&ensp;&ensp;Storage Engine是指表类型，也即在表创建时指明其使用的存储引擎，同一 库中不同表可以使用不同的存储引擎&ensp;&ensp;同一个库中表建议要使用同一种存储引擎类型 CREATE TABLE [IF NOT EXISTS] ‘tbl_name’ (col1 type1 修饰符, col2 type2 修饰符, …)字段信息&ensp;&ensp;col type1&ensp;&ensp;PRIMARY KEY(col1,…)&ensp;&ensp;INDEX(col1, …)&ensp;&ensp;UNIQUE KEY(col1, …)表选项：ENGINE [=] engine_name&ensp;&ensp;SHOW ENGINES;查看支持的engine类型ROW_FORMAT [=] {DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT| COMPACT}获取帮助：mysql&gt; HELP CREATE TABLE; 表操作查看所有的引擎：SHOW ENGINES查看表：SHOW TABLES [FROM db_name]查看表结构：DESC [db_name.]tb_name删除表：DROP TABLE [IF EXISTS] tb_name查看表创建命令：SHOW CREATE TABLE tbl_name查看表状态：SHOW TABLE STATUS LIKE ‘tbl_name’查看库中所有表状态：SHOW TABLE STATUS FROM db_name 数据类型数据类型：&ensp;&ensp;数据长什么样&ensp;&ensp;数据需要多少空间来存放 系统内置数据类型和用户定义数据类型MySql支持多种列类型：&ensp;&ensp;数值类型&ensp;&ensp;日期/时间类型&ensp;&ensp;字符串(字符)类型&ensp;&ensp;https://dev.mysql.com/doc/refman/5.5/en/data-types.html 选择正确的数据类型对于获得高性能至关重要，三大原则：&ensp;&ensp;更小的通常更好，尽量使用可正确存储数据的最小数据类型&ensp;&ensp;简单就好，简单数据类型的操作通常需要更少的CPU周期&ensp;&ensp;尽量避免NULL，包含为NULL的列，对MySQL更难优化 数据类型1、整型&ensp;&ensp;tinyint(m) 1个字节 范围(-128~127)&ensp;&ensp;smallint(m) 2个字节 范围(-32768~32767)&ensp;&ensp;mediumint(m) 3个字节 范围(-8388608~8388607)&ensp;&ensp;int(m) 4个字节 范围(-2147483648~2147483647)&ensp;&ensp;bigint(m) 8个字节 范围(+-9.22*10的18次方)加了unsigned，则最大值翻倍，如：tinyint unsigned的取值范围为(0~255) int(m)里的m是表示SELECT查询结果集中的显示宽度，并不影响实际的取值范 围，规定了MySQL的一些交互工具（例如MySQL命令行客户端）用来显示字符 的个数。对于存储和计算来说，Int(1)和Int(20)是相同的BOOL，BOOLEAN：布尔型，是TINYINT(1)的同义词。zero值被视为假， 非zero值视为真 2、浮点型(float和double)，近似值&ensp;&ensp;float(m,d) 单精度浮点型 8位精度(4字节) m总个数，d小数位&ensp;&ensp;double(m,d) 双精度浮点型16位精度(8字节) m总个数，d小数位&ensp;&ensp;设一个字段定义为float(6,3)，如果插入一个数123.45678,实际数据库里存 的是123.457，但总个数还以实际为准，即6位 3、定点数&ensp;&ensp;在数据库中存放的是精确值,存为十进制&ensp;&ensp;decimal(m,d) 参数m&lt;65 是总个数，d&lt;30且 d&lt;m 是小数位&ensp;&ensp;MySQL5.0和更高版本将数字打包保存到一个二进制字符串中（每4个字节存 9个数字）。例如，decimal(18,9)小数点两边将各存储9个数字，一共使用9 个字节：小数点前的数字用4个字节，小数点后的数字用4个字节，小数点本 身占1个字节浮点类型在存储同样范围的值时，通常比decimal使用更少的空间。float使 用4个字节存储。double占用8个字节&ensp;&ensp;因为需要额外的空间和计算开销，所以应该尽量只在对小数进行精确计算时 才使用decimal——例如存储财务数据。但在数据量比较大的时候，可以考 虑使用bigint代替decimal 4、字符串(char,varchar,_text)&ensp;&ensp;char(n) 固定长度，最多255个字符&ensp;&ensp;varchar(n) 可变长度，最多65535个字符&ensp;&ensp;tinytext 可变长度，最多255个字符&ensp;&ensp;text 可变长度，最多65535个字符&ensp;&ensp;mediumtext 可变长度，最多2的24次方-1个字符&ensp;&ensp;longtext 可变长度，最多2的32次方-1个字符&ensp;&ensp;BINARY(M) 固定长度，可存二进制或字符，长度为0-M字节&ensp;&ensp;VARBINARY(M) 可变长度，可存二进制或字符，允许长度为0-M字节&ensp;&ensp;内建类型：ENUM枚举, SET集合 char和varchar：&ensp;&ensp;1.char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉， 所以char类型存储的字符串末尾不能有空格，varchar不限于此&ensp;&ensp;2.char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar 是存入的实际字符数+1个字节（n&lt; n&gt;255)，所以varchar(4),存入3个字符将 占用4个字节&ensp;&ensp;3.char类型的字符串检索速度要比varchar类型的快varchar和text：&ensp;&ensp;1.varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个 字节（n&lt; n&gt;255)，text是实际字符数+2个字节 。&ensp;&ensp;2.text类型不能有默认值&ensp;&ensp;3.varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速 度快于text 5.二进制数据：BLOB&ensp;&ensp;BLOB和text存储方式不同，TEXT以文本方式存储，英文存储区分大小写，而Blob是以二进制方式存储，不分大小写&ensp;&ensp;BLOB存储的数据只能整体读出&ensp;&ensp;TEXT可以指定字符集，BLOB不用指定字符集 6.日期时间类型&ensp;&ensp;date 日期 ‘2008-12-2’&ensp;&ensp;time 时间 ‘12:25:36’&ensp;&ensp;datetime 日期时间 ‘2008-12-2 22:06:44’&ensp;&ensp;timestamp 自动存储记录修改时间&ensp;&ensp;YEAR(2), YEAR(4)：年份timestamp字段里的时间数据会随其他字段修改的时候自动刷新，这个数 据类型的字段可以存放这条记录最后被修改的时间 修饰符所有类型：&ensp;&ensp;NULL 数据列可包含NULL值&ensp;&ensp;NOT NULL 数据列不允许包含NULL值&ensp;&ensp;DEFAULT 默认值&ensp;&ensp;PRIMARY KEY 主键&ensp;&ensp;UNIQUE KEY 唯一键&ensp;&ensp;CHARACTER SET name 指定一个字符集数值型&ensp;&ensp;AUTO_INCREMENT 自动递增，适用于整数类型&ensp;&ensp;UNSIGNED 无符号 表操作DROP TABLE [IF EXISTS] ‘tbl_name’;ALTER TABLE ‘tbl_name’&ensp;&ensp;字段：&ensp;&ensp;&ensp;&ensp;添加字段：add&ensp;&ensp;&ensp;&ensp;ADD col1 data_type [FIRST|AFTER col_name]&ensp;&ensp;&ensp;&ensp;删除字段：drop&ensp;&ensp;&ensp;&ensp;修改字段： alter（默认值）, change（字段名）, modify（字段属性）&ensp;&ensp;索引:&ensp;&ensp;&ensp;&ensp;添加索引：add index&ensp;&ensp;&ensp;&ensp;删除索引：drop index&ensp;&ensp;表选项&ensp;&ensp;&ensp;&ensp;修改:查看表上的索引：SHOW INDEXES FROM [db_name.]tbl_name;查看帮助：Help ALTER TABLE 修改表示例ALTER TABLE students ADD gender ENUM(‘m’,’f’)ALETR TABLE students CHANGE id sid int UNSIGNED NOT NULL PRIMARY KEY;ALTER TABLE students ADD UNIQUE KEY(name);ALTER TABLE students ADD INDEX(age);DESC students;SHOW INDEXES FROM students;ALTER TABLE students DROP age; DML语句DML: INSERT增加, DELETE删除, UPDATE 修改INSERT：一次插入一行或多行数据语法INSERT [L OW_PRIORITY | DELAYED | HIGH_PRIORITY][IGNORE] [INTO] tbl_name [(col_name,…)]{VALUES | VALUE} ({expr | DEFAULT},…),(…),…[ ON DUPLICATE KEY UPDATE 如果重复更新之col_name=expr[, col_name=expr] … ] 简化写法： INSERT tbl_name [(col1,…)] VALUES (val1,…), (val21,…) INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]SET col_name={expr | DEFAULT}, …[ ON DUPLICATE KEY UPDATEcol_name=expr[, col_name=expr] … ] INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE][INTO] tbl_name [(col_name,…)]SELECT …[ ON DUPLICATE KEY UPDATEcol_name=expr[, col_name=expr] … ] UPDATE：UPDATE [LOW_PRIORITY] [IGNORE] table_referenceSET col_name1={expr1|DEFAULT} [, col_name2={expr2|DEFAULT}] …[WHERE where_condition][ORDER BY …][LIMIT row_count]注意：一定要有限制条件，否则将修改所有行的指定字段限制条件：WHERELIMITMysql 选项：-U|–safe-updates| –i-am-a-dummy DELETE:DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name[WHERE where_condition][ORDER BY …][LIMIT row_count]可先排序再指定删除的行数注意：一定要有限制条件，否则将清空表中的所有数据限制条件：WHERELIMITTRUNCATE TABLE tbl_name; 清空表 DQL语句SELECT[ALL | DISTINCT | DISTINCTROW ][SQL_CACHE | SQL_NO_CACHE]select_expr [, select_expr …][FROM table_references[WHERE where_condition][GROUP BY {col_name | expr | position}[ASC | DESC], … [WITH ROLLUP]][HAVING where_condition][ORDER BY {col_name | expr | position}[ASC | DESC], …][LIMIT {[offset,] row_count | row_count OFFSET offset}[FOR UPDATE | LOCK IN SHARE MODE] SELECT字段显示可以使用别名：&ensp;&ensp;col1 AS alias1, col2 AS alias2, … WHERE子句：指明过滤条件以实现“选择”的功能：&ensp;&ensp;过滤条件：布尔型表达式&ensp;&ensp;算术操作符：+, -, *, /, %1234567891011MariaDB [hellodb]&gt; select 2*3;+-----+| 2*3 |+-----+| 6 |+-----+1 row in set (0.00 sec)不等于：&lt;&gt; 或者 !=（显示学生性别不为女的）MariaDB [hellodb]&gt; select * from students where gender &lt;&gt; 'F'; &ensp;&ensp;比较操作符：=,&lt;=&gt;（相等或都为空）, &lt;&gt;, !=(非标准SQL), &gt;, &gt;=, &lt;, &lt;=&ensp;&ensp;BETWEEN min_num AND max_num&ensp;&ensp;IN (element1, element2, …)&ensp;&ensp;IS NULL&ensp;&ensp;IS NOT NULL DISTINCT 去除重复列&ensp;&ensp;SELECT DISTINCT gender FROM students; like:&ensp;&ensp;% 任意长度的任意字符&ensp;&ensp;_ 任意单个字符 RLIKE：正则表达式，索引失效，不建议使用REGEXP：匹配字符串可用正则表达式书写模式，同上逻辑操作符： NOT AND OR XO GROUP：根据指定的条件把查询结果进行“分组”以用于做“聚合”运算 avg(), max(), min(), count(), sum() 总和HAVING: 对分组聚合运算后的结果指定过滤条件 ORDER BY: 根据指定的字段对查询结果进行排序&ensp;&ensp;升序：ASC&ensp;&ensp;降序：DESCLIMIT [[offset,]row_count]：对查询的结果进行输出行数数量限制对查询结果中的数据请求施加“锁”&ensp;&ensp;FOR UPDATE: 写锁，独占或排它锁，只有一个读和写&ensp;&ensp;LOCK IN SHARE MODE: 读锁，共享锁，同时多个读 示例DESC students;INSERT INTO students VALUES(1,’tom’，’m’),(2,’alice’,’f’);INSERT INTO students(id,name) VALUES(3,’jack’),(4,’allen’);SELECT FROM students WHERE id &lt; 3;SELECT FROM students WHERE gender=’m’;SELECT FROM students WHERE gender IS NULL;SELECT FROM students WHERE gender IS NOT NULL;SELECT FROM students ORDER BY name DESC LIMIT 2;SELECT FROM students ORDER BY name DESC LIMIT 1,2;SELECT FROM students WHERE id &gt;=2 and id &lt;=4SELECT FROM students WHERE BETWEEN 2 AND 4SELECT FROM students WHERE name LIKE ‘t%’SELECT FROM students WHERE name RLIKE ‘.[lo].‘;SELECT id stuid,name as stuname FROM students 多表操作多表查询交叉连接：笛卡尔乘积内连接：&ensp;&ensp;等值连接：让表之间的字段以“等值”建立连接关系；&ensp;&ensp;不等值连接&ensp;&ensp;自然连接:去掉重复列的等值连接&ensp;&ensp;自连接外连接：&ensp;&ensp;左外连接： FROM tb1 LEFT JOIN tb2 ON tb1.col=tb2.col&ensp;&ensp;右外连接: FROM tb1 RIGHT JOIN tb2 ON tb1.col=tb2.col 子查询：在查询语句嵌套着查询语句，性能较差&ensp;&ensp;基于某语句的查询结果再次进行的查询用在WHERE子句中的子查询&ensp;&ensp;用于比较表达式中的子查询；子查询仅能返回单个值&ensp;&ensp;&ensp;&ensp;SELECT Name,Age FROM students WHERE Age&gt;(SELECT avg(Age) FROM students);&ensp;&ensp;用于IN中的子查询：子查询应该单键查询并返回一个或多个值从构成列表&ensp;&ensp;&ensp;&ensp;SELECT Name,Age FROM students WHERE Age IN (SELECT Age FROM teachers);&ensp;&ensp;用于EXISTS 多表查询用于FROM子句中的子查询使用格式：SELECT tb_alias.col1,… FROM (SELECT clause) AS tb_alias WHERE Clause; 示例： SELECT s.aage,s.ClassID FROM (SELECT avg(Age) AS aage,ClassID FROM students WHERE ClassID IS NOT NULL GROUP BY ClassID) AS s WHERE s.aage&gt;30; 联合查询：UNIONSELECT Name,Age FROM students UNION SELECT Name,Age FROM teachers; 实操创建数据库123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172查看目前已经创建好的数据库列表MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema | 特殊的数据库，并非再物理磁盘中，再内存中，再数据目录中看不到| mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)查看具体命令的帮助说明MariaDB [(none)]&gt; help create database; （如果目标数据库不存在，则创建，如果存在则不创建）创建数据库MariaDB [(none)]&gt; cerate database +数据库名查看系统支持的字符集MariaDB [(none)]&gt; show character set;创建数据库（数据库，表的集合）MariaDB [(none)]&gt; create database testdb;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || testdb |+--------------------+5 rows in set (0.00 sec)[root@centos7 ~]# cat /var/lib/mysql/testdb/db.opt default-character-set=latin1 默认的字符集default-collation=latin1_swedish_ci 排序规则查看系统自带的排序规则MariaDB [(none)]&gt; show collation;+--------------------------+----------+-----+---------+----------+---------+| Collation | Charset | Id | Default | Compiled | Sortlen |+--------------------------+----------+-----+---------+----------+---------+| big5_chinese_ci | big5 | 1 | Yes | Yes | 1 || big5_bin | big5 | 84 | | Yes | 1 |查看数据库使用的字符集MariaDB [(none)]&gt; show create database testdb;+----------+-------------------------------------------------------------------+| Database | Create Database |+----------+-------------------------------------------------------------------+| testdb | CREATE DATABASE `testdb` /*!40100 DEFAULT CHARACTER SET latin1 */ |+----------+-------------------------------------------------------------------+1 row in set (0.00 sec)创建数据库并指定此数据库使用的字符集MariaDB [(none)]&gt; create database db_utf8mb4 character set=utf8mb4;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; show create database db_utf8mb4;+------------+------------------------------------------------------------------------+| Database | Create Database |+------------+------------------------------------------------------------------------+| db_utf8mb4 | CREATE DATABASE `db_utf8mb4` /*!40100 DEFAULT CHARACTER SET utf8mb4 */ |+------------+------------------------------------------------------------------------+1 row in set (0.00 sec)[root@centos7 ~]# cat /var/lib/mysql/db_utf8mb4/db.opt default-character-set=utf8mb4default-collation=utf8mb4_general_ci 查看当前使用的信息包括字符集123456789101112131415161718192021222324MariaDB [(none)]&gt; status--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 4Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1Db characterset: latin1Client characterset: utf8Conn. characterset: utf8UNIX socket: /var/lib/mysql/mysql.sockUptime: 58 min 31 secThreads: 1 Questions: 16 Slow queries: 0 Opens: 4 Flush tables: 2 Open tables: 30 Queries per second avg: 0.004-------------- 管理数据库123456789101112131415删除数据库MariaDB [(none)]&gt; drop database testdb;Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || db_utf8mb4 || mysql || performance_schema || test |+--------------------+5 rows in set (0.00 sec) 创建表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980创建一个模拟学生信息的数据库MariaDB [(none)]&gt; create database studentdb;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; use studentdbDatabase changedMariaDB [studentdb]&gt; create table student (id int unsigned auto_increment primary key,name varchar(10) not null,sex enum('f','m') default 'm',age tinyint unsigned ,phone char(11),address varchar(50));Query OK, 0 rows affected (0.02 sec)查看创建的表结构方法1：MariaDB [studentdb]&gt; desc student;+---------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(10) | NO | | NULL | || sex | enum('f','m') | YES | | m | || age | tinyint(3) unsigned | YES | | NULL | || phone | char(11) | YES | | NULL | || address | varchar(50) | YES | | NULL | |+---------+---------------------+------+-----+---------+----------------+6 rows in set (0.00 sec)方法2：MariaDB [studentdb]&gt; show columns from student;+---------+---------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+----------------+| id | int(10) unsigned | NO | PRI | NULL | auto_increment || name | varchar(10) | NO | | NULL | || sex | enum('f','m') | YES | | m | || age | tinyint(3) unsigned | YES | | NULL | || phone | char(11) | YES | | NULL | || address | varchar(50) | YES | | NULL | |+---------+---------------------+------+-----+---------+----------------+6 rows in set (0.00 sec)常看定义表的步骤即定义表的详情MariaDB [studentdb]&gt; show create table student;+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| student | CREATE TABLE `student` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `name` varchar(10) NOT NULL, `sex` enum('f','m') DEFAULT 'm', `age` tinyint(3) unsigned DEFAULT NULL, `phone` char(11) DEFAULT NULL, `address` varchar(50) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=latin1 |+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)查看表的状态MariaDB [studentdb]&gt; show table status like 'student'\G*************************** 1. row *************************** Name: student Engine: InnoDB 存储引擎 Version: 10 Row_format: Compact 紧致格式 Rows: 0 Avg_row_length: 0 Data_length: 16384Max_data_length: 0 Index_length: 0 Data_free: 10485760 Auto_increment: 1 Create_time: 2018-11-29 15:40:42 创建时间 Update_time: NULL Check_time: NULL Collation: latin1_swedish_ci 字符集 Checksum: NULL Create_options: Comment: 描述1 row in set (0.00 sec)查看当前使用的数据库中的所有的表结构SHOW TABLE STATUS FROM db_name 12345678910111213141516171819询表中是否有索引（以及索引信息）MariaDB [studentdb]&gt; show indexes from student\G*************************** 1. row *************************** Table: student Non_unique: 0 Key_name: PRIMARY 主键索引 Seq_in_index: 1 Column_name: id Collation: A Cardinality: 0 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment: Index_comment: 1 row in set (0.00 sec)建立主键自动建立索引：索引可以提高查询速度]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql源码编译多实例和数据库管理]]></title>
    <url>%2F2019%2F02%2F20%2Fmysql%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%A4%9A%E5%AE%9E%E4%BE%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql源码编译多实例和数据库管理 多实例（基于yum安装配置多实例）多用于测试环境123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327实验准备：1.基于yum安装mairiadb-server Version : 5.5.562.基于网络通讯，每个实例使用不同的端口号：3306：3307：33083.准备不同存放数据库数据文件的路径： /data/mysql/3306 /data/mysql/3307 /data/mysql/33084.将数据库程序文件单独防止 /data/mysql/3306&#123;etc,log,data,pid,bin&#125; /data/mysql/3307&#123;etc,log,data,pid,bin&#125; /data/mysql/3308&#123;etc,log,data,pid,bin&#125;范例：基于yum源安装mysql数据库第一步：安装数据库（安装好，系统默认已经创建好了账号）[root@centos7 ~]# yum install mariadb-server -y第二步：根据规划创建相应的数据文件，并修改属性（可以参照安装好的文件属性修改）[root@centos7 ~]# cd /data[root@centos7 data]# mkdir -p mysql/&#123;3306,3307,3308&#125;/&#123;etc,data,socket,log,pid,bin&#125;[root@centos7 ~]# tree /data/mysql//data/mysql/├── 3306│ ├── bin 二进制文件│ ├── data 二进制数据│ ├── etc 主配置文件│ ├── log 日志为文件│ ├── pid pid文件│ └── socket 套接字文件├── 3307│ ├── bin│ ├── data│ ├── etc│ ├── log│ ├── pid│ └── socket└── 3308 ├── bin ├── data ├── etc ├── log ├── pid └── socket[root@centos7 ~]# cd /data[root@centos7 data]# lsmysql[root@centos7 data]# chown -R mysql:mysql mysql/第三步：通过yum安装好的数据库程序脚本，生成规划好的数据库数据文件[root@centos7 ~]# /usr/bin/mysql_install_db --datadir=/data/mysql/3306/data --user=mysql[root@centos7 ~]# /usr/bin/mysql_install_db --datadir=/data/mysql/3307/data --user=mysql[root@centos7 ~]# /usr/bin/mysql_install_db --datadir=/data/mysql/3308/data --user=mysql第四步：准备相应的配置文件：并根据自定义的路径进行修改3306的主配置文件[root@centos7 ~]# cp /etc/my.cnf /data/mysql/3306/etc/[root@centos7 ~]# vim /data/mysql/3306/etc/my.cnf [mysqld]port=3306datadir=/data/mysql/3306/datasocket=/data/mysql/3306/socket/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/data/mysql/3306/log/mariadb.logpid-file=/data/mysql/3306/pid/mariadb.pid# include all files from the config directory#!includedir /etc/my.cnf.d 此行加注释3307的主配置文件(可以在vim编辑器中使用替换的功能：%s/6/8/)[root@centos7 ~]# cp /data/mysql/3306/etc/my.cnf /data/mysql/3307/etc/my.cnf[mysqld]port=3307datadir=/data/mysql/3307/datasocket=/data/mysql/3307/socket/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/data/mysql/3307/log/mariadb.logpid-file=/data/mysql/3307/pid/mariadb.pid# include all files from the config directory#!includedir /etc/my.cnf.d3308的主配置[root@centos7 ~]# cp /data/mysql/3306/etc/my.cnf /data/mysql/3308/etc/my.cnf[root@centos7 ~]# vim /data/mysql/3308/etc/my.cnf [mysqld]port=3308datadir=/data/mysql/3308/datasocket=/data/mysql/3308/socket/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemd[mysqld_safe]log-error=/data/mysql/3308/log/mariadb.logpid-file=/data/mysql/3308/pid/mariadb.pid# include all files from the config directory#!includedir /etc/my.cnf.d第五步：准备启动程序的脚本手写启动脚本[root@centos7 ~]# cat mysqld.sh #!/bin/bashport=3307mysql_user="root"mysql_basedir="/data/mysql"mysql_sock="$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting mysql...\n" $&#123;cmd_path&#125;/mysql_safe --defaults-file=$&#123;mysql_basedir&#125;/$&#123;port&#125;/etc/my.cnf &amp;&gt; /dev/null &amp; else printf "mysql is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "mysql is stopped...\n" exit else printf "stoping mysql...\n" fi&#125;function_restart_mysql()&#123; print "restarting mysql...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) print "Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n"esac修改启动脚本3306[root@centos7 ~]# cp mysqld.sh /data/mysql/3306/bin/mysqld[root@centos7 ~]# vim /data/mysql/3306/bin/mysqld[root@centos7 ~]# vim /data/mysql/3307/bin/mysqld #!/bin/bashport=3306mysql_user="root"mysql_basedir="/data/mysql"mysql_sock="$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting mysql...\n" $&#123;cmd_path&#125;/mysql_safe --defaults-file=$&#123;mysql_basedir&#125;/$&#123;port&#125;/etc/my.cnf &amp;&gt; /dev/null &amp; else printf "mysql is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "mysql is stopped...\n" exit else printf "stoping mysql...\n" fi&#125;function_restart_mysql()&#123; printf "restarting mysql...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf "Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n"esac3307[root@centos7 ~]# cp /data/mysql/3306/bin/mysqld /data/mysql/3307/bin/[root@centos7 ~]# vim /data/mysql/3307/bin/mysqld #!/bin/bashport=3307mysql_user="root"mysql_basedir="/data/mysql"mysql_sock="$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting mysql...\n" $&#123;cmd_path&#125;/mysql_safe --defaults-file=$&#123;mysql_basedir&#125;/$&#123;port&#125;/etc/my.cnf &amp;&gt; /dev/null &amp; else printf "mysql is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "mysql is stopped...\n" exit else printf "stoping mysql...\n" fi&#125;function_restart_mysql()&#123; printf "restarting mysql...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf "Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n"esac3308[root@centos7 ~]# vim /data/mysql/3308/bin/mysqld #!/bin/bashport=3308mysql_user="root"mysql_basedir="/data/mysql"mysql_sock="$&#123;mysql_basedir&#125;/$&#123;port&#125;/socket/mysql.sock"function_start_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "Starting mysql...\n" else printf "mysql is running...\n" exit fi&#125;function_stop_mysql()&#123; if [ ! -e "$mysql_sock" ];then printf "mysql is stopped...\n" exit else printf "stoping mysql...\n" fi&#125;function_restart_mysql()&#123; printf "restarting mysql...\n" function_stop_mysql sleep 2 function_start_mysql&#125;case $1 instart) function_start_mysql;;stop) function_stop_mysql;;restart) function_restart_mysql;;*) printf "Usage: $&#123;mysql_basedir&#125;/$&#123;port&#125;/bin/mysqld &#123;start|stop|restart&#125;\n"esac第六步：给执行程序添加执行权限[root@centos7 ~]# chmod +x /data/mysql/3306/bin/mysqld [root@centos7 ~]# chmod +x /data/mysql/3307/bin/mysqld [root@centos7 ~]# chmod +x /data/mysql/3308/bin/mysqld 启动：]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash收集系统日志及tomcat的json日志]]></title>
    <url>%2F2019%2F02%2F19%2FELK%E4%B9%8BLogstash%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E5%8F%8Atomcat%E7%9A%84json%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[ELK之Logstash收集系统日志json格式的tomcat日志 通过logtsash收集tomcat和java日志： 收集Tomcat服务器的访问日志以及Tomcat错误日志进行实时统计，在kibana页面进行搜索展现，每台Tomcat服务器要安装logstash负责收集日志，然后将日志转发给elasticsearch进行分析，在通过kibana在前端展现，配置过程如下： 1：安装tomcat(logstash必须和tomcat在同一台主机上才能收集tomcat的日志)12345678910111213141516171819202122232425262728293031323334验证java JDK版本信息 ~]# java -version java version "1.8.0_192" Java(TM) SE Runtime Environment (build 1.8.0_192-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.192-b12, mixed mode)安装tomcat ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# tar xvf apache-tomcat-8.5.37.tar.gz -C /usr/local/ ~]# ln -vs /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat （链接形式方便升级）tomcat不可使用root用户运行 ~]# useradd tomcat ~]# chown -R tomcat.tomcat /usr/local/tomcat/ ~]# chown -R tomcat.tomcat /usr/local/tomcat/* ~]# su - tomcat -c "/usr/local/tomcat/bin/catalina.sh start" Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/bin/default Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/u ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http）tomcat两个重要的日志文件 ~]# ll /usr/local/tomcat/logs/host-manager.2019-02-19.log #每天滚动的日志 ~]# ll /usr/local/tomcat/logs/catalina.out 2：配置编辑logstash配置文件来收集tomcat日志文件catalina.out1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 ~]# cd /etc/logstash/conf.d/ conf.d]# vim tomcatlog.conf input &#123; file &#123; path =&gt; "/usr/local/tomcat/logs/catalina.out" type =&gt; "tomcatlog" start_position =&gt; "beginning" stat_interval =&gt; "3" &#125; &#125; output &#123; if [type] == "tomcatlog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] index =&gt; "tomcat-log-%&#123;+YYYY.MM.dd&#125;" &#125;&#125; &#125;修改收集日志的权限也可以将logstash运行身份修改为root，可以在启动脚本中进行修改 ~]# vim /etc/systemd/system/logstash.service [Unit] Description=logstash [Service] Type=simple User=root Group=root EnvironmentFile=-/etc/default/logstash EnvironmentFile=-/etc/sysconfig/logstash ExecStart=/usr/share/logstash/bin/logstash "--path.settings" "/etc/logstash" Restart=always WorkingDirectory=/ Nice=19 LimitNOFILE=16384 [Install] WantedBy=multi-user.target配置文件语法检查 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/tomcatlog.conf -t重启logstash ~]# systemctl restart logstash ~]# systemctl enable logstash 3：web界面确认tomcat可以访问 4:将日志索引在kibana中进行图形化展示 5:查看是否记录数据 将tomcat的日志格式打印为json格式1：将tomcat的日志修改为json格式的日志格式 12345678910111213141516171819202122232425262728编辑tomcat的主配置文件 ~]# vim /etc/tomcat/server.xml 137~140源文件 &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; 修改为 &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="tomcat_access_log" suffix=".log" pattern="&#123;&amp;quot;clientip&amp;quot;:&amp;quot;%h&amp;quot;,&amp;quot;ClientUser&amp;quot;:&amp;quot;%l&amp;quot;,&amp;quot;authenticated&amp;quot;:&amp;quot;%u&amp;quot;,&amp;quot;AccessTime&amp;quot;:&amp;quot;%t&amp;quot;,&amp;quot;method&amp;quot;:&amp;quot;%r&amp;quot;,&amp;quot;status&amp;quot;:&amp;quot;%s&amp;quot;,&amp;quot;SendBytes&amp;quot;:&amp;quot;%b&amp;quot;,&amp;quot;Query?string&amp;quot;:&amp;quot;%q&amp;quot;,&amp;quot;partner&amp;quot;:&amp;quot;%&#123;Referer&#125;i&amp;quot;,&amp;quot;AgentVersion&amp;quot;:&amp;quot;%&#123;User-Agent&#125;i&amp;quot;&#125;"/&gt;重启启动tomcat并访问tomcat页面查看是否生成日志 ~]# systemctl resatrt tomcat 访问tomcat ~]# curl 172.20.101.221:8080 查看日志格式 ~]# cd /var/log/tomcat/ tomcat]# ls tomcat_access_log2019-02-20.log &#123;"clientip":"172.20.101.221","ClientUser":"-","authenticated":"-","AccessTime":"[20/Feb/2019:20:13:37 +0800]","method":"GET / HTTP/1.1","status":"200","SendBytes":"11217","Query?string":"","partner":"-","AgentVersion":"curl/7.29.0"&#125; 重启查看日志 验证日志是否json格式：http://www.kjson.com/ 2：配置编辑logstash配置文件来收集tomcat日志文件catalina.out 和自己定义的日志tomcat_access_log(json格式)1234567891011121314151617181920212223242526272829303132333435~]# vim /etc/logstash/conf.d/tomcatlog.conf input &#123; file &#123; path =&gt; "/var/log/tomcat/catalina.out" type =&gt; "tomcatlog" start_position =&gt; "beginning" stat_interval =&gt; "3" &#125; file &#123; #此处做统配匹配日志。因为定义的日志为每天更新，文件格式以日期格式命令 path =&gt; "/var/log/tomcat_access_log.*.log" type =&gt; "accesslog" start_psition =&gt; "beginning" stat_interval =&gt; "3" codec =&gt; json #声明收集的此日志的格式为json格式 &#125;&#125;output &#123; if [type] == "tomcatlog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] index =&gt; "tomcat-log-%&#123;+YYYY.MM.dd&#125;" &#125;&#125; if [type] == "accesslog" &#123; elasticsearch &#123; hosts =&gt; ["172.18.135.1:9200"] index =&gt; "access-tomcat-log-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;&#125;重启logstash ~]# systemctl restart logstash 3.定义kibana按索引的名称做日志收集并添图形展示界面]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Kibana安装部署]]></title>
    <url>%2F2019%2F02%2F19%2FELK%E4%B9%8BKibana%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[ELK之Kibana安装部署 一句话介绍kibana kibana 可以通过图形界面友好的展示你在es中的数据 Host4主机 kibana部署及日志收集：1.安装并配置kibana：可以通过rpm包或者二进制的方式进行安装123~]# lskibana-5.6.13-x86_64.rpm ~]# rpm -ivh kibana-5.6.13-x86_64.rpm 2.编辑Kibana配置文件123456789#端口默认56012 server.port: 5601 #指定监听本机的地址7 server.host: "0.0.0.0"#指定ES主机的客户端监听地址21 elasticsearch.url: "http://Host1主机或者Host2主机:9200" 3.启动host4主机上的kibana服务1234~]# systemctl start kibana~]# systemctl enable kibana~]# ss -tnl*:5601 4.测试Host3主机Logstash输出到Host1主机elasticsearch123456789101112131415Logstash收集本机的日志将日志输出至ES服务器上方法1：~]# /usr/share/logstash/bin/logstash -e 'input &#123; stdin&#123;&#125; &#125; output &#123; elasticsearch &#123;hosts =&gt; ["host1:9200"] index =&gt; "mytest-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;'方法2：不指定存入ES主机的名称默认为[logstash-]YYYY.MM.DD~]# /usr/share/logstash/bin/logstash -e 'input &#123; stdin&#123;&#125; &#125; output &#123; elasticsearch &#123;hosts =&gt; ["172.18.135.1:9200"] &#125;&#125;'ES主机ES-host1查看是否已经收集到Lsgstash过滤发送来的日志信息~]# ls /data/esdata/nodes/0/indices/-gghAdfzRDqtsflB0i-Ajw #名称为随机生成的名称 5.web界面访问Host4地址的5601端口第四步方法1： 第四步方法2：]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK之Logstash安装及基本语法]]></title>
    <url>%2F2019%2F02%2F19%2FELK%E4%B9%8BLogstash%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[ELK之Logstash安装及基本语法 ELK–&gt;logstashLogstash介绍官方站点：https://www.elastic.co/cn/products/logstash 集中、转换和存储数据 Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。） 输入 采集各种样式、大小和来源的数据 数据往往以各种各样的形式，或分散或集中地存在于很多系统中。 Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤器 实时解析和转换数据 数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 利用 Grok 从非结构化数据中派生出结构 从 IP 地址破译出地理坐标 将 PII 数据匿名化，完全排除敏感字段 简化整体处理，不受数据源、格式或架构的影响 输出 选择您的存储库，导出您的数据 尽管 Elasticsearch 是我们的首选输出方向，能够为我们的搜索和分析带来无限可能，但它并非唯一选择。 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 即插即用 使用 Elastic Stack 更快获得洞察 Logstash 模块通过热门的数据源（如 ArcSight 和 Netflow ）呈现瞬间可视化的体验。通过立即部署摄入管道和复杂的仪表板，您在短短几分钟内便可开始数据探索。 可扩展 以您自己的方式创建和配置管道 Logstash 采用可插拔框架，拥有 200 多个插件。您可以将不同的输入选择、过滤器和输出选择混合搭配、精心安排，让它们在管道中和谐地运行。 从自定义应用程序采集数据？没有看到所需的插件？Logstash 插件很容易构建。我们有一个极好的插件开发 API 和插件生成器，可帮助您开始和分享您的创作。 可靠性与安全性 构建可信的交付管道 假如 Logstash 节点发生故障，Logstash 会通过持久化队列来保证至少将运行中的事件送达一次。那些未被正常处理的消息会被送往死信队列（dead letter queue）以便做进一步处理。由于具备了这种吸收吞吐量的能力，现在您无需采用额外的队列层，Logstash 就能平稳度过高峰期。 我们让您能够全方位地保护您的数据加工管道，不管您是运行 10 个还是 1000 个 Logstash 实例。来自 Beats 的数据和其他数据输入一同在网络层被加密传输，并且与安全的 Elasticsearch 集群完整集成。 监控 全方位监视您的部署 Logstash 管道通常服务于多种用途，会变得非常复杂，因此充分了解管道性能、可用性和瓶颈异常重要。借助 Elastic Stack 的监控功能，您可以轻松观察和研究处于活动状态的 Logstash 节点或整个部署。 管理和治理 使用单个 UI 集中式管理部署 借助 Pipeline 管理图形界面来管理 Logstash 的部署，您可以轻而易举地治理数据加工管道。此外，此项管理功能也与 Elastic Stack 内置的安全特性无缝集成，用以避免任何意外操作。 补充 logstash 可以被消息队列kafka 代替，收取的数据存储在es中就好 logstash 支持多种数据获取机制，可以通过TCP／UDP协议，文件、syslog、- windows EVENTlog 等 logstash 获取到数据后，执行对数据执行过滤，修改等操作(filter插件) logstash 是使用Jruby 语言研发的，所以需要使用JVM虚拟机，需要java支持 logstash 如果agent端过多，数据量多大，我们需要在logstash客户端 与 server 端部署消息队列 一般使用redis，支持发布订阅等功能 Host3主机部署Logstash：（logstash+java环境） 官方帮助文档：https://www.elastic.co/guide/index.html 1：logstash环境准备及安装： Logstash是一个开源的数据收集引擎，可以水平伸缩，而且logstash整个ELK当中拥有最多插件的一个组件，其可以接收来自不同来源的数据并统一输出到指定的且可以是多个不同目的地。 2.rpm安装Logstash+java环境123456789101112131415161718192021环境准备： ~]# ls logstash-5.6.13.rpm jdk-8u192-linux-x64.rpm 关闭防火墙和selinux，并且安装java环境 ~]# systemctl stop firewalld ~]# systemctl disable firewalld ~]# sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config ~]# rpm -ivh jdk-8u192-linux-x64.rpm ~]# java -version java version "1.8.0_121" Java(TM) SE Runtime Environment (build 1.8.0_121-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)安装logstash ~]# ~]# rpm -ivh logstash-5.6.13.rpm #权限更改为logstash用户和组，否则启动的时候日志报错 ~]# chown logstash.logstash /usr/share/logstash/data/queue –R 测试Logstash：1：测试标准输入和输出：123456789101112131415161718192021222324252627 ~]# /usr/share/logstash/bin/logstash -e 'input &#123; stdin&#123;&#125; &#125; output &#123; stdout&#123; codec =&gt; rubydebug &#125;&#125;' WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults Could not find log4j2 configuration at path /usr/share/logstash/config/log4j2.properties. Using default config which logs errors to the console The stdin plugin is now waiting for input: hellow word &#123; "@version" =&gt; "1", #一个事件的第几个版本 "host" =&gt; "host-192-168-35-103", #当前主机名，此日志是在哪台主机上产生的 "@timestamp" =&gt; 2019-02-19T04:04:01.351Z, #时间戳 "message" =&gt; "hellow word" &#125;一个最简单的配置文件：标准输入，标准输出（和上述命令行指定的含义相同）input&#123;stdin &#123;&#125;&#125;output&#123; stdout&#123; codec =&gt; rubydebug &#125;&#125; 2.查看Logsstash的模块12345~]# /usr/share/logstash/bin/logstash-plugin --help #查看帮助~]# /usr/share/logstash/bin/logstash-plugin list #列出已经安装的模块~]# /usr/share/logstash/bin/logstash-plugin install #加载新的模块+模块名称~]# /usr/share/logstash/bin/logstash-plugin update #更新模块~]# /usr/share/logstash/bin/logstash-plugin remove #删除哪个模块 2.配置文件声明123456789101112131415配置文件说明：logstash 开始是没有配置文件的，配置文件一般是由以下组成 input&#123;规则&#125;filter&#123;规则&#125;output&#123;规则&#125; Logstash常用的Input/output插件：file插件详细介绍 path字段的说明 path 是指定输入文件的路径，你可以使用/var/log/*.log，必须是绝对路径，不能是相对路径 你也可以指定多个路径 例如 path =&gt; [ “/var/log/messages”, “/var/log/s.log” ] 首先你可以看到 path 是 required yes的状态，那就是说你只要使用file这个input插件，那么file里面一定要定义path 1:指定输入查询的文件，输出为标准出1~]# /usr/share/logstash/bin/logstash -e 'input &#123; file &#123; path =&gt; "/var/log/message" &#125; &#125; output &#123; stdout&#123; &#125;&#125;' 2.指定标准输入，和输出到指定的文件中1~]# /usr/share/logstash/bin/logstash -e 'input &#123; stdin&#123;&#125; &#125; output &#123; file &#123; path =&gt; "/tmp/log-%&#123;+YYYY.MM.dd&#125;messages.gz"&#125;&#125; 3.指定输入的文件，和输出的文件1~]# /usr/share/logstash/bin/logstash -e 'input &#123; file &#123; path =&gt; "/var/log/message" &#125; &#125; output &#123; file &#123; path =&gt; "/data/eslogs.conf" &#125;&#125;' 测试输出到elasticsearch12345678Logstash收集本机的日志将日志输出至ES服务器上~]# /usr/share/logstash/bin/logstash -e 'input &#123; stdin&#123;&#125; &#125; output &#123; elasticsearch &#123;hosts =&gt; ["host1:9200"] index =&gt; "mytest-%&#123;+YYYY.MM.dd&#125;" &#125;&#125;'ES主机ES-host1查看是否已经收集到Lsgstash过滤发送来的日志信息~]# ls /data/esdata/nodes/0/indices/-gghAdfzRDqtsflB0i-Ajw #名称为随机生成的名称 Kibana笔记地址：https://www.daizhe.net.cn/2019/02/19/ELK%E4%B9%8BKibana%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/#more 通过logstash收集日志：1：收集单个系统日志并输出至ES服务器中：（标准输入为/var/logmesssage 标准输出到ES）12345678910111213141516171819202122232425262728293031323334353637383940414243前提需要logstash用户对被收集的日志文件有读的权限并对写入的文件有写权限。将此前的命令行实现的方式放置在logstash配置文件实现 ~]# cd /etc/logstash/conf.d/ #logstash默认找配置文件的目录 conf.d]# vim systemlog.conf input &#123; file &#123; path =&gt; "/var/log/messages" &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; "172.18.135.1:9200"&#125; &#125;修改/var/log/message文件的权限#默认启动logstash程序使用的是logstash用户启动的，而/var/log/message此文件属主属组为root所以要修改其权限，也可以将logstash运行身份修改为root，可以在启动脚本中进行修改 ~]# chmod 644 /var/log/messages配置文件语法检测 ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/systemlog.conf -t Configuration OK启动logstash ~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/systemlog.conf logstash主机在本机的/var/log/message文件中模拟日志存入 ~]# echo "test" &gt;&gt; /var/log/messages 查看logstash日志文件 ~]# ls /var/log/logstash/ logstash-plain.log Kibana主机上查看日志是否收集 2：logstash收集日志指定开始收集的位置123456789101112131415161718192021~]# cat /etc/logstash/conf.d/system-log.conf input &#123; file &#123; type =&gt; "messagelog" path =&gt; "/var/log/messages"start_position =&gt; "beginning" #第一次从头收集，之后从新添加的日志收集 &#125;&#125;output &#123; file &#123; path =&gt; "/tmp/%&#123;type&#125;.%&#123;+yyyy.MM.dd&#125;" &#125;&#125;~]# chmod 644 /var/log/messages~]# systemctl restart logstash 3：通过logstash收集多个日志文件：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849Logstash配置：logstash]# cat /etc/logstash/conf.d/system-log.conf input &#123; file &#123; path =&gt; "/var/log/messages" #日志路径 type =&gt; "systemlog" #事件的唯一类型 start_position =&gt; "beginning" #第一次收集日志的位置 stat_interval =&gt; "3" #日志收集的间隔时间，默认的间隔事件为1秒钟 &#125; file &#123; path =&gt; "/var/log/secure" type =&gt; "securelog" start_position =&gt; "beginning" stat_interval =&gt; "3" &#125;&#125;output &#123; if [type] == "systemlog" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "system-log-%&#123;+YYYY.MM.dd&#125;" &#125;&#125; if [type] == "securelog" &#123; elasticsearch &#123; hosts =&gt; ["192.168.15.11:9200"] index =&gt; "secury-log-%&#123;+YYYY.MM.dd&#125;" &#125;&#125; &#125;修改权限 因为此文件默认属主和属组为root，也可以将logstash运行身份修改为root，可以在启动脚本中进行修改~]# chmod 644 /var/log/secure~]# chmod 644 /var/log/messages检测配置文件语法~]# /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/systemlog.conf -t~]# systemctl restart logstash模拟日志增加~]# echo "123" &gt;&gt; /var/log/messages ~]# echo "123" &gt;&gt; /var/log/secure 在kibana界面添加system-log索引和secury-log索引: kibana展示]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK介绍及ES集群安装]]></title>
    <url>%2F2019%2F02%2F19%2FELK%E4%BB%8B%E7%BB%8D%E5%8F%8AES%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[ELK介绍及集群安装 介绍ELK什么是ELK？ 通俗来讲，ELK是由Elasticsearch、Logstash、Kibana 、filebeat三个开源软件的组成的一个组合体，这三个软件当中，每个软件用于完成不同的功能，ELK 又称为ELK stack，官方域名为stactic.co，ELK stack的主要优点有如下几个： 1.处理方式灵活： elasticsearch是实时全文索引，具有强大的搜索功能 2.配置相对简单：elasticsearch全部使用JSON 接口，logstash使用模块配置，kibana的配置文件部分更简单。 3.检索性能高效：基于优秀的设计，虽然每次查询都是实时，但是也可以达到百亿级数据的查询秒级响应。 4.集群线性扩展：elasticsearch和logstash都可以灵活线性扩展 5.前端操作绚丽：kibana的前端设计比较绚丽，而且操作简单（前端前端展示界面） 什么是Elasticsearch： 是一个高度可扩展的开源全文搜索和分析引擎，它可实现数据的实时全文搜索搜索、支持分布式可实现高可用、提供API接口，可以处理大规模日志数据，比如Nginx、Tomcat、系统日志等功能。 什么是Logstash 可以通过插件实现日志收集和转发，支持日志过滤，支持普通log、自定义json格式的日志解析。 什么是kibana： 主要是通过接口调用elasticsearch的数据，并进行前端数据可视化的展现。 为什么使用 ELK？ ELK组件在海量日志系统的运维中，可用于解决以下主要问题： 分布式日志数据统一收集，实现集中式查询和管理 故障排查 安全信息和事件管理 报表功能 ELK组件在大数据运维系统中，主要可解决的问题如下： 日志查询，问题排查，故障恢复，故障自愈 应用日志分析，错误报警 性能分析，用户行为分析 ELK使用场景 ELK–&gt;elasticsearch（ES）Host1和Host2主机 elasticsearch（ES）部署：（es+java环境） 1：环境初始化： 最小化安装 Centos 7.2 x86_64操作系统的虚拟机，vcpu 2，内存4G或更多，操作系统盘50G，主机名设置规则为linux-hostX.exmaple.com，其中host1和host2为elasticsearch服务器，为保证效果特额外添加一块单独的数据磁盘大小为50G并格式化挂载。 2：host1和host2添加磁盘格式化挂载： 123456789101112131415161718192021222324252627282930查看原有磁盘数量 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 200G 0 disk 新添加的磁盘在不重启主机的情况下扫描发现新的磁盘 ~]# echo "- - -" &gt; /sys/class/scsi_host/host0(TAB)/scan ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 200G 0 disk sdb 8:16 0 50G 0 disk格式化新的磁盘（用于存放收集的日志） ~]# mkfs.xfs /dev/sdb 挂载新的磁盘，/data/esdata目录用来存放elasticsearch存储数据 ~]# mkdir -p /data/&#123;esdata,eslogs&#125; ~]# mount /dev/sdb /data/ ~]# lsblk sdb 8:16 0 50G 0 disk /data/设置开机自动挂载 ~]# vim /etc/fstab #最好使用uuid进行挂载。使用blkid /dev/sdb查看磁盘的uuid /dev/sdb /data xfs defaults 0 0 3：host1和host2防火墙和selinux： 关闭防所有服务器的火墙和selinux，包括web服务器、redis和logstash服务器的防火墙和selinux全部关闭，此步骤是为了避免出现因为防火墙策略或selinux安全权限引起的各种未知问题，以下只显示了host1和host2的命令，但是其他服务器都要执行。12345~]# systemctl disable firewalld~]# systemctl disable NetworkManager~]# sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config~]# echo "* soft nofile 65536" &gt;&gt; /etc/security/limits.conf~]# echo "* hard nofile 65536" &gt;&gt; /etc/security/limits.conf 4：host1和host2设置epel源、安装基本操作命令并同步时间以及各服务器配置本地域名解析：12345678910111213141516171819202122232425262728293031各服务器配置本地域名解析主机名立即生效~]#vim /etc/hostname~]#hostname es1.com #退出重新登陆则生效host1和host2 ~]# vim /etc/hosts192.168.15.11 linux-host1.exmaple.com192.168.15.12 linux-host2.exmaple.com192.168.15.13 linux-host3.exmaple.com192.168.15.14 linux-host4.exmaple.com192.168.15.15 linux-host5.exmaple.com192.168.15.16 linux-host6.exmaple.com获取epel源 ~]# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo安装依赖包 ~]# yum install -y net-tools vim lrzsz tree screen lsof tcpdump wget ntpdate设置时间同步并设置计划任务定时同步时间 ~]# cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ~]# echo "*/5 * * * * ntpdate time1.aliyun.com &amp;&gt; /dev/null &amp;&amp; hwclock -w" &gt;&gt; /var/spool/cron/root ~]# systemctl restart crond ~]# reboot #重启检查各项配置是否生效，没有问题的话给虚拟机做快照以方便后期还原 5：在host1和host2分别安装elasticsearch： 5.1：在两台服务器准备java环境： 因为elasticsearch服务运行需要java环境，因此两台elasticsearch服务器需要安装java环境，可以使用以下方式安装： 方式一：直接使用yum安装openjdk1~]# yum install java-1.8.0* 方式二：本地安装在oracle官网下载rpm安装包：1~]# yum localinstall jdk-8u92-linux-x64.rpm 方式三：下载二进制包自定义profile环境变量：1234567891011121314下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html ~]# tar xvf jdk-8u121-linux-x64.tar.gz -C /usr/local/ ~]# ln -sv /usr/local/jdk1.8.0_121 /usr/local/jdk ~]# vim /etc/profile export HISTTIMEFORMAT="%F %T `whoami` " export JAVA_HOME=/usr/local/jdk export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin ~]# source /etc/profile ~]# java -version java version "1.8.0_121" #确认可以出现当前的java版本号 Java(TM) SE Runtime Environment (build 1.8.0_121-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode) 这里采用rpm包方式安装JDK123~]# lsjdk-8u192-linux-x64.rpm ~]# rpm -ivh jdk-8u192-linux-x64.rpm 5.2：官网下载elasticsearch RPM包并安装：下载地址：https://www.elastic.co/downloads/elasticsearch，当前最新版本5.3.0 host1和host2两台服务器分别安装elasticsearch:12345678910~]# rpm -ivh elasticsearch-5.6.13.rpm ~]# rpm -ql elasticsearch #主配置文件/etc/elasticsearch/elasticsearch.yml #调优的配置文件/etc/elasticsearch/jvm.options#启动程序文件（默认定义的启动程序的身份为elasticsearch用户）/usr/lib/systemd/system/elasticsearch.service #主要使用.jar文件实现模块化的扩展 6：目录权限更改：host1和host2各服务器创建数据和日志目录并修改目录权限为elasticsearch：12~]# mkdir /data/&#123;esdata,eslogs&#125;~]# chown -R elasticsearch.elasticsearch /data 7：编辑host1和host2各elasticsearch服务器的服务配置文件解析：配置的官方帮助文档：https://www.elastic.co/guide/en/elasticsearch/reference/index.html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#未特殊标注的host1和host2主机的配置相同 ~]# vim /etc/elasticsearch/elasticsearch.yml #ELK的集群名称，名称相同即属于是同一个集群（集群名称是各个ES服务端一致的） 17 cluster.name: ELK-Cluster #将host1节点和host2节点集群名称保持一致 #本机在集群内的节点名称（各ES节点的node.name不可重复） 23 node.name: elk-node1 #host1名称elk-node1 #host2名称elk-node2 #数据保存目录 33 path.data: /data/esdata #日志保存目录 37 path.logs: /data/eslogs #服务启动的时候锁定足够的内存，防止数据写入swap #43 bootstrap.memory_lock: true #监听IP，默认监听本机的所有地址 55 network.host: 0.0.0.0 #客户端端口，提供Logstash向elasticsearch写上缴日志数据时使用(还有一个9300,elasticsearch集群中同步数据以及集群间状态选举通讯使用) 59 http.port: 9200 #集群几点状态发现使用，默认在整个网段中做广播，改为组播的方式，指定哪些机器发送数据包（设置尽在host1主机和host2主机间发送组播） 68 discovery.zen.ping.unicast.hosts: ["host1地址", "host2地址"] 生产参考配置项 #discovery.zen.minimum_master_nodes: 3 #设置这个参数来保证集群中的节点可以知道其它N个有 #master资格的节点，默认为1，当集群多余三个节点时，可以设置大一点的值(2-4) 生产配置项：了解即可 #gateway.recover_after_nodes: 3 #在完全重新启动集群后阻塞初始恢复，直到启动N个节点: #node.max_local_storage_nodes: 1 #默认情况下，多个节点可以在同一个安装路径启动，如果你想让你的Elasticsearch只启动一个节点，在这合理设置。 #设置是否可以通过正则或者_all删除或者关闭索引。 #action.destructive_requires_name: truehost1配置主文件 ~]# grep "^[a-Z]" /etc/elasticsearch/elasticsearch.yml cluster.name: ELK-Cluster node.name: elk-node1 path.data: /data/esdata path.logs: /data/eslogs network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: ["host1地址", "host2地址"]host2配置文件 ~]# grep "^[a-Z]" /etc/elasticsearch/elasticsearch.yml cluster.name: ELK-Cluster node.name: elk-node2 path.data: /data/esdata path.logs: /data/eslogs bootstrap.memory_lock: true network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: ["host1地址", "host2地址"] 8：host1和host2启动elasticsearch服务并验证，端口监听是否成功：123456789101112~]# systemctl restart elasticsearch~]# systemctl enable elasticsearch~]# tail -f /data/eslogs/ELK-Cluster.log ~]# ss -tnl:::9200 #用户访问的接口 :::9300 #集群内部通讯的端口~]# ps -ef | grep elasticsearch#默认的可使用的最大内存和最小内存未2Gelastic+ 15756 1 10 14:04 ? 00:00:31 /bin/java -Xms2g -Xmx2g 9：通过浏览器访问elasticsearch服务端口： 9.1：访问host1主机 9.2：访问host2主机 10：host1和host2修改启动脚本，修改内存限制，并同步配置文件： 这里为测试场景不需要修改12345678910111213编辑elasticsearch启动脚本声明启动时都内存不做限制 ~]# vim /usr/lib/systemd/system/elasticsearch.service #修改内存限制 40 LimitMEMLOCK=infinity #最大化使用内存编辑修改elasticsearch节点中的内存限制配置文件 ~]# vim /etc/elasticsearch/jvm.options 22 -Xms2g 23 -Xmx2g #最小和最大内存限制，为什么最小和最大设置一样大？(不可设置为浮点数，只可以设置为整数) ~]# systemctl daemon-reload ~]# systemctl start elasticsearch 官方配置文档最大建议30G以内：https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html 后面安装elasticsearch插件之head,由于宿主机内存不足，系统内核会将占用内存最大的进程强制kill掉，以保证系统的正常运行以及其他服务的正常运行。 ES插件安装elasticsearch插件之head1：安装elasticsearch插件之head： 插件是为了完成不同的功能，官方提供了一些插件但大部分是收费的，另外也有一些开发爱好者提供的插件，可以实现对elasticsearch集群的状态监控与管理配置等功能。1.4.1：安装5.x版本的head插件： 在elasticsearch 5.x版本以后不再支持直接安装head插件，而是需要通过启动一个服务方式， github托管地址：https://github.com/mobz/elasticsearch-head 2：host1和host2服务放置安装elasticsearch插件之head1234567891011~]# yum install -y npm# NPM的全称是Node Package Manager，是随同NodeJS一起安装的包管理和分发工具，它很方便让JavaScript开发者下载、安装、上传以及管理已经安装的包。~]# cd /usr/local/src/src]#git clone git://github.com/mobz/elasticsearch-head.git src]# cd elasticsearch-head/elasticsearch-head]# yum install npm -yelasticsearch-head]# npm install grunt -saveelasticsearch-head]# ll node_modules/grunt #确认生成文件elasticsearch-head]# npm install #执行安装 elasticsearch-head]# npm run start &amp; #后台启动服务 2.1：host1和host2修改elasticsearch服务配置文件：12345开启跨域访问支持，然后重启elasticsearch服务： ~]# vim /etc/elasticsearch/elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: "*" ~]# /etc/init.d/elasticsearch restart 3：host1和host2docker安装elasticsearch插件之head1234567891011121314151617181920212223242526272829303132安装docker ~]# cd /etc/yum.repos.d/ yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo安装时如果报这种错误并解决 ~]# yum install docker-ce -y You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest ~]# yum install http://vault.centos.org/centos/7.3.1611/extras/x86_64/Packages/container-selinux-2.9-4.el7.noarch.rpm ~]# yum install docker-ce -y启动docker并加入开机启动项 ~]# systemctl start docker &amp;&amp; systemctl enable docker使用dicker 下载head镜像 ~]# docker pull mobz/elasticsearch-head:5以容器的方式运行elasticsearch插件head，并映射端口到宿主机 ~]# docker run -d -p 9100:9100 mobz/elasticsearch-head:5查看容器的状态 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ca48d7d13e87 mobz/elasticsearch-head:5 "/bin/sh -c 'grunt s…" 34 seconds ago Up 31 seconds 0.0.0.0:9100-&gt;9100/tcp compassionate_williamson 3.1：host1和host2修改elasticsearch服务配置文件：12345678910开启跨域访问支持，然后重启elasticsearch服务： ~]# vim /etc/elasticsearch/elasticsearch.yml #可以添加至配置文件的最后一行中 http.cors.enabled: true http.cors.allow-origin: "*"重启启动elasticsearch ~]# systemctl restart elasticsearch.service 4：通过浏览器访问host1和host2主机elasticsearch组件head,映射宿主机的端口为9100 5：Master与Slave的区别： Master的职责： 统计各node节点状态信息、集群状态信息统计、索引的创建和删除、索引分配的管理、关闭node节点等 Slave的职责： 从master同步数据、等待机会成为Master 6：导入本地的docker镜像： 本章外123456~]# docker save docker.io/mobz/elasticsearch-head &gt; /opt/elasticsearch-head-docker.tar.gz #导出镜像src]# docker load &lt; /opt/elasticsearch-head-docker.tar.gz #导入src]# docker images#验证REPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/mobz/elasticsearch-head 5 b19a5c98e43b 4 months ago 823.9 MBsrc]# docker run -d -p 9100:9100 --name elastic docker.io/mobz/elasticsearch-head:5 #从本地docker images 启动容器 1.4.2：elasticsearch插件之kopf1：elasticsearch插件之kopf：2：kopf(已经无人维护)： Git地址:https://github.com/lmenezes/elasticsearch-kopf 但是目前还不支持5.x版本的elasticsearch，但是可以安装在elasticsearc 1.x或2.x的版本安装。 ELK集群监控使用AIP接口（curl）状态查看1：监控elasticsearch集群状态：2：通过shell命令/python脚本获取集群状态（使用zabbix监控集群状态结合python脚本）： 获取到的是一个json格式的返回值，那就可以通过python对其中的信息进行分析，例如对status进行分析，如果等于green(绿色)就是运行在正常，等于yellow(黄色)表示副本分片丢失，red(红色)表示主分片丢失 1curl -sXGET http://192.168.15.211:9200/_cluster/health?pretty=true 对elasticsearch集群状态监控，并结合zabbix实现报警，原理为通过python脚本获取到elasticsearch集群的运行状态并取出status的值，如果状态为green表示正常的值就传递给zabbix一个值为100，如果是其他状态就返回值为50，zabbix根据最后一个值的结果判断，如果不是100就报警，设置如下：1.python脚本：取出集群的状态1234567891011121314151617181920212223242526[root@linux-host1 ~]# cat els-cluster-monitor.py [root@es1 ~]# cat es.py#!/usr/bin/env python#coding:utf-8#Author Zhang Jieimport smtplibfrom email.mime.text import MIMETextfrom email.utils import formataddrimport subprocessbody = ""false="false"obj = subprocess.Popen(("curl -sXGET http://192.168.15.211:9200/_cluster/health?pretty=true"),shell=True, stdout=subprocess.PIPE)data = obj.stdout.read()data1 = eval(data)status = data1.get("status")if status == "green": print("50")else: print("100")[root@elk-s1 ~]# chmod a+x /etc/zabbix/zabbix_agentd.d/els_status.py脚本执行结果：~]# python els-cluster-monitor.py 50 2.zabbix 添加监控123456789101112配置zabbix-agent配置文件导入自定义配置文件：[root@elk-s1 ~]# vim /etc/zabbix/zabbix_agentd.confInclude=/etc/zabbix/zabbix_agentd.d/*.conf自定义配置文件：[root@elk-s1 ~]# vim /etc/zabbix/zabbix_agentd.d/els_status.confUserParameter=els.status,/usr/bin/python /etc/zabbix/zabbix_agentd.d/els_status.py[root@elk-s1 ~]# systemctl restart zabbix-agent 3.zabbix-server端测试能否获取到值，获取到100表示集群正常运行，否则表示出现问题需要排查： 4.在zabbix-serve的对应的elasticsearch服务器r端添加监控项： 5.创建触发器 6.创建图形 7.查看图形 8.关闭一个elasticsearch服务器测试能否触发邮件报警：123[root@els-s2 tianqi]# systemctl stop elasticsearch #在elasticsearch服务器关闭[root@Zabbix tianqi]# zabbix_get -s 192.168.0.33 -k els.status #在zabbix-server测试获取的返回值是否为5050 9.关于elasticsearch存储index的定期删除，elasticsearch存储的日志较多的时候会影响搜索性能，因此建议定期清理，脚本如下，这次是shell脚本：123456789101112131415161718192021222324#!/bin/bashDATE=`date -d "2 days ago" +%Y.%m.%d`LOG_NAME="api4-systemlog"FILE_NAME=$&#123;LOG_NAME&#125;-$&#123;DATE&#125;curl -XDELETE http://hfelk.chinacloudapp.cn:9200/$&#123;FILE_NAME&#125;echo "$&#123;FILE_NAME&#125; delete success"[root@els-s2 ~]# chmod a+x /root/els_delete.sh 测试执行：[root@els-s2 ~]# bash -x /root/els_delete.sh++ date -d '30 days ago' +%Y.%m.%d+ DATE=2016.08.05+ LOG_NAME=api4-systemlog+ FILE_NAME=api4-systemlog-2016.08.05+ curl -XDELETE http://hfelk.chinacloudapp.cn:9200/api4-systemlog-2016.08.05&#123;"acknowledged":true&#125;+ echo 'api4-systemlog-2016.08.05 delete success'api4-systemlog-2016.08.05 delete success添加任务计定期执行即可：[root@els-s2 ~]# crontab -e1 * * * * /root/els_delete.sh #每天凌晨一点清除一月之前的日志 列出集群中所有节点：123~]# curl -X GET "http://172.18.135.1:9200/_cat/nodes "172.18.135.1 9 70 1 0.00 0.05 0.16 mdi * es1.com172.18.135.2 15 52 0 0.04 0.31 0.59 mdi - es2.com # mdi m es2.com此处的m表示可以成为备用master节点 查看集群索引状态：1234~]# curl -X GET "http://172.18.135.1:9200/_cat/nodes?v"ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name172.18.135.1 10 81 0 0.03 0.07 0.13 mdi * es1.com172.18.135.2 15 52 1 0.33 0.22 0.40 mdi - es2.com 查看现在集群中哪个是主节点12~]# curl -X GET "http://172.18.135.1:9200/_cat/master"u5qBvduFQ3GOa5CjROsWOQ 172.18.135.1 172.18.135.1 es1.com _cat API来查看集群状态：1234567集群状态： green 正常 red 不可用 yellow 修复状态~]# curl -X GET http://172.18.135.1:9200/_cat/health1550496241 21:24:01 ES green 2 2 0 0 0 0 0 0 - 100.0% _cat API帮助：12345~]# curl -X GET http://172.18.135.1:9200/_cat/nodes?helphelp下面你发现了好多可选，比如说我想看help下的 uptime，我应该用h= uptime的语法来看 ~]# curl -X GET http://172.18.135.1:9200/_cat/nodes?h=uptime27.2m23.8m 1.5.2:cluster API 分类总结1）_cluster/health 来显示集群状态123456789101112131415161718~]# curl -X GET "172.18.135.1:9200/_cluster/health?pretty"&#123; "cluster_name" : "ES", "status" : "green", "timed_out" : false, "number_of_nodes" : 2, "number_of_data_nodes" : 2, "active_primary_shards" : 0, "active_shards" : 0, "relocating_shards" : 0, "initializing_shards" : 0, "unassigned_shards" : 0, "delayed_unassigned_shards" : 0, "number_of_pending_tasks" : 0, "number_of_in_flight_fetch" : 0, "task_max_waiting_in_queue_millis" : 0, "active_shards_percent_as_number" : 100.0&#125; 2) _cluster/state API 查看状态123456789101112131415161718~]# curl -XGET "http://172.18.135.1:9200/_cluster/state/nodes?pretty"&#123; "cluster_name" : "ES", "nodes" : &#123; "u5qBvduFQ3GOa5CjROsWOQ" : &#123; "name" : "es1.com", "ephemeral_id" : "t7qVHOZSTuyjMa1d7Zhm7w", "transport_address" : "172.18.135.1:9300", "attributes" : &#123; &#125; &#125;, "2jAXgTrdQfmZrsaLnDQATA" : &#123; "name" : "es2.com", "ephemeral_id" : "BjSFicySSQGsF_X9Aqk0ng", "transport_address" : "172.18.135.2:9300", "attributes" : &#123; &#125; &#125; &#125;&#125; 3) _cluster/stats API（统计） 统计数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134主要来查看索引、分片等~]# curl -XGET "http://172.18.135.1:9200/_cluster/stats?pretty" &#123; "_nodes" : &#123; "total" : 2, "successful" : 2, "failed" : 0 &#125;, "cluster_name" : "ES", "timestamp" : 1550496718730, "status" : "green", "indices" : &#123; "count" : 0, "shards" : &#123; &#125;, "docs" : &#123; "count" : 0, "deleted" : 0 &#125;, "store" : &#123; "size_in_bytes" : 0, "throttle_time_in_millis" : 0 &#125;, "fielddata" : &#123; "memory_size_in_bytes" : 0, "evictions" : 0 &#125;, "query_cache" : &#123; "memory_size_in_bytes" : 0, "total_count" : 0, "hit_count" : 0, "miss_count" : 0, "cache_size" : 0, "cache_count" : 0, "evictions" : 0 &#125;, "completion" : &#123; "size_in_bytes" : 0 &#125;, "segments" : &#123; "count" : 0, "memory_in_bytes" : 0, "terms_memory_in_bytes" : 0, "stored_fields_memory_in_bytes" : 0, "term_vectors_memory_in_bytes" : 0, "norms_memory_in_bytes" : 0, "points_memory_in_bytes" : 0, "doc_values_memory_in_bytes" : 0, "index_writer_memory_in_bytes" : 0, "version_map_memory_in_bytes" : 0, "fixed_bit_set_memory_in_bytes" : 0, "max_unsafe_auto_id_timestamp" : -9223372036854775808, "file_sizes" : &#123; &#125; &#125; &#125;, "nodes" : &#123; "count" : &#123; "total" : 2, "data" : 2, "coordinating_only" : 0, "master" : 2, "ingest" : 2 &#125;, "versions" : [ "5.6.13" ], "os" : &#123; "available_processors" : 4, "allocated_processors" : 4, "names" : [ &#123; "name" : "Linux", "count" : 2 &#125; ], "mem" : &#123; "total_in_bytes" : 6144528384, "free_in_bytes" : 2384535552, "used_in_bytes" : 3759992832, "free_percent" : 39, "used_percent" : 61 &#125; &#125;, "process" : &#123; "cpu" : &#123; "percent" : 1 &#125;, "open_file_descriptors" : &#123; "min" : 160, "max" : 161, "avg" : 160 &#125; &#125;, "jvm" : &#123; "max_uptime_in_millis" : 1998393, "versions" : [ &#123; "version" : "1.8.0_131", "vm_name" : "OpenJDK 64-Bit Server VM", "vm_version" : "25.131-b12", "vm_vendor" : "Oracle Corporation", "count" : 1 &#125;, &#123; "version" : "1.8.0_161", "vm_name" : "OpenJDK 64-Bit Server VM", "vm_version" : "25.161-b14", "vm_vendor" : "Oracle Corporation", "count" : 1 &#125; ], "mem" : &#123; "heap_used_in_bytes" : 301069112, "heap_max_in_bytes" : 2112618496 &#125;, "threads" : 58 &#125;, "fs" : &#123; "total_in_bytes" : 75125227520, "free_in_bytes" : 75057504256, "available_in_bytes" : 75057504256, "spins" : "true" &#125;, "plugins" : [ ], "network_types" : &#123; "transport_types" : &#123; "netty4" : 2 &#125;, "http_types" : &#123; "netty4" : 2 &#125; &#125; &#125;&#125; 补充了解_cluster系列123456789101112131415161718192021222324252627282930313233341、查询设置集群状态 curl -XGET localhost:9200/_cluster/health?pretty=true pretty=true表示格式化输出 level=indices 表示显示索引状态 level=shards 表示显示分片信息 2、curl -XGET localhost:9200/_cluster/stats?pretty=true 显示集群系统信息，包括CPU JVM等等 3、curl -XGET localhost:9200/_cluster/state?pretty=true 集群的详细信息。包括节点、分片等。 3、curl -XGET localhost:9200/_cluster/pending_tasks?pretty=true 获取集群堆积的任务 3、修改集群配置 举例：curl -XPUT localhost:9200/_cluster/settings -d ‘&#123; “persistent” : &#123; “discovery.zen.minimum_master_nodes” : 2 &#125; &#125;’ transient 表示临时的，persistent表示永久的 4、curl -XPOST ‘localhost:9200/_cluster/reroute’ -d ‘xxxxxx’ 对shard的手动控制，参考http://zhaoyanblog.com/archives/687.html 5、关闭节点 关闭指定192.168.1.1节点 curl -XPOST ‘http://192.168.1.1:9200/_cluster/nodes/_local/_shutdown’ curl -XPOST ‘http://localhost:9200/_cluster/nodes/192.168.1.1/_shutdown’ 关闭主节点 curl -XPOST ‘http://localhost:9200/_cluster/nodes/_master/_shutdown’ 关闭整个集群 $ curl -XPOST ‘http://localhost:9200/_shutdown?delay=10s’ $ curl -XPOST ‘http://localhost:9200/_cluster/nodes/_shutdown’ $ curl -XPOST ‘http://localhost:9200/_cluster/nodes/_all/_shutdown’ delay=10s表示延迟10秒关闭 _nodes系列1234567891、查询节点的状态 curl -XGET ‘http://localhost:9200/_nodes/stats?pretty=true’ curl -XGET ‘http://localhost:9200/_nodes/192.168.1.2/stats?pretty=true’ curl -XGET ‘http://localhost:9200/_nodes/process’ curl -XGET ‘http://localhost:9200/_nodes/_all/process’ curl -XGET ‘http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/jvm,process’ curl -XGET ‘http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/info/jvm,process’ curl -XGET ‘http://localhost:9200/_nodes/192.168.1.2,192.168.1.3/_all curl -XGET ‘http://localhost:9200/_nodes/hot_threads 索引操作1234567891011121314151617181920212223242526272829303132333435363738394041424344451、获取索引 curl -XGET ‘http://localhost:9200/&#123;index&#125;/&#123;type&#125;/&#123;id&#125;’ 2、索引数据 curl -XPOST ‘http://localhost:9200/&#123;index&#125;/&#123;type&#125;/&#123;id&#125;’ -d’&#123;“a”:”avalue”,”b”:”bvalue”&#125;’ 3、删除索引 curl -XDELETE ‘http://localhost:9200/&#123;index&#125;/&#123;type&#125;/&#123;id&#125;’ 4、设置mappingcurl -XPUT http://localhost:9200/&#123;index&#125;/&#123;type&#125;/_mapping -d ‘&#123; “&#123;type&#125;” : &#123; “properties” : &#123; “date” : &#123; “type” : “long” &#125;, “name” : &#123; “type” : “string”, “index” : “not_analyzed” &#125;, “status” : &#123; “type” : “integer” &#125;, “type” : &#123; “type” : “integer” &#125; &#125; &#125; &#125;’ 5、获取mapping curl -XGET http://localhost:9200/&#123;index&#125;/&#123;type&#125;/_mapping 6、搜索curl -XGET ‘http://localhost:9200/&#123;index&#125;/&#123;type&#125;/_search’ -d ‘&#123; “query” : &#123; “term” : &#123; “user” : “kimchy” &#125; //查所有 “match_all”: &#123;&#125; &#125;, “sort” : [&#123; “age” : &#123;“order” : “asc”&#125;&#125;,&#123; “name” : “desc” &#125; ], “from”:0, “size”:100 &#125; curl -XGET ‘http://localhost:9200/&#123;index&#125;/&#123;type&#125;/_search’ -d ‘&#123; “filter”: &#123;“and”:&#123;“filters”:[&#123;“term”:&#123;“age”:”123”&#125;&#125;,&#123;“term”:&#123;“name”:”张三”&#125;&#125;]&#125;, “sort” : [&#123; “age” : &#123;“order” : “asc”&#125;&#125;,&#123; “name” : “desc” &#125; ], “from”:0, “size”:100 &#125;]]></content>
      <categories>
        <category>ELK Stack</category>
      </categories>
      <tags>
        <tag>ELK Stack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab介绍及配置]]></title>
    <url>%2F2019%2F02%2F16%2FGitlab%E4%BB%8B%E7%BB%8D%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Gitlab介绍及配置 一：DevOps简介： DevOps 是Development和Operations的组合，也就是开发和运维的简写。 DevOps 是针对企业中的研发人员、运维人员和测试人员的工作理念，是他们在应用开发、代码部署和质量测试等整条生命周期中协作和沟通的最佳实践，DevOps 强调整个组织的合作以及交付和基础设施变更的自动化、从而实现持续集成、持续部署和持续交付。 DevOps 四大平台：代码托管(gitlab/svn)、项目管理(jira)、运维平台(腾讯蓝鲸/开源平台)、持续交付(Jenkins/gitlab) 1.1：什么是DevOps： 1.2：为什么要推广DevOps？ DevOps 强调团队协作、相互协助、持续发展，然而传统的模式是开发人员只顾开发程序，运维只负责基础环境管理和代码部署及监控等，其并不是为了一个共同的目标而共同实现最终的目的，而DevOps 则实现团队作战，即无论是开发、运维还是测试，都为了最终的代码发布、持续部署和业务稳定而付出各自的努力，从而实现产品设计、开发、测试和部署的良性循环，实现产品的最终持续交付。 1.3：传统技术团队： 1.4：DevOps技术团队： 1.5：什么是持续集成(CI-Continuous integration) 持续集成是指多名开发者在开发不同功能代码的过程当中，可以频繁的将代码行合并到一起并切相互不影响工作。 1.6：什么是持续部署(CD-continuous deployment) 是基于某种工具或平台实现代码自动化的构建、测试和部署到线上环境以实现交付高质量的产品,持续部署在某种程度上代表了一个开发团队的更新迭代速率。 1.7：什么是持续交付(Continuous Delivery) 持续交付是在持续部署的基础之上，将产品交付到线上环境，因此持续交付是产品价值的一种交付，是产品价值的一种盈利的实现。 1.8：常见的部署方式： 开发自己上传–最原始的方案 开发给运维手动上传–运维自己手动部署 运维使用脚本复制–半自动化 结合web界面一键部署–自动化 1.9：常见的持续集成开源工具： 在公司的服务器安装某种程序，该程序用于按照特定格式和方式记录和保存公司多名开发人员不定期提交的源代码，且后期可以按照某种标记及方式对用户提交的数据进行还原。 1.9.1：CVS(Concurrent Version System)： 早期的集中式版本控制系统，现已基本淘汰会出现数据提交后不完整的情况 1.9.2：SVN(Subversion)–集中式版本控制系统 2000年开始开发，目标就是替代CVS集中式管理，依赖于网络，一台服务器集中管理目前依然有部分公司在使用 1.9.3：Gitlib—分布式版本控制系统 Linus在1991年创建了开源的Linux内核，从此Linux便不断快速发展，不过 Linux的壮大是离不开全世界的开发者的参与，这么多人在世界各地为Linux编写代码，那Linux内核的代码是如何管理的呢？事实是，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码！你也许会想，为什么Linus不把Linux代码放到版本控制系统里呢？不是有CVS、SVN这些免费的版本控制系统吗？因为Linus坚定地反对CVS和SVN，这些集中式的版本控制系统不但速度慢，且必须联网才能使用，但是也有一些商用的版本控制系统，虽然比CVS、SVN好用，但那是付费的，和Linux的开源精神不符,不过，到了2002年，Linux系统已经发展了十年了，代码库之大让Linus很难继续通过手工方式管理了，社区的弟兄们也对这种方式表达了强烈不满，于是Linus选择了一个商业的版本控制系统BitKeeper，BitKeeper的东家BitMover公司出于人道主义精神，授权Linux社区免费使用这个版本控制系统,但是安定团结的大好局面在2005年就被打破了，原因是Linux社区牛人聚集，不免沾染了一些梁山好汉的江湖习气，开发Samba的Andrew试图破解BitKeeper的协议（这么干的其实也不只他一个），被BitMover公司发现了（监控工作做得不错！），于是BitMover公司怒了，要收回Linux社区的免费使用权,这时候其实Linus可以向BitMover公司道个歉，保证以后严格管教弟兄们，但这是不可能的，而且实际情况是Linus自己花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！一个月之内，Linux内核的源码已经由Git管理了！牛是怎么定义的呢？大家可以体会一下,然后Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，包括jQuery，PHP，Ruby等等。 1.10：版本控制系统分类：1.10.1：集中式版本控制系统： 任何的提交和回滚都依赖于连接服务器SVN服务器是单点 1.10.2：分布式版本控制系统： Git在每个用户都有一个完整的服务器，然后在有一个中央服务器，用户可以先将代码提交到本 地，没有网络也可以先提交到本地，然后在有网络的时候再提交到中央服务器，这样就大大方便了开发者，而相比CVS和SVN都是集中式的版本控制系统，工作的时候需要先从中央服务器获 取最新的代码，改完之后需要提交，如果是一个比较大的文件则需要足够快的网络才能快速提交完成，而使用分布式的版本控制系统，每个用户都是一个完整的版本库，即使没有中央服务器也可以提交代码或者回滚，最终再把改好的代码提交至中央服务器进行合并即可。 避免混淆的名称 gitlab–&gt;应用软件 git–&gt;命令行的客户端 github–&gt;代码托管网站 二：Gitlab部署与使用：2.1：下载并部署gitlab：官方站点：https://about.gitlab.com/ 2.1.1：Centos 系统环境在准备：2.1.2：gitlab安装及使用 安装包下载地址：https://packages.gitlab.com/gitlab/gitlab-ce rpm包国内下载地址：https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix分布式监控与性能优化]]></title>
    <url>%2F2019%2F02%2F15%2Fzabbix%E5%88%86%E5%B8%83%E5%BC%8F%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[第五章： zabbix分布式监控与性能优化 zabbix-proxy分布式概述 zabbix-proxy官方文档 https://www.zabbix.com/documentation/3.4/manual/distributed_monitoring/proxies 概观 Zabbix代理可以代表Zabbix服务器收集性能和可用性数据。这样，代理可以承担一些收集数据和卸载Zabbix服务器的负担。 此外，当所有代理和代理向一个Zabbix服务器报告并且集中收集所有数据时，使用代理是实现集中式和分布式监视的最简单方法。 Zabbix-proxy使用场景： 监控远程位置，解决跨机房 监控主机多，性能跟不上，延迟大 解决网络不稳定 zabbix-proxy特征 proxy不支持图形 proxy不支持报警 proxy需要数据库 proxy不能和server装在一起 zabbix-proxy分布式图解环境： 部署： 1.安装zabbix-server12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273741.安装 ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm2.安装Zabbix服务器，前端，代理（zabbix要连接数据库）解决的依赖关系，安装了php、httpdzabbix-agent ： zabbix客户端 ~]# yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent -y3.安装数据库 ~]# yum install mariadb-server -y4.创建zabbix数据库以及用户 #启动数据库，加入开机启动项 ~]# systemctl start mariadb ~]# systemctl enable mariadb #创建数据库并授权 ~]# mysql -uroot mysql&gt; create database zabbix character set utf8 collate utf8_bin; mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by 'centos'; mysql&gt; quit;5.导入初始架构和数据。系统将提示您输入新创建的密码（） ~]# cd /usr/share/doc/zabbix-server-mysql-4.0.4/ #查看压缩包的内容不解压zcat #导入到zabbix库中 zabbix-server-mysql-4.0.4]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uroot zabbix(zabbix为前面创建的数据库名称)6.启动zabbix server进程 #在zabbix_server.conf中编辑配置数据库配置 ~]# vim /etc/zabbix/zabbix_server.conf 91行 # DBHost=localhost #数据库的地址，这里演示的为单机模式，默认也是localhost 100行 DBName=zabbix #数据库的名称，这里演示创建的数据库的名称也为zabbix 116行 DBUser=zabbix #授权的数据库的用户 124行 DBPassword=centos #数据库的密码 #启动前关闭selinux ~]# systemctl start zabbix-server ~]# systemctl enable zabbix-server #保证80端口为安装zabbix时安装的依赖的httpd使用 ~]# ss -tnl *:10051 *:3306 *:80 7.编辑zabbix前端的PHP配置 #zabbix前端的apache配置文件位于/etc/httpd/conf.d/zabbix.conf 一些php设置已经完成了配置 #依据所在的时区，设置时间，更改配置文件后，重启Apache服务器 ~]# vim /etc/httpd/conf.d/zabbix.conf Alias /zabbix /usr/share/zabbix #如果访问uri路径为/zabbix 则调度到/usr/share/zabbix 路径下，别名意思 &lt;Directory "/usr/share/zabbix"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;IfModule mod_php5.c&gt; ... 20行修改为(仅一处修改即可) php_value date.timezone Asia/Shanghai &lt;/IfModule&gt; ... ~]# systemctl restart httpd ~]# systemctl enable httpd 2.安装、配置 zabbix-proxy（proxy端的版本和proxy端以及zabbix-agent端的版本要一致）阿里云仓库：https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354配置好epel源安装zabbix-proxy ~]# yum localinstall https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-proxy-mysql-3.4.12-1.el7.x86_64.rpm安装数据库 ~]# yum install mariadb-server -y创建zabbix数据库以及用户 #启动数据库，加入开机启动项 ~]# systemctl start mariadb ~]# systemctl enable mariadb创建数据库并授权 ~]# mysql -uroot mysql&gt; create database zabbix_proxy character set utf8 collate utf8_bin; mysql&gt; grant all privileges on zabbix_proxy.* to zabbix_proxy@localhost identified by 'centos'; mysql&gt; quit;配置zabbix-proxy ~]# vim /etc/zabbix/zabbix_proxy.conf #定义的使用zabbix-proxy主动模式还是被动模式（默认使用的是主动模式） 6 ### Option: ProxyMode 7 # Proxy operating mode. 8 # 0 - proxy in the active mode 9 # 1 - proxy in the passive mode 10 # 11 # Mandatory: no 12 # Default: 13 # ProxyMode=0 24 Server=zabbix-server地址 43 Hostname=Zabbix proxy #此主机名很重要是zabbix-server定义代理的名称 #zabbix-proxy在内网中人为自己就是老大（所以zabbix-server和zabbix-proxy不能安装在同一台主机上） 59 # ListenPort=10051 #定义zabbix-proxy数据保存的数据库的位置，这里zabbix-proxy的数据库和安装在同一台主机上 151 # DBHost=localhost #填写zabbix-proxy主机上安装数据库的名称 167 DBName=zabbix_proxy #授权的zabbix-proxy上数据库中数据库的用户 182 DBUser=zabbix_proxy #定义zabbix-proxy上数据库中数据库的用户的密码 190 DBPassword=centos 2.将zabbix-proxy导入mysql初始架构和数据。系统将提示您输入新创建的数据库以及新建的用户的密码1234567891011查看安装zabbix-proxy安装包的文件 ~]# rpm -q zabbix-proxy-mysql zabbix-proxy-mysql-3.4.12-1.el7.x86_64 ~]# rpm -q zabbix-proxy-mysql /usr/share/doc/zabbix-proxy-mysql-3.4.12/schema.sql.gz将zabbix-proxy导入mysql初始架构和数据。系统将提示您输入新创建的密码（） ~]# cd /usr/share/doc/zabbix-proxy-mysql-3.4.12/ zabbix-proxy-mysql-3.4.12]# zcat schema.sql.gz | mysql -uzabbix_proxy -pcentos zabbix_proxy 3.登陆zabbix-proxy上安装的数据库查看是否将zabbix-proxy中的123MariaDB [(none)]&gt; use zabbix_proxy;MariaDB [zabbix_proxy]&gt; show tables;MariaDB [zabbix_proxy]&gt; exit 4.启动zabbix-proxy12345~]# systemctl start zabbix-proxy~]# systemctl enable zabbix-proxy~]# ss -tnl*:10051 *:3306 5.配置内网中的zabbix-agent客户端指向内网中zabbix-proxy123456789101112131415安装zabbix-agent客户端 ~] # rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm配置zabbix-agent客户端的配置文件指定允许服务端监控的地址 ~]# vim /etc/zabbix/zabbix_agentd.conf 97 Server=zabbix-proxy地址 138 ServerActive=zabbix-proxy地址 （允许zabbix-proxy自动发现zabbix-agent） 149 Hostname=agent-01-172.18.139.71重启zabbix-agent并加入开启启动项 ~]# systemctl restart zabbix-agent ~]# systemctl enable zabbix-agent 6.使用zabbix-server中的zabbix-web界面链接zabbix-proxy 6.1创建代理 6.2zabbix-server的wab界面中链接内网中的zabbix-agent主机，链接时并配置代理 代理只需要一个到Zabbix服务器的TCP连接。这样就可以更容易地绕过防火墙，因为您只需要配置一个防火墙规则。 代理收集的所有数据在将其传输到服务器之前存储在本地。这样，由于服务器的任何临时通信问题，都不会丢失数据。代理配置文件中的ProxyLocalBuffer和ProxyOfflineBuffer参数控制数据在本地保存多长时间。 性能调优 1.针对于mysql，zabbix-server和mysql拆分架构，写多读少 2.去掉无用监控项，增加监控项的取值间隔，减少历史数据保存周期（housekeeper） 3.把被动模式修改为主动模式，增加zabbix-porxy 4.针对于zabbix-server进行进行调优，就加大它的进行数 5.针对于zabbix-server缓存调优，谁的剩余内存少，就加大它的缓存值 定义监控项时，设置历史数据保留时长，（30天~60天） 如果监控的数据的之大于30天，则会被zabbix-server中的程序清理 手动执行数据清理 zabbix-server -R housekeeper_execute]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自动化监控深入实践]]></title>
    <url>%2F2019%2F02%2F14%2Fzabbix%E8%87%AA%E5%8A%A8%E5%8C%96%E7%9B%91%E6%8E%A7%E6%B7%B1%E5%85%A5%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[第四章： zabbix自动化监控（自动发现|主动注册|主动模式被动模式） web网站可用性监控 1.使用命令行实现网站的登陆（curl登陆discuz,需要关闭discuz的验证码） 2.使用curl模型登陆zabix_web 扩展知识 静态页面：纯静态网站就是服务器的源代码和客户端的源代码一致。（HTML标记语言） 动态页面：&lt;?php phpinfo()?&gt; 每次用户访问的时候，html都是在内存中动态生成的，支持登陆，支持用户交互 动态网站需要有东西存下来 服务端：session 客户端：cookie 当用户第一次访问网站，肯定不会携带cookie信息，服务端返回网页的时候，给该客户分配一个sessionID 当用户第二次访问网站的时候，会携带cookie访问，服务端就会通过session验证用户的sookie进行验证 模拟登陆：curl -L -c cook -b cook -d ‘原始数据’ 请求url 登陆成功后，使用curl -c cook -b cook url 访问想要访问 的内容，然后追加至一个html文件中，验证是否成功 自动发现（server端轮询网段扫描发现agent）：被动模式 zabbbix-server段主动去发现此网段中主机上安装zabbix-agent客户端并且agent配置文件中server地址指向的是zabbix-server的主机的地址的主机，则可以被zabbix-server主机扫描到添加到监控的主机中 zabbix自动发现和主机注册(重要) 操作步骤： 1.自动发现，自动添加监控给主机 配置–&gt;自动发现–&gt;选择扫描的主机端 配置–&gt;动作–&gt;事件源–&gt;自动发现–&gt;定制消息 自动发现问题：server每60s扫描一次小弟，资源开销厉害 演示： 1.zabbix-web开启配置中的自动发现默认规则 2.zabbix-web端默认的发现规则的检测规则 12~]# zabbix_get -s 172.18.139.70 -k "system.uname"Linux centos7.com 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 3.验证自动发现123456789重新创建一个zabbix-agent端 ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm定义agent端的配置文件中的server（允许那台server监控此agent端） ~]# vim /etc/zabbix/zabbix_agentd.conf Server=172.18.139.69 #填写zabbix-server端的地址 ~]# systemctl restart zabbix-agent 4.zabbix-web开启自动发现的动作 5.zabbix-web配置自动发现zabbix-agent-动作 6.zabbix-web配置自动发现zabbix-agent-操作 7.刷新zabbix-web界面查看自动检测的主机是否被zabbix-server监控 自动发现：ip、ftp、ssh、web、pop3、imap、tcp ip范文自动发现（两个阶段：发现–&gt;动作） 自动发现所执行的动作 发送消息 添加/删除主机 启用/禁用主机 添加主机到组 从组中删除主机 将主机链接到模板/从模板中取消链接 执行远程脚本命令 定义操作-即发送邮件的信息 可以使用系统自带的宏变量设置 官方站点：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location {} DISCOVERY.DEVICE.IPADDRESS →发现通知 已发现设备的IP地址。始终可用，不依赖于添加的主机。 {DISCOVERY.DEVICE。DNS } →发现通知 已发现设备的DNS名称。始终可用，不依赖于添加的主机。 {} DISCOVERY.DEVICE.STATUS →发现通知 已发现设备的状态：可以是UP或DOWN。 {} DISCOVERY.DEVICE.UPTIME →发现通知 自上次更改特定设备的发现状态以来的时间。对于状态为DOWN的设备，这是其停机时间。 {} DISCOVERY.RULE.NAME →发现通知 发现设备或服务存在与否的发现规则的名称。 {} DISCOVERY.SERVICE.NAME →发现通知 发现的服务的名称。例如：HTTP。 {} DISCOVERY.SERVICE.PORT →发现通知 发现的服务的端口。例如：80。 {} DISCOVERY.SERVICE.STATUS →发现通知 已发现服务的状态：可以是UP或DOWN。 {} DISCOVERY.SERVICE.UPTIME →发现通知 自上次更改特定服务的发现状态以来的时间。例如：1小时29分钟。对于状态为DOWN的服务，这是他们停机的时间段。 主机注册（agent端主动告诉server端请求加入）：主动模式操作步骤： 主机注册 #修改配置文件 vim /etc/zabbix/zabbix_agent.conf ServerActive= Hostname= systemctl restart zabbix-agent #Web界面 1.配置–&gt;动作–&gt;事件源–&gt;自动注册–&gt;创建 2.动作–&gt;名称–&gt;触发条件 3.操作–&gt;操作细节–&gt;关联模板–&gt;发送消息 演示： 1.zabbix-agent端修改配置文件1234567891011~]# vim /etc/zabbix/zabbix_agentd.conf97行Server=172.18.139.69 #zabbix-server 端的地址（允许哪台server主机监控）138行ServerActive=172.18.139.69 #zabbix-server 端的地址 （向哪台server主机提请注册） 149行Hostname=agent-01-172.18.139.71 #定义主机可以选择和系统主机名称保持一致重启~]# systemctl restart zabbix-agent.service 2.zabbix-web界面配置创建自动注册机制 3.zabbix-web界面配置创建自动注册触发动作（主机名称包含agent则触发动作） 4.zabbix-web界面配置创建自动注册操作细节（关联模板+发送邮件） 5.zabbix-web关闭自动发现功能 6.刷新界面查看agent是否被server端发现 主动模式被动模式主动模式与被动模式主要是站在zabbix-agent身份来说 1.被动模式（zabbix-server轮询检测zabbix-agent） 2.主动模式（zabbix-agent主动上报给zabbix-server）优 zabbix主动模式与被动模式选择 1.当（Queue）队列中有大量的延迟监控项 2.当监控主机超过300+ ,建议使用主动模式 zabbix默认是被动模式 被动模式100个监控，需要100个回合 主动模式100个监控，需要1个回合 zabbix被动模式（默认） zabbix主动模式（优） 主动模式演示 1.zabbix-agent修改配置文件 1234vim /etc/zabbix/zabbix_agentd.conf Server=zabbix-server端地址 ServerActive=zabbix-server端地址 Hostname=定义主机 2.添加主机（自动注册） 3.zabbix—web需要将模板修改为主动模式 1.全克隆默认被动模式的模板–&gt;改名–&gt;主动模式的模板 2.修改克隆好的模板，进行监控项的修改，修改为主动模式 3.主机引用，先取消被动模式使用的模板（取消链接并清理），然后链接新的模板]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix应用服务器监控之php-fpm服务状态]]></title>
    <url>%2F2019%2F02%2F13%2Fzabbix%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E4%B9%8Bphp-fpm%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[第三章：zabbix应用服务器监控之php-fpm服务状态 PHP-FPM服务状态监控过程 1.在nginx配置文件开启php-fpm状态显示 2.编写脚本对php-fpm状态数据进行采集 3.在zabbix agent设置用户的自定义参数 4.重启zabbix-agent服务使配置生效 5.在zabbix服务端添加item 6.创建监控图形 7.创建事件触发器 8.创建模板以方便后期配置其他主机 实战1.zabbix-server端已经安装好 2.zabbix-agent端安装zabbix-agent和php-fpm并开启状态页面 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758agent端安装php-fpm以及zabbix-agent ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm ~]# yum install php-fpm php -y配置zabbix-agent配置文件定义zabbix-server的地址 ~]# vim /etc/zabbix/zabbix_agentd.conf Server=172.18.139.69 #zabbix-server端的地址 ~]# systemctl start zabbix-agent.service ~]# ss -tnl 10050 php-fpm 开启状态模块 ~]# vim /etc/php-fpm.d/www.conf 121行 pm.status_path = /phpfpm_status ~]# systemctl start php-fpm ~]# ss -tnl 127.0.0.1:9000 此时用户不可直接访问php-fpm的状态页面查看，去要借助nginx去做请求 ~]# yum install nginx ~]# vim /etc/nginx/nginx.conf server &#123; listen 80; location ~ /(phpfpm_status)$ &#123; include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; &#125; &#125; ~]# nginx -t ~]# nginx -s reload访问指定路径查看php-fpm状态信息 ~]# curl -s 172.18.139.71:80/phpfpm_status pool: www process manager: dynamic start time: 13/Feb/2019:16:29:34 +0800 start since: 703 accepted conn: 1 listen queue: 0 max listen queue: 0 listen queue len: 128 idle processes: 4 active processes: 1 total processes: 5 max active processes: 1 max children reached: 0 slow requests: 0 补充回顾： pool – fpm池子名称，大多数为www process manager – 进程管理方式,值：static(静态), dynamic or ondemand. dynamic（动态） start time – 启动日期,如果reload了php-fpm，时间会更新 start since – 运行时长 accepted conn – 当前池子接受的请求数 listen queue – 请求等待队列，如果这个值不为0，那么要增加FPM的进程数量 max listen queue – 请求等待队列最高的数量 listen queue len – socket等待队列长度 idle processes – 空闲进程数量 active processes – 活跃进程数量 total processes – 总进程数量 max active processes – 最大的活跃进程数量（FPM启动开始算） max children reached - 大道进程最大数量限制的次数，如果这个数量不为0，那说明你的最大进程数量太小了，请改大一点。 slow requests – 启用了php-fpm slow-log，缓慢请求的数量 3.zabbix-agent端(php-fpm)文件中定义监控项，调用脚本或者命令 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899创建一个目录作为以后存放zabbix-agent的调用脚本的目录创建目录 ~]# mkdir /etc/zabbix/scripts在此目录下创建取nginx状态键值的脚本 ~]# cd /etc/zabbix/scripts/ scripts]# cat php_fpm_status.sh #!/bin/bash ############################################ #$name: nginx_status.sh #author: daizhe #Create Date: 2019-02-13 ############################################ PHPFPM_COMMAND=$1 PHPFPM_PORT=80 #根据监听不同端口进行调整 start_since()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^start since:/ &#123;print $NF&#125;' &#125; accepted_conn()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^accepted conn:/ &#123;print $NF&#125;' &#125; listen_queue()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^listen queue:/ &#123;print $NF&#125;' &#125; max_listen_queue()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^max listen queue:/ &#123;print $NF&#125;' &#125; listen_queue_len()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^listen queue len:/ &#123;print $NF&#125;' &#125; idle_processes()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^idle processes:/ &#123;print $NF&#125;' &#125; active_processes()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^active processes:/ &#123;print $NF&#125;' &#125; total_processes()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^total processes:/ &#123;print $NF&#125;' &#125; max_active_processes()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^max active processes:/ &#123;print $NF&#125;' &#125; max_children_reached()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^max children reached:/ &#123;print $NF&#125;' &#125; slow_requests()&#123; /usr/bin/curl -s "http://127.0.0.1:"$PHPFPM_PORT"/phpfpm_status" |awk '/^slow requests:/ &#123;print $NF&#125;' &#125; case $PHPFPM_COMMAND in start_since) start_since; ;; accepted_conn) accepted_conn; ;; listen_queue) listen_queue; ;; max_listen_queue) max_listen_queue; ;; listen_queue_len) listen_queue_len; ;; idle_processes) idle_processes; ;; active_processes) active_processes; ;; total_processes) total_processes; ;; max_active_processes) max_active_processes; ;; max_children_reached) max_children_reached; ;; slow_requests) slow_requests; ;; *) echo $"USAGE:$0 &#123;start_since|accepted_conn|listen_queue|max_listen_queue|listen_queue_len|idle_processes|active_processes|total_processes|max_active_processes|max_children_reached&#125;" esac将脚本添加执行权 scripts]# chmod +x php_fpm_status.sh 执行脚本测试验证是否可以取值 scripts]# sh php_fpm_status.sh max_listen_queue 0 4.zabbix-agent端文件中定义键值，调用脚本或者命令1234567891011121314151617进入zabbix-agent定义键值的路径下 ~]# cd /etc/zabbix/zabbix_agentd.d/在此处添加取键值的文件 zabbix_agentd.d]# vim php_fpm_status.conf UserParameter=php_fpm_status[*],/bin/bash /etc/zabbix/scripts/php_fpm_status.sh "$1"重启zabbix-agent ~]# systemctl restart zabbix-agentzabbix-agent端过滤是否有php_fpm_status监控项 ~]# zabbix_agentd -p | grep php_fpm_status php_fpm_status [t|USAGE:/etc/zabbix/scripts/php_fpm_status.sh &#123;start_since|accepted_conn|listen_queue|max_listen_queue|listen_queue_len|idle_processes|active_processes|total_processes|max_active_processes|max_children_reached&#125;] 5.zabbix-server端验证zabbix-agent取值是否可以正常取值1234567891011验证zabbix-server端是否可以正常采取zabbix-agent端的键值执行不添加参数提示怎么使用及参数选项 ~]# zabbix_get -s 172.18.139.71 -k php_fpm_status USAGE:/etc/zabbix/scripts/php_fpm_status.sh &#123;start_since|accepted_conn|listen_queue|max_listen_queue|listen_queue_len|idle_processes|active_processes|total_processes|max_active_processes|max_children_reached&#125;指定验证是否可以正常采取 ~]# zabbix_get -s 172.18.139.71 -k php_fpm_status[listen_queue] 0]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix应用服务器监控之nginx服务状态]]></title>
    <url>%2F2019%2F02%2F13%2Fzabbix%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E4%B9%8Bnginx%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[第三章：zabbix应用服务器监控之nginx服务状态 基础模板 自定义监控项 自定义触发器 自定义报警（邮件|微信） 自定义图形、聚合图形、幻灯片 自定义模板（给主机添加） 服务监控 1.对应的服务本身都具备打开状态页面（服务要有对应的信息展示功能），针对状态页面取值，定义监控项，传递给zabbix-agent 2.在zabbixweb添加对应的key和主机，zabbix-server抓取zabbix-agent上的数据 nginx PHP-fpm mysql tomcat redis nginx服务状态监控过程 1.在nginx配置文件开启Nginx状态显示 2.编写脚本对nginx状态数据进行采集 3.在zabbix agent设置用户的自定义参数 4.重启zabbix-agent服务使配置生效 5.在zabbix服务端添加item 6.创建监控图形 7.创建事件触发器 8.创建模板以方便后期配置其他主机 实战1.zabbix-server端已经安装好 2.zabbix-agent端安装zabbix-agent和nginx并开启状态页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136agent端安装nginx以及zabbix-agent ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm ~]# yum install nginx -y配置zabbix-agent配置文件定义zabbix-server的地址 ~]# vim /etc/zabbix/zabbix_agentd.conf Server=172.18.139.69 #zabbix-server端的地址 ~]# systemctl start zabbix-agent.service ~]# ss -tnl 10050 nginx开启状态页面 ~]# vim /etc/nginx/nginx.conf server &#123; listen 80; .... location /status &#123; stub_status; access_log off; #allow 允许的主机的地址; #仅允许此台机器访问此uri #deny all; &#125; &#125; ~]# nginx -t ~]# nginx -s reload访问指定路径查看nginx状态信息 ~]# curl 172.18.139.71:80/status Active connections: 1 server accepts handled requests 12 12 12 Reading: 0 Writing: 1 Waiting: 0 ``` ---补充回顾：- Active connections: 291 - server accepts handled requests- 16630948 16630948 31070465 - Reading: 6 Writing: 179 Waiting: 106 - Active connections: 活动状态的连接数； - accepts：已经接受的客户端请求的总数； - handled：已经处理完成的客户端请求的总数； - requests：客户端发来的总的请求数； - Reading：处于读取客户端请求报文首部的连接的连接数； - Writing：处于向客户端发送响应报文过程中的连接数； - Waiting：处于等待客户端发出请求的空闲连接数；---3.zabbix-agent端（nginx）文件中定义监控项，调用脚本或者命令```bash创建一个目录作为以后存放zabbix-agent的调用脚本的目录创建目录 ~]# mkdir /etc/zabbix/scripts在此目录下创建取nginx状态键值的脚本 ~]# cd /etc/zabbix/scripts/ scripts]# ls nginx_status.sh scripts]# cat nginx_status.sh ############################################ #$name: nginx_status.sh #author: daizhe #Create Date: 2019-02-13 ############################################ NGINX_PORT=80 #端口根据nginx的端口进行修改 NGINX_COMMAND=$1 nginx_active()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk '/Active/ &#123;print $NF&#125;' #/status/路径根据 nginx配置文件定义状态页面的路径进行修改 &#125; nginx_reading()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk '/Reading/ &#123;print $2&#125;' &#125; nginx_writing()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk '/Writing/ &#123;print $4&#125;' &#125; nginx_waiting()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk '/Waiting/ &#123;print $6&#125;' &#125; nginx_accepts()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk 'NR==3 &#123;print $1&#125;' &#125; nginx_handled()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk 'NR==3 &#123;print $2&#125;' &#125; nginx_requests()&#123; /usr/bin/curl -s "http://127.0.0.1:"$NGINX_PORT"/status/" |awk 'NR==3 &#123;print $3&#125;' &#125; case $NGINX_COMMAND in active) nginx_active; ;; reading) nginx_reading; ;; writing) nginx_writing; ;; waiting) nginx_waiting; ;; accepts) nginx_accepts; ;; handled) nginx_handled; ;; requests) nginx_requests; ;; *) echo $"USAGE:$0 &#123;active|reading|writing|waiting|accepts|handled|requests&#125;" esac将脚本添加执行权 scripts]# chmod +x nginx_status.sh 执行脚本测试验证是否可以取值（范例为：活动状态连接数） scripts]# sh nginx_status.sh active 1 4.zabbix-agent端文件中定义键值，调用脚本或者命令1234567891011121314151617进入zabbix-agent定义键值的路径下 ~]# cd /etc/zabbix/zabbix_agentd.d/在此处添加取键值的文件 zabbix_agentd.d]# vim nginx_status.conf UserParameter=nginx_status[*],/bin/bash /etc/zabbix/scripts/nginx_status.sh "$1" #此路径根据定义的取值脚本路径填写重启zabbix-agent ~]# systemctl restart zabbix-agentzabbix-agent端过滤是否有nginx_status监控项 ~]# zabbix_agentd -p | grep nginx_status nginx_status [t|USAGE:/etc/zabbix/scripts/nginx_status.sh &#123;active|reading|writing|waiting|accepts|handled|requests&#125;] 5.zabbix-server端验证zabbix-agent取值是否可以正常取值12345678910111213验证zabbix-server端是否可以正常采取zabbix-agent端的键值执行不添加参数提示怎么使用及参数选项 ~]# zabbix_get -s 172.18.139.71 -k nginx_status USAGE:/etc/zabbix/scripts/nginx_status.sh &#123;active|reading|writing|waiting|accepts|handled|requests&#125;指定验证是否可以正常采取 ~]# zabbix_get -s 172.18.139.71 -k nginx_status[active] 1 ~]# zabbix_get -s 172.18.139.71 -k nginx_status[handled] 39 6.zabbix-web界面添加监控的zabbix-agent客户端主机 7.创建新的应用集，将监控项关联至应用集（将所有的监控项添加到应用集中） 8.应用监控项 1.添加监听nginx服务器是否存活（zabbix-agent） 2.查看监控状态 3.可以定义触发器进行监控 实战经验总结： 1.先查看文档中有没有对应的脚本和xml模板 2.在服务端导入模板，查看对应的监控项名称 3.测试脚本是否能取值，并存放置于/etc/zabbix/scripts目录下，一定要增加执行权限 4.编写xx.conf文件，里面主要存放的是如何定义监控项 5.最后重启zabbix-agent 6.使用服务端zabbix-get 获取 zabbix-agent对应的监控项的数据]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义内容报警图形及模板]]></title>
    <url>%2F2019%2F02%2F12%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E5%86%85%E5%AE%B9%E6%8A%A5%E8%AD%A6%E5%9B%BE%E5%BD%A2%E5%8F%8A%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义内容报警图形及模板 报警内容实战 告警消息内容 12345报警主机 ：&#123;HOST.NAME1&#125;报警服务 ：&#123;ITEM.NAME1&#125;报警KEY1 : &#123;ITEM.KEY1&#125;: &#123;ITEM.VALUE1&#125; #依据自己报警项数量进行定义报警KEY2 : &#123;ITEM.KEY2&#125;: &#123;ITEM.VALUE2&#125;严重级别 ： &#123;TRIGGER.SEVERITY&#125; 恢复消息内容 1234恢复主机 ：&#123;HOST.NAME1&#125;恢复服务 ：&#123;ITEM.NAME1&#125;恢复KEY1 : &#123;ITEM.KEY1&#125;: &#123;ITEM.VALUE1&#125; #依据自己报警项数量进行定义恢复KEY2 : &#123;ITEM.KEY2&#125;: &#123;ITEM.VALUE2&#125; 故障报警 恢复报警操作 自定义图形实战1.自定义图形监控项（应用集–&gt;监控项–&gt;基于监控项创建触发器–&gt;基于监控项创建图形） 2.设置图形名称及大小 3.预览查看 4.保存设置的图形监控查看 自定义聚合图形 聚合图形–&gt;将多张图整合起来，合并为一张图 1.常见聚合图形 2.在聚合图形中构造函数 3.成品 自定义聚合图形幻灯片1.创建幻灯片 2.将监控的聚合图形添加到幻灯片 3.查看幻灯片/聚合图形 自定义图形Graphtree 功能 1、集中展示所有分组设备 2、集中展示一个分组图像 3、集中展示一个设备图像 4、展示设备下的Application 5、展示每个Application下的图像 6、展示每个Application下的日志 7、对原生无图的监控项进行绘图 注意问题: 在组和主机级别，默认只显示系统配置的graph点击application后，会显示3种数据： 1.系统默认有graph的； 2.系统默认无graph的； 3.日志类的 githun解释文档及手册：https://github.com/OneOaaS/graphtrees 安装:如果您已经安装了zabbix web RPM repo ＃从未使用过3.0.1的补丁12345678910111213141516171819202122zabbix-server端 安装Graphtree ~]# cd /usr/share/zabbix zabbix]# wget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3.0.4.patch ~]# yum install -y patch 导入补丁包 zabbix]# patch -Np0 &lt;graphtree3.0.4.patch zabbix]# chown -R apache.apache oneoaas 修改apache配置文件 ~]# vim /etc/httpd/conf.d/zabbix.conf 最后一行添加 Alias /oneoaas /usr/share/zabbix/oneoaas Alias /zabbix /user/share/zabbix 重启apache ~]# systemctl restart httpd 刷新zabbix-web查看 自定义模板 1.模板是支持导入与导出（模板里面的监控项是由脚本支撑，所有脚本需一起打包） 2.zabbix-agent端.conf的文件中定义监控项及对应的键值，调用脚本或者命令 2.如果希望将之前定义的监控项做成模板，找到监控项–&gt;全选–&gt;复制 自定义模板的好处：可以将监控项重复的使用 1.创建模板 2.将原模板的监控项（键值）复制到新的模板中 3.查看自定义的模板中是否存在复制的监控项 将定义的模板关联到其他主机上（这里将此模板关联到zabbix-server主机上，此时server端扮演zabbix-sgent身份）1.被关联模板的主机必须要定义监控项和对应的取值脚本1.11234567891011121314被监控的主机，安装zabbix客户端：zabbix-agent ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm配置客户端（设置允许zabbix_server端的地址，声明此客户端允许那台服务端进行监控） ~]# vim /etc/zabbix/zabbix_agentd.conf 97行（填写server端的ip/主机名） Server=192.168.52.202启动zabbix-agent客户端 ~]# systemctl start zabbix-agent ~]# systemctl enable zabbix-agentserver端平滑重新加载 ~]# zabbix_server -R config_cache_reload 1.2查看想要被模板连接的主机（agent端）是否被server端监控 2.将原模板添加到应用集中 2.被关联的主机上导入模板 3.zabbix-server端验证是否添加应用集，应用集中是有监控项键值（但是此时出现红色感叹号！说明server端获取不到agent的键值） 4.在agent端设置对应的应用集（将原agent端定义应用集文件scp到新的agent端） 123456789101112~]# cat /etc/zabbix/zabbix_agentd.d/iostart.conf UserParameter=IO,iostat | awk '/^sda/&#123;print $2&#125;'UserParameter=TCP_STATUS_[*],netstat -an | grep -c "$1"UserParameter=Mem_pre,free -m | awk '/Mem/&#123;print $NF*100/$2&#125;'UserParameter=SWAP_pre,free -m | awk '/Swap/&#123;print $3*100/$2&#125;'~]# systemctl restart zabbix-agent.service#刷新不支持的key默认刷新时间间隔为10m#如何修改#管理--&gt;一般--&gt;其他--&gt;修改刷新不支持的项目时间 5.查看模板是否导入成功]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义监控深入之tcp连接状态监控]]></title>
    <url>%2F2019%2F02%2F11%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E6%B7%B1%E5%85%A5%E4%B9%8Btcp%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义监控深入之tcp连接状态监控 列表详解实战一下实现自定义一个监控项自定义监控项-监控tcp连接ESTABLISHED状态 server端自定义的监控agent端的监控项的键值默认是不存在的所以要在agent以脚本的形式定义在响应的位置中，这样server端才可以取出agent端对应的键值 查看定义的应用集 查看自定义的监控项 tcp11种状态实战实现定义多个监控项即tcp的多种连接状态1.可以在agent定义的脚本的文件中使用传递参数的方式实现 2.server端验证键值取值方式 3.zabbix-web界面也修改为监控多中tcp的连接的状态 4.修改完成后显示不支持的key 5.快速发现新的键值-缩短发现时长 6.已经实现监控多个键值监控项 7.可以点击克隆添加其他tcp连接状态 8.在server-web界面将创建好的应用集中的监控项添加到监控的agent端 tcp的十一种状态详解 LISTEN - 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 - 从远程TCP等待连接中断请求； CLOSE-WAIT - 等待从本地用户发来的连接中断请求； CLOSING -等待远程TCP对连接中断的确认； LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认； TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； CLOSED - 没有任何连接状态； 客户端独有的：（1）SYN_SENT （2）FIN_WAIT1 （3）FIN_WAIT2 （4）CLOSING （5）TIME_WAIT 。 服务端独有的：（1）LISTEN （2）SYN_RCVD （3）CLOSE_WAIT （4）LAST_ACK 。 共有的：（1）CLOSED （2）ESTABLISHED 。 值映射实战1.定义一个检测agent端ssh22 号端口是否开启的监控项（演示监听tcp的22端口是否处于监听状态，使用类型是字符类型–&gt;使用的Server state值映射） 2.已经添加在此tcp_status应用集 3.添加触发器 4.添加报警媒介（如果忘记见第一章节zabbix入门/邮件报警） 值映射解释]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义监控深入之内存百分比实战]]></title>
    <url>%2F2019%2F02%2F11%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E6%B7%B1%E5%85%A5%E4%B9%8B%E5%86%85%E5%AD%98%E7%99%BE%E5%88%86%E6%AF%94%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义监控深入之内存百分比实战 取内存的百分比 取出内存的可用的MB大小 / 总内存的大小 = 实际可用的百分比 1234567891011 ~]# free -m （总内存大小） （可用内存的大小） total used free shared buff/cache availableMem: 1821 548 303 8 970 1029Swap: 2047 3 2044命令行计算实际可用内存的百分比 ~]# echo 1029*100/1821 | bc 56 #百分之56~]# free -m | awk '/Mem/&#123;print $NF*100/$2&#125;'56.5074 1.客户端编写监控键值脚本（zabbix-agent） 2.服务端测试查看是否可以通过定义的键值取值 3.zabbix-web端创建监控项 4.查看监控的实际的可用的内存百分比 5.压测zabbix-agent端查看图形是否有变化 图形展示乱码处理6.在zabbix-server服务端解决图像化乱码默认的字体文件实际上是软连接 7.zabbix-server将原字体文件备份 8.将windows的字体复制导入到zabbix-server对应的字体目录中 9.刷新zabbix-web查看是否更改成功 第二种解决字体乱码的方式12~] # yum install wqy-microhei-fonts~] # cp /usr/share/fonts/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf 触发器深入实战 自定义单条件触发器，设置内存低于30%进行报警 10.定义触发器当可用内存低于阈值则报警 11.查看是否添加成功触发器 12.压低zabbix-agent内存，检测报警邮件 13.调试报警邮箱的动作使用系统内置的变量使得发送的邮箱内容更加详细 自定义报警信息和恢复信息 14.重新压测查看发送的邮箱信息内容 实现既监控内存的使用的情况又监控swap的剩余的使用的内存(多条触发器规则) 内存低于百分之10加上，swap使用超过百分之5，在此进行监控报警（更精准） 1.zabbix-agent客户端编写监控键值脚本 2.zabbix-server服务端测试查看是否可以通过定义的键值取值 3.在zabbix-web端创建监控项 4.在zabbix-web端创建多条件的触发器 5.已经定义多条件的触发器（满足内存低于30%规则，并且同时满足swap使用率超过5%则报警） 常用的触发器表达式，常用的函数 and 并且 or 或者 last() 最新的值 avg() 解决波动报警，流量在多少分钟平均达到多少报警 nodata() 收不到数据进行报警]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义监控深入之系统内置监控项]]></title>
    <url>%2F2019%2F02%2F11%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E6%B7%B1%E5%85%A5%E4%B9%8B%E7%B3%BB%E7%BB%9F%E5%86%85%E7%BD%AE%E7%9B%91%E6%8E%A7%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义监控深入之系统内置监控项 1.所有的主机必须统一监控项 nginx.conf,tomcat.conf 2.将监控项进行分类，然后配置不同模板 手动一个个的当以监控项–&gt;加入nginx模板 3.不同的主机引用不同模板 nginx这台主机–&gt;关联–&gt;nginx模板 系统自带的监控项的意义（zabbix客户端 被动模式） 如果查看此监控项对用的agent值123456789101112131415可以在zabbix-server端查看agent键值1.重启agent客户端，验证是否已经添加到监控项 ~]# systemctl restart zabbix-agent ~]# zabbix_agentd -p | grep IO IO [t|2.53] #如果此处出现IO [t| IO commond not found] 表示这个iostat命令未安装2.zabbix-server验证zabbix-agent是否有对应的监控项 ~]# yum install zabbix-get -y zabbix-get -s 指定agent ip地址 -k 指定定义在agent监控项的名称 -p 指定agent 端口 ，默认为10050 ~]# zabbix_get -s 172.20.139.70 -k IO 2.25 1234系统自带监控项是有些是支持传递参数的~]# zabbix_get -s 172.20.139.70 -k 'net.tcp.port[&lt;ip&gt;,port]~]# zabbix_get -s 172.20.139.70 -k 'net.tcp.port[&lt;172.20.139.70&gt;,22]']]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义监控项之自定义微信报警]]></title>
    <url>%2F2019%2F02%2F10%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BE%AE%E4%BF%A1%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义监控之自定义微信报警 企业微信注册 官方站点：https://work.weixin.qq.com 实现企业微信报警 1.创建媒体介质类型–&gt;脚本–&gt;写什么内容–&gt;脚本放在哪儿 12345脚本的放置位置在zabbixx-server的配置文件中有定义 ~]# vim /etc/zabbix/zabbix_server.conf 516行 #定义将脚本放置在此文件中 AlertScriptsPath=/usr/lib/zabbix/alertscripts weixin.py程序内容 1.将此文件配置完成后放置在/usr/lib/zabbix/alertscripts 路径下并添加+x 执行权 2.执行python脚本需要安装 yum install python-pip pip install requests #python 扩展模块 3.执行脚本./weixin.py weixinID 发送的信息，如果企业微信收到发送的信息，则代表测试成功，成功后会生成一个日志信息/tmp/weixin.log ，需要将此日志文件的所有者和所属组修改为zabbix用户 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#!/usr/bin/env python# encoding: utf-8# Create time 2016-10-08#Auth chenpengimport urllib2import jsonimport sysimport timeclass WebChat(object):def __init__(self,CropID,Secret):self.CropID = CropIDself.Secret = Secretdef Get_Token(self,info):''':param info: 存储执行结果和执行程序状态码code （0代表执行成功，非零表示不成功）:return:'''self.info = infogurl = "https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=%s&amp;corpsecret=%s" % (self.CropID,self.Secret)try:#通过Get方式获取tokenreq = urllib2.Request(gurl)response = urllib2.urlopen(req)g_result = json.loads(response.read(),"UTF-8")if g_result .has_key('access_token'):self.info['result']= g_result ['access_token']self.info['code'] = 0else:self.info['result'] = g_resultself.info['code'] = 1except Exception,e:self.info['code'] = 1self.info['result'] = edef Send_Msg(self,touser,toparty,agentid,access_token,content,info,*args,**kwargs):'''发送信息到微信:param touser: 部门成员id，zabbix中定义的微信接收者,成员ID列表（消息接收者，多个接收者用‘|'分隔，最多支持1000个）。特殊情况：指定为@all，则向关注该企业应用的全部成员发送:param toparty: 部门id，定义了范围，组内成员都可接收到消息,部门ID列表，多个接收者用‘|'分隔，最多支持100个。当touser为@all时忽略本参数:param agentid: 企业应用的id，整型。可在应用的设置页面查看:param access_token: 根据CropID,Secret获取的访问token值:param content: 滤出zabbix传递的第三个参数,表示发送微信消息的内容消息内容，最长不超过2048个字节，注意：主页型应用推送的文本消息在微信端最多只显示20个字（包含中英文）:param info: 返回执行结果信息&#123;'result':None,'code':None&#125;;'code':0或者非零 ;0表示成功 非零表示失败:param args::param kwargs::return:'''self.touser = touserself.toparty = topartyself.agentid = agentidself.conntent = contentself.access_token = access_tokenself.info = infopurl = "https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s" % (access_token)data = &#123;"touser": "","toparty": "","totag": "", #标签ID列表，多个接收者用‘|'分隔，最多支持100个。当touser为@all时忽略本参数,非必须"msgtype": "text", #必须"agentid": "", #必须"text": &#123;"content": "" #必须&#125;,"safe": "0" # 表示是否是保密消息，0表示否，1表示是，默认0&#125;data['touser'] = self.touserdata['agentid'] = self.agentiddata['toparty'] = self.topartydata['text']['content']=self.conntentdata = json.dumps(data,ensure_ascii=False)try:#通过PUT方式获取发送数据req = urllib2.Request(purl, data)response = urllib2.urlopen(req)res = json.loads(response.read())self.info['code'] = res['errcode']self.info['result'] = res['errmsg']except Exception,e:self.info['result'] = eself.info['code'] = 1if __name__ == '__main__':reload(sys)sys.setdefaultencoding('utf-8')def log(date, touser, content,info):'''发送的日志打印日志:param date: 时间:param touser: 发送给谁:param content: 发送的信息内容:param info: 发送执行的结果:return:'''msg = '%s %s %s 发送结果 - %s\n' % (date, touser, content, info)with open('msg.log', 'a') as f:f.write(msg)agentid = sys.argv[1]#agentid = 1touser = 'xxxxxxx@qq.com'toparty = ''content = sys.argv[2:]content = '\n'.join(content)#content = '测试'CropID = 'xxxxxxxxxxxxxxxxxxx'Secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'info=&#123;'result':None,'code':None&#125;date = time.strftime('%Y-%m-%d %H:%M:%S')res=WebChat(CropID,Secret)res.Get_Token(info)if info['code'] == 0:access_token = info['result']res.Send_Msg(touser=touser, toparty=toparty, agentid=agentid, access_token=access_token,content=content,info=info)if info['code'] == 0:content = eval(content)log(date, touser, content,info)else:log(date, touser, content, info)else:log(date,touser,content,info) 上面的微信报警已经实现单点发送 1.创建报警媒介 2.创建报警企业微信接收人 3.测试即可]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自定义监控项之自定义邮件报警]]></title>
    <url>%2F2019%2F02%2F10%2Fzabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E4%B9%8B%E8%87%AA%E5%AE%9A%E4%B9%89%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[第二章：zabbix自定义监控之自定义邮件报警 自定义邮件报警信息 当监控项超过触发器设定的阈值–&gt;触发动作–&gt;发送消息|执行动作 需要考虑到的问题 1.怎么报警 2.报警怎么发 3.发什么内容 4.报警发给谁 1.打开动作选项（入门：定义的监控项的数值达到阈值时仅发生 wen界面的报警但并未有处理动作） 2.设定消息发送的介质（邮件/微信）3.配置发件人的账号和授权码(注意：不是收件人)使用qq邮箱接收信息开启邮箱一下功能4.配置收件人接收的邮箱地址5.添加收件人的邮箱，以及接受报警的等级6.一定要点击更新按钮7.测试触发邮箱报警 继续使用入门级的监控agent客户端系统连接数 agent端开启三个窗口连接 已经触发报警 邮箱收到报警邮箱]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix入门]]></title>
    <url>%2F2019%2F02%2F10%2Fzabbix%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[第一章：zabbix入门 监控机基础知识概况 zabbix并非监控，而是实现监控的工具 Zabbix-server是一个c/s和b/s结构 安装zabbbix的服务器安装时和php7.1有冲突：若此机器上已经安装php7.1就安装不上zabbix 监控知识体系 为什么要使用监控 1.对系统不间断实时监控 2.实时反馈系统当前状态 3.保证服务可靠性安全性 4.保证业务持续稳定运行 监控怎么用，比如我们需要监控磁盘的使用率 1.如何查看磁盘使用率 （df -h） 2.监控磁盘的哪些指标 （block、inode） 3.如何获取具体的信息 （df -h | awk ‘/\/$/{print $(NF-1)}’） 4.获取的数值到达多少报警 小于等于80% 有哪些监控软件 cacti、nagios、zabbix lepus(天兔)数据库监控系统 open-falcon 小米 prometheus (普罗米修斯，dcker，k8s) 如果去到一家新的公司，如何入手？ 1.硬件监控——路由器、交换机、防火墙 2.系统监控——cpu、内存、磁盘、网络、进程、tcp 3.服务监控——nginx、php、tomcat、redis、memcache、mysql 4.web监控——响应时间、加载时间、渲染时间 5.日志监控——ELK、（收集、存储、分析、展示）日志 6.安全监控——firewalld、WAF(nginx+lua)、安全宝、牛盾云、安全狗 zabbix大纲 0.单机监控 1.安装zabbix 2.zabbix基础架构 3.监控一台主机 4.自定义监控项 （自己编写脚本-&gt;zabbix） 5.自定义阈值 （达到预设的瓶颈） 6.自定义动作 （发邮件|执行命令） 7.自定义报警 单机监控 单机进程cpu查看负载和使用率 uptime top htop 主要重要的查看项(调度用户&lt;——&gt;系统 ：上下文切换) us:用户空间的使用（小于等于35%） sy：内核空间的使用（小于等于35%） 查看此进程的用户/内核的使用 time ls id cpu：空闲的cpu使用率（最低不得小于5%） 单机内存查看 free -m 单机磁盘查看 df iotop iostat 单机查看网络 ifconfig iftop -n 界面显示的是类似刻度的范围，为显示流量图的长条作标尺用的 中间的&lt;= =&gt;这两个左右的箭头表示的是流量的方向 TX：发送流量 RX：接收的流量 TOTAL: 总流量 Cumm: 运行iftop到目前时间的总流量 peak: 流量峰值 rates： 分别表示过去2s 10s 40s 的平均流量 nethogs netstat -tnlp -na -rn glances(可以查看全局的命令) 12[root@example.com ~]# yum install -y epel-release[root@example.com ~]# yum install -y glances Mbps: 1000Mbps Mbps / 8 = MB MB: 12MB 引入zabbix分布式监控系统1.使用shell脚本来监控服务器 内存：每隔1分钟，当你的可用内存低于100m,发送邮件报警，要求显示剩余内存1234567891011121314151617181920212223242526模拟可用内存低于100m 临时管理swap（swap硬盘模拟内存） swapoff -a （关闭） swapon -a (开启) 消耗内存 dd if=/dev/ser0 of=/dev/null bs=800M 此时内存全部使用，但是系统不会崩溃，因为linux系当检测到内存全部用完的时候，为了保障系统不会崩溃，从而将使用内存最多的进程杀死（oom）。实现步骤： 1.怎么获取内存的可用值 ~]# free -m | awk '/^Mem/&#123;print $NF&#125;' 2.获取到内存可用的值如何设定阈值进行比较 3.比较如果大于100m则不处理，如果小于100m则报警 编写脚本实现取出内存当前的阈值进行比较 ~]# !vim HostName=$(hostname)_$(hostname -i) Date=$(date +%F) while true;do Free=$(free -m|awk '/^Mem/&#123;print $NF&#125;') if [ $Free -le 100 ];then echo "$Date $HostName Mem Is &lt; $&#123;Free&#125;MB" fi sleep 1 done 4.如何每隔1分钟执行一次 范例： 公司未启用swap（swap也是公司中服务器不建议启用的，因为swap是将磁盘模拟内存使用，消耗cpu的性能，建议关闭swap。加大内存），随着客户的流量日益增大，导致将zabbix服务进程强制OOM，Zabbix服务进程被kill，有两种解决的方法，如果公司为了性能着想加大内存，如果公司资有限添加swap,如果是为了服务的效率建议使用添加内存的方式， Zabbix-server是一个c/s和b/s结构 安装zabbix（单机） 官方安装使用手册：https://www.zabbix.com/documentation/4.0/zh/manual/installation 服务端安装：端口10051 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273741.安装 ~]# rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm2.安装Zabbix服务器，前端，代理（zabbix要连接数据库）解决的依赖关系，安装了php、httpdzabbix-agent ： zabbix客户端 ~]# yum install zabbix-server-mysql zabbix-web-mysql zabbix-agent -y3.安装数据库 ~]# yum install mariadb-server -y4.创建zabbix数据库以及用户 #启动数据库，加入开机启动项 ~]# systemctl start mariadb ~]# systemctl enable mariadb #创建数据库并授权 ~]# mysql -uroot mysql&gt; create database zabbix character set utf8 collate utf8_bin; mysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by 'centos'; mysql&gt; quit;5.导入初始架构和数据。系统将提示您输入新创建的密码（） ~]# cd /usr/share/doc/zabbix-server-mysql-4.0.4/ #查看压缩包的内容不解压zcat #导入到zabbix库中 zabbix-server-mysql-4.0.4]# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uroot zabbix(zabbix为前面创建的数据库名称)6.启动zabbix server进程 #在zabbix_server.conf中编辑配置数据库配置 ~]# vim /etc/zabbix/zabbix_server.conf 91行 # DBHost=localhost #数据库的地址，这里演示的为单机模式，默认也是localhost 100行 DBName=zabbix #数据库的名称，这里演示创建的数据库的名称也为zabbix 116行 DBUser=zabbix #授权的数据库的用户 124行 DBPassword=centos #数据库的密码 #启动前关闭selinux ~]# systemctl start zabbix-server ~]# systemctl enable zabbix-server #保证80端口为安装zabbix时安装的依赖的httpd使用 ~]# ss -tnl *:10051 *:3306 *:80 7.编辑zabbix前端的PHP配置 #zabbix前端的apache配置文件位于/etc/httpd/conf.d/zabbix.conf 一些php设置已经完成了配置 #依据所在的时区，设置时间，更改配置文件后，重启Apache服务器 ~]# vim /etc/httpd/conf.d/zabbix.conf Alias /zabbix /usr/share/zabbix #如果访问uri路径为/zabbix 则调度到/usr/share/zabbix 路径下，别名意思 &lt;Directory "/usr/share/zabbix"&gt; Options FollowSymLinks AllowOverride None Require all granted &lt;IfModule mod_php5.c&gt; ... 20行修改为(仅一处修改即可) php_value date.timezone Asia/Shanghai &lt;/IfModule&gt; ... ~]# systemctl restart httpd ~]# systemctl enable httpd 8.访问zabbix页面健康检测zabbix_web连接数据库zabbix_web连接zabbix_server确认配置生成的安装配置123456789101112131415161718192021#可以在生成的此文件中，以后更改配置 ~]# cat /etc/zabbix/web/zabbix.conf.php&lt;?php// Zabbix GUI configuration file.global $DB;$DB['TYPE'] = 'MYSQL';$DB['SERVER'] = 'localhost';$DB['PORT'] = '0';$DB['DATABASE'] = 'zabbix';$DB['USER'] = 'zabbix';$DB['PASSWORD'] = 'centos';// Schema name. Used for IBM DB2 and PostgreSQL.$DB['SCHEMA'] = '';$ZBX_SERVER = 'localhost';$ZBX_SERVER_PORT = '10051';$ZBX_SERVER_NAME = '代哲的zabbix';$IMAGE_FORMAT_DEFAULT = IMAGE_FORMAT_PNG; 登陆 初始登陆界面修改语言 zabbix快速监控一台服务器 监控一台服务器 此被监控的主机必须安装客户端 客户端安装：端口10050 zabbix客户端aliyun下载站点：https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/ 1234567891011121314151.被监控的主机安装客户端（zabbix-agent） #被监控的主机，安装zabbix客户端：zabbix-agent ~]# rpm -ivh https://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.3-1.el7.x86_64.rpm2.配置客户端（设置允许zabbix_server端的地址，声明此客户端允许那台服务端进行监控） ~]# vim /etc/zabbix/zabbix_agentd.conf 97行（填写server端的ip/主机名） Server=192.168.52.2023.启动zabbix-agent客户端 ~]# systemctl start zabbix-agent ~]# systemctl enable zabbix-agent ~]# ss -tnl :::10050 服务端添加监控项，来监控已经安装zabbix-agent的客户端 1.添加监控的主机 2.查看监控的 zabbix基础架构与分离数据库实战基础架构 zbbix监控工具的基本架构zabbix-agent—-&gt;zabbix-server—-&gt;数据库&lt;—– zabbix-web数据采集 &ensp;&ensp;&ensp; &ensp; 数据分析|报警 &ensp; &ensp; &ensp; &ensp; 数据存储 &ensp; &ensp; &ensp; 数据展示 server端去主动向agent端收取数据 分离数据实战 单台： LAMP 拆分-架构 LAP + Mysql 单台主机监控性能是有瓶颈的，可以检测的主机也是有限的。 单台–&gt;架构拆分的修改项 zabbix-server 修改zabbix-server连接数据库的连接信息 /etc/zabbix/zabbix_server.conf zabbix-web 修改zabbix-web连接数据库的连接信息(web界面创建数据库连接界面点击生成) /etc/zabbix/web/zabbix.conf.php 范例：单机–&gt;架构拆分 LAP + MYSQL12345678910111213141516171819202122232425262728293031323334353637383940414243将原有建立在zabbix-servers上的mariadb的数据库进行打包导入分离开来的新的数据库中1.在新的数据库上创建zabbix数据库 mysql&gt; create database zabbix character set utf8 collate utf8_bin; mysql&gt; grant all privileges on zabbix.* to zabbix@'%' identified by 'centos';2.在旧的zabbix服务器上备份数据库文件，然后导入至新的数据库中 ~]# mysqldump -uroot --databases zabbix --single-transaction &gt; `date +%F%H`-zabbix.sql ~]# cat 2019-02-1013-zabbix.sql | mysql -h 新的数据库的地址 -uzabbix -pcentos zabbix3.验证新的数据库是否已经备份旧的数据库的数据 ~]# mysql -e "show databases;" +--------------------+ Database | +--------------------+ | information_schema | | mysql | | performance_schema | | test | | zabbix | +--------------------+4.修改zabbix-server的数据库连接的配置文件 ~]# grep '^[a-Z]' /etc/zabbix/zabbix_server.conf LogFile=/var/log/zabbix/zabbix_server.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_server.pid SocketDir=/var/run/zabbix DBHost=新的数据库的ip地址 DBName=zabbix #新的数据库的数据库名称 DBUser=zabbix #新的数据库上授权的账号的信息 SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 ~]# systemctl restart zabbix-server5.修改zabbix-web连接数据库信息的配置文件 ~]# vim /etc/zabbix/web/zabbix.conf.php ~]# systemctl restart httpd zabbix自定义监控实战 iostat 命令可以对系统的磁盘IO和CPU使用情况进行监控。iostat属于sysstat软件包 常见的选项 -c 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 执行命令可查看的字段信息解释 %user：用户进程消耗cpu的比例 %nice：用户进程优先级调整消耗的cpu比例 %sys：系统内核消耗的cpu比例 %iowait：等待磁盘io所消耗的cpu比例 %idle：闲置cpu的比例（不包括等待磁盘io的s） tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量 kB_wrtn/s：每秒向设备（drive expressed）写入的数据量 kB_read：读取的总数据量 kB_wrtn：写入的总数量数据量 这些单位都为Kilobytes。 常用组合： iostat -k 1 10 或 iostat -m 1 10 iostat -d -x -k 1 10 iostart -c 1 10 定义监控项的要点 1.监控的系统中的对象 iostat | awk ‘/^sda/{print $2}’ 2.如何增加监控项 Userparameter=&lt;监控项名称&gt;,&lt;监控项所指定的命令&gt;(固定格式) 3.agetnt如何验证自己是否有对应的监控项并取值 ~]# zabbix_agentd -p | grep 4.zabbix-server如何验证zabbix-agent是否有对应的监控项 zabbix-get 5.zabbixweb界面进行关联zabbix-agent监控项 范例：自定义监控的磁盘IO的，每秒传输次数1234567要想使得zabbix-server端主动去收集zabbix-agent端的指定的数据信息，需要在zabbix-agent定义监控的系统对象zabbix-agnet端的配置文件中包含了一些定义的配置文件的位置可以将监控的系统对象写在此包含的文件中~]# vim /etc/zabbix/zabbix_agentd.conf Include=/etc/zabbix/zabbix_agentd.d/*.conf 12345678910111213141516171819201.zabbix-agent监控的系统中的对象 - iostat | awk '/^sda/&#123;print $2&#125;'2.在zabbix-agent端定义监控磁盘IO每秒传输的速率 ~]# vim /etc/zabbix/zabbix_agentd.d/iostart.conf UserParameter=IO,iostat | awk '/^sda/&#123;print $2&#125;'3.重启agent客户端，验证是否已经添加到监控项 ~]# systemctl restart zabbix-agent ~]# zabbix_agentd -p | grep IO IO [t|2.53] #如果此处出现IO [t| IO commond not found] 表示这个iostat命令未安装4.zabbix-server验证zabbix-agent是否有对应的监控项 ~]# yum install zabbix-get -y zabbix-get -s 指定agent ip地址 -k 指定定义在agent监控项的名称 -p 指定agent 端口 ，默认为10050 ~]# zabbix_get -s 172.20.139.70 -k IO 2.25 5.zabbixweb界面进行关联zabbix-agent监控项图1图2图3 zabbix自定义监控阈值实战 监控项检测到监控的数据达到一个阈值则触发报警信息 系统默认监控agent中/etc/passwd文件发生变化报警1.缩短检测/etc/passwd文件的时长方便检测2.开启报警3.在客户端修改/etc/passwd文件触发报警（web页面报警） 针对系统默认监控的系统主机登陆的终端个数来定义报警 1.定义触发器，如果系统登陆的终端如果大于2则触发报警信息 2.查看定义的监控项3.触发监控的报警4.已经收到报警]]></content>
      <categories>
        <category>zabbix_老男孩</category>
      </categories>
      <tags>
        <tag>zabbix_老男孩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived使用基础]]></title>
    <url>%2F2019%2F02%2F04%2Fkeepalived%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[keepalived使用基础]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived简介]]></title>
    <url>%2F2019%2F01%2F28%2Fkeepalived%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[keepalived简介 HA 即（high available）高可用，又被叫做双机热备，用于关键性业务（冗余）。 高可用集群概念 集群类型： LB lvs/nginx（http/upstream, stream/upstream） HA 高可用性（多适用于接入层的高可用） SPoF: Single Point of Failure，单点故障 HPC 高性能集群(High Performance Computing) 系统可用性：SLA(Service-Level Agreement) 95%=(602430)*(1-0.9995) （指标）=99%, …, 99.999%，99.9999% 系统故障： 硬件故障：设计缺陷、wear out（损耗）、自然灾害…… 软件故障：设计缺陷 提升系统高用性（SLA）的解决方案之降低MTTR(平均故障时间) 解决方案：建立冗余机制 active/passive 主/备 active/active 双主 active –&gt; HEARTBEAT（心跳检测机制判断对方是否存活） –&gt; passive active HEARTBEAT active 高可用的是“服务” HA nginx service： vip/nginx process[/shared storage] 资源：组成一个高可用服务的“组件” (1) passive node的数量（从节点的数量） (2) 资源切换（ip地址的切换或者说是服务的切换） shared storage：共享存储 NAS(Network Attached Storage)：网络附加存储，基于网络的共享文件系统。 SAN(Storage Area Network)：存储区域网络，基于网络的块级别的共享 Network partition：网络分区 quorum：法定人数 with quorum： &gt; total/2（剩余存活的节点一定是大于总节点的一半的） without quorum: &lt;= total/2（故障节点的数量，一定要小于总节点的一半） 隔离设备： fence（高可用的fence设备：基于网络的交换机，自动检测服务器上的网络是否出现问题，会直接在网络层断开网络的存储，断电重启） node：STONITH = Shooting The Other Node In The Head 断电重启 资源：断开存储的连接 双节点集群(TWO nodes Cluster) 辅助设备：ping node, quorum disk(仲裁设备) Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作 Failback：故障移回，即某资源的主节点故障后重新修改上线后，将之前已转移至其它节点的资源重新切回的过程 HA Cluster实现方案: AIS(Applicaiton Interface Specification)应用程序接口规范 RHCS：Red Hat Cluster Suite红帽集群套件 heartbeat：基于心跳监测实现服务高可用（centos6及之前的版本会使用此机制） pacemaker+corosync：资源管理与故障转移（配置复杂） vrrp(Virtual Router Redundancy Protocol)：虚拟路由冗余协议,解决静态网关单点风险 软件层—keepalived 物理层—路由器、三层交换机、防火墙 高可用集群-&gt;后端存储 高可用集群-&gt;后端存储 JBOD （ Just a Bunch Of Disks ）不是标准的 RAID 等级，它通常用来表示一个没有控制软件提供协调控制的磁盘集合， JBOD 将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘， JBOD 的数据存放机制是由第一块磁盘开始按顺序往后存储，当前磁盘存储空间用完后，再依次往后面的磁盘存储数据， JBOD 存储性能完全等同于单块磁盘，而且也不提供数据安全保护，它只是简单提供一种扩展存储空间的机制， JBOD 可用存储容量等于所有成员磁盘的存储空间之和。 高可用集群-&gt;网络层实现高可用（VRRP） Keepalived简介 Keepalived软件主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。 重要作用 管理LVS负载均衡软件 实现LVS集群节点的健康检查中 作为系统网络服务的高可用性（failover） keepalived: vrrp协议的软件实现，原生设计目的为了高可用ipvs服务（初期针对LVS高可用） 功能： 基于vrrp协议完成地址流动 为vip地址所在的节点生成ipvs规则(在配置文件中预先定义) 为ipvs集群的各RS做健康状态检测 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务，以此支持nginx、haproxy等服务 组件： 用户空间核心组件： vrrp stack-VIP消息通告 checkers-监测real server system call-标记real server权重 SMTP-邮件组件 ipvs wrapper-生成IPVS规则 Netlink Reflector-网络接口 WatchDog-监控进程 控制组件：配置文件分析器 IO复用器 内存管理组件 官方站点：http://keepalived.org/index.html 官方参考手册：http://keepalived.org/documentation.html DOWNLOAD:http://keepalived.org/download.html keepalived： vrrp协议：Virtual Router Redundancy Protocol（keepalived基于此协议实现ip地址的高可用） 术语： 虚拟路由器：Virtual Router 虚拟路由器标识：VRID(0-255)优先级，唯一标识虚拟路由器 物理路由器： master：主设备 backup：备用设备 priority：优先级（优先级数值越大，优先级越高） VIP：Virtual IP VMAC：Virutal MAC (00-00-5e-00-01-VRID)：虚拟mac地址 通告：心跳，优先级等，周期性 工作方式：抢占式，非抢占式 安全工作： 认证： 无认证 简单字符认证：预共享密钥 工作模式： 主/备：单虚拟路由器 主/主：主/备（虚拟路由器1），备/主（虚拟路由器2） vrrp协议的工作流程 vrrp（虚拟路由冗余协议）是一种容错协议，他保证当主机的吓一跳路由器出现故障时，由另一台路由器来代替出现故障的路由器进行工作，从而保持网络通讯的连续性和可靠性。 vrrp具有如下优点： 简化网络管理。在具有多播或广播能力的局域网（如以太网）中，借助vrrp能在某台设备出现故障时仍然提供高可靠的缺省链路，有效避免单一链路发生的故障后网络终端的问题，而无需修改动态路由协议，路由发现协议等配置信息，也无需修改主机的默认的网关配置。 适应性强。vrrp报文封装在ip报文中，支持各种上层协议。 网络开销小，vrrp只定义了一种报文—vrrp通告报文，并且只有处于master状态的路由器可以发送vrrp报文 vrrp协议中的相关的术语 虚拟路由器：由一个master路由器和多个backup路由器组成，主机将虚拟路由器当作默认网关。 vrid：虚拟路由器的标识，有相同vrid的一组路由器构成一个虚拟路由器。 master路由器：虚拟路由器中承担报文转发任务的路由器。 backup路由器：master路由器出现故障时，能够代替master路由器工作的路由器。 虚拟ip地址：虚拟路由器的ip地址，一个虚拟路由器可以拥有一个或者多个ip地址。 ip地址拥有者：接口ip地址与虚拟ip地址相同的路由器被称之为ip地址拥有者。 虚拟mac地址：一个虚拟路由器拥有一个虚拟mac地址。虚拟mac地址的合适为00-00-5E-00-01-{VRID}。通常情况下，虚拟路由器回应ARP请求使用的时虚拟MAC地址，只有虚拟路由器做特殊配置的时候，才会赢接口的真实的MAC地址。 优先级：VRRP根据优先级来确定虚拟路由器中每台路由器的地位。 非抢占方式：如果backup路由器工作在非抢占方式下，则只要master路由器没有出现故障，backup路由器即使随后被配置了更高的优先级也不会为master路由器。 抢占方式：如果backup路由器工作在抢占方式下，当它收到vrrp报文后，会将自己的优先级与通告报文中的优先级进行比较。如果自己的优先级比当前master路由器的优先级高，就会主动抢占成为master路由器；否则，将保持backup状态。]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxyACL]]></title>
    <url>%2F2019%2F01%2F24%2FHAproxyACL%2F</url>
    <content type="text"><![CDATA[HAproxy的ACL过滤器及自定义错误页 一、ACL过滤器（七层http模式下） acl：对接收到的报文进行匹配和过滤，基于请求报文头部中的源地址、源端口、目标地址、目标端口、请求方法、URL、文件后缀等信息内容进行匹配并执行进一步操作（基于类型的调度决策）。 acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] acl &ensp;&ensp; 名称 &ensp;&ensp;&ensp;&ensp; 过滤条件 &ensp;&ensp; &ensp;&ensp; 条件标记位 &ensp;&ensp; 具体操作符 &ensp;&ensp; 操作对象类型 acl image_service hdr_dom(host) -i img.daizhe.net.cn hdr_dom(host)：客户端请求的头部的域名 用hots做匹配条件的好处，可以将ip地址复用，对一个ip进行监听，当用户请求进行请求时，可以将一个地址对应多个A记录解析的域名（一个ip地址监听多个公网的域名）。 hdr_dom(User-Agent) ：客户端请求使用的浏览器的类型 可以根据客户使用的类型，将客户发来的请求做处理转发。调度器转发后其他后端的提供服务的服务器上。 ACL名称，可以使用大字母A-Z、小写字母a-z、数字0-9、冒号：、点.、中横线和下划线，并且严格区分大小写，必须Image_site和image_site完全是两个acl(严格区分大小写)。 Criterion_ACL(定义ACL标准) &lt;criterion&gt; ：匹配条件 dst 目标IP dst_port 目标PORT src 源IP src_port 源PORT hdr &lt;string&gt;用于测试请求头部首部指定内容 hdr_dom(host) 请求的host名称，如 www.daizhe.net.cn hdr_beg(host) 请求的host开头，如 www. img. video. download. ftp. hdr_end(host) 请求的host结尾，如 .com .net .cn path_beg 请求的URL开头，如/static、/images、/img、/css path_end 请求的URL中资源的结尾，如 .gif .png .css .js .jpg .jpeg flags（条件标记位） &lt;flags&gt;-条件标记 -i 不区分大小写(域名经过haproxy调度时不区分域名的字符大小写) -m 使用指定的pattern匹配方法 -n 不做DNS解析 -u 禁止acl重名，否则多个同名ACL匹配或关系(调度器上定义acl的名称尽量不要重名，如果有重名，默认隐含的是或的关系) – 强制flag结束. 当字符串和某个flag相似时使用 operator（具体操作符） [operator]-操作符： 整数比较：eq、ge、gt、le、lt字符比较： exact match (-m str) :字符串必须完全匹配模式 substring match (-m sub) :在提取的字符串中查找模式，如果其中任何一个被发现，ACL将匹配 prefix match (-m beg) :在提取的字符串首部中查找模式，如果其中任何一个被发现，ACL将匹配 suffix match (-m end) :将模式与提取字符串的尾部进行比较，如果其中任何一个匹配，则ACL进行匹配 subdir match (-m dir) :查看提取出来的用斜线分隔（“/”）的字符串，如果其中任何一个匹配，则ACL进行匹配 domain match (-m dom) :查找提取的用点（“.”）分隔字符串，如果其中任何一个匹配，则ACL进行匹配 value（操作对象类型） &lt;value&gt;的类型： Boolean #布尔值 integer or integer range #整数或整数范围，比如用于匹配端口范围 IP address / network #IP地址或IP范围 string （字符串的方式制定域名） exact –精确比较 substring—子串 prefix-前缀比较 subdir-路径， /wp-includes/js/jquery/jquery.js #匹配子路径 domain-域名，daizhe.net.cn regular expression #正则表达式 hex block #16进制 Acl定义与调用 acl作为条件时的逻辑关系： 与：隐式（默认）使用 或：使用“or” 或 “||”表示 否定：使用“!“ 表示 示例： if invalid_src invalid_port 与关系 if invalid_src || invalid_port 或 if ! invalid_src 非 范例：调度器拒绝192.16.52.175的主机访问即调度器检测到此地址段的主机则不今次那个调度到后端的主机上1234567891011121314151617181920haproxy_server ~]# vim /etc/haproxy/haproxy.cfg frontend web-port-80 mode http rspadd X-Via:\ HAPorxy default_backend websrvs bind 0.0.0.0:8888 acl huaidan src 192.168.52.175 #### block if huaidan #### backend websrvs cookie SERVER-COOKIE insert indirect nocache option forwardfor server web1 192.168.52.162:80 cookie web1 check inter 2000 fall 3 rise 5 ~]# systemctl restart haproxy使用192.16.52.175的主机充当客户端访问调度器验证是否可进行后端服务器的调度 ~]# curl 192.168.52.175:8888 &lt;html&gt;&lt;body&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt; Request forbidden by administrative rules. &lt;/body&gt;&lt;/html&gt; 范例：acl中与关系的体现 12345678910111213141516171819202122232425262728293031#acl bad_curl hdr_sub(User-Agent) -i curl#block if bad_curl 定义客户端的请求报文中如果首部User-Agent的值有一个子字串，中是否存在curl命令，这里是两个条件一起判断则两个acl是与的关系，表示为来自192.16.52.175地址的主机并且是用curl命令请求数据，通过调度器转后端服务器时才被拒绝 ~]# vim /etc/haproxy/haproxy.cfg frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl huaidan src 192.168.52.175 #### acl bad_curl hdr_sub(User-Agent) -i curl #### block if huaidan bad_curl #### backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 ~]# systemctl restart haproxy使用192.16.52.175的主机充当客户端访问调度器验证是否可进行后端服务器的调度 # 使用wget命令测试 ~]# wget -O - -q http://192.168.52.175:8888 web1 # 使用curl命令测试 ~]# curl 192.168.52.175:8888 &lt;html&gt;&lt;body&gt;&lt;h1&gt;403 Forbidden&lt;/h1&gt; Request forbidden by administrative rules. &lt;/body&gt;&lt;/html&gt; 范例：acl中或关系的体现12345678910111213~]# vim /etc/haproxy/haproxy.cfgfrontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl huaidan src 192.168.52.175 acl bad_curl hdr_sub(User-Agent) -i curl block if huaidan || bad_curl ####backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 二、自定义错误页 errorfile &lt;code&gt; &lt;file&gt; 返回文件内容，而不是HAProxy生成的错误 &lt;code&gt;:HTTP状态代码。目前，HAProxy能够生成代码200、400、403、408、500、502、503和504。 &lt;file&gt;:指定一个文件包含完整的HTTP响应。 范例：自定义错误页面1234567891011121314haproxy设置acl过滤器 frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl huaidan src 192.168.0.106 acl huandan1 hdr(User-Agent) -m sub -i chrome #定义客户段请求是通过chrome浏览器进行访问则拒绝 block if huaidan || huaidan1 #或的关系 backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 192.168.0.106客户端的windows主机进行访问测试显示的为内建默认的错误页 自己定义错误页面12345678910111213141516171819202122创建存放错误页面的路径 ~]# mkdir /etc/haproxy/err_pages创建一个错误响应403调用的页面 ~]# vim /etc/haproxy/err_pages/403.forbiddeng.html &lt;h1&gt;403&lt;/h1&gt;haproxy_server ~]# vim /etc/haproxy/haproxy.cfg frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl huaidan src 192.168.0.106 acl huandan1 hdr(User-Agent) -m sub -i chrome block if huaidan || huaidan1 errorfile 403 /etc/haproxy/err_pages/403.forbiddeng.html #### backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 定义将错误的页面进行其他网站或者其他的url的跳转1234567891011121314~]# vim /etc/haproxy/haproxy.cfg frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl huaidan src 192.168.0.106 acl huandan1 hdr(User-Agent) -m sub -i chrome block if huaidan || huaidan1 errorloc302 403 https://www.daizhe.net.cn/ #### backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 三、acl (根据客户端请求的资源path进行acl过滤 user_backend) path : exact string match path_beg : prefix match path_dir : subdir match path_dom : domain match path_end : suffix match path_len : length match path_reg : regex match path_sub : substring match 1234567891011121314151617181920定义客户的请求path中路径的内容，来进行调度frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs #默认的后端主机组 acl images path -m end -i .jpg .jpeg .png .gif #如果客户请求的url资源是以这些文件类型结尾的 acl images path -m beg /images #且请求的文件的路径是来自后端服务器中/images文件夹中 user_backend imagsrvs if images #如果满足上所述两个条则则全部归类到images，如果客户端请求的是images这类的文件则使用后端的imagsrvs 中的后端服务器组响应，反之则使用默认的服务器响应 backend websrvs cookie SERVER-COOKIE insert indirect nocache server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 backend imagsrvs server web3 192.168.62.88:80 check 四、http-request 七层负载acl http-request { allow | deny } [ { if | unless } &lt;condition&gt; ] 7层请求的访问控制1234567891011121314haproxy_server frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl haoren src 192.168.52.100 #### http-request allow if haoren #### #定义了一个白名单仅允许192.168.52.100主机通过调度器访问后端的主机，来自其他源地址的主机则拒绝访问后端的主机 http-request deny #### backend websrvs server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5 五、tcp-request 四层负载acl tcp-request connection {accept|reject} [{if | unless} &lt;condition&gt;] 根据第4层条件对传入连接执行操作 六、url （根据客户端请求的资源url进行acl过滤） url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match url包括： 协议 服务器 地址 端口 path url的范围要比path限制acl更广泛 1234567891011121314151617181920212223242526定义合法的引用，如果为合法的引用则调度器则将客户端的请求调度到后端的服务器上，如果不为合法的引用则不进行调度#仅允许来自daizhe字段的域名的外链的地址用户可以访问后端的服务器#如果不符合此条件直接拒绝hproxy_server frontend web-port-80 mode http rspadd X-Via:\ HAPorxy bind 0.0.0.0:8888 default_backend websrvs acl hefadeyinyong（定义的acl名称） hdr(Referer) -m dom -i daizhe block if ! hefayinyong backend websrvs server web1 192.168.52.162:80 check inter 2000 fall 3 rise 5 server web2 192.168.0.105:80 check inter 3000 fall 3 rise 5访问测试 直接访问调度器 ~]# curl http: http://haproxy ip 403 模拟外链跳转来的访问 ~]# curl -e "http://www.daizhe.net.cn http://haproxy ip" 200 七、内建的acl123456789101112131415161718192021Pre-defined ACLs ACL name Equivalent to Usage FALSE always_false never match HTTP req_proto_http match if protocol is valid HTTP HTTP_1.0 req_ver 1.0 match HTTP version 1.0 HTTP_1.1 req_ver 1.1 match HTTP version 1.1 HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-length HTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with scheme HTTP_URL_SLASH url_beg / match URL beginning with "/" HTTP_URL_STAR url * match URL equal to "*" LOCALHOST src 127.0.0.1/8 match connection from local host METH_CONNECT method CONNECT match HTTP CONNECT method METH_GET method GET HEAD match HTTP GET or HEAD method METH_HEAD method HEAD match HTTP HEAD method METH_OPTIONS method OPTIONS match HTTP OPTIONS method METH_POST method POST match HTTP POST method METH_TRACE method TRACE match HTTP TRACE method RDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookie REQ_CONTENT req_len gt 0 match data in the request buffer TRUE always_true always match WAIT_END wait_end wait for end of content analysis]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy日志配置及报文操作]]></title>
    <url>%2F2019%2F01%2F23%2FHAproxy%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%8A%A5%E6%96%87%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[HAproxy日志配置及报文操作 一、配置HAProxy状态页1.haproxy状态页面开启1234567891011121314paproxy_server ~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 #默认监听的地址为0.0.0.0,最好不要监听本机的所有地址。监听的端口不要和现有的业务冲突 stats enable log global stats uri /haproxy-status #默认访问状态页面的uri（可以自己定义） stats auth haadmin:q1w2e3r4ys #默认访问uri的用户名和密码 stats auth daizhe:123456 #指定用户访问此uri提供的用户名和密码 stats realm HAPorxy\ Stats\ Page #设置用户访问uri时提示输入密码的提示信息 ~]# systemctl restart haproxy web界面访问查看此状态页面 2.开启管理状态页面12345678910111213~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys stats auth admin:123456 stats realm HAPorxy\ Stats\ Page stats admin if TRUE #如果登陆的是daizhe这个用户则打开状态管理页面（或者也可写为 stats admin if LOCAHOST 表示为如果访问的为本机的主机则允许验证账号授权登陆） ~]# systemctl restart haproxy web界面访问查看此状态页面 3.隐藏管理状态页面的haproxy的版本号123456789101112131415~]# vim /etc/haproxy/haproxy.cfg listen stats mode http bind 172.18.135.2:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys stats auth admin:123456 stats realm HAPorxy\ Stats\ Page stats admin if TRUE stats hide-version #隐藏版本号 ~]# systemctl restart haproxy web界面访问查看此状态页面 二、HAproxy修改报文首部(http模式) 在请求报文尾部添加指定首部 reqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 在响应报文尾部添加指定首部 rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 示例：rspadd X-Via:\ HAPorxy 1234567891011客户端中可以查看到响应是通过haproxy调度器调度响应的listen web-port-80 mode http rspadd X-Via:\ HAPorxy #### bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.1:8080 cookie web2 check inter 3000 fall 3 rise 5 从请求报文中删除匹配正则表达式的首部 reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;] reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 不分大小写 1234567891011删除响应报文中的server字段的信息listen web-port-80 mode http rspadd X-Via:\ HAPorxy rspdel Server:* bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 从响应报文中删除匹配正则表达式的首部 rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;] rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 示例： rspidel server.* #从相应报文删除server信息 rspidel X-Powered-By:.* #从响应报文删除X-Powered-By信息 三、HAProxy 日志配置 在default配置项定义： log 127.0.0.1 local{1-7} info #基于syslog记录日志到指定设备，级别有(err、warning、info、debug) 范例：基于rsyslog配置收集haproxy日志信息(udp)1234567891011121314151617181920开启haproxy服务器上的rsyslog功能 ~]# vim /etc/rsyslog.conf 15~16行 $ModLoad imudp $UDPServerRun 514 74行 local3.* /var/log/haproxy.log配置haproxy配置文件 ~]# vim /etc/haproxy/haproxy.cfg global ... log 127.0.0.1 local3 info重启服务 ~]# systemctl restart rsyslog haproxy客户访问后端web_server 查看haproxy日志 范例：可以将haproxy日志格式使用tcp/http记录在rsyslog日志中1234567配置HAProxy：listen web_port bind 127.0.0.1:80 mode http log globaloption tcplog server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5 详细日志参考手册：http://cbonte.github.io/haproxy-dconv/1.8/configuration.html#8.1 四、自定义haproxy记录日志 将特定信息记录在日志中 capture cookie &lt;name&gt; len &lt;length&gt; #捕获请求和响应报文中的 cookie并记录日志 capture request header &lt;name&gt; len &lt;length&gt; #捕获请求报文中指定的首部内容和长度并记录日志 capture response header &lt;name&gt; len &lt;length&gt; #捕获响应报文中指定的内容和长度首部并记录日志 示例：配置haproxy配置文件，注意配置字段和生效的位置（最好设置单独的listen中，仅对一组server生效） capture request header Host len 256 capture request header User-Agent len 512 五、压缩功能 compression algo #启用http协议中的压缩机制，常用算法有gzip deflate compression type #要压缩的类型 示例： compression algo gzip compression type compression type text/plain text/html text/css text/xml text/javascript application/javascript Web服务器状态监测 option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 12345678listen web_prot_http_nodes bind 192.168.7.102:80 mode http log global option httpchk GET /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0 #基于指定URL #option httpchk HEAD /wp-includes/js/jquery/jquery.js?ver=1.12.4 HTTP/1.0\r\nHost:\ 192.168.7.102 #通过request获取的头部信息进行匹配进行健康检测 server 192.168.7.102 blogs.studylinux.net:80 check inter 3000 fall 3 rise 5 server 192.168.7.101 192.168.7.101:8080 cookie web1 check inter 3000 fall 3 rise 5]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy基于cookie会话保持]]></title>
    <url>%2F2019%2F01%2F23%2FHAproxy%E5%9F%BA%E4%BA%8Ecookie%E4%BC%9A%E8%AF%9D%E4%BF%9D%E6%8C%81%2F</url>
    <content type="text"><![CDATA[HAproxy基于cookie会话保持 Cookie 配置 cookie &lt;value&gt;：为当前server指定cookie值，实现基于cookie的会话黏性 cookie &lt;name&gt; [ rewrite | insert | prefix ] [ indirect ] [ nocache ] [ postonly ] [ preserve ] [ httponly ] [ secure ] [ domain &lt;domain&gt; ]* [ maxidle &lt;idle&gt; ] [ maxlife &lt;life&gt; ] &lt;name&gt;：cookie名称，用于实现持久连接 rewrite：重写 insert：插入 prefix：前缀 nocache：当client和hapoxy之间有缓存时，不缓存cookie 范例：使用haproxy实现基于cookie会话保持（haproxy必须在http协议的模式下实现）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#模拟httpd_server不直接对外服务，通过haproxy负载对外进程调度服务#范例：使用haproxy实现基于cookie会话保持（haproxy必须在http协议的模式下实现）也彻底解决会话调度不均衡实验准备 四台主机： haproxy_server : yum install haproxy -y httpd_serverA : yum install httpd -y httpd_serverB : yum install httpd -y windows_firefox配置httpd_server测试页面 httpd_serverA ~]# echo "172.18.135.1" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080 httpd_serverB ~]# echo "172.18.135.5" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080配置haproxy负载 ~]# yum install haproxy -y ~]# cat /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1111 gid 1111 daemon nbproc 4 cpu-map 1 0 cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys #httpd_server基于cookie实现调度 listen web-port-80 #web-port-80指定的此分组的名称 mode http #必须为http bind 172.18.135.2:80 option forwardfor cookie SERVER-COOKIE insert indirect nocache #不缓存 server web1 172.18.135.5:8080 cookie web1 check inter 2000 fall 3 rise 5 # 172.18.135.5为定义的主机的名称，172.18.135.5:8080 定义的后端的主机的地址及服务的端口 server 172.18.135.5 172.18.135.1:8080 cookie web2 check inter 3000 fall 3 rise 5 #cookie 指定cookie的值，实现区分不同的web_server,也可在请求的头部看到此信息 启动查看端口 ~]# systemctl start haproxy ~]# ss -tnl 9999 172.18.135.2:80 windows_firefox测试 客户端访问查看请求的头部（请求不跳转，实现基于cookie的会话保持和负载不均衡的情况） 也可以使用curl命令验证]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy IP地址透传]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxyIP%E5%9C%B0%E5%9D%80%E9%80%8F%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[HAproxy IP地址透传（七层/四层） 四层负载 mode http 七层负载 mode tcp 实验准备12345678910111213```bash#如果客户端访问的地址为公网地址上的一个网站，如果客户端用的是NAT方式出去上网的，则后端的nginx查看的日志信息源ip地址应该是客户端通过NAT方式出去的地址实验准备： haproxy_server 172.18.135.2模拟私网地址 nginx_server 172.18.135.5模拟公网地址 windows_firefox 172.18.88.88模拟客户端浏览器模拟： haproxy_server和windows_firefox 为私网地址 nginx_server 为公网地址#windows_firefox通过haporxy_server的地址透传（NAT）,实现windows_firefox通过访问haporxy_server的地址从跳转至私网地址nginx_server服务器上进行访问 七层地址透传(http)1234567891011121314151617181920212223242526272829303132333435363738394041424344haproxy_server配置haproxy实现透传 ~]# yum install haproxy -y ~]# vim /etc/haproxy/haproxy.cfg #七层地址透传 listen web-port-80 mode http #此透传仅支持http协议，在tcp协议上不影响haproxy启动，但是nginx日志中会写出记录不到真实访问的地址 option forwardfor #如果后端服务器需要获得客户端的真实IP需要配置此参数，将可以从HttpHeader中获得客户端IP bind 172.18.135.2:80 #此地址为调度器的地址 server web1 172.18.135.5:80 weight 2 check inter 2000 fall 3 rise 5 #web1为定义后端主机的名称 ~]# systemctl restart haproxy ~]# curl -I 172.18.135.2:80windown_firefox客户端浏览器访问haproxy_server地址 http://172.18.135.2/nginx_server查看web服务器的访问日志 ~]# yum install nginx -y ~]# vim /etc/nginx/nginx.conf #定义nginx的日志文件为json格式输出，并可以查看到真实的客户端的地址（这里值得是windows_firefox） http &#123; log_format json '&#123;"@timestamp":"$time_iso8601",' '"host":"$server_addr",' '"clientip":"$remote_addr",' '"size":$body_bytes_sent,' '"responsetime":$request_time,' '"upstreamtime":"$upstream_response_time",' '"upstreamhost":"$upstream_addr",' '"http_host":"$host",' '"url":"$uri",' '"referer":"$http_referer",' '"agent":"$http_user_agent",' '"xff":"$http_x_forwarded_for",' '"status":"$status"&#125;'; access_log /var/log/nginx/access_json json; ~]# systemctl start nginx ~]# cat /var/log/nginx/access_json &#123;"@timestamp":"2019-01-22T22:00:54+08:00","host":"172.18.135.5","clientip":"172.18.135.2","size":0,"responsetime":0.000,"upstreamtime":"-","upstreamhost":"-","http_host":"172.18.135.2","url":"/poweredby.png","referer":"http://172.18.135.2/","agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:64.0) Gecko/20100101 Firefox/64.0","xff":"172.18.88.88","status":"304"&#125; #可以查看到真实访问的windiws_firefox的真实地址 四层地址透传(tcp)12345678910111213141516171819202122232425262728293031323334353637383940haproxy_server ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 mode tcp bind 172.18.135.2:80 option forwardfor server web1 172.18.135.5:80 send-proxy weight 2 check inter 2000 fall 3 rise 5 ~]# systemctl restart haproxynginx_server ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 proxy_protocol; #TCP获取客户端真实IP日志格式 # listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; ~]# systemctl restart nginx 客户端访查看nginx日志]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy调度算法]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxy%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[HAproxy调度算法（四层） HAProxy 调度算法使用的生效字段： defaults listen backend 动态算法和静态算法 静态算法（算法仅根据算法本身与请求报文特征进行调度 起点公平） 不支持运行时动态调整，不支持慢启动 动态算法（额外考虑后端各RS的当前的负载的状态 结果公平） 支持运行时调整，支持慢启动 HAProxy 静态调度算法 balance： 指明对后端服务器的调度算法，配置在listen或backend静态算法：按照事先定义好的规则轮询公平调度，不关心后端服务器的当前负载、链接数和相应速度等，且无法实时修改权重，只能重启后生效。 static-rr：基于权重的轮询调度，不支持权重的运行时调整及后端服务器慢启动，其后端主机数量没有限制 first：根据服务器在列表中的位置，自上而下进行调度，但是其只会当第一台服务器的连接数达到上限，新请求才会分配给下一台服务，因此会忽略服务器的权重设置。 范例：静态调度--&gt;static-rr:基于权重的轮询调度12345678910111213141516171819roundrobin最大后端主机为4096static-rr 最大后端主机不上限#weight 设置权重#这里设置的172.18.135.1权重为2，172.18.135.5权重为1~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance static-rr server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1~]# systemctl restart haproxy 范例：静态调度--&gt;first:根据服务器在列表中的位置，自上而下进行调度即优先使用第一台，当第一台的连接数上限时，才会调度到其他的主机上1234567891011121314# maxconn 10 设置主机的最大连接数~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance first server 172.18.135.1 172.18.135.1:8080 maxconn 10 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080~]# systemctl restart haproxy HAProxy 动态调度算法 动态算法：基于后端服务器 状态进行调度适当调整，比如优先调度至当前负载较低的服务器，且权重可以在haproxy运行时动态调整无需重启(支持缓慢启动，实现慢慢的将流量均匀的分配到其他的后端服务器上,也支持运行时重载配置文件)。 roundrobin：基于权重的轮询动态调度算法，支持权重的运行时调整，不等于lvs 的rr，支持慢启动即新加的服务器会逐渐增加转发数，每个后端backend中最多支持4095个server，此为默认调度算法，server 权重设置 weight leastconn： 加权的最少连接的动态，支持权重的运行时调整和慢启动，即当前后端服务器连接最少的优先调度，比较适合长连接的场景使用，比如MySQL等场景。 123# 默认动态算法roundrobin：基于权重的轮询动态调度算法#roundrobin 适用于无状态的连接，如果做过session会话共享或者会话绑定也可以使用 HAProxy 调度算法-source source：源地址hash，基于用户源地址hash并将请求转发到后端服务器，默认为静态即取模方式，但是可以通过hash-type支持的选项更改，后续同一个源地址请求将被转发至同一个后端web服务器，比较适用于session保持等场景。 map-based：取模法，基于服务器权重的hash数组取模，该hash是静态的即不支持在线调整权重，不支持慢启动，其对后端服务器调度均衡，缺点是当服务器的总权重发生变化时，即有服务器上线或下线，都会因权重发生变化而导致调度结果整体改变。 consistent：一致性哈希，该hash是动态的，支持在线调整权重，支持慢启动，优点在于当服务器的总权重发生变化时，对调度结果影响是局部的，不会引起大的变动，该算法很容易导致后端服务器负载不均衡，但是比较适合session保持。 HAproxy 服务器动态上下线 静态算法：无法动态上下线 1234567891011121314151617181920212223242526272829303132333435363738394041 ~]# useradd haproxy -s /sbin/nologin #编译安装的需要创建账号，yum安装的则不需要创建账号 ~]# mkdir /var/lib/haproxy ~]# chown haproxy.haproxy /var/lib/haproxy/ -R ~]# vim /etc/haproxy/haproxy.cfg global 4行 stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #主要是基于socket文件对服务器进行动态修改 ... #httpd_server调度 frontend web-port-80 bind 172.18.135.2:80 use_backend web_host backend web_host balance static-rr server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy负载上安装支持的依赖包 ~]# yum install socat -y #输入重定向的工具查看使用帮助 ~]# echo "show info" | socat stdio /var/lib/haproxy/haproxy.sock ~]# echo "help" | socat stdio /var/lib/haproxy/haproxy.sock基于socat动态对话负载haproxy #动态修改主机的权重 ~]# echo "set weight " | socat stdio /var/lib/haproxy/haproxy.sock Require 'backend/server'. #指明backend名称以及server名称 ~]# echo "set weight web_host/172.18.135.1 4" | socat stdio /var/lib/haproxy/haproxy.sock Backend is using a static LB algorithm and only accepts weights '0%' and '100%'. #提示不可以设置为4的权重，因为是使用的静态的算法只能设置为0%或者为100%（在线或者下线）查看权重 ~]# echo "get weight web_host/172.18.135.1" | socat stdio /var/lib/haproxy/haproxy.sock 2 (initial 2) 动态算法：支持动态上下线1234567891011121314151617181920212223242526272829303132#使用consistent：一致性哈希方式1：~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host balance source hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1方式2：listen~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度listen web-port-80 bind 172.18.135.2:80 balance source hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy动态修改权重（1.8版本的那个太修改权重有BUG，1.5版本就没问题） ~]# echo "set weight web_host/172.18.135.5 3" | socat stdio /var/lib/haproxy/haproxy.sock ~]# echo "get weight web_host/172.18.135.5 3" | socat stdio /var/lib/haproxy/haproxy.sock 2019/01/22 16:42:40 socat[15995] E connect(5, AF=1 "/var/lib/haproxy/haproxy.sock", 31): Connection refused HAProxy 调度算法-uri uri：基于对用户请求的uri做hash并将请求转发到后端指定服务器(多适用于缓存服务器，会使得后端的服务器更好的命中缓存的结果例如缓存服务器 Varnish) map-based：取模法 consistent：一致性哈希 http://example.org/absolute/URI/with/absolute/path/to/resource.txt #URI/URL ftp://example.org/resource.txt #URI/URL /relative/URI/with/absolute/path/to/resource.txt #URI uri: uniform resource identifier，统一资源标识符,是一个用于标识某一互联网资源名称的字符串 范例：uri调度算法示例123456789101112131415161718192021前提： #协议必须是http，不支持tcp，会切换到tcp的roundrobin负载模式 #七层调度：应用层 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 bind 172.18.135.2:80 balance uri hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy客户端请求测试（已经实现基于uri绑定调度） ~]# curl http://172.18.135.2/ 172.18.135.1 ~]# curl http://172.18.135.2/index1.html 172.18.135.2/2 HAProxy 调度算法-url_param url_param： 对用户请求的url中的&lt;params&gt;部分中的参数name作hash计算，并由服务器总权重相除以后派发至某挑出的服务器；通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server 假设url = http://www.magedu.com/foo/bar/index.php?k1=v1&amp;k2=v2 范例：根据用户请求的url_param做调度12345678~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度listen web-port-80 bind 172.18.135.2:80 balance url-param name hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 HAProxy 调度算法-hdr hdr(&lt;name&gt;)：针对用户每个http头部(header)请求中的指定信息做hash，此处由&lt;name&gt;指定的http首部将会被取出并做hash计算，然后由服务器总权重相除以后派发至某挑出的服务器，假如无有效的值，则会被轮询调度 hdr( Cookie、 User-Agent、host ) 范例：调度算法-hdr：针对用户每个http头部123456789101112#可以获取报文头部的所有数据因为实在应用层 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 listen web-port-80 mode http bind 172.18.135.2:80 balance hdr(User-Agent) hash-type consistent server 172.18.135.1 172.18.135.1:8080 weight 2 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 weight 1 ~]# systemctl restart haproxy 测试：基于不同的浏览器做访问 HAProxy 调度算法- rdp-cookie(几乎不用) rdp-cookie对远程桌面的负载，使用cookie保持会话 rdp-cookie(&lt;name&gt;) 1234567#haproxylisten RDPbind 192.168.7.101:3389balance rdp-cookiemode tcpserver rdp0 172.18.139.20:3389 check fall 3 rise 5 inter 2000 weight 1server rdp1 172.18.139.21:3389 check fall 3 rise 5 inter 2000 weight 1 1234#基于iptables实现目标地址转换：#开启内核的转发功能：iptables -t nat -A PREROUTING -d 目标主机地址 -p tcp --dport 目标端口 -j DNAT --to-destination 转换哪个主机的：哪个端口iptables -t nat -A POSTROUTING -s 此网段的地址 -j SNAT --to-source 转换为哪个地址 算法总结及适用场景 static-rr first source:会话保持，小型业务或者用户源地址非集中访问 uri:缓存 roundrobin:无状态，session共享或者会话保持 leastconn:数据库，长连接 url_param hdr:多适用于域名转发，将多个域名转发到同一个地址中 roundrobin——–&gt;tcp/http 动态 leastconn———–&gt;tcp/http 动态 static-rr————–&gt;tcp/http 静态 first——————–&gt;tcp/http 静态 source—————-&gt;tcp/http # uri———————-&gt;http # url_param———-&gt;http # #取决于hash_type是否consistent hdr———————&gt;http # rdp-cookie———&gt;tcp # 四层与七层的区别： 四层： 在四层负载设备中，把client发送的报文目标地址(原来是负载均衡设备的IP地址)，根据均衡设备设置的选择web服务器的规则选择对应的web服务器IP地址，这样client就可以直接跟此服务器建立TCP连接并发送数据。 七层： 七层负载均衡服务器起了一个代理服务器的作用，服务器建立一次TCP连接要三次握手，而client要访问webserver要先与七层负载设备进行三次握手后建立TCP连接，把要访问的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的webserver，然后通过三次握手与此台webserver建立TCP连接，然后webserver把需要的数据发送给七层负载均衡设备，负载均衡设备再把数据发送给client；所以，七层负载均衡设备起到了代理服务器的作用。]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy基本配置]]></title>
    <url>%2F2019%2F01%2F22%2FHAproxy%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[HAproxy基本配置 一、源码编译安装haproxyhaproxy 1.8版本：新特性 多进程：可以最大限度的利用cpu多核心的特性，开启多个工作进程实现最大限度响应用户的目的。 安装包下载路径：https://www.haproxy.org/download/1.8/src/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990安装依赖包 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate -y ~]# cd /usr/local/src/ src]# ls haproxy-1.8.16.tar.gz src]# tar xvf haproxy-1.8.16.tar.gz src]# cd haproxy-1.8.16/ haproxy-1.8.16]# pwd /usr/local/src/haproxy-1.8.16编译安装 haproxy-1.8.16]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy haproxy-1.8.16]# make install PREFIX=/usr/local/haproxy haproxy-1.8.16]# cp haproxy /usr/sbin/创建启动脚本 ~]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target查看haproxy 版本 ~]# haproxy -v HA-Proxy version 1.8.16-5c3f237 2018/12/21 Copyright 2000-2018 Willy Tarreau &lt;willy@haproxy.org&gt;创建目录和用户(默认启动的用户为nobody) ~]# mkdir /etc/haproxy ~]# useradd haproxy -s /sbin/nologin -u 1111 ~]# id haproxy uid=1111(haproxy) gid=1111(haproxy) groups=1111(haproxy)创建配置文件 ~]# vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1000 gid 1000 daemon #nbproc 4 #cpu-map 1 0 #cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys listen web_port bind 0.0.0.0:80 mode http log global server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5启动 ~]# systemctl start haproxy进程查看 ~]# ps -ef | grep haproxy root 5883 1 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid haproxy 5886 5883 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid root 5907 5491 0 09:37 pts/0 00:00:00 grep --color=auto haproxy 二、HAProxy组成 程序环境： 主程序：/usr/sbin/haproxy 配置文件：/etc/haproxy/haproxy.cfg Unit file：/usr/lib/systemd/system/haproxy.service 配置段： global：全局配置段 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxy：代理配置段 defaults：为frontend, backend, listen提供默认配置 frontend：前端，相当于nginx中的server {} #指明监听的地址和端口不要写* backend：后端，相当于nginx中的upstream {} listen：同时拥有前端和后端,适用于一对一环境 Haproxy 配置-global（全局配置端） global配置参数： https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3 chroot #锁定运行目录，当haproxy本身出现漏洞被攻击时，工作目录仅限于此运行目录 deamon #以守护进程运行 #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin #本地通讯的socket文件 user, group, uid, gid #运行haproxy的用户身份（可以设置用户的id或者用户名称） nbproc #开启的haproxy进程数，与CPU保持一致 nbthread #指定每个haproxy进程开启的线程数，默认为每个进程一个线程 cpu-map 1 0 #绑定haproxy 进程至指定CPU maxconn #每个haproxy进程的最大并发连接数 maxsslconn #SSL每个haproxy进程ssl最大连接数 maxconnrate #每个进程每秒最大连接数 spread-checks #后端server状态check随机提前或延迟百分比时间，建议2-5(20%-50%)之间 pidfile #指定pid文件路径 log 127.0.0.1 local3 info #定义全局的syslog服务器；最多可以定义两个 123456789101112131415~]# vim /etc/haproxy/haproxy.cfg ...nbproc 4 #指定haproxy的进程数cpu-map 1 0 #将第一进程绑定在第0颗cpucpu-map 2 1 #将第二进程绑定在第1颗cpu...#实现了一个主进程多个子进程~]# ps -ef | grep haproxyroot 11803 1 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11805 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11806 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11807 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidhaproxy 11808 11803 0 10:34 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 11811 5491 0 10:35 pts/0 00:00:00 grep --color=auto haproxy HAProxy Proxies配置（代理配置段） defaults [&lt;name&gt;] #默认配置项，针对以下的frontend、backend和lsiten生效，可以多个name frontend &lt;name&gt; #前端servername，类似于Nginx的一个虚拟主机 server backend &lt;name&gt; #后端服务器组，等于nginx的upstream listen &lt;name&gt; #将frontend和backend合并在一起配置 注：name字段只能使用”-”、”_”、”.”、和”:”，并且严格区分大小写，例如：Web和web是完全不同的两组服务器即是区分大小写的 Proxies配置- defaults（默认配置项） option redispatch #当server Id对应的服务器挂掉后，强制定向到其他健康的服务器 option abortonclose #当服务器负载很高的时候，自动结束掉当前队列处理比较久的链接 option http-keep-alive #开启会话保持 option forwardfor #开启IP透传 mode http #默认工作类型 timeout connect 120s #连接到一台后端server的最长时间 timeout client 600s #与客户端的最长空闲时间 timeout server 600s #等待服务端的超时时长 timeout http-keep-alive 120s #session 会话保持时间 #timeout check 5s #对后端服务器的检测超时时间 Proxies配置- frontend配置参数(前端servername) bind：指定HAProxy的监听地址，可以是IPV4或IPV6，可以同时监听多个IP或端口，可同时用于listen字段中 bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] mode http/tcp #指定负载协议类型 use_backend backend_name #调用的后端服务器组名称 示例： frontend WEB_PORT bind :80,:8080 #支持以逗号分隔的列表格式指定监听的地址以及端口多个套接字 bind 192.168.7.102:10080,192.168.7.102:10043 use_backend backend_name 范例：使用haproxy实现调度apache1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#模拟httpd_server不直接对外服务，通过haproxy负载对外进程调度服务#配置haproxy实现基客户端第一次请求服务端保留的cookie进行调度实验准备 三台主机： haproxy_server : yum install haproxy -y httpd_serverA : yum install httpd -y httpd_serverB : yum install httpd -y配置httpd_server测试页面 httpd_serverA ~]# echo "172.18.135.1" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080 httpd_serverB ~]# echo "172.18.135.5" &gt; /var/www/html/index.html ~]# systemctl start httpd 修改端口8080配置haproxy负载 ~]# yum install haproxy -y ~]# cat /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 1111 gid 1111 daemon nbproc 4 cpu-map 1 0 cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys #httpd_server调度 frontend web-port-80 #web-port-80指定的此分组的名称 bind 172.18.135.2:80 #绑定在调度器本地的地址和端口 use_backend web_host #web_hos 定义的服务的主机组 backend web_host #调用web_hos主机组 server 172.18.135.1 172.18.135.1:80 # 172.18.135.1为定义的主机的名称，172.18.135.1:80 定义的后端的主机的地址及服务的端口 server 172.18.135.5 172.18.135.5:80启动查看端口 ~]# systemctl start haproxy ~]# ss -tnl 9999 172.18.135.2:80 -----------------------------------------------------------------------------------------------haproxy的配置文件中调用主机中也可以写为 #此处制定默认的backend，适用于backend少的情况下使用frontend myweb *:80 default_backend webserverbackend webserver server web1 后端主机地址A check server web1 后端主机地址B check----------------------------------------------------------------------------------------------也可以使用listen的方式指定listen myweb bind server web1 后端主机的地址A check server web2 后端主机的地址B check 测试：访问调度器地址验证是否调度成功 默认的调度算法为轮询 也可以使用下面命令的用法来验证调度是否成功 1~]# while true; do curl http://172.18.135.2/; sleep .5; done Proxies配置- backend配置参数 mode http/tcp/health #指定负载协议类型 option #配置选项 server #定义后端real server 注意：option后面加httpchk，smtpchk, mysql-check, pgsql-check，ssl-hello-chk方法，可用于实现更多应用层检测功能。 三、后端服务器状态监测及相关配置 check #对指定real进行健康状态检查，默认不开启 addr IP #可指定的健康状态监测IP port num #指定的健康状态监测端口 inter num #健康状态检查间隔时间，默认2000 ms(2秒) fall num #后端服务器失效检查次数，默认为3 rise num #后端服务器从下线恢复检查次数，默认为2 weight #默认为1，最大值为256，0表示不参与负载均衡 (默认轮询、加权) backup #将后端服务器标记为备份状态 disabled #将后端服务器标记为不可用状态 redir http://www.magedu.com/ #将请求临时重定向至其它URL，只适用于http模式 maxconn &lt;maxconn&gt;：当前后端server的最大并发连接数 backlog &lt;backlog&gt;：当server的连接数达到上限后的后援队列长度 范例：对调度器调度的后端服务器开启健康状态检测123456789101112生产中的定义恢复的次数要比下线的次数要长~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host server 172.18.135.1 172.18.135.1:8080 check addr 172.18.135.1 port 8080 inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080~]# systemctl restart haproxy frontend和backend 字段也可以写为listen（适用于配置较多的场景）1234567891011121314151617181920~]# vim /etc/haproxy/haproxy.cfg listen的配置当时#httpd_server调度listen web-port-80bind 172.18.135.2:80 server 172.18.135.5 172.18.135.5:8080 server 172.18.135.1 172.18.135.1:8080 check inter 2000 fall 3 rise 5frontend和backend配置方式#httpd_server调度frontend web-port-80 bind 172.18.135.2:80 use_backend web_hostbackend web_host server 172.18.135.1 172.18.135.1:8080 check inter 2000 fall 3 rise 5 server 172.18.135.5 172.18.135.5:8080 范例：redir将请求临时重定向至其它URL，只适用于http模式12345678910111213141516171819202122编辑paproxy调度器的配置文件 ~]# vim /etc/haproxy/haproxy.cfg #httpd_server调度 frontend web-port-80 bind 172.18.135.2:80 use_backend web_host backend web_host redirect prefix http://www.daizhe.net.cn/ ~]# systemctl restart haproxy客户端访问负载的地址 ~]# curl -I 172.18.135.2:80 HTTP/1.1 302 Found Cache-Control: no-cache Content-length: 0 Location: http://www.daizhe.net.cn//#302临时重定向#301永久重定向]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAproxy简介]]></title>
    <url>%2F2019%2F01%2F21%2FHAproxy%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[HAproxy简介 LB（负载均衡）集群 公有云Web架构 一、什么是负载均衡： 负载均衡(Load Balance，简称LB)是一种服务或基于硬件设备等实现的高可用反向代理技术，负载均衡将特定的业务(web服务、网络流量等)分担给指定的一个或多个后端特定的服务器或设备，从而提高了公司业务的并发处理能力、保证了业务的高可用性、方便了业务后期的水平动态扩展。 阿里云SLB介绍 https://yq.aliyun.com/articles/1803 二、为什么使用负载均衡 Web服务器的动态水平扩展 对用户无感知 增加业务并发访问及处理能力 解决单服务器瓶颈问题 节约公网IP地址 降低IT支出成本 隐藏内部服务器IP 提高内部服务器安全性 配置简单 固定格式的配置文件 功能丰富 支持四层和七层，支持动态下线主机 性能较强 并发数万甚至数十万 三、常见的负载均衡 软件负载： 四层： LVS(Linux Virtual Server)：工作在内核当中 HAProxy(High Availability Proxy) Nginx （1.9.0 以上版本 stream功能） 七层： HAProxy Nginx 硬件负载： F5 Netscaler 应用场景： 四层：Redis、Mysql、RabbitMQ、Memcache等 七层：Nginx、Tomcat、Apache、PHP 、图片、动静分离、API等 四、HAProxy介绍 HAProxy: 是法国开发者Willy Tarreau开发的一个开源软件，是一款具备高并发、高性能的TCP和HTTP负载均衡器，支持基于cookie的持久性，自动故障切换，支持正则表达式为基础的控制运行时间基本web的报表，高级日志记录以帮助排除故障的应用或网络及其他功能。 LB Cluster: 四层：lvs, nginx(stream模式且nginx1.9.0或更新版本)，haproxy(mode tcp) 七层：http: nginx(http), haproxy(mode http), httpd... 官网： http://www.haproxy.org https://www.haproxy.com githun上的文档：https://cbonte.github.io/haproxy-dconv/ 五、HAProxy功能 HAProxy是TCP / HTTP反向代理服务器，尤其适合于高可用性高并发环境 可以针对HTTP请求添加cookie，进行路由后端服务器 可平衡负载至后端服务器，并支持持久连接 支持基于cookie进行调度 支持所有主服务器故障切换至备用服务器 支持专用端口实现监控服务 支持不影响现有连接情况下停止接受新连接请求 可以在双向添加，修改或删除HTTP报文首部 支持基于pattern实现连接请求的访问控制 通过特定的URI为授权用户提供详细的状态信息 HAproxy工作场景：七层http/四层tcp 工作于七层:解析http请求，可以完成对用户请求的按照内容的类型进行分别调度 工作于四层：模拟对其他tcp/udp协议传输的应用层服务的调度转发 工作于前端: 作为https的卸载器 应用场景 六、安装HAproxy1、yum 方式安装haproxy1234567891011121314151617181920212223242526默认base源中HAproxy 1.5版本 ~]# yum list haproxy haproxy.x86_64 1.5.18-8.el7 base ~]# yum install haproxy -y分析haproxy安装的程序文件 ~]# rpm -ql haproxy /etc/haproxy/haproxy.cfg #主配置文件 /etc/sysconfig/haproxy #环境变量的配置文件，用途少，主要用于传递参数 /usr/lib/systemd/system/haproxy.service #程序的启动脚本 #1.7版本之前启动调用的二进制文件，1.8以后则不使用了（ExecStart=/usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy） /usr/sbin/haproxy /usr/sbin/haproxy-systemd-wrapper启动 ~]# systemctl start haproxy ~]# ss -tnl *:5000 查看1.5版本实现的伪多进程 ~]# ps -ef | grep haproxy root 3856 1 0 21:00 ? 00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid #主进程 haproxy 3857 3856 0 21:00 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Ds haproxy 3858 3857 0 21:00 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Ds root 4097 2822 0 21:02 pts/0 00:00:00 grep --color=auto haproxy 2、源码编译安装haproxyhaproxy 1.8版本：新特性 多进程：可以最大限度的利用cpu多核心的特性，开启多个工作进程实现最大限度响应用户的目的。 安装包下载路径：https://www.haproxy.org/download/1.8/src/123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687安装依赖包 ~]# yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate -y ~]# cd /usr/local/src/ src]# ls haproxy-1.8.16.tar.gz src]# tar xvf haproxy-1.8.16.tar.gz src]# cd haproxy-1.8.16/ haproxy-1.8.16]# pwd /usr/local/src/haproxy-1.8.16编译安装 haproxy-1.8.16]# make ARCH=x86_64 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 USE_SYSTEMD=1 USE_CPU_AFFINITY=1 PREFIX=/usr/local/haproxy haproxy-1.8.16]# make install PREFIX=/usr/local/haproxy haproxy-1.8.16]# cp haproxy /usr/sbin/创建启动脚本 ~]# vim /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=syslog.target network.target [Service] ExecStartPre=/usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -c -q ExecStart=/usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target查看haproxy 版本 ~]# haproxy -v HA-Proxy version 1.8.16-5c3f237 2018/12/21 Copyright 2000-2018 Willy Tarreau &lt;willy@haproxy.org&gt;创建目录和用户 ~]# mkdir /etc/haproxy创建配置文件 ~]# vim /etc/haproxy/haproxy.cfg global maxconn 100000 chroot /usr/local/haproxy #stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin uid 99 gid 99 daemon #nbproc 4 #cpu-map 1 0 #cpu-map 2 1 pidfile /usr/local/haproxy/run/haproxy.pid log 127.0.0.1 local3 info defaults option http-keep-alive option forwardfor maxconn 100000 mode http timeout connect 300000ms timeout client 300000ms timeout server 300000ms listen stats mode http bind 0.0.0.0:9999 stats enable log global stats uri /haproxy-status stats auth haadmin:q1w2e3r4ys listen web_port bind 0.0.0.0:80 mode http log global server web1 127.0.0.1:8080 check inter 3000 fall 2 rise 5启动 ~]# systemctl start haproxy ~]# systemctl enable haproxy进程查看 ~]# ps -ef | grep haproxy root 5883 1 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid nobody 5886 5883 0 09:36 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid root 5907 5491 0 09:37 pts/0 00:00:00 grep --color=auto haproxy 启动验证haproxy状态： 以下是1.8.3版本的单主进程多子进程模式： 1234567891011haproxy-1.8.3]# systemctl daemon-reloadhaproxy-1.8.3]# systemctl restart haproxyhaproxy-1.8.3]# cat /run/haproxy.pid 41998haproxy-1.8.3]# ps -ef | grep haproxyroot 41998 1 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 41999 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42000 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42001 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidnobody 42002 41998 0 16:27 ? 00:00:00 /usr/sbin/haproxy -Ws -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 42186 10580 0 16:28 pts/14 00:00:00 grep --color=auto haproxy 以下是1.7版本的传统多进程的haproxy模式： 12345678~]# ps -ef | grep haproxyroot 118786 1 0 17:10 ? 00:00:00 /usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pidroot 118787 118786 0 17:10 ? 00:00:00 [haproxy] &lt;defunct&gt;nobody 118788 1 6 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118789 1 6 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118790 1 3 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsnobody 118791 1 5 17:10 ? 00:00:00 /usr/sbin/haproxy -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid -Dsroot 118814 99636 0 17:10 pts/0 00:00:00 grep --color=auto haproxy 以下是Nginx的单主进程多子进程模式，此模式和1.8.3版本的haproxy工作模式是类似的： 1234567891011~]# ps -ef | grep nginxroot 13399 1 0 Jan06 ? 00:00:01 nginx: master process /apps/tengine/sbin/nginx -s startdevops 22165 22122 0 16:20 pts/0 00:00:00 grep --color=auto nginxzceo 22915 13399 0 Jan13 ? 00:41:41 nginx: worker processzceo 22916 13399 0 Jan13 ? 00:41:59 nginx: worker processzceo 22917 13399 0 Jan13 ? 00:41:38 nginx: worker processzceo 22918 13399 0 Jan13 ? 00:41:32 nginx: worker processzceo 22919 13399 0 Jan13 ? 00:41:22 nginx: worker processzceo 22920 13399 0 Jan13 ? 00:41:40 nginx: worker processzceo 22921 13399 0 Jan13 ? 00:42:07 nginx: worker processzceo 22922 13399 0 Jan13 ? 00:41:40 nginx: worker process 以下是apache的单主进程多子进程模式，也和1.8.3版本的haproxy工作模式类似： 12345678910~]# ps -ef | grep apacheroot 6758 1 0 11:01 ? 00:00:00 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6760 6758 0 11:01 ? 00:00:00 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6761 6758 0 11:01 ? 00:00:02 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6762 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6764 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6770 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6771 6758 0 11:01 ? 00:00:03 /usr/local/apache2.2.17/bin/httpd -k startwebshop 6780 6758 0 11:01 ? 00:00:02 /usr/local/apache2.2.17/bin/httpd -k startroot 8076 8038 0 11:50 pts/2 00:00:00 grep apache]]></content>
      <categories>
        <category>HAproxy</category>
      </categories>
      <tags>
        <tag>HAproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[session一致性架构设计实践]]></title>
    <url>%2F2019%2F01%2F20%2Fsession%E4%B8%80%E8%87%B4%E6%80%A7%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[session一致性架构设计实践 一、缘起什么是session？ 服务器为每个用户创建一个会话，存储用户的相关信息，以便多次请求能够定位到同一个上下文。 Web开发中，web-server可以自动为同一个浏览器的访问用户自动创建session，提供数据存储功能。最常见的，会把用户的登录信息、用户信息存储在session中，以保持登录状态。 什么是session一致性问题？ 只要用户不重启浏览器，每次http短连接请求，理论上服务端都能定位到session，保持会话。 当只有一台web-server提供服务时，每次http短连接请求，都能够正确路由到存储session的对应web-server（废话，因为只有一台）。 此时的web-server是无法保证高可用的，采用“冗余+故障转移”的多台web-server来保证高可用时，每次http短连接请求就不一定能路由到正确的session了。 如上图，假设用户包含登录信息的session都记录在第一台web-server上，反向代理如果将请求路由到另一台web-server上，可能就找不到相关信息，而导致用户需要重新登录。 在web-server高可用时，如何保证session路由的一致性，是今天将要讨论的问题。 二、session同步法 思路：多个web-server之间相互同步session，这样每个web-server之间都包含全部的session 优点：web-server支持的功能，应用程序不需要修改代码 不足： session的同步需要数据传输，占内网带宽，有时延 所有web-server都包含所有session数据，数据量受内存限制，无法水平扩展 有更多web-server时要歇菜 三、客户端存储法 思路：服务端存储所有用户的session，内存占用较大，可以将session存储到浏览器cookie中，每个端只要存储一个用户的数据了 优点：服务端不需要存储 缺点： 每次http请求都携带session，占外网带宽 数据存储在端上，并在网络传输，存在泄漏、篡改、窃取等安全隐患 session存储的数据大小受cookie限制 “端存储”的方案虽然不常用，但确实是一种思路。 四、反向代理hash一致性 思路：web-server为了保证高可用，有多台冗余，反向代理层能不能做一些事情，让同一个用户的请求保证落在一台web-server上呢？ 方案一：四层代理hash 反向代理层使用用户ip来做hash，以保证同一个ip的请求落在同一个web-server上 方案二：七层代理hash 反向代理使用http协议中的某些业务属性来做hash，例如sid，city_id，user_id等，能够更加灵活的实施hash策略，以保证同一个浏览器用户的请求落在同一个web-server上 优点： 只需要改nginx配置，不需要修改应用代码 负载均衡，只要hash属性是均匀的，多台web-server的负载是均衡的 可以支持web-server水平扩展（session同步法是不行的，受内存限制） 不足： 如果web-server重启，一部分session会丢失，产生业务影响，例如部分用户重新登录 如果web-server水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session session一般是有有效期的，所有不足中的两点，可以认为等同于部分session失效，一般问题不大。 对于四层hash还是七层hash，个人推荐前者：让专业的软件做专业的事情，反向代理就负责转发，尽量不要引入应用层业务属性，除非不得不这么做（例如，有时候多机房多活需要按照业务属性路由到不同机房的web-server）。 四、后端统一存储 思路：将session存储在web-server后端的存储层，数据库或者缓存 优点： 没有安全隐患 可以水平扩展，数据库/缓存水平切分即可 web-server重启或者扩容都不会有session丢失 不足：增加了一次网络调用，并且需要修改应用代码 对于db存储还是cache，个人推荐后者：session读取的频率会很高，数据库压力会比较大。如果有session高可用需求，cache可以做高可用，但大部分情况下session可以丢失，一般也不需要考虑高可用。 五、总结 保证session一致性的架构设计常见方法： session同步法：多台web-server相互同步数据 客户端存储法：一个用户只存储自己的数据 反向代理hash一致性：四层hash和七层hash都可以做，保证一个用户的请求落在一台web-server上 后端统一存储：web-server重启和扩容，session也不会丢失 对于方案3和方案4，个人建议推荐后者： web层、service层无状态是大规模分布式系统设计原则之一，session属于状态，不宜放在web层 让专业的软件做专业的事情，web-server存session？还是让cache去做这样的事情吧]]></content>
      <categories>
        <category>outside class</category>
      </categories>
      <tags>
        <tag>outside class</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat会话服务]]></title>
    <url>%2F2019%2F01%2F20%2Ftomcat%E4%BC%9A%E8%AF%9D%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Tomcat Session Server session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 session server:后端服务器之后即存储服务器 存储系统种类繁多 Session Manager 需要专门添加并非内建 存储系统性能高 存储系统要保存session ，而session通常都是简单的数据，但是必须要具有流逝化的特性 session变化特别的频繁所以存储系统必须要做到快速的存取 存储系统要有冗余能力 存储系统一旦成为一个集中的session server后，将成为整个系统的单点 Cache 缓存：无持久能力（memcached） 一般而言都是在内存当中或者即便实在磁盘上，通常系统重启后数据则将丢失，无法完成重构。 Store 存储 (redis) 数据的读写有可能是在内存中完成，但是本身却拥有持久存储功能即持久是必备功能 memcached（缓存服务） 缓存的数据的大小不可大于1M，如果数据大于1M则不被缓存 完全基于内存工作 缓存系统使用场景 服务器存储的系统存在热区 服务器的数据读多写少 memcached特证 协议简单 基于libevent的事件处理（单进程处理多路请求） 内置内存存储方式 memcached不互通信额分布式 范例：基于nginx实现负载均衡，实现mamcache会话缓存 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109实验准备 三台主机 nginx_server yum install nginx -y tomcat_serverA yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y yum install memcached -y tomcat_serverB yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y yum install memcached -y 在两台tomcat上分别创建测试页面并定制虚拟主机tomcatA ~]# mkdir /data/webapps/myapp-v0.1 ~]# cd /data/webapps/myapp-v0.1 myapp-v0.1]# mkdir classes lib WEB-INF WETA-INF myapp-v0.1]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="purple"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp ~]# tree /data /data └── webapps ├── myapp -&gt; myapp-v0.1 └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnltomcatB ~]# tree /data /data └── webapps └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF ~]# vim /data/webapps/myapp-v0.1/index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatB.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnl 访问测试是否配置成功 tomcat默认不支持将session会话信息放进memcached中，需要借助第三方MSM（memcached session manager）,意思是将memcached当作session会话的后端的session管理器 支持的存储程序 memcached redis couchbase 托管在github上地址：https://github.com/magro/memcached-session-manager 配置参考手册：https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration 配置tomcatA和tomcatB 可以实现两个tomcat可以使用两个memcached 实现两台memcached各存储部分session 会话信息，实现双活机制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788tomcatA 安装memcached (base仓库) 监听的端口 tcp 11211 / udp 11211 ~]# yum install memcached -y ~]# rpm -ql memcached /etc/sysconfig/memcached #配置文件 /usr/bin/memcached #命令执行文件 usr/lib/systemd/system/memcached.service #启动程序文件 查看memcached命令帮助 ~]# memcached -h -p &lt;num&gt; # 监听tcp 11211端口 -U &lt;num&gt; # 监听UDP 11211端口 ， 设置upd协议为0 表示关闭udp协议的端口 -l &lt;addr&gt; # 指定监听的地址 -d # 运行为守护进程 -u &lt;username&gt; # 指定运行的身份 -m &lt;num&gt; # 使用多大的内存空间当作缓存 ，默认为64M ，必须调大 -M # 内存耗尽禁用LRU 表示内存耗尽禁止新存储的数据存储 -c &lt;num&gt; # 最大并发连接数，默认为1024 -v # 输出信息到前台 -vv # 详细 -vvv # 详详细 -f &lt;factor&gt; # 增长因子 默认为1.25 #查看增长因子 #~]# su - daizhe #~]$ memcached -vvv -m 256m -f 1.25 #slab class 1: chunk size 96 perslab 10922 #slab class 2: chunk size 120 perslab 8738 #slab class 3: chunk size 152 perslab 6898 #slab class 4: chunk size 192 perslab 5461 #slab class 5: chunk size 240 perslab 4369编辑memcache的配置文件启动 ~]# vim /etc/sysconfig/memcached PORT="11211" #端口 USER="memcached" #运行身份 MAXCONN="1024" CACHESIZE="256" #内存空间 OPTIONS="-f 1.1 -M" #指定增长因子 ~]# systemctl start memcached ~]# ss -tnl 11211安装c程序调用memcache依赖的库# php程序员： php-pecl-memcache# python程序员： python-memcached.noarch# c程序员: libmemcached ~]# yum install libmemcached -y 使用telnet连接（memcached支持文本协议即纯文本的字符串） ~]# yum install telnet -y ~]# telnet 127.0.0.1 11211 #stats查看状态使用信息 设置一个键 set mykey 123 60 6 daizhe STORED # 键名：mykey # 值：123 # 超时时长：60内有效 # 指定字节数 查看已经存储的键值 get mykey获取memcached的信息 ~]# memstat -h --servers= #指定服务器地址 ~]# memstat --servers=127.0.0.1:11211dump出所有存储的键 ~]# memdump --servers=127.0.0.1:11211清空所有的键 ~]# memflush删除所有的键 ~]# memrm更新键的时间戳 ~]# memtouch判断存在性 ~]# memexist 123456789101112131415tomcatA 安装memcached ~]# yum install memcached -y编辑memcache的配置文件启动 ~]# vim /etc/sysconfig/memcached PORT="11211" #端口 USER="memcached" #运行身份 MAXCONN="1024" CACHESIZE="256" #内存空间 OPTIONS="-f 1.1 -M" #指定增长因子 ~]# systemctl start memcached ~]# ss -tnl 11211 jar文件下载路径：http://repo1.maven.org/maven2/de/javakaffee/msm/memcached-session-manager/123456为tomcatA 节点和 tomcatB 节点的tomcat准备 jar文件 查看默认的tomcat的jar文件的存放路径 ~]# rpm -ql tomcat-lib ~]# cd /usr/share/java/tomcat/ #所有的tomcat节点上都要放置jar文件 将所有的jar文件防止在此路径下 1234567891011121314配置tomcatA和tomcatB 节点的tomcat的配置文件（不要和tomcat_session 会话集群同时使用）tomcatA和tomcatB ~]# vim /etc/tomcat/server.xml #105 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tcA"&gt; #两个节点做区分 tcA / tcB#140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""&gt; &lt;Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager" memcachedNodes="172.18.135.1:11211,172.18.135.5:11211" failoverNodes="n1" requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$" transcoderFactoryClass="de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory" /&gt;&lt;/Context&gt; 1234启动节点中所有tamcat服务器并监控日志信息 ~]# systemctl restart tomcat ~]#tail -f /var/log/tomcat/catalina.2019-01-20.log 使用nginx调度测试]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat会话集群]]></title>
    <url>%2F2019%2F01%2F19%2Ftomcat%E4%BC%9A%E8%AF%9D%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Tomcat Session Cluster session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 session replication cluster (sesssion复制集群)：后端服务器组织成集群 tomcat中自身就带有了一种cluster机制（集群仅是针对于保持用户session会话问题上实现集群） 将后端多个正常工作的主机在session管理问题上将其基于专有的网络接口或者面向客户端的通用网络接口构建出一个会话集群，此集群可以实现让每一个节点获得会话信息后通过所谓通讯当中的多播机制或者称之为组播机制（Multicast），将自己所获得的会话信息多播到事先约定的多播信道上，实现在同一多播网络中的其他主机获取到相关的会话信息，并将其合并到本地已有的会话信息中。 构建通讯集群的方式 单播：效率最低 多播：多播方式最优，可以配置同一集群中的主机，大家共同使用同一个多播地址（多播域），而后在规定的多播第之内发送多播信息，只有同一多播地址上的主机才可以收到此会话信息。 广播：后端主机获得会话信息后直接以广播的方式发送到其他后端主机上（但是播及面太大，造成影响范围太大）。 tomcat本身就是java语言编写，所以具有完全面向对象的特性，必须使用类来完成任何功能，包括会话管理，在tomcat上会话管理组件称为session manager (会话管理器)，在tomcat上有好几种会话管理机制，统称为会话管理器 默认使用的是持久会话管理 tomcat接收到客户的session会话信息，是先保存在内存中，会周期性的同步在磁盘上进行数据的保存（所以将tomcat重启后，被正常存储好的会话信息会被将回复回来，但是在未到周期同步在磁盘上的session会话信息，也就是存在内存中的会话尚未同步在磁盘上的会话信息在tomcat宕机时会丢失session会话信息） 持久会话管理，一定会影响磁盘的IO性能（受本地的磁盘IO限制） Delta Session Manager 会话管理器 增量变动之意 每一个节点自己后来生成的session会话增量变量的信息，将增量的会话变动通过多播方式，多播到多播域内，同一多播域中的其他主机也存在相同的Delta Session Manager 接收其他主机在多播域内变动的session会话信息，并且合并在本地的session存储中 劣势：session manager 中的每个节点都要保存所有的会话信息并且通常是保存在内存中，一旦客户端访问的数量增多时会使得后端session manager存储会话的节点中都存在大量的会话信息，会使得会话无法被扩展。 Backup Session Manager 备份会话管理器 每一个会话节点（session manager）在保存会话和生成会话时，会将会话同传给集群中的其他一个节点或者说是有限节点，而不是所有会话集群中的所有节点，因为每个节点禁止有所有会话节点中一定比例的会话信息。 此类会话管理须实现前端调度的会话绑定，且保持会话管理的节点一但宕机后可以将此会话信息保持 发送到另一台备份会话信息的会话管理器上（而不是任何一个会话管理节点）。此类会话管理，需要管理员精心介入到调度拓扑结构中。 也就是此类会话管理无会话动态性需要管理员明确管理指定，如有宕机需精确的重定向，那台会话管理节点备份了哪台会话节点的会话信息。 打破了不会让每一个节点持有整个集群的session会话的信息 自定义会话管理器 将tomcat生成的会话信息不记录在服务器的内存中，而是将会话信息存储到外部适配的缓存的服务器上比如mamcached、redis 一旦有session会话保持时通过是配置直接保存在外部存储上，这样则使得tomcat可以是同Session_server保存用户的会话信息 范例：Delta Session Manager 会话管理器参考文档：http://tomcat.apache.org/tomcat-7.0-doc/cluster-howto.html1234567891011121314151617181920212223242526272829303132333435363738394041配置启用集群，将下列配置放置于&lt;engine&gt;或&lt;host&gt;中； &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" #属性指明使用的类 channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" #指定使用的会话管理器 expireSessionsOnShutdown="false" #DeltaManager 用到的属性 notifyListenersOnReplication="true"/&gt; #DeltaManager 用到的属性 &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; #定义多播信息及集群通讯信道 &lt;Membership className="org.apache.catalina.tribes.membership.McastService" #定义集群成员的关系 address="228.0.0.4" #多播地址，D类地址用来组播（224~239），多播即大家使用同一个D类中相同的一个地址 port="45564" #多播端口 frequency="500" #每个多长时间发一次心跳 默认500毫秒 dropTime="3000"/&gt; #多长时间内收不到节点的心跳 判断为超时，从而从集群成员中剔除 &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" #定义如何接收传递的session会话信息 address="auto" port="4000" #监听的端口，如果有冲突，自动切换（4000~4100） autoBind="100" #自动绑定，如有错误自动重新绑定 selectorTimeout="5000" #选择器的超时时长默认5秒 maxThreads="6"/&gt; #最大线程数，默认值为6，已经足够使用 &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; #向外发送心跳以及session会话信息 &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; #心跳大佛那个的方式轮询 &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; #探测器校验信息是否出错 &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" #定义过滤器，过滤复制集群相关的信息 filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; #绑定JVM的路由信息 &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; #集群侦听器，确保集群相关的资源仅被集群中的成员所使用 &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798会话集群配置第一步：配置session集群(修改所有的tomcat服务器会话集群的配置文件) ~]# vim /etc/tomcat/server.xml 105行 添加标注信息 &lt;Engine name="Catalina" defaultHost="localhost" jvmRoute="tcA"&gt; #每个节点上的标识不要相同 128行 &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt; &lt;Manager className="org.apache.catalina.ha.session.DeltaManager" expireSessionsOnShutdown="false" notifyListenersOnReplication="true"/&gt; &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt; &lt;Membership className="org.apache.catalina.tribes.membership.McastService" address="228.0.100.10" port="45564" frequency="500" dropTime="3000"/&gt; &lt;Receiver className="org.apache.catalina.tribes.transport.nio.NioReceiver" address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt; &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt; &lt;Transport className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt; &lt;/Sender&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt; &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt; &lt;/Channel&gt; &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt; &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt; &lt;Deployer className="org.apache.catalina.ha.deploy.FarmWarDeployer" tempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/" watchDir="/tmp/war-listen/" watchEnabled="false"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener"/&gt; &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt; &lt;/Cluster&gt;第二步：拷贝 web.xml文件到自己定义的路径别名的虚拟主机中(修改所有的tomcat服务器会话集群虚拟主机的web.xml) ~]# cp /etc/tomcat/web.xml /data/webapps/myapp/WEB-INF/ WEB-INF]# pwd /data/webapps/myapp/WEB-INF 23行 &lt;distributable/&gt; #必须虚拟主机路经下存在web.xml 并且改文件中存在&lt;distributable/&gt; 才可使用会话集群第三步：集群成员间的时间必须同步 ~] # ntpdate注意：此时调度器应该继续使用会话粘性，保证客户端请求都调度到一台服务器，因为后端的会话集群服务器同步会话信息并非实时同步。这样可以确保当给客户端提供会话的主机宕机后也可以让令外会话集权中的服务器继续保持会话第四步：重新启动会话集群中的tomcat服务器 ~]# systemctl start tomcat ~]# tail -f /var/log/tomcat/catalina.2019-01-20.log 调度器使用nginx调度测试 ~]# vim /etc/nginx/nginx.conf upstream tcserver &#123; server 172.18.135.1:8080; server 172.18.135.5:8080; &#125; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://tcserver; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; ~]# nginx -t ~]# nginx -s reload 测试(已经实现会话保持和nginx默认的轮询调度)]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat负载均衡--nginx | httpd]]></title>
    <url>%2F2019%2F01%2F19%2Ftomcat%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[tomcat负载均衡及会话保持–nginx | httpd session会话 session(会话保持) session stick:调度器 使用调度器的调度算法来解决问题，损害调度器的负载均衡效果，引入session单点即有一台服务器宕机都会造成数据的丢失。 session replication cluster (sesssion复制集群)：后端服务器组织成集群 将后端的服务器组织起来（单播，多播，广播等方式）将单个服务器的会话同步给集群中的其他服务器，从而使得用户的请求被调度到任何一个服务器上得到的session都是相同的（实现调度的服务器到后端被调度的服务器之间的解耦，实现将有状态变成了无状态实现按需进行调度） 劣势：每个节点都会持有集群中的所有的session信息，对内存资源的消耗非常大，同时对网络资源的占用也非常严重 session server:后端服务器之后即存储服务器 如果对tomcat实现负载均衡调度，一定要考虑到会话保持 如何对tomcat实现负载均衡（ session stick:调度器） 范例：使用nginx实现负载均衡123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109实验准备 三台主机 nginx_server yum install nginx -y tomcat_serverA yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y tomcat_serverB yum install java-11-openjdk-devel -y &amp;&amp; yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y 在两台tomcat上分别创建测试页面并定制虚拟主机tomcatA ~]# mkdir /data/webapps/myapp-v0.1 ~]# cd /data/webapps/myapp-v0.1 myapp-v0.1]# mkdir classes lib WEB-INF WETA-INF myapp-v0.1]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="purple"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp ~]# tree /data /data └── webapps ├── myapp -&gt; myapp-v0.1 └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnltomcatB ~]# tree /data /data └── webapps └── myapp-v0.1 ├── classes ├── index.jsp ├── lib ├── WEB-INF └── WETA-INF ~]# vim /data/webapps/myapp-v0.1/index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatB.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; webapps]# ln -sv myapp-v0.1 myapp#定义虚拟主机使用别名访问 ~]# vim /etc/tomcat/server.xml #140行 &lt;Context path="/myapp" docBase="/data/webapps/myapp" reloadable=""/&gt;#打开页面管理接口（manager app和 host manager） ~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt; &lt;role rolename="manager-script"/&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt; ~]# systemctl start tomcat ~]# ss -tnl 访问测试是否配置成功 12345678910111213141516171819202122232425262728293031使用nginx实现客户端的请求完全向后端代理nginx_server ~]# vim /etc/nginx/nginx.conf upstream tcserver &#123; server 172.18.135.1:8080; #tomcat A 地址 server 172.18.135.5:8080; #tomcat B 地址 &#125; server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://tcserver/; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; ~]# nginx -t ~]# nginx -s reload ~]# ss -tnl 客户端测试查看（此时是不能保持session会话,服务器认为是不同的session） 1234567891011利用nginx的hash算法实现会话绑定#基于一致性BASH算法实现会话绑定nginx_server upstream tcserver &#123; hash $remote_addr consistent; server 172.18.135.1:8080; server 172.18.135.5:8080; &#125; ~]# nginx -t ~]# nginx -s reload 客户端测试（怎么刷新都会是一个tomcat服务器响应，认为是一个客户端） 但是这用基于bash的机制是存在劣势的，万一响应的服务器宕机则客户端则无法接收到响应 范例：使用http实现负载均衡 httpd也可以实现负载均衡以及会话保持，甚至支持coocki级别的会话保持 持续支持的调度算法（lbmethod） bytraffic:后端服务器流量大小承载调度（流量小被调度） byrequests:根据请求调度，不考虑后端服务器的繁忙程度（轮询） bybusyness ：根据后端繁忙服务器程度进行调度，永不排队（商业版本支持） 参考手册：http://httpd.apache.org/docs/2.4/howto/reverse_proxy.html 方式1:http协议1234567891011121314151617181920212223242526272829#httpd做tomcat前端调度支持的协议（http\ajp 8009）#nginx做tomcat前端调度支持的协议（http）httpd_server httpd协议 ~]# vim /etc/httpd/conf.d/tomcat-cluster.conf &lt;proxy balancer://tcsrvs&gt; BalancerMember http://172.18.135.1:8080 loadfactor=2 #定义负载因子如果不定义默认都为1 BalancerMember http://172.18.135.5:8080 ProxySet lbmethod=byrequests &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName www.centos.com #nginx主机名 ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t ~]# systemctl start httpd 访问测试（此时保证不了会话绑定） 方式2：ajp协议1234567891011121314151617181920212223242526httpd_server ajp协议 &lt;proxy balancer://tcsrvs&gt; BalancerMember ajp://172.18.100.67:8009 BalancerMember ajp://172.18.100.68:8009 ProxySet lbmethod=byrequests &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName lb.magedu.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;Location /balancer-manager&gt; SetHandler balancer-manager ProxyPass ! Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; 会话粘性（httpd基于cookie的会话粘性）1234567891011#httpd不支持客户端地址的粘性#httpd是根据客户端的cookie做会话粘性httpd服务保持会话粘性： #当服务器第一次收到客户端的请求给他设定cookie时候，在这个cookie中把原有值之外额外设置添加一个对应的键（键名可以自己定义），值则是调度器第一次挑选要负载用户请求的后端服务器的名称，随后用户每后来的访问一定默认会带着cookie,而人为定义之后cookie之中是带有人为设置的键和值的对应信息的（不是基于原ip绑定，而是实现人为的会话中的cookie中插入的键值一致性实现的）Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGEDHeader add Set-Cookie #给客户端设置的cookie ROUTEID= #键名 .%&#123;BALANCER_WORKER_ROUTE&#125;e #调度服务器挑选出后端服务器 path= #指定会话cookie的适用范围 1234567891011121314151617181920212223242526编辑调度器httpd_server设置会话粘性 ~]# vim /etc/httpd/conf.d/tomcat-cluster.conf Header add Set-Cookie "ROUTEID=.%&#123;BALANCER_WORKER_ROUTE&#125;e; path=/" env=BALANCER_ROUTE_CHANGED &lt;proxy balancer://tcsrvs&gt;BalancerMember http://172.18.135.1:8080 loadfactor=2 route=TomcatA BalancerMember http://172.18.135.5:8080 route=TomcatA loadfactor=1 ProxySet lbmethod=byrequests ProxySet stickysession=ROUTEID &lt;/Proxy&gt; &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyVia On ProxyRequests Off ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / balancer://tcsrvs/ ProxyPassReverse / balancer://tcsrvs/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t ~]# systemctl restart httpd 客户端测试（已经实现基于cookie的会话粘性。可以使用Chrome开发者模式F12查看）]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置进阶--反代]]></title>
    <url>%2F2019%2F01%2F18%2Ftomcat%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B62%2F</url>
    <content type="text"><![CDATA[tomcat配置进阶–反代 tomcat配置进阶–反代nginx反代配置方式完全代理 客户端请求的所有资源都经由nginx反代给后端tomcat 123456#完全向后反代nginx配置文件location / &#123; proxy_pass http://127.0.0.1:8080/;&#125; 动静分离（动静分离的前提是应用程序支持动态页面和静态页面分开也可以达到客户端请求资源的一致性） nginx配置中指明客户端请求的闻不见类型为jsp或do结尾才代理给后端的tomcat服务器，除了此类型的文件外都经由nginx处理响应客户端的请求 为什么要实现动静分离 nginx的处理静态资源能力超强 主要是nginx处理静态页面的效率远高于tomcat的处理能力，如果tomcat的请求量为1000次，则nginx的请求量为6000次，tomcat每秒的吞吐量为0.6M，nginx的每秒吞吐量为3.6M，可以说，nginx处理静态资源的能力是tomcat处理能力的6倍，优势可见一斑。 动态资源和静态资源分开，使服务器结构更清晰。 动静分离原理： 服务端接收来自客户端的请求中，有一部分是静态资源的请求，例如html,css,js和图片资源等等，有一部分是动态数据的请求。因为tomcat处理静态资源的速度比较慢，所以我们可以考虑把所有静态资源独立开来，交给处理静态资源更快的服务器例如nginx处理，而把动态请求交给tomcat处理。如下图所示，我们在机器上同时安装了nginx和tomcat,把所有的静态资源都放置在nginx的webroot目录下面，把动态请求的程序都放在tomcat的webroot目录下面，当客户端访问服务端的时候，如果是静态资源的请求，就直接到nginx的webroot目录下面获取资源，如果是动态资源的请求，nginx利用反向代理的原理，把请求转发给tomcat进行处理，这样就实现了动静分离，提高了服务器处理请求的性能。 12345678910#有选择的进行反代以便实现动静分离nginx 配置文件location ~* \.(jsp|do)$ &#123; proxy_pass www.tomcat.com:8080; #此处最好使用后端tomcat主机名，如果tomcat在本地，则使用localhost&#125;location / &#123; root /data/myapp/ROOT&#125; 实现nginx反向代理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# 这里使用了docker容器化技术，将tomcat运行在docker容器中运行，运行的容器默认使用docker0桥与宿主机建立关联关系,并在宿主机上安装nginx接受客户端的请求代理给运行在docker容器中的tomcat安装docker ~]# cd /etc/yum.repos.d/ yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ~]# yum install docker-ce -y ~]# systemctl start docker获取tomcat镜像 https://hub.docker.com/_/tomcat?tab=tags下载tomcat镜像 ~]# docker pull tomcat:8.5-alpine后启动容器（指定容器中tomcat的工作目录与宿主机的目录生成docker管理的卷的存储卷关系） ~]# docker run --name tc1 -d -v /usr/local/tomcat/webapps tomcat:8.5-alpine ~]# docker container inspect tc1 ~]# cd /var/lib/docker/volumes/12d5e74a0cc8e916b7545898b41d802f85fed1cd0a5996fe7f74582245a8b2a3/_data _data]# ls docs examples host-manager manager ROOT宿主机上测试访问 ~]# curl 172.17.0.2:8080宿主机上安装nginx并配置实现代理 ~]# yum install nginx -y ~]# systemctl start nginx ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://172.17.0.1:8080/; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; ~]# nginx -t ~]# nginx -s reload客户端访问宿主机地址(此时nginx已经实现反向代理到tomcat) ~]# curl 172.18.135.1 #访问宿主机地址实现nginx反代tomcat动静分离（仅查看一下动静分离查看效果） ~]# vim /etc/nginx/nginx.conf server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; index index.jsp index.html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://172.17.0.2:8080; &#125; location ~* \.(jsp|do)$ &#123; root "映射在宿主机上的存储的卷"; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; 实现httpd反向代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172# 这里使用了docker容器化技术，将tomcat运行在docker容器中运行，运行的容器默认使用docker0桥与宿主机建立关联关系,并在宿主机上安装httpd接受客户端的请求代理给运行在docker容器中的tomcatproxy_ajp_module代理配置示例：# &lt;VirtualHost *:80&gt;# ServerName tc1.centos.com# ProxyRequests Off #关闭正向代理# ProxyVia On # 对每一个响应报文都添加一个via首部（可以查看代理的主机地址）# ProxyPreserveHost On #用户请求的主机向后端代理时要不要保留代理服务器使用的主机名# &lt;Proxy *&gt; #定义代理服务# Require all granted #允许任何请求使用代理服务# &lt;/Proxy&gt;# ProxyPass / ajp://tc1.centos.com:8009/ #将用户请求的根代理到服务器端真正的根# ProxyPassReverse / ajp://tc1.centos.com:8009/ #如果tomcat服务器返回一个重写的法则，也将此法则返回给客户端# &lt;Location /&gt; #客户端请求rul根，设置权限# Require all granted #接受所有请求# &lt;/Location&gt;# &lt;/VirtualHost&gt;proxy_http_module代理配置示例：# &lt;VirtualHost *:80&gt;# ServerName tc1.centos.com# ProxyRequests Off# ProxyVia On# ProxyPreserveHost On# &lt;Proxy *&gt;# Require all granted# &lt;/Proxy&gt;# ProxyPass / http://tc1.centos.com:8080/# ProxyPassReverse / http://tc1.centos.com:8080/ # &lt;Location /&gt;# Require all granted# &lt;/Location&gt;# &lt;/VirtualHost&gt; # &lt;LocationMatch "\.(jsp|do)$&gt; #基于正则表达式匹配检查# ProxyPass / http://tc1.centos.com:8080/ #定义反代的url，客户请求的其他的url则不进行反代# &lt;/LocationMatch&gt; 宿主上安装httpd（完全代理） ~]# yum install httpd -y ~]# httpd -M #确认proxy_module反代模块存在，否则不支持httpd反向代理 proxy_module (shared) proxy_ajp_module (shared) #反代支持ajp协议 proxy_http_module (shared) #httpd协议反代 proxy_fcgi_module (shared) 配置httpd ~]# vim /etc/httpd/conf.d/tomcat-http.conf ~]# vim /etc/httpd/conf.d/tomcat-http.conf &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyRequests Off ProxyVia On #对每一个响应报文都添加一个via首部 ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / http://172.17.0.2:8080/ #后端tomcat地址 ProxyPassReverse / http://172.17.0.2:8080/ &lt;Location /&gt; Require all granted &lt;/Location&gt; &lt;/VirtualHost&gt; ~]# httpd -t Syntax OK~]# systemctl start httpd测试 ~]# curl 172.18.135.1 配置文件中添加 ProxyVia On 可以使用浏览器开发者接口查看到 http基于ajp协议实现反代1234567891011121314 &lt;VirtualHost *:80&gt; ServerName www.centos.com ProxyRequests Off ProxyVia On ProxyPreserveHost On &lt;Proxy *&gt; Require all granted &lt;/Proxy&gt; ProxyPass / ajp://172.17.0.2:8009/ ProxyPassReverse / ajp://172.17.0.2:8009/&lt;Location /&gt; Require all granted&lt;/Location&gt;&lt;/VirtualHost&gt;]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置进阶--热部署]]></title>
    <url>%2F2019%2F01%2F16%2Ftomcat%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[tomcat配置进阶–热部署 tomcat配置进阶–热部署范例：Valve组件（过滤器）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152一、 ~]# vim /etc/tomcat/server.xml &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;#AccessLogValve 定义记录访问日志#directory 日志记录的路径，默认使用的是相对路径#prefix 日志文件的前缀，默认情况下，一天滚动一次（日志的前后缀可以按需求定义）#suffix 日志文件的后缀 （yum安装的生成的日志存放路径： /var/log/tomcat/）#pattern 日志文件所记录的日志格式 #%h远程客户端地址 #%l登陆的用户名 #%t访问时间 #%r请求报文的起始行（请求方法，请求的url,协议报文） #%s响应码 #%b响应的版本#一般而言Valve日志是host级别的，每一个虚拟主机有一个单独专用的日志将自己定义的主机也有自己单独的日志 ~]# vim /etc/tomcat/server.xml &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="centos.com_log." suffix=".log" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt;查看是否生成单独的虚拟主机的日志文件 ~]# systemctl restart tomcat ~]# ls /var/log/tomcat/ a_log.2019-01-16.txt 二、将tomcat的访问日志转化为json格式 修改tomcat的server.xml文件 &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".log" pattern="&#123;&amp;quot;client&amp;quot;:&amp;quot;%h&amp;quot;, &amp;quot;client user&amp;quot;:&amp;quot;%l&amp;quot;, &amp;quot;authenticated&amp;quot;:&amp;quot;%u&amp;quot;, &amp;quot;access time&amp;quot;:&amp;quot;%t&amp;quot;, &amp;quot;method&amp;quot;:&amp;quot;%r&amp;quot;, &amp;quot;status&amp;quot;:&amp;quot;%s&amp;quot;, &amp;quot;send bytes&amp;quot;:&amp;quot;%b&amp;quot;, &amp;quot;Query?string&amp;quot;:&amp;quot;%q&amp;quot;, &amp;quot;partner&amp;quot;:&amp;quot;%&#123;Referer&#125;i&amp;quot;, &amp;quot;Agent version&amp;quot;:&amp;quot;%&#123;User-Agent&#125;i&amp;quot;&#125;"/&gt;三、Valve存在多种类型：（根据客户端原地址做访问控制） 定义访问日志：org.apache.catalina.valves.AccessLogValve 定义访问控制：org.apache.catalina.valves.RemoteAddrValve &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" deny="172\.16\.100\.67"/&gt;#禁止172.16.100.67此台主机对tomcat的访问（黑名单）#可以使用deny与allow做访问控制，可以只用同配符 默认界面分析 点击接口进入：但是需要认证进入，点击取消可以查看如何授权用户访问此管理接口 授权用户一下几种权限： manager-gui - allows access to the HTML GUI and the status pages（授权的用户可以通过web界面访问） manager-script - allows access to the text interface and the status pages（授权的用户可以通过命令行的界面访问） manager-jmx - allows access to the JMX proxy and the status pages（可以只用java管理扩展来进行操作，多用于监控） manager-status - allows access to the status pages only（仅可以用于状态查看的用户即只读用户） 一、部署(manager)部署方式1：范例：授权账号可以访问web界面的manager的控制接口12345678~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; --&gt; &lt;user username="tomcat" password="centos" roles="manager-gui,manager-script"/&gt; &lt;/tomcat-users&gt;#此文件是tomcat启动时加载到内存中的所以要重新启动tomcat~]# systemctl restart tomcat 已经授权账号，登陆查看 在图形化管理界面stop一个应用程序并非清除内存，代表着类实例化出的对象还都在JVM的内存区段当中相当于暂停状态。 Undeplay意思为写在完全清除，达到真正的释放资源。 Deploy:部署方式 热部署：（manager部署工具）在tomcat不停机的状态下部署，可以实现客户端访问。 冷部署：先停掉tomcat进程，放上应用程序，启动tomcat加载应用程序。 自动部署：直接将应用程序放进tomcat,自动实现部署。 手动部署：将依赖的类库一个个的装载上。 范例:实现Deploy热部署12345678910111213141516171819202122232425创建目录结构及jsp文件 ~]# mkdir /data/mywebs ~]# mkdir /data/mywebs ~]# cd /data/mywebs/ mywebs]# mkdir classes lib WEB-INF WETA-INFmywebs]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.daizhe.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("a.com","a.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 热部署(重启tomcat也不会配置有影响，虽然不会出现在配置文件中，但是也是持久有效的) 方式2： 诊断（极少用到） 版本信息 帮助 二、运行状态 （server status) 三、管理虚拟主机（Host manager）授权用户访问此虚拟主机类管理界面启用方式和manager相同1234567~]# vim /etc/tomcat/tomcat-users.xml &lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;role rolename="admin-gui"/&gt;&lt;user username="tomcat" password="centos" roles="manager-gui,manager-script,admin-gui,admin-script"/&gt; &lt;/tomcat-users&gt;~]# systemctl restart tomcat 创建新的虚拟主机 注意：因为以上如部署权限过大，所以谨慎做好安全控制12345678# 可以对用户访问的http://172.18.135.1:8080/host-manager/或者http://172.18.135.1:8080/manager/html 做安装访问控制~]# vim /etc/tomcat/tomcat-users.xml &lt;Valve className="org.apache.catalina.valves.RemoteAddrValve" allow="172\.16\.100\.67"/&gt;#/host-manager/和/manager/html两个目录仅允许本机客户端地址进行访问连接#或者用不到的话安装tomcat就不要安装这两个组件]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置tomcat]]></title>
    <url>%2F2019%2F01%2F16%2F%E9%85%8D%E7%BD%AEtomcat%2F</url>
    <content type="text"><![CDATA[tomcat配置 部署Tomcat(JDK+Tomcat) 运行者身份不能为root(user:tomcat)端口默认为8080/tcp 部署方式1：OpenJDK(openjdk 11 + tomcat 7.0)12345678910111213141516171819202122232425262728#rel兼容多个版本JDK并存，可以设置默认的JDK版本# ~]# alternatives --install JDK# ~]# alternatives --config javayum安装OpenJDK ~]# yum install java-11-openjdk-devel -y ~]# java -version openjdk version "11.0.1" 2018-10-16 LTS(长期支持版) OpenJDK Runtime Environment 18.9 (build 11.0.1+13-LTS) OpenJDK 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode, sharing) ~]# which java /usr/bin/java ~]# ll /usr/bin/java /usr/bin/java -&gt; /etc/alternatives/java ~]# ll /etc/alternatives/java /etc/alternatives/java -&gt; /usr/lib/jvm/java-11-openjdk-11.0.1.13-3.el7_6.x86_64/bin/java安装tomcat(7.0) tomcat-admin-webapps.noarch #tomcat的web界面的管理的接口 tomcat-docs-webapp.noarch #参考文档 ~]# yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y ~]# systemctl restart tomcat #运行身份为Java虚拟机运行 ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 部署方式2：Oracle JDK(oracle jdk 8u191 + tomcat 8.5)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253oracle jdk 下载地址：https://www.oracle.com/technetwork/java/javase/downloads/index.html ~]# ls jdk-8u191-linux-x64.rpm ~]# rpm -ivh jdk-8u191-linux-x64.rpm 默认安装路径 ~]# ls /usr/java/ default jdk1.8.0_191-amd64 latest ~]# ll /usr/java/ default -&gt; /usr/java/latest #支持设置默认的版本 jdk1.8.0_191-amd64 #同样支持多版本共存 latest -&gt; /usr/java/jdk1.8.0_191-amd64 #支持设置最新的版本 验证是否安装成功（直接运行java程序） 查看版本信息 amd64]# pwd /usr/java/jdk1.8.0_191-amd64 amd64]# /bin/java -version java version "1.8.0_191" Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) 修改PATH变量 ~]# vim /etc/profile.d/java.sh JAVA_HOME=/usr/java/default PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH ~]# source /etc/profile.d/java.sh ~]# printenv tomcat 8.5安装下载路径：http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# tar xvf apache-tomcat-8.5.37.tar.gz -C /usr/local/ ~]# ln -vs /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat （链接形式方便升级） tomcat不可使用root用户运行 ~]# useradd tomcat ~]# chown -R tomcat.tomcat /usr/local/tomcat/ ~]# chown -R tomcat.tomcat /usr/local/tomcat/* ~]# su - tomcat -c "/usr/local/tomcat/bin/catalina.sh start" Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/bin/default Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/u ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） server.xml默认配置 Tomcat： 使用java语言编写： java程序运行环境 运行在JVM虚拟机上 jvm虚拟机组成部分 类加载器 程序运行引擎 tomcat的配置文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； log4j （目前已经在第二版） 12345678910111213141516171819Tomcat的核心组件：server.xml &lt;Server&gt; &lt;Service&gt; &lt;connector/&gt; &lt;connector/&gt; ... &lt;Engine&gt; &lt;Host&gt; &lt;Context/&gt; &lt;Context/&gt; ... &lt;/Host&gt; &lt;Host&gt; ... &lt;/Host&gt; ... &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt; 每一个组件都由一个Java“类”实现，这些组件大体可分为以下几个类型： 顶级组件：Server 服务类组件：Service 连接器组件：http, https, ajp（apache jserv protocol） 容器类：Engine, Host, Context 被嵌套类：valve, logger, realm, loader, manager, … 集群类组件：listener, cluster, … 基本web服务器的组成 JSP WebAPP的组织结构：（WEB-INF/和WEB-INF/是当前程序专有的且不可被其他程序所使用，也不能让用户通过互联网路径来访问，因为此文件用于参考部署启动应用程序） /: webapps的根目录 index.jsp, index.html：主页； WEB-INF/：当前webapp的私有资源路径；通常用于存储当前webapp的web.xml和context.xml配置文件； WEB-INF/：类似于WEB-INF/； classes/：类文件，当前webapp所提供的类 .java格式； lib/：类文件，当前webapp所提供的类，被打包为jar格式； webapp归档格式： .war：webapp（web_server的应用程序归档文件） .jar：EJB的类打包文件； .rar：资源适配器类打包文件； .ear：企业级webapp； 部署(deploy)webapp的相关操作： deploy：将webapp的源文件放置于目标目录(网页程序文件存放目录)，配置tomcat服务器能够基于web.xml和context.xml文件中定义的路径来访问此webapp；将其特有的类和依赖的类通过class loader装载至JVM； 部署有两种方式： 自动部署：auto deploy 手动部署: 冷部署：把webapp复制到指定的位置，而后才启动tomcat；- 热部署：在不停止tomcat的前提下进行部署； - 部署工具：manager、ant脚本、tcd(tomcat client deployer)等； undeploy：反部署，停止webapp，并从tomcat实例上卸载webapp； start：启动处于停止状态的webapp； stop：停止webapp，不再向用户提供服务；其类依然在jvm上； redeploy：重新部署； 范例：手动提供一测试类应用，并冷部署12345678910111213141516171819202122232425262728293031323334353637~]# mkdir testapp/~]# cd testapp/创建程序运行的相关的文件格式 testapp]# mkdir classes lib WEB-INF WETA-INF testapp]# ls classes lib WEB-INF WETA-INF创建网页文件 testapp]# vi index.jsp &lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello world"); %&gt; &lt;/body&gt; &lt;/html&gt; ~]# cp testapp testapp-v0.1将此文件复制到网页文件根目录（/usr/share/tomcat/webapps） ~]# cd /usr/share/tomcat/webapps webapps]# ls docs examples host-manager manager ROOT sample #ROOT 默认主站文件目录 webapps]# cp -r /root/testapp /usr/share/tomcat/webapps/ webapps]# ls docs examples host-manager manager ROOT sample testapp访问测试 ~]# curl 172.20.101.228:8080/testapp/ 1234567891011121314151617181920212223242526查看tomcat的工作目录 ~]# cd /usr/share/tomcat/work work]# tree . └── Catalina └── localhost #当前虚拟主机的名称 ├── _ │ └── org │ └── apache │ └── jsp │ ├── index_jsp.class │ └── index_jsp.java ├── docs ├── examples ├── host-manager ├── manager ├── sample └── testapp └── org └── apache └── jsp ├── index_jsp.class └── index_jsp.java#将自己定义放置在/usr/share/tomcat/webapps目录下testapp/index.jsp文件转换为java代码，再次编译成.class类文件#将来在生产中部署完应用程序，应该对每个url先自己访问一次，编译完成，然后再上线 tomcat的常用组件配置： Server：代表tomcat instance，即表现出的一个java进程；监听在8005端口，只接收“SHUTDOWN”。各server监听的端口不能相同，因此，在同一物理主机启动多个实例时，需要修改其监听端口为不同的端口； Service：用于实现将一个或多个connector组件关联至一个engine组件； Connector组件：端点 负责接收请求，常见的有三类http/https/ajp； 进入tomcat的请求可分为两类： (1) standalone : 请求来自于客户端浏览器； (2) 由其它的web server反代：来自前端的反代服务器； nginx –&gt; http connector –&gt; tomcat httpd(proxy_http_module) –&gt; http connector –&gt; tomcat httpd(proxy_ajp_module) –&gt; ajp connector –&gt; tomcat httpd(mod_jk) –&gt; ajp connector –&gt; tomcat 属性： port=”8080” protocol=”HTTP/1.1” connectionTimeout=”20000” address：监听的IP地址；默认为本机所有可用地址； maxThreads：最大并发连接数，默认为200； enableLookups：是否启用DNS查询功能； acceptCount：等待队列的最大长度； secure： sslProtocol： 范例：Server组件（顶级组件）1234567891011121314151617181920212223242526 ~]# vim /etc/tomcat/server.xml &lt;Server port="8005" shutdown="SHUTDOWN"&gt;#Server中两个属性需要定义# - port="8080" #端口# - shutdown="SHUTDOWN"# - 内建的管理接口，只要给SHUTDOWN字串则相当与停止整个tomcat进程 ~]# yum install telnet -y ~]# telnet 127.0.0.1 8005 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. SHUTDOWN Connection closed by foreign host. ~]# ss -tnl#此时tomcat已经停止，所以tomcat的8005端口默认监听在本机的127.0.0.1所以为了安全起见，建议关闭方法1：修改密码&lt;Server port="8005" shutdown="可以将命令修改的复杂"&gt;方法2：关闭监听端口&lt;Server port="-1" shutdown="SHUTDOWN"&gt; 范例：Service组件（类连接器）12345678910111213141516171819202122 ~]# vim /etc/tomcat/server.xml &lt;Service name="Catalina"&gt;........................http协议............................#Service中一个组件#将connector与Engine建立关联关系 &lt;Connector port="8080" protocol="HTTP/1.1" #端口、协议版本（1.1主流协议） connectionTimeout="20000" #超时时长20秒（单位毫秒） redirectPort="8443" /&gt; #&lt;!--#&lt;Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"#maxThreads="150" SSLEnabled="true" scheme="https" secure="true"#clientAuth="false" sslProtocol="TLS" /&gt;#--&gt;#如果启用8443端口表示TLS加密传输，注释行表示如果用户访问的端口为http则重写到https（但是tomcat一般不直接作为web_server运行，tomcat运行jsp本身就很消耗cpu，一般也不使用ssl）........................ajp协议............................ &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; 范例：Engine组件（容器组件）123456 ~]# vim /etc/tomcat/server.xml &lt;Engine name="Catalina" defaultHost="localhost"&gt;#name="Catalina" Engine名称，多个不可同名#defaultHost 默认的虚拟主机#jvmRoute 创建tomcat集群时用到 范例：Host（Host虚拟主机组件）123456789101112131415161718192021222324 ~]# vim /etc/tomcat/server.xml &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt;#appBase 定义网页文件根目录(可以使用相对路径即相对于tomcat的根，最好使用绝对路径)#unpackWARs 如果用户提供的就是.war格式的文件要不要自动展开#autoDeploy 是否支持自动部署(必要时可以关闭，自己手动部署)自己定义新的Host ~]# vim /etc/tomcat/server.xml 141行 &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;/Host&gt; ~]# mkdir -pv /data/webapps ~]# cp -r /root/testapp /data/webspps/ webapps]# mv testapp ROOT webapps]# ls ROOT #ROOT不可使用链接重启验证 ~]# systemctl restart tomcat ~]# curl www.centos.com:8080 范例：Context组件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 ~]# vim /etc/tomcat/server.xml &lt;Context path="/PATH" docBase="/PATH/TO/SOMEDIR" reloadable=""/&gt;#Context path 指明url#docBase 本地文件系统路径#reloadable 支不支持重新载入 webapps]# pwd /data/webapps webapps]# ls ROOT ~]# mkdir /myweb ~]# cd /myweb/ myweb]# vim testapp-v0.1 &lt;%@ page language="java" %&gt; &lt;%@ page import="java.util.*" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Test Page&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;% out.println("hello aaaaaaaaaa"); %&gt; &lt;/body&gt; &lt;/html&gt; myweb]# ls testapp-v0.1 ~]# ln -sv /myweb/testapp-v0.1 /myweb/testapp ~]# vim /etc/tomcat/server.xml &lt;/Host&gt; &lt;Host name="www.centos.com" appBase="/data/webapps/" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/mymyapp" docBase="/myweb/testapp" reloadable=""/&gt; &lt;/Host&gt; ~]# systemctl restart tomcat测试访问： ~]# curl www.centos.com:8080/mymyapp hello aaaaaaaaaa#Context 类似于http的路径别名 ：alias]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat基础与组件]]></title>
    <url>%2F2019%2F01%2F14%2Ftomcat%E5%9F%BA%E7%A1%80%E4%B8%8E%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[tomcat基础与组件 关于Tomcat Tomcat是Apache 软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun 和其他一些公司及个人共同开发而成。由于有了Sun 的参与和支持，最新的Servlet 和JSP 规范总是能在Tomcat 中得到体现，Tomcat 5支持最新的Servlet 2.4 和JSP 2.0 规范。因为Tomcat 技术先进、性能稳定，而且免费，因而深受Java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web 应用服务器。 Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用）页面的访问请求。实际上Tomcat 部分是Apache 服务器的扩展，但它是独立运行的，所以当你运行tomcat 时，它实际上作为一个与Apache 独立的进程单独运行的。 官网地址：http://tomcat.apache.org/ 部署Tomcat(JDK+Tomcat) Tomcat也是java编程语言编写的，是运行在JVM中的一个进程。它定义为【中间件】，顾名思义，是一个在Java项目与JVM之间的中间容器。 java程序写的网站用Tomcat+JDK来运行，Tomcat是一个中间件，真正起作用的，解析Java脚本的是JDK。JDK（Java development kit）是整个Java的核心，它包含了Java运行环境和一堆Java相关的工具以及Java基础库。最主流的JDK是由sun公司发布的JDK，除此之外，IBM公司也有发布JDK，centos上也可以使用yum安装openjdkJava写的网页后缀名是.jsp。 运行者身份不能为root(user:tomcat)端口默认为8080/tcp 部署方式1：OpenJDK(openjdk 11 + tomcat 7.0)12345678910111213141516171819202122232425262728#rel兼容多个版本JDK并存，可以设置默认的JDK版本# ~]# alternatives --install JDK# ~]# alternatives --config java #设置默认的jdk版本yum安装OpenJDK ~]# yum install java-11-openjdk-devel -y ~]# java -version openjdk version "11.0.1" 2018-10-16 LTS(长期支持版) OpenJDK Runtime Environment 18.9 (build 11.0.1+13-LTS) OpenJDK 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode, sharing) ~]# which java /usr/bin/java ~]# ll /usr/bin/java /usr/bin/java -&gt; /etc/alternatives/java ~]# ll /etc/alternatives/java /etc/alternatives/java -&gt; /usr/lib/jvm/java-11-openjdk-11.0.1.13-3.el7_6.x86_64/bin/java安装tomcat(7.0) tomcat-admin-webapps.noarch #tomcat的web界面的管理的接口 tomcat-docs-webapp.noarch #参考文档 ~]# yum install tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp -y ~]# systemctl restart tomcat #运行身份为Java虚拟机运行 ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 部署方式2：Oracle JDK(oracle jdk 8u191 + tomcat 8.5)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253oracle jdk 下载地址：https://www.oracle.com/technetwork/java/javase/downloads/index.html ~]# ls jdk-8u191-linux-x64.rpm ~]# rpm -ivh jdk-8u191-linux-x64.rpm 默认安装路径 ~]# ls /usr/java/ default jdk1.8.0_191-amd64 latest ~]# ll /usr/java/ default -&gt; /usr/java/latest #支持设置默认的版本 jdk1.8.0_191-amd64 #同样支持多版本共存 latest -&gt; /usr/java/jdk1.8.0_191-amd64 #支持设置最新的版本 验证是否安装成功（直接运行java程序） 查看版本信息 amd64]# pwd /usr/java/jdk1.8.0_191-amd64 amd64]# /bin/java -version java version "1.8.0_191" Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) 修改PATH变量 ~]# vim /etc/profile.d/java.sh JAVA_HOME=/usr/java/default PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH ~]# source /etc/profile.d/java.sh ~]# printenv tomcat 8.5安装下载路径：http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-8/v8.5.37/bin/apache-tomcat-8.5.37.tar.gz ~]# tar xvf apache-tomcat-8.5.37.tar.gz -C /usr/local/ ~]# ln -vs /usr/local/apache-tomcat-8.5.37 /usr/local/tomcat （链接形式方便升级） tomcat不可使用root用户运行 ~]# useradd tomcat ~]# chown -R tomcat.tomcat /usr/local/tomcat/ ~]# chown -R tomcat.tomcat /usr/local/tomcat/* ~]# su - tomcat -c "/usr/local/tomcat/bin/catalina.sh start" Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /usr/bin/default Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/u ~]# ss -tnl LISTEN 0 100 :::8009 (ajp) LISTEN 0 100 127.0.0.1:8005 (管理接口) LISTEN 0 100 :::8080 （http） 欢迎页： Manager App(应用程序管理器、web界面部署其他应用程序) 与 Host Manager 部署的管理程序 Tomcat基本框架及相关配置 如上图，Tomcat可以按功能划分许多不同的组件，这些组件都可以通过/conf/server.xml(部署描述符文件)文件中可定义和配置，包括Server, Service, Connector, Engine, Cluster, Host, Alias, Context, Realm, Valve, Manager, Listener, Resources, ResourceEnvRef, WatchedResource, Store, Transaction, Channel, Membership, Transport, Member, ClusterListener等，一般可分为以下四类： 1、Server顶级组件：位于配置层次的顶级，并且彼此间有着严格的对应关系，有Server组件、Service组件； 2、Connector连接器：连接客户端（可以是浏览器或Web服务器）请求至Servlet容器，只有Connector组件（Connector才是一个具体特定、真正的程序，可以被单独部署和管理、启动停止暂停等。） 3、Engine容器：表示其功能是处理传入请求的组件，并创建相应的响应。如Engine处理对一个Service的所有请求，Host处理对特定虚拟主机的所有请求，并且Context处理对特定web应用的所有请求（容器类容器组件，可以容纳JSP应用程序的顶级组件）； 4、Context被嵌套的组件：位于一个容器当中，但不能包含其它组件；一些组件可以嵌套在任何Container中，而另一些只能嵌套在Context中。 server.xml默认配置 Tomcat： 使用java语言编写： tomcat的配置文件构成： server.xml：主配置文件； web.xml：每个webapp只有“部署”后才能被访问，它的部署方式通常由web.xml进行定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认部署相关的配置； context.xml：每个webapp都可以专用的配置文件，它通常由专用的配置文件context.xml来定义，其存放位置为WEB-INF/目录中；此文件为所有的webapps提供默认配置； tomcat-users.xml：用户认证的账号和密码文件； catalina.policy：当使用-security选项启动tomcat时，用于为tomcat设置安全策略； catalina.properties：Java属性的定义文件，用于设定类加载器路径，以及一些与JVM调优相关参数； logging.properties：日志系统相关的配置； log4j 12345678910111213141516171819Tomcat的核心组件：server.xml &lt;Server&gt; &lt;Service&gt; &lt;connector/&gt; &lt;connector/&gt; ... &lt;Engine&gt; &lt;Host&gt; &lt;Context/&gt; &lt;Context/&gt; ... &lt;/Host&gt; &lt;Host&gt; ... &lt;/Host&gt; ... &lt;/Engine&gt; &lt;/Service&gt; &lt;/Server&gt; 更多Server配置信息请参考：《Apache Tomcat 8 Configuration Reference》 The Server Component基本组件 1、Server组件 erver（服务器）表示Tomcat的一个实例，因此，它必须是/conf / server.xml配置文件中的单个最外层元素，它的属性表示servlet容器的整体特性。通常一个JVM只能包含一个Tomcat实例。 默认配置表示监听在8005端口以接收shutdown命令，默认仅允许通过本机访问。 2、Service组件 Service（服务）主要用于关联一个Engine和与此Engine相关的Connector，每个Connector通过一个特定的端口和协议接收请求，并将其转发至关联的Engine进行处理。 因此，Service可以包含一个Engine、以有一个或多个Connector；而一个Server可以包含多个Service组件，但通常情下只为一个Server指派一个Service。通常需要给Service命名，可以方便管理员在日志文件中识别不同Service产生的日志。 如默认配置中server只包含一个名为”Catalina”的service，而service里包含两个Connector，其中一个监听8080端口接收HTTP请求，另一个监听8009端口接收AJP协议的请求。 3、Connector组件 如上面所述，Connector（连接器）通过一个特定的端口接收特定协议的客户端请求，并将其转发至关联的Engine进行处理。一个Engine可以配置多个连接器，但这些连接器必须使用不同的端口。 定义连接器可以使用多种属性，有些属性也只适用于某特定的连接器类型。一般说来，连接器类型可以分为两种： （1）、HTTP连接器 HTTP连接器元素表示支持HTTP / 1.1协议的连接器组件，它能使Tomcat能够作为独立的Web服务器。此组件的特定实例侦听服务器上特定TCP端口号上的连接，每个转发到相关联的Engine以执行请求处理并创建响应。 默认配置文件，定义了一个连接器为protocol=”HTTP/1.1” 表示的是使用自动切换机制来选择基于Java NIOConnector或基于APR /Native Connector（需要设置），也可以手动指定 2）、AJP 1.3连接器 AJP连接器元素表示通过AJP(Apache JServ Protocol)协议与Web连接器通信的连接器组件。 AJP协议是基于二进制的格式在Web服务器和Tomcat之间传输数据，这比HTTPP获得更好的效率，但比较复杂不通用。 通常用于将Tomcat集成到现有Apache服务器中，并且希望Apache处理Web应用程序中包含的静态内容或SSL连接处理的情况，即Apache服务器作为代理服务器。Apache与Tomcat结合可以由mod_jk或mod_proxy模块来实现，但它们的使用范围不同：mod_jk支持apache/1.3,apache/2.0，mod_proxy支持apache/2.2+。 默认配置文件中定义了一个监听8009端口的AJP连接器，其实官方文档说明这种连接器不久后不再支持，一般用得不多，就不再多介绍了。 定义连接器时可以配置的属性非常多，但通常定义HTTP连接器时必须定义的属性只有”port”，定义AJP连接器时必须定义的属性只有”protocol”，因为默认的协议为HTTP。以下为常用属性的说明（更多请参考前面给出的文档）： 1、address：指定连接器监听的地址，默认为所有地址，即0.0.0.0； 2、maxThreads：支持的最大并发连接数，默认为200； 3、port：监听的端口，默认为0； 4、protocol：连接器使用的协议，默认为HTTP/1.1，定义AJP协议时通常为AJP/1.3； 5、redirectPort：如果某连接器支持的协议是HTTP，当接收客户端发来的HTTPS请求时，则转发至此属性定义的端口； 6、connectionTimeout：等待客户端发送请求的超时时间，单位为毫秒，默认为60000，即1分钟； 7、enableLookups：是否通过request.getRemoteHost()进行DNS查询以获取客户端的主机名；默认为true； 8、acceptCount：设置等待队列的最大长度；通常在tomcat所有处理线程均处于繁忙状态时，新发来的请求将被放置于等待队列中； 4、Engine组件 Engine（引擎）表示与特定Service相关联的整个请求处理机制，即Servlet容器引擎。它接收和处理来自一个或多个连接器的所有请求，并检查每一个请求的HTTP首部信息以辨别此请求应该发往哪个Host或Context，并将完成的响应返回到连接器，以便最终传输回客户端。 一个Engine元素必须嵌套在Service元素内，它可以包含多个host组件，还可以包含Realm、Listener和Valve等子容器。 常用的属性定义： 1、defaultHost：Tomcat支持基于FQDN的虚拟主机，这些虚拟主机可以通过在Engine容器中定义多个不同的Host组件来实现；但如果此引擎的连接器收到一个发往非非明确定义虚拟主机的请求时则需要将此请求发往一个默认的虚拟主机进行处理，因此，在Engine中定义的多个虚拟主机的主机名称中至少要有一个跟defaultHost定义的主机名称同名。 2、name：Engine组件的名称，用于日志和错误信息记录时区别不同的引擎。 如默认配置中定义了一个名为”Catalina”的Engine，而Engine里包含一个Hots，并被配置为默认的虚拟主机。 5、Host组件 Host（虚拟主机）类似于Apache中的虚拟主机，但在Tomcat中只支持基于FQDN的”虚拟主机”。Host位于Engine容器中用于接收请求并进行相应处理，它是服务器（例如”www.mycompany.com&quot;）的网络名称与运行Tomcat的特定服务器的关联。 客户端通常使用主机名来标识他们希望连接的服务器，但要使客户端能够使用其网络名称连接到Tomcat服务器，此名称必须在管理所属的Internet域的域名服务（DNS）服务器中注册。此主机名也包含在HTTP请求标头中，Tomcat从HTTP头中提取主机名，并查找具有匹配名称的主机；如果未找到匹配项，请求将路由到默认主机。 一个Engine至少要包含一个Host组件，而在Host元素内可以嵌入与此虚拟主机关联的Web应用程序的Context等元素。 常用属性说明： 1、name：此Host的FQDN虚拟主机名称； 2、appBase：此Host的webapps目录，即存放非归档的web应用程序的目录或归档后的WAR文件的目录路径；可以使用基于$CATALINA_HOME的相对路径； 3、autoDeploy：在Tomcat处于运行状态时放置于appBase目录中的应用程序文件是否自动进行deploy；默认为true； 4、unpackWars：在启用此webapps时是否对WAR格式的归档文件先进行展开；默认为true。 如默认配置中定义了一个主机名为”localhost”的Host，而webapps目录为$ CATALINA_BASE相对的”webapps”，即前面说到的默认目录，也可用绝对路径来配置其他目录。 6、Context组件 Context（上下文）表示在特定虚拟主机中运行的Web应用程序，一个Context对应一个Web应用程序，而里面的Wrapper可以理解为一个个Servlet程序。 Context需要根据其定义的上下文路径（path）匹配请求URI的最长前缀（除主机名外）来选择。一旦选择，可以由docBase来找到该上下文将对应的web应用程序部署目录，由目录中web.xml定义的servlet映射选择一个合适的servlet来处理传入的请求。 一个Host可以有多个Context，通常不建议定义在server.xml文件中，而是每一个context定义使用一个单独的XML文件进行，其文件的目录为$CATALINA_HOME/conf/&lt;engine name&gt;/&lt;host name&gt; 可以看到server.xml中默认没有定义Context，但存在/conf/context.xml，在前面说Tomcat配置文件时曾介绍过，context.xml为部署与此Tomcat实例上所有的web应用程序提供的默认配置文件， 通过它可以找到默认的和各web应用程序提供部署描述符文件web.xml，/conf/web.xml定义了Tomcat提供的默认Servlet处理程序，主要用来处理静态资源请求；而各webapp的web.xml可以定义其他的动态请求url映射到不同Servlet程序处理。 常用的属性定义有： 1、docBase：相应的Web应用程序的存放位置；也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径；切记，docBase的路径名不能与相应的Host中appBase中定义的路径名有包含关系，比如，如果appBase为deploy，而docBase绝不能为deploy-bbs类的名字； 2、path：相对于Web服务器根路径而言的URI；如果为空””，则表示为此webapp的根路径；如果context定义在一个单独的xml文件中，此属性不需要定义； 3、reloadable：是否允许重新加载此context相关的Web应用程序的类；默认为false； 7、Realm组件 Realm（领域）表示分配给这些用户的用户名，密码和角色（类似于Unix组）的”数据库”。一个Realm（领域）表示一个安全上下文，它是一个授权访问某个给定Context的用户列表和某用户所允许切换的角色相关定义的列表。 Catalina容器（Engine，Host或Context）可以包含不超过一个Realm元素（但自身可以嵌套）。此外，与引擎或主机关联的领域由低级容器自动继承，除非下级容器显式定义了自己的领域。如果没有为引擎配置领域，将自动为引擎配置空领域的实例。 定义Realm时惟一必须要提供的属性是classname，它是Realm的多个不同实现，用于表示此Realm认证的用户及角色等认证信息的存放位置，Tomcat中实现了多种不同的Realm，如下： UserDatabaseRealm：基于UserDatabase文件(通常是tomcat-user.xml)实现用户认证，它实现是一个完全可更新和持久有效的MemoryRealm，因此能够跟标准的MemoryRealm兼容；它通过JNDI实现； LockOutRealm：提供锁定功能，以便在给定时间段内出现过多的失败认证尝试时提供用户锁定机制； JAASRealm：基于Java Authintication and Authorization Service实现用户认证； JDBCRealm：通过JDBC访问某关系型数据库表实现用户认证； JNDIRealm：基于JNDI使用目录服务实现认证信息的获取； MemoryRealm：查找tomcat-user.xml文件实现用户信息的获取。 可以看到默认配置文件中定义了一个LockOutRealm并嵌套一个UserDatabaseRealm的Realm来通过tomcat-user.xml文件实现用户认证。 8、Valve组件 Valve（阀门）类似于过滤器，用来拦截请求并在将其转至目标之前进行某种处理操作；它可以工作于Engine和Host/Context之间、Host和Context之间以及Context和Web应用程序的某资源之间。 Valve常被用来记录客户端请求、客户端IP地址和服务器等信息，这种处理技术通常被称作请求转储(request dumping)。请求转储valve记录请求客户端请求数据包中的HTTP首部信息和cookie信息文件中，响应转储valve则记录响应数据包首部信息和cookie信息至文件中。 一个容器内可以建立多个Valve，而且Valve定义的次序也决定了它们生效的次序。不同类型的Value具有不同的处理能力，Tomcat中实现了多种不同的Valve： AccessLogValve：访问日志Valve ExtendedAccessValve：扩展功能的访问日志Valve RequestDumperValve：请求转储Valve； RemoteAddrValve：基于远程地址的访问控制； RemoteHostValve：基于远程主机名称的访问控制； SemaphoreValve：用于控制Tomcat主机上任何容器上的并发访问数量； ReplicationValve：专用于Tomcat集群架构中，可以在某个请求的session信息发生更改时触发session数据在各节点间进行复制； SingleSignOn：将两个或多个需要对用户进行认证webapp在认证用户时连接在一起，即一次认证即可访问所有连接在一起的webapp； ClusterSingleSingOn：对SingleSignOn的扩展，专用于Tomcat集群当中，需要结合ClusterSingleSignOnListener进行工作。 通过属性className定义相关的java实现的类名来选择Value。如默认配置文件中定义了一个AccessLogValve的Value来记录访问日志到文件中。 其他组件 1、Logger 日志记录器(Logger)：用于记录组件内部的状态信息，可被用于除Context之外的任何容器中。日志记录的功能可被继承，因此，一个引擎级别的Logger将会记录引擎内部所有组件相关的信息，除非某内部组件定义了自己的Logger组件（前面介绍的AccessLogValve使用自包含的逻辑来写它的日志文件，以获得更好的效率）。 2、Listener Listener用于创建和配置LifecycleListener对象，而LifecycleListener通常被开发人员用来创建和删除容器。 3、Loader Java的动态装载功能是其语言功能强大表现之一，Servlet容器使用此功能在运行时动态装载servlet和它们所依赖的类。Loader可以用于Context中控制java类的加载，即WebApp类加载器。 4、Resources 经常用于实现在Context中指定需要装载的但不在Tomcat本地磁盘上的应用资源，如Java类，HTML页面，JSP文件等。 5、GlobalNamingResources 应用于整个服务器的JNDI映射，此可以避免每个Web应用程序都需要在各自的web.xml创建，这在web应用程序以WAR的形式存在时尤为有用。它通常可以包含三个子元素：Environment、Resource和ResourceEnvRef。 6、WatchedResource WatchedResource可以用于Context中监视指定的webapp程序文件的改变，并且能够在监视到文件内容发生改变时重新装载此文件。 7、Manager Manger对象用于实现HTTP会话管理的功能，Tomcat中有5种Manger的实现： 1)StandardManager Tomcat6的默认会话管理器，用于非集群环境中对单个处于运行状态的Tomcat实例会话进行管理。当Tomcat关闭时，这些会话相关的数据会被写入磁盘上的一个名叫SESSION.ser的文件，并在Tomcat下次启动时读取此文件。 2) PersistentManager 当一个会话长时间处于空闲状态时会被写入到swap会话对象，这对于内存资源比较吃紧的应用环境来说比较有用。 3)DeltaManager 属于ClusterManager，用于Tomcat集群的会话管理器，它通过将改变了会话数据同步给集群中的其它节点实现会话复制。这种实现会将所有会话的改变同步给集群中的每一个节点，也是在集群环境中用得最多的一种实现方式。 但集群节点较多时，会消耗大量的网络资源，一般适用于3、4个节点的集群。 4)BackupManager 属于ClusterManager，用于Tomcat集群的会话管理器，与DeltaManager不同的是，某节点会话的改变只会同步给集群中的另一个而非所有节点。 5)SimpleTcpReplicationManager Tomcat4时用到的版本，过于老旧了。 8、Stores PersistentManager必须包含一个Store元素以指定将会话数据存储至何处。这通常有两种实现方式：FileStore和JDBCStore。 9、Cluster 专用于配置Tomcat集群的元素，可用于Engine和Host容器中。在用于Engine容器中时，Engine中的所有Host均支持集群功能。在Cluster元素中，需要直接定义一个Manager元素，这个Manager元素有一个其值为org.apache.catalina.ha.session.DeltaManager或org.apache.catalina.ha.session.BackupManager的className属性。同时，Cluster中还需要分别定义一个Channel和ClusterListener元素。 10、Channel 用于Cluster中给集群中同一组中的节点定义通信”信道”。Channel中需要至少定义Membership、Receiver和Sender三个元素，此外还有一个可选元素Interceptor。 11、Membership 用于Channel中配置同一通信信道上节点集群组中的成员情况，即监控加入当前集群组中的节点并在各节点间传递心跳信息，而且可以在接收不到某成员的心跳信息时将其从集群节点中移除。Tomcat6中Membership的实现是org.apache.catalina.tribes.membership.McastService。 12、Sender 用于Channel中配置”复制信息”的发送器，实现发送需要同步给其它节点的数据至集群中的其它节点。发送器不需要属性的定义，但可以在其内部定义一个Transport元素。 13、Transport 用于Sender内部，配置数据如何发送至集群中的其它节点。Tomcat有两种Transport的实现： 1) PooledMultiSender 基于Java阻塞式IO，可以将一次将多个信息并发发送至其它节点，但一次只能传送给一个节点。 2)PooledParallelSener 基于Java非阻塞式IO，即NIO，可以一次发送多个信息至一个或多个节点。 14、Receiver 用于Channel定义某节点如何从其它节点的Sender接收复制数据，Tomcat中实现的接收方式有两种BioReceiver和NioReceiver。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat之java基础]]></title>
    <url>%2F2019%2F01%2F14%2Ftomcat%E4%B9%8Bjava%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[tomcat之java基础 java基础什么是java java所涉及到的相关概念如下图。总体来说就是java语言、java API、jvm等构成。 jvm：java虚拟机，java的代码都是运行在jvm上，这是java语言跨平台的保证，针对不同的系统jvm也不同，这就实现了同一份代码，通过不同jvm的运行可以让对应的操作系统识别。 JRE（java running environment）：就是提供给java代码一个运行环境，java代码运行在jvm上，但是开发程序的时候往往除本身代码外会有引入的api，当程序运行时，jvm会加载相关的类，所以一个能保证代码能正常运行的环境是jvm+api（java se api）。 JDK（java development kit）：java开发环境，JDK=java语言+开发相关的API+JRE。开发环境除了要正常运行程序外（JRE环境），还需要进行开发相关的操作如打包、编译等这类工具。 JAVA API 平时API听多了，但是或许并不了解，这里做下简要解释。一个操作系统会提供很多API接口让程序员使用计算机的硬件资源，这是系统API，这里涉及到一个POSXI的概念，POSIX表示可移植操作系统接口（Portable Operating System Interface ，缩写为 POSIX ），POSIX标准定义了操作系统应该为应用程序提供的接口标准，为一个POSIX兼容的操作系统编写的程序，应该可以在任何其它的POSIX操作系统（即使是来自另一个厂商）上编译执行。因为遵循POSXI标准的操作系统，所定义的操作系统API都相同，所以开发程序的时候，使用的API在名称参数上都可以兼容，所以换一个系统，不需要重新编写代码。POSIX是针对API的标准，即针对API的函数名，返回值，参数类型等。POSIX兼容也就指定这些接口函数兼容，但是并不管API具体如何实现。 Java api：就是用java语言编写的功能代码，为访问主机上的本地资源，Java api调用了本地方法（操作系统API），直接通过内核请求调用相关内核函数。而后将功能相似的这些代码归类，组成java api类库。 以linux编程为例：我们编写linux用户程序的时候，是不能直接调用内核里面的函数的，内核里面的函数位于进程虚拟地址空间里面的内核空间，用户空间函数及函数库都处于进程虚拟地址空间里面的用户空间，用户空间调用内核空间的函数只有一个通道，这个通道就是系统调用指令，所以通常要调用glibc等库的接口函数（C语言的API），glibc也是用户空间的，但glibc自己实现了调用特殊的宏汇编系统调用指令进行cpu运行状态的切换，把进程从用户空间切换到内核空间。 JVM 内存结构 java中通过多线程机制使得多个任务同时执行处理，所有的线程共享JVM内存区域main memory，而每个线程又单独的有自己的工作内存，当线程与内存区域进行交互时，数据从主存拷贝到工作内存，进而交由线程处理。 程序计数器（Program Counter Register）：由于Java 虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器 Java 虚拟机栈（Java Virtual Machine Stacks）：每个放在被执行的时候都会同时创建一个栈帧用于存当前线程中局部基本类型的变量（java中定义的八种基本类型：boolean、char、byte、short、int、long、float、double），操作数栈，动态链接，方法出口等信息。虚拟内存栈就是我们经常讲的“栈”。其中局部变量表所需内存是在编译期完成分配。 方法区（Method Area）：与Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。它有一个别名叫做Non-Heap（非堆），目的应该是与Java 堆区分开来。也称为持久代（Permanet Generation）。 Java 堆（Java Heap）：是Java 虚拟机所管理的内存中最大的一块。它是JVM用来存储对象实例以及数组值的区域，可以认为Java中所有通过new创建的对象的内存都在此分配。Java 堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”（Garbage Collected Heap）。 本地方法栈：与虚拟机栈类似，区别在于虚拟机栈为虚拟机执行Java方法服务，而本地方法栈为虚拟机使用Native方法（系统接口）服务。 WEB CGI 早期的web只能实现静态的页面，如果我们需要一种效果，就是我们向服务器请求时想让web服务器现场处理并将处理过的数据结果返回给我们，该如何实现呢。 第一种方式：开发一个程序，接收用户请求，解析请求内容，查找相关数据进行计算处理，将处理结果封装成响应报文返回给用户。 第二种方式：既然已经存在web服务器了，那没必要重新开发程序来处理HTTP协议的东西，只需要开发另一种方式，让计算机能够将处理后的数据，发送给web服务器，服务器再返回给用户 于是CGI协议就产生了，web服务器接收到请求，可是它自身无法解决请求之中需要经过计算处理的内容，那样服务器就去找帮手，找个能处理这个内容的其他程序，这个其他程序通过一种方式（CGI）和服务器进行交流，处理好之后将结果送给web服务器。 早期使用的web服务器扩展机制CGI，它允许用户调用web服务器上的CGI程序。CGI即是公共网关接口，大多数的CGI程序使用Perl来编写，也使用C、Pyhton或者PHP来编写。用户通过单机某个链接或者直接在浏览器的地址栏中输入Url来访问CGI程序，web服务接收到请求后，发现这个请求是给CGI程序的，于是就启动并运行这个CGI程序，对用户请求进行处理，CGI程序解析请求中的CGI数据，处理数据，并产生了一个响应（通常是HTML页面）。这个响应被返回给Web服务器，Web服务器包装这个响应（例如添加消息报头），以HTTP响应的形式发送给web浏览器 什么是CGI 如上文所述，HTTP服务器是一个很简单的东西，并不负责动态页面的构建，只能转发静态页面，事物总是不断发展，网站也越来越复杂，所以出现动态技术。同时Apache也说，能支持perl，生成动态页面，这个支持perl，其实是Apache越位了，做了一件额外的事情。 既然HTTP Server自己不能做，外包给别人但是要与第三者做个约定，我给你什么，然后你给我什么，就是我把请求参数发给你，然后我接收你的处理结果给客户端，那这个约定就是Common Gatway Interface(CGI) CGI全称是“通用网关接口”，是HTTP服务器与你的或其他机器上的程序进行“交谈”的一种工具，其程序必须运行在网络服务器上，是一种根据请求信息动态产生的响应内容的接口协议，CGI可以用任何一种语言编写，只要这种语言具有标准输入，输出和环境变量。如php，perl,tcl等。 通过CGI,HTTP sERVER可以将根据请求不同启动不同的外部程序，并将请求内容转发给该程序，在程序执行结束后，将执行结果作为回应返回给客户端。也就是说，对于每个请求，都要产生一个新的进程进行处理，因为每个进程都会占有很多服务器的资源和时间，这就导致服务器无法同时处理很多的并发请求，另外CGI程序都是与操作系统平台相关的，虽然在互联网爆发的初期，CGI为开发互联网应用做出了很大的贡献，但是随着技术的发展，开始逐渐衰落。所以，CGI的定义是：外部应用程序与HTTP服务器之间的接口协议。 Serlvet与Servlet容器 当java想实现CGI这样的功能时，因为java代码运行在jvm中，而jvm是没有办法直接跟web服务器进行交流的，所以Servlet就出现了。 当初在Apache Server 开发时CGI这样的功能时还未出现Serlet的概念，所以Apache不能内置支持Servlet。实际上，除了Apache，其他许多HTTP Server软件都不能直接支持Servlet。为了支持Servlet，通常要单独开发程序，这种程序一般称为服务小程序的容器（servlet container） ，有时也叫做服务器小程序引擎（servlet engine）。它的web服务器或者应用程序服务器的一部分，用于在发送的请求和响应之上提供的网络服务，解码基于MMIE的请求，格式化基于MIME的响应，它在Servlet的生命周期内包括和管理Servlet，是一个实时运行的外壳程序，运行时由wab服务器软件处理一般的请求，并把Servlet调用传递给“容器”来处理。 既然java作为编程语言，那么我们可以开发自己想要的功能，我们开发一个程序，使之能够与web服务器进行交互。所以java写了一个servlet类，这个类可以实例化为servlet程序，这个程序可以接受来自web服务器的请求并处理。那问题又来了， 如果多个web请求过来，仅仅一个Servlet程序是不够的，而且请求来了如何对java代码编译呢，于是乎就在外层增加一个管理功能的容器（这里纯属个人臆想），所以如果把Servlet类库完整实现了，那就是Servlet容器。这个容器的作用是什么呢？ 1、利用容器提供的方法，你能轻松的让servlet与web服务器对话，而不用自己建立serversocket、监听某个端口、创建流等等。容器知道自己与web服务器之间的协议，所以你的servlet不用担心web服务器（如Apache）和你自己的web代码之间的API，只需要考虑如何在servlet中实现业务逻辑（比如从数据库或者磁盘中获取数据并处理）。 2、多线程支持：容器会自动为它所接收的每个servlet请求创建一个新的java线程。针对用户的请求，如果servlet已经运行完相应的http服务方法，这个线程就会结束。 3、生命周期管理：servlet容器控制着servlet的生与死，它负责加载类、实例化和初始化servlet，调用servlet方法，以及使servlet实例被垃圾回收。 Java Servlet 是运行在 Web 服务器或应用服务器上的程序，它是作为来自 Web 浏览器或其他 HTTP 客户端的请求和 HTTP 服务器上的数据库或应用程序（服务器响应）之间的中间层，位于Web 服务器内部的服务器端的Java应用程序，与传统的从命令行启动的Java应用程序不同，Servlet由Web服务器进行加载，该Web服务器必须包含支持Servlet的Java虚拟机。客户端发送请求至服务器；服务器启动并调用Servlet，Servlet根据客户端请求生成响应内容并将其传给服务器；服务器将响应返回客户端。 servlet就是一个组件，需要部署到servlet容器才能运行。servlet容器为servlet提供网络相关的服务：即servlet容器为将请求中的相关数据解析出来，并且封装到请求对象(request)里面，这样一来，servlet就不需要理解http协议(只需要调用request对象的相关方法即可获取数)，另外，当servlet处理请求完毕，只需要将结果写到响应对象(response)里面,servlet容器会自动将response对象中的数据打包，发送给浏览器。 java servlet 简单代码实现 Java Servlet与CGI (Common Gateway Interface 公共网关接口)的比较: 与传统的CGI和许多其他类似CGI的技术相比，Java Servlet具有更高的效率，更容易使用，功能更强大，具有更好的可移植性，更节省投资。在未来的技术发展过程中，Servlet有可能彻底取代CGI。 在传统的CGI中，每个请求都要启动一个新的进程，如果CGI程序本身的执行时间较短，启动进程所需要的开销很可能反而超过实际执行时间。而在Servlet中，每个请求由一个轻量级的Java线程处理(而不是重量级的操作系统进程)。 在传统CGI中，如果有N个并发的对同一CGI程序的请求，则该CGI程序的代码在内存中重复装载了N次；而对于Servlet，处理请求的是N个线程，只需要一份Servlet类代码。在性能优化方面，Servlet也比CGI有着更多的选择。 JSP 使用Servlet可以实现java程序和web服务器的交互，但是Servlet和CGI一样存在一个问题，Servlet程序在返回结果的时候必须连带HTML标签一起返回，所以负责格式显示的HTML代码和负责数据产生的Java代码混在一起了，程序员和页面编辑人员无法各自实现自己的工作，就要求java程序员必须要了解HTML显示效果。所以就有了JSP技术产生，有了JSP一个web请求的执行流程如下。 其实JSP也是java的一个类库而已，要想写出的JSP代码能够被识别，这时候就需要一个JSP容器负责来解析。JSP代码最终会被编译成Servlet，然后再由Servlet处理请求。一个JSP页面包含了JSP规范的java代码（元素）和HTML标签（数据模板），元素则交给JSP容器处理，模板数据直接返回给客户端。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mariadb实现二进制安装]]></title>
    <url>%2F2019%2F01%2F13%2Fmariadb%E5%AE%9E%E7%8E%B0%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[mariadb实现二进制安装 通用二进制格式安装过程范例：二进制格式安装的mysql版本为：mysql-10.2 第一步：将二进制编译完的文件传进linux中，解压缩、创建软连接 [root@centos7 ~]# ls mariadb-10.2.19-linux-x86_64.tar.gz [root@centos7 ~]# tar xfv mariadb-10.2.19-linux-x86_64.tar.gz -C /usr/local [root@centos7 ~]# ls /usr/local bin games lib libexec sbin src etc include lib64 mariadb-10.2.19-linux-x86_64 share 创建软连接，方便下次升级（链接程序所在路径，因为源码编译时文档中指定程序路径放置在/usr/local/mysql） [root@centos7 ~]# ln -s /usr/local/mariadb-10.2.19-linux-x86_64/ /usr/local/mysql [root@centos7 ~]# ll /usr/local/mysql lrwxrwxrwx. 1 root root 40 Nov 27 17:01 /usr/local/mysql -&gt; /usr/local/mariadb-10.2.19-linux-x86_64/ 第二步：修改程序目录的属性 [root@centos7 ~]# chown -R root:root /usr/local/mysql/ [root@centos7 ~]# ll /usr/local/mysql/ total 180 drwxrwxr-x. 2 root root 4096 Sep 23 10:13 bin 程序 -rw-r--r--. 1 root root 17987 Nov 13 00:32 COPYING -rw-r--r--. 1 root root 86263 Nov 13 00:32 COPYING.thirdparty -rw-r--r--. 1 root root 2354 Nov 13 00:32 CREDITS drwxrwxr-x. 3 root root 18 Nov 13 07:37 data -rw-r--r--. 1 root root 8245 Nov 13 00:32 EXCEPTIONS-CLIENT drwxrwxr-x. 3 root root 19 Nov 13 07:37 include -rw-r--r--. 1 root root 8694 Nov 13 00:32 INSTALL-BINARY drwxrwxr-x. 5 root root 4096 Sep 23 10:14 lib drwxrwxr-x. 4 root root 30 Nov 13 07:37 man drwxrwxr-x. 11 root root 4096 Nov 13 07:37 mysql-test -rw-r--r--. 1 root root 2469 Nov 13 00:32 README.md -rw-r--r--. 1 root root 19510 Nov 13 00:32 README-wsrep drwxrwxr-x. 2 root root 30 Nov 13 07:37 scripts drwxrwxr-x. 32 root root 4096 Nov 13 07:37 share drwxrwxr-x. 4 root root 4096 Nov 13 07:37 sql-bench drwxrwxr-x. 3 root root 275 Nov 13 07:37 support-files 第三步：创建程序用户 [root@centos7 ~]# useradd -r -s /sbin/nologin -d /data/mysql -c "mariadb user" mysql [root@centos7 ~]# getent passwd mysql mysql:x:989:983:mariadb user:/data/mysql:/sbin/nologin 第四步：创建数据库目录：存放数据库的数据 [root@centos7 ~]# ls -ld /data/mysql ls: cannot access /data/mysql: No such file or directory [root@centos7 ~]# mkdir /data/mysql [root@centos7 ~]# install -d /data/mysql -o root -g mysql [root@centos7 ~]# ls -ld /data/mysql drwxr-xr-x. 2 root mysql 6 Nov 27 17:15 /data/mysql 第四步：生成系统数据库 [root@centos7 ~]# ls /usr/local/mysql/ bin include README-wsrep COPYING INSTALL-BINARY scripts COPYING.thirdparty lib share CREDITS man sql-bench data mysql-test support-files EXCEPTIONS-CLIENT README.md 安装数据库的脚本：生成系统数据库 [root@centos7 ~]# ls /usr/local/mysql/scripts/ mysql_install_db [root@centos7 mysql]# pwd /usr/local/mysql [root@centos7 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql 确定是否生成了数据库 [root@centos7 mysql]# ls /data/mysql/ aria_log.00000001 ibdata1 mysql aria_log_control ib_logfile0 performance_schema ib_buffer_pool ib_logfile1 test 第五步：准备数据库的配置文件 [root@centos7 ~]# mkdir /etc/mysql [root@centos7 ~]# ls /usr/local/mysql/support-files/ binary-configure my-medium.cnf policy magic my-small.cnf wsrep.cnf my-huge.cnf mysqld_multi.server wsrep_notify my-innodb-heavy-4G.cnf mysql-log-rotate my-large.cnf mysql.server [root@centos7 ~]# cd /usr/local/mysql/support-files/ [root@centos7 support-files]# cp my-huge.cnf /etc/mysql/my.cnf 第六步：修改配置文件，根据自己定义的数据路径进行修改 [root@centos7 ~]# vim /etc/mysql/my.cnf [mysqld] datadir=/data/mysql port = 3306 socket = /tmp/mysql.sock 第七步：准备程序服务的启动脚本 [root@centos7 ~]# ls /usr/local/mysql/support-files/ mysql.server [root@centos7 ~]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/ 可以改名，方便启动 [root@centos7 ~]# cd /etc/init.d/ [root@centos7 init.d]# ls functions mysql.server netconsole network README [root@centos7 init.d]# mv mysql.server mysqld 第八步：准备启动 [root@centos7 ~]# chkconfig --add mysqld [root@centos7 ~]# chkconfig --list mysqld 0:off 1:off 2:on 3:on 4:on 5:on 6:off netconsole 0:off 1:off 2:off 3:off 4:off 5:off 6:off network 0:off 1:off 2:on 3:on 4:on 5:on 6:off 启动 [root@centos7 ~]# service mysqld restart Restarting mysqld (via systemctl): [ OK ] 准备PATH变量 [root@centos7 ~]# echo 'PATH=/usr/local/mysql/bin:$PATH' &gt; /etc/profile.d/mysql.sh [root@centos7 ~]# source /etc/profile.d/mysql.sh 连接测试 [root@centos7 ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \g. Your MariaDB connection id is 10 Server version: 10.2.19-MariaDB-log MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\h' for help. Type '\c' to clear the current input statement. MariaDB [(none)]&gt; exit 查看数据库路径 方法1 MariaDB [(none)]&gt; show variables like 'datadir' -&gt; ; +---------------+--------------+ | Variable_name | Value | +---------------+--------------+ | datadir | /data/mysql/ | +---------------+--------------+ 1 row in set (0.01 sec) 方法2 MariaDB [(none)]&gt; select @@datadir -&gt; ; +--------------+ | @@datadir | +--------------+ | /data/mysql/ | +--------------+ 1 row in set (0.00 sec) 执行初始化安装脚本 [root@centos7 ~]# ls /usr/local/mysql/bin/ mysql_secure_installation [root@centos7 ~]# mysql_secure_installation]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mairadb实现源码安装]]></title>
    <url>%2F2019%2F01%2F13%2Fmairadb%E5%AE%9E%E7%8E%B0%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[mairadb实现源码安装 mairadb实现源码安装10.2.19123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112第一步：安装相关的依赖包[root@centos7 yum.repos.d]# yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel第二步：创建对应的账号 （数据库存放数据的路径）[root@centos7 yum.repos.d]# useradd -r -s /sbin/nologin -d /data/mysql/ mysql 第三步：创建数据对应的数据库路径[root@centos7 ~]# mkdir /data/mysql[root@centos7 ~]# chown mysql:mysql /data/mysql第四步：下载源码解压[root@centos7 ~]# lsmariadb-10.2.19.tar.gz[root@centos7 ~]# tar xvf mariadb-10.2.19.tar.gz [root@centos7 ~]# lsmariadb-10.2.19 mariadb-10.2.19.tar.gz[root@centos7 ~]# du -sh mariadb-10.2.19506M mariadb-10.2.19第五步：cmack编译[root@centos7 ~]# cd mariadb-10.2.19/[root@centos7 mariadb-10.2.19]# cmake . \-DCMAKE_INSTALL_PREFIX=/app/mysql \-DMYSQL_DATADIR=/data/mysql/ \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITHOUT_MROONGA_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DENABLED_LOCAL_INFILE=1 \-DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci 多线程编译[root@centos7 ~]# make -j 4 &amp;&amp; make install[root@centos7 mariadb-10.2.19]# ls /app/mysql/bin EXCEPTIONS-CLIENT README.mdCOPYING include README-wsrepCOPYING.thirdparty INSTALL-BINARY scriptsCREDITS lib sharedata man sql-benchdocs mysql-test support-files第五步：生成数据库文件[root@centos7 mysql]# scripts/mysql_install_db --user=mysql --datadir=/data/mysql[root@centos7 mysql]# ls -l /data/mysql/total 110620-rw-rw----. 1 mysql mysql 16384 Nov 27 21:02 aria_log.00000001-rw-rw----. 1 mysql mysql 52 Nov 27 21:02 aria_log_control-rw-rw----. 1 mysql mysql 938 Nov 27 21:02 ib_buffer_pool-rw-rw----. 1 mysql mysql 12582912 Nov 27 21:02 ibdata1-rw-rw----. 1 mysql mysql 50331648 Nov 27 21:02 ib_logfile0-rw-rw----. 1 mysql mysql 50331648 Nov 27 21:02 ib_logfile1drwx------. 2 mysql root 4096 Nov 27 21:02 mysqldrwx------. 2 mysql mysql 20 Nov 27 21:02 performance_schemadrwx------. 2 mysql root 6 Nov 27 21:02 test第六步：设置PATH变量[root@centos7 mysql]# echo 'PATH=/app/mysql/bin:$PATH' &gt; /etc/profile.d/mysql.sh[root@centos7 mysql]# source /etc/profile.d/mysql.sh 第七步：拷贝模板配置文件[root@centos7 mysql]# pwd/app/mysql[root@centos7 mysql]# cp support-files/my-huge.cnf /etc/my.cnfcp: overwrite ‘/etc/my.cnf’? y第八步：设置启动脚本[root@centos7 ~]# cd /app/mysql/support-files/[root@centos7 support-files]# lsbinary-configure my-medium.cnf policymagic my-small.cnf wsrep.cnfmy-huge.cnf mysqld_multi.server wsrep_notifymy-innodb-heavy-4G.cnf mysql-log-rotatemy-large.cnf mysql.server[root@centos7 support-files]# cp mysql.server /etc/init.d/mysqld[root@centos7 ~]# chkconfig --add mysqld[root@centos7 ~]# chkconfig --listNote: This output shows SysV services only and does not include native systemd services. SysV configuration data might be overridden by native systemd configuration. If you want to list systemd services use 'systemctl list-unit-files'. To see services enabled on particular target use 'systemctl list-dependencies [target]'.mysqld 0:off 1:off 2:on 3:on 4:on 5:on 6:off启动[root@centos7 ~]# service mysqld restartRestarting mysqld (via systemctl): [ OK ][root@centos7 ~]# ss -ntlLISTEN 0 80 :::3306 :::* 安全脚本mysql_secure_installation]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos6安装mysql]]></title>
    <url>%2F2019%2F01%2F13%2Fcentos6%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[centos6安装mysql mysql安装 centos6光盘自带的版本12345678910111213141516171819202122[root@centos6 ~]# yum info mysqlLoaded plugins: fastestmirror, refresh-packagekit, securityLoading mirror speeds from cached hostfile * base: mirror.bit.edu.cn * extras: ftp.sjtu.edu.cn * updates: mirrors.huaweicloud.comAvailable PackagesName : mysqlArch : x86_64Version : 5.1.73Release : 8.el6_8Size : 895 kRepo : baseSummary : MySQL client programs and shared librariesURL : http://www.mysql.comLicense : GPLv2 with exceptionsDescription : MySQL is a multi-user, multi-threaded SQL database : server. MySQL is a client/server implementation : consisting of a server daemon (mysqld) and many different : client programs and libraries. The base package contains : the standard MySQL client programs and generic MySQL : files. rpm 方式安装Mariadb：mysql端口默认为tcp 3306123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113安装：[root@centos6 ~]# yum install mysql-server -y查看安装包主要的文件列表：[root@centos6 ~]# rpm -ql mysql-server/etc/rc.d/init.d/mysqld 服务启动脚本/usr/libexec/mysqld 服务器主程序/var/lib/mysql 存放数据库的数据的路径/var/log/mysqld.log 日志文件/etc/my.cnf 服务的配置文件[root@centos6 ~]# rpm -qf /etc/my.cnf （可以作为mysql数据库的服务器的配置文件，也可以作为客户端的配置文件）mysql-libs-5.1.73-8.el6_8.x86_64启动服务：[root@centos6 ~]# service mysqld starInstalling MySQL system tables...OKFilling help tables...OKTo start mysqld at boot time you have to copysupport-files/mysql.server to the right place for your systePLEASE REMEMBERTO SET A PASSWORD FOR THE MySQL root USER !To do so, start the server, then issue the following command/usr/bin/mysqladmin -u root password 'new-password'/usr/bin/mysqladmin -u root -h centos6.com password 'new-pasd'Alternatively you can run:/usr/bin/mysql_secure_installation 初始化服务脚本，可以设置root口令，也可以更安全的数据库which will also give you the option of removing the testdatabases and anonymous user created by default. This isstrongly recommended for production servers.See the manual for more instructions.You can start the MySQL daemon with:cd /usr ; /usr/bin/mysqld_safe &amp;You can test the MySQL daemon with mysql-test-run.plcd /usr/mysql-test ; perl mysql-test-run.plPlease report any problems with the /usr/bin/mysqlbug script [ ok ]Starting mysqld: [ ok ] 启动程序后，生成数据库数据相关的文件，未启动之前时空的： [root@centos6 ~]# ls /var/lib/mysql/ ibdata1 ib_logfile0 ib_logfile1 mysql mysql.sock（数据库的套接字） test 自己连接本机的mysql服务端，可以走套接字（数据库服务的用户与linux用户无关）使用客户端工具连接数据库[root@centos6 ~]# which mysql/usr/bin/mysql[root@centos6 ~]# rpm -qf /usr/bin/mysqlmysql-5.1.73-8.el6_8.x86_64查看进程：[root@centos6 ~]# ps auxroot 4616 0.0 0.0 108228 1468 pts/1 S 21:05 0:00 /bin/sh /usr/bin/mysqld_safe --datadir=/var/lib/mysql --socket=/var/lib/mysql/mysql.sock --（数据库的主程序）mysql 4718 0.0 1.6 367520 30848 pts/1 Sl 21:05 0:00 /usr/libexec/mysqld --basedir=/usr --datadir=/var/lib/mysql --user=mysql --log-error=/var/lmysql数据库是单进程多线程的数据库程序：[root@centos6 ~]# pstree -p├─mysqld_safe(4616)───mysqld(4718)─┬─&#123;mysqld&#125;(4720) │ ├─&#123;mysqld&#125;(4721)线程 │ ├─&#123;mysqld&#125;(4722) │ ├─&#123;mysqld&#125;(4723) │ ├─&#123;mysqld&#125;(4724) │ ├─&#123;mysqld&#125;(4725) │ ├─&#123;mysqld&#125;(4726) │ ├─&#123;mysqld&#125;(4727) │ └─&#123;mysqld&#125;(4728)查看数据库安装脚本[root@centos6 ~]# rpm -q --scripts mysql-serverpreinstall scriptlet (using /bin/sh):/usr/sbin/groupadd -g 27 -o -r mysql &gt;/dev/null 2&gt;&amp;1 || :/usr/sbin/useradd -M -N -g mysql -o -r -d /var/lib/mysql -s /bin/bash \ -c "MySQL Server" -u 27 mysql &gt;/dev/null 2&gt;&amp;1 || :postinstall scriptlet (using /bin/sh):if [ $1 = 1 ]; then /sbin/chkconfig --add mysqldfi/bin/chmod 0755 /var/lib/mysql/bin/touch /var/log/mysqld.logpreuninstall scriptlet (using /bin/sh):if [ $1 = 0 ]; then /sbin/service mysqld stop &gt;/dev/null 2&gt;&amp;1 /sbin/chkconfig --del mysqldfipostuninstall scriptlet (using /bin/sh):if [ $1 -ge 1 ]; then /sbin/service mysqld condrestart &gt;/dev/null 2&gt;&amp;1 || :fi连接数据库：（本地连接数据库是由本机的sock套接字连接） 使用mysql客户端工具连接： mysql -u 数据库用户 -p （提示输入口令）-s 指定套接字路径 （默认为/var/lib/mysql/mysql.sock）[root@centos6 ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' 帮助for help. Type '\c'清屏 to clear the current input statement.mysql&gt; 范例：下面为mysql数据库的客户端命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869下面为mysql数据库的客户端命令mysql&gt; help List of all MySQL commands:Note that all text commands must be first on line and end with ';'? (\?) Synonym for `help'. clear (\c) --清除当前输入的语句connect (\r) --重新连接，通常用于被剔除或异常断开后重新连接，SQL*plus下也有这样一个connect命令delimiter (\d) --设置命令终止符，缺省为；，比如我们可以设定为/来表示语句结束 edit (\e) --编辑缓冲区的上一条SQL语句到文件，缺省调用vi，文件会放在/tmp路径下ego (\G) --控制结果显示为垂直显示exit (\q) --退出mysqlgo (\g) --发送命令到mysql服务help (\h) Display this help.nopager (\n) --关闭页设置，打印到标准输出 notee (\t) --关闭输出到文件pager (\P) --设置pager方式，可以设置为调用more,less等等，主要是用于分页显示print (\p) Print current command. prompt (\R) --改变mysql的提示符 quit (\q) Quit mysql. rehash (\#) --自动补齐相关对象名字 source (\.) --执行脚本文件status (\s) --获得状态信息system (\!) --执行系统命令 tee (\T) --操作结果输出到文件 use (\u) --切换数据库charset (\C) --设置字符集warnings (\W) --打印警告信息nowarning (\w) Don't show warnings after every statement.--上面的所有命令，扩号内的为快捷操作，即只需要输入“\”+ 字母即可执行查看mysql数据库的存储引擎：（服务器端命令）mysql&gt; show engines;+------------+---------+------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+------------+---------+------------------------------------------------------------+--------------+------+------------+| MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || MyISAM | DEFAULT | Default engine as of MySQL 3.23 with great performance | NO | NO | NO || InnoDB | YES | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO |+------------+---------+------------------------------------------------------------+--------------+------+------------+5 rows in set (0.00 sec)从服务器中得到相关的状态信息mysql&gt; status--------------mysql Ver 14.14 Distrib 5.1.73, for redhat-linux-gnu (x86_64) using readline 5.1Connection id: 2Current database: Current user: root@localhost（当前连接身份）SSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server version: 5.1.73 Source distributionProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1 （字符集）Db characterset: latin1Client characterset: latin1Conn. characterset: latin1UNIX socket: /var/lib/mysql/mysql.sock（套接字文件路径）Uptime: 1 hour 1 min 14 secThreads: 1（当前线程） Questions: 8 Slow queries: 0 Opens: 15 Flush tables: 1 Open tables: 8 Queries per second avg: 0.2--------------调用linux命令mysql&gt; system hostnamecentos6.com 范例：mysql中的提示符1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162提示符：修改方式建议为了方便我们在平时的使用，有效的给我们提示信息。 建议参考Linux系统的提示符方式命名，即：用户名@主机名+当前所在位置。 在MySQL中可以通过参数来获取提示符信息，下面列表中列出了常用的四个信息，方便我们等下修改MySQL提示符。参数 描述\D 完整的日期\d 当前数据库\h 服务器名称\u 当前用户mysql&gt; PROMPT \u@\h \d &gt; root@localhost (none) &gt;CREATE DATABASE testdb;root@localhost (none) &gt;USE testdb;root@localhost testdb &gt;修改mysql数据库的提示符mysql&gt; prompt mysql--&gt;PROMPT set to 'mysql--&gt;'mysql--&gt;命令行进入mysql顺便修改提示符[root@centos6 ~]# mysql --prompt="\u@\D"Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 3Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reservedOracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.root@Tue Nov 27 22:53:50 2018修改mysql提示符，永久保存生效(centos6的服务端和客户端的配置文件在同一个文件中) 编辑数据库的配置文件，写入客户端配置[root@centos6 ~]# vim /etc/my.cnf 服务端配置[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockuser=mysql# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0服务端配置[mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid客户端配置，写入提示符信息[mysql]prompt='\u@\D-&gt;'保存，进入数据库，查看提示符，是否发生变化[root@centos6 ~]# mysqlWelcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 4Server version: 5.1.73 Source distributionCopyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.root@Tue Nov 27 22:58:29 2018-&gt;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7安装mysql]]></title>
    <url>%2F2019%2F01%2F13%2Fcentos7%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[centos7安装mysql mysql安装 centos7光盘自带的版本123456789101112131415161718192021222324[root@centos7 ~]# yum info mariadbLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfile * base: mirrors.tuna.tsinghua.edu.cn * extras: mirror.bit.edu.cn * updates: mirror.bit.edu.cnAvailable PackagesName : mariadbArch : x86_64Epoch : 1Version : 5.5.60Release : 1.el7_5Size : 8.9 MRepo : updates/7/x86_64Summary : A community developed branch of MySQLURL : http://mariadb.orgLicense : GPLv2 with exceptions and LGPLv2 and BSDDescription : MariaDB is a community developed branch of MySQL. : MariaDB is a multi-user, multi-threaded SQL database : server. It is a client/server implementation consisting : of a server daemon (mysqld) and many different client : programs and libraries. The base package contains the : standard MariaDB/MySQL client programs and generic MySQL : files. rpm 方式安装Mariadb：mysql端口默认为tcp 3306123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172安装：[root@centos7 ~]# yum install mariadb-server -y查看安装包主要的文件列表：[root@centos7 ~]# rpm -ql mariadb-server/etc/my.cnf.d/server.cnf 服务器端配置文件/usr/libexec/mysqld 服务器主程序/var/lib/mysql 存放数据库数据的路径/var/log/mariadb/mariadb.log 日志/usr/lib/systemd/system/mariadb.service 服务启动脚本启动程序： 启动前查看数据库数据目录是为空 [root@centos7 ~]# ls /var/lib/mysql/ [root@centos7 ~]# [root@centos7 ~]# systemctl restart mariadbroot@centos7 ~]# ls /var/lib/mysql/aria_log.00000001 ib_logfile0 mysql.sockaria_log_control ib_logfile1 performance_schemaibdata1 mysql test连接数据库：[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; 查看搜索引擎：MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+10 rows in set (0.00 sec)从服务器中得到相关的状态信息MariaDB [(none)]&gt; \s--------------mysql Ver 15.1 Distrib 5.5.60-MariaDB, for Linux (x86_64) using readline 5.1Connection id: 2Current database: Current user: root@localhostSSL: Not in useCurrent pager: stdoutUsing outfile: ''Using delimiter: ;Server: MariaDBServer version: 5.5.60-MariaDB MariaDB ServerProtocol version: 10Connection: Localhost via UNIX socketServer characterset: latin1Db characterset: latin1Client characterset: utf8Conn. characterset: utf8UNIX socket: /var/lib/mysql/mysql.sockUptime: 9 min 44 secThreads: 1 Questions: 6 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 26 Queries per second avg: 0.010-------------- 范例：centos7修改提示符：（centos7mysql的配置文件和客户端是分开的）1234567891011121314151617[root@centos7 ~]# cd /etc/my.cnf.d/[root@centos7 my.cnf.d]# lsclient.cnf mysql-clients.cnf server.cnf编辑客户端配置文件修改提示符[root@centos7 my.cnf.d]# vim mysql-clients.cnf [mysql]prompt='\u@\D-&gt;'查看是否修改成功[root@centos7 my.cnf.d]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 3Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and otherType 'help;' or '\h' for help. Type '\c' to clear the current inputatement.root@Tue Nov 27 15:04:34 2018-&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546MariaDB [(none)]&gt; none:表示当前正在处于哪个数据库里面查看数据库的数据路径目录形式的代表数据库，也是系统自带的数据库，所以可以理解为数据库存放数据 分为系统自身用的数据、用户创建生产的数据库[root@centos7 ~]# ls /var/lib/mysql/aria_log.00000001 ib_logfile0 mysql.sockaria_log_control ib_logfile1 performance_schemaibdata1 mysql test查看当前有多少数据库即表MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)查看当前数据库的版本信息（数据库中带有括号的命令，表现为系统自带的函数）MariaDB [(none)]&gt; select version();+----------------+| version() |+----------------+| 5.5.60-MariaDB |+----------------+1 row in set (0.00 sec)查看当前的用户信息MariaDB [(none)]&gt; select user();+----------------+| user() |+----------------+| root@localhost |+----------------+1 row in set (0.00 sec)查看用户当前所在哪个数据库中MariaDB [(none)]&gt; select database();+------------+| database() |+------------+| NULL |+------------+1 row in set (0.00 sec) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179使用use 客户端工具切换到指定的数据库，作为当前使用的数据库MariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; 查看当前使用的数据库中的所有表列表MariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)命令行指定显示指定数据库中的表列表(意义同上命令)MariaDB [mysql]&gt; show tables from mysql;....上面的数据库中的表实际表现为[root@centos7 ~]# ls /var/lib/mysql/mysql查看服务端命令的帮助help + 服务端命令``` `范例：安装完数据库，linux上的任何用户都可以使用mysql的root用户登陆，也可以使用任何一个用户连接登陆````bash查看mysql存放的用户信息[root@centos7 ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 7Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)MariaDB [mysql]&gt; select user,host,password from user;+------+-------------+----------+| user | host | password |+------+-------------+----------+| root | localhost | || root | centos7.com | || root | 127.0.0.1 | || root | ::1 | || | localhost | || | centos7.com | |+------+-------------+----------+6 rows in set (0.00 sec)安全加固，执行初始化命令[root@centos7 ~]# mysql_secure_installation Enter current password for root (enter for none): （输入当前数据库中root用户的口令，若无口令，直接回车）Set root password? [Y/n] （是否设置root的口令）yNew password: 口令Re-enter new password: 确定口令Password updated successfully!Reloading privilege tables.. ... Success!Remove anonymous users? [Y/n] （是否删除匿名用户）yDisallow root login remotely? [Y/n] (是否禁用远程登陆)yRemove test database and access to it? [Y/n] (是否删除测试数据库)yReload privilege tables now? [Y/n] (是否重新加载特权表)yThanks for using MariaDB!再次连接mysql数据库[root@centos7 ~]# mysql -u root -pMariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; show tables;+---------------------------+| Tables_in_mysql |+---------------------------+| columns_priv || db || event || func || general_log || help_category || help_keyword || help_relation || help_topic || host || ndb_binlog_index || plugin || proc || procs_priv || proxies_priv || servers || slow_log || tables_priv || time_zone || time_zone_leap_second || time_zone_name || time_zone_transition || time_zone_transition_type || user |+---------------------------+24 rows in set (0.00 sec)MariaDB [mysql]&gt; select user,host,password from user;+------+-----------+-------------------------------------------+| user | host | password |+------+-----------+-------------------------------------------+| root | localhost | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | 127.0.0.1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 || root | ::1 | *0E04F27C8B21547FD069D6E8519AE49B7ECE8E94 |+------+-----------+-------------------------------------------+3 rows in set (0.00 sec)目前仅可以本机连接，使用centos6连接测试[root@centos6 ~]# mysql -u root -p centos -h 172.18.135.88Enter password: 连接不上 范例：查看mysql账号数据库是否活跃123[root@centos7 ~]# mysqladmin -u root -p pingEnter password: mysqld is alive 范例：停止此用户的数据库123456789101112131415[root@centos7 ~]# mysqladmin -u root -p shutdownEnter password: 测试：连接不上去了[root@centos7 ~]# mysql -u root -pEnter password: ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)启动服务[root@centos7 ~]# systemctl restart mariadb查看连接信息[root@centos7 ~]# mysqladmin statusUptime: 23 Threads: 1 Questions: 3 Slow queries: 0 Opens: 0 Flush tables: 2 Open tables: 18 Queries per second avg: 0.130`]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql安装和基本操作]]></title>
    <url>%2F2019%2F01%2F13%2Fmysql%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[mysql安装和基本操作 MYSQL的特性插件式存储引擎：也称为“表类型”，存储管理器有多种实现版本，功能和特 性可能均略有差别；用户可根据需要灵活选择,Mysql5.5.5开始&amp;innoDB引擎是 MYSQL默认引擎&ensp;&ensp;MyISAM ==&gt; Aria&ensp;&ensp;InnoDB ==&gt; XtraDB单进程，多线程诸多扩展和新特性提供了较多测试组件开源 安装MYSQLMariadb安装方式：1、源代码：编译安装2、二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用3、程序包管理器管理的程序包CentOS 安装光盘项目官方： https://downloads.mariadb.org/mariadb/repositories/国内镜像： https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadbx.y.z/yum/centos/7/x86_64/ RPM包安装MySQLRPM包安装&ensp;&ensp;CentOS 7：安装光盘直接提供&ensp;&ensp;&ensp;&ensp;mariadb-server 服务器包&ensp;&ensp;&ensp;&ensp;mariadb 客户端工具包&ensp;&ensp;CentOS 6提高安全性&ensp;&ensp;mysql_secure_installation&ensp;&ensp;&ensp;&ensp;设置数据库管理员root口令&ensp;&ensp;&ensp;&ensp;禁止root远程登录&ensp;&ensp;&ensp;&ensp;删除anonymous用户帐号&ensp;&ensp;&ensp;&ensp;删除test数据库 MariaDB程序客户端程序：&ensp;&ensp;mysql: 交互式的CLI工具&ensp;&ensp;mysqldump：备份工具，基于mysql协议向mysqld发起查询请求，并将查得的所有数据转换成insert等写操作语句保存文本文件中&ensp;&ensp;mysqladmin：基于mysql协议管理mysqld&ensp;&ensp;mysqlimport：数据导入工具MyISAM存储引擎的管理工具：&ensp;&ensp;myisamchk：检查MyISAM库&ensp;&ensp;myisampack：打包MyISAM表，只读服务器端程序&ensp;&ensp;mysqld_safe&ensp;&ensp;mysqld&ensp;&ensp;mysqld_multi 多实例（一个程序在系统上运行多次，多个进程，缺点仅能实现单一版本的多实例） ，示例：mysqld_multi –example 用户账号mysql用户账号由两部分组成：&ensp;&ensp;‘USERNAME‘@’HOST‘说明：&ensp;&ensp;HOST限制此用户可通过哪些远程主机连接mysql服务器&ensp;&ensp;支持使用通配符：&ensp;&ensp;&ensp;&ensp;% 匹配任意长度的任意字符&ensp;&ensp;&ensp;&ensp;172.16.0.0/255.255.0.0 或 172.16.%.%&ensp;&ensp;&ensp;&ensp;_ 匹配任意单个字符 Mysql 客户端mysql使用模式：交互式模式：&ensp;&ensp;可运行命令有两类：&ensp;&ensp;客户端命令：&ensp;&ensp;&ensp;&ensp;\h, help&ensp;&ensp;&ensp;&ensp;\u，use&ensp;&ensp;&ensp;&ensp;\s，status&ensp;&ensp;&ensp;&ensp;!，system&ensp;&ensp;服务器端命令：&ensp;&ensp;&ensp;&ensp;SQL语句， 需要语句结束符；脚本模式：&ensp;&ensp;mysql –uUSERNAME -pPASSWORD &lt; /path/somefile.sql&ensp;&ensp;mysql&gt; source /path/from/somefile.sql Mysql客户端mysql客户端可用选项：-A, –no-auto-rehash 禁止补全-u, –user= 用户名,默认为root-h, –host= 服务器主机,默认为localhost-p, –passowrd= 用户密码,建议使用-p,默认为空密码-P, –port= 服务器端口-S, –socket= 指定连接socket文件路径-D, –database= 指定默认数据库-C, –compress 启用压缩-e “SQL“ 执行SQL命令-V, –version 显示版本-v –verbose 显示详细信息–print-defaults 获取程序默认使用的配置 socket地址服务器监听的两种socket地址：&ensp;&ensp;ip socket: 监听在tcp的3306端口，支持远程通信&ensp;&ensp;unix sock: 监听在sock文件上，仅支持本机通信&ensp;&ensp;&ensp;&ensp;如：/var/lib/mysql/mysql.sock)说明：host为localhost,127.0.0.1时自动使用unix sock 执行命令运行mysql命令：默认空密码登录&ensp;&ensp;mysql&gt;use mysql&ensp;&ensp;mysql&gt;select user();查看当前用户&ensp;&ensp;mysql&gt;SELECT User,Host,Password FROM user;登录系统：mysql –uroot –p客户端命令：本地执行&ensp;&ensp;mysql&gt; help&ensp;&ensp;每个命令都完整形式和简写格式&ensp;&ensp;mysql&gt; status 或 \s服务端命令：通过mysql协议发往服务器执行并取回结果 每个命令末尾都必须使用命令结束符号，默认为分号&ensp;&ensp;示例：SELECT VERSION(); 服务器端配置服务器端(mysqld)：工作特性有多种配置方式1、命令行选项：2、配置文件：类ini格式集中式的配置，能够为mysql的各应用程序提供配置信息&ensp;&ensp;[mysqld]&ensp;&ensp;[mysqld_safe]&ensp;&ensp;[mysqld_multi]&ensp;&ensp;[mysql]&ensp;&ensp;[mysqldump]&ensp;&ensp;[server]&ensp;&ensp;[client]格式：parameter = value说明：_和- 相同&ensp;&ensp;1，ON，TRUE意义相同， 0，OFF，FALSE意义相同 配置文件配置文件：后面覆盖前面的配置文件，顺序如下：下面的优先级高/etc/my.cnf &ensp;&ensp; Global选项/etc/mysql/my.cnf &ensp;&ensp; Global选项SYSCONFDIR/my.cnf &ensp;&ensp; Global选项$MYSQL_HOME/my.cnf &ensp;&ensp; Server-specific 选项–defaults-extra-file= path~/.my.cnf &ensp;&ensp; User-specific 选项 MairaDB配置侦听3306/tcp端口可以在绑定有一个或全部接口IP上vim /etc/my.cnf[mysqld]skip-networking=1关闭网络连接，只侦听本地客户端， 所有和服务器的交互都通过一个socket实 现，socket的配置存放在/var/lib/mysql/mysql.sock） 可在/etc/my.cnf修改 通用二进制格式安装过程二进制格式安装过程(1) 准备用户&ensp;&ensp;groupadd -r -g 306 mysql&ensp;&ensp;useradd -r -g 306 -u 306 –d /data/mysql mysql(2) 准备数据目录，建议使用逻辑卷&ensp;&ensp;mkdir /data/mysql&ensp;&ensp;chown mysql:mysql /data/mysql(3) 准备二进制程序&ensp;&ensp;tar xf mariadb-VERSION-linux-x86_64.tar.gz -C /usr/local&ensp;&ensp;cd /usr/local&ensp;&ensp;ln -sv mariadb-VERSION mysql&ensp;&ensp;chown -R root:mysql /usr/local/mysql/(4) 准备配置文件&ensp;&ensp;mkdir /etc/mysql/&ensp;&ensp;cp support-files/my-large.cnf /etc/mysql/my.cnf&ensp;&ensp;[mysqld]中添加三个选项：&ensp;&ensp;datadir = /data/mysql&ensp;&ensp;innodb_file_per_table = on&ensp;&ensp;skip_name_resolve = on 禁止主机名解析，建议使用(5)创建数据库文件&ensp;&ensp;cd /usr/local/mysql/&ensp;&ensp;./scripts/mysql_install_db –datadir=/data/mysql –user=mysql(6)准备服务脚本，并启动服务&ensp;&ensp;cp ./support-files/mysql.server /etc/rc.d/init.d/mysqld&ensp;&ensp;chkconfig –add mysqldservice mysqld start(7)PATH路径&ensp;&ensp;echo ‘PATH=/user/local/mysql/bin:$PATH’ &gt; /etc/profile.d/mysql(8)安全初始化 &ensp;&ensp;/user/local/mysql/bin/mysql_secure_installation 源码编译安装mariadb安装包&ensp;&ensp;yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost-devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl-devel libevent-devel libaio-devel做准备用户和数据目录&ensp;&ensp;useradd –r –s /sbin/nologin –d /data/mysql/ mysql&ensp;&ensp;mkdir /data/mysql&ensp;&ensp;chown mysql.mysql /data/mysql&ensp;&ensp;tar xvf mariadb-10.2.18.tar.gzcmake 编译安装&ensp;&ensp;cmake的重要特性之一是其独立于源码(out-of-source)的编译功能，即编译工作可以在 另一个指定的目录中而非源码目录中进行，这可以保证源码目录不受任何一次编译的影 响，因此在同一个源码树上可以进行多次不同的编译，如针对于不同平台编译 编译选项:https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html cd mariadb-10.2.18/cmake . \-DCMAKE_INSTALL_PREFIX=/app/mysql \-DMYSQL_DATADIR=/data/mysql/ \-DSYSCONFDIR=/etc \-DMYSQL_USER=mysql \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_ARCHIVE_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITHOUT_MROONGA_STORAGE_ENGINE=1 \-DWITH_DEBUG=0 \-DWITH_READLINE=1 \-DWITH_SSL=system \-DWITH_ZLIB=system \-DWITH_LIBWRAP=0 \-DENABLED_LOCAL_INFILE=1 \-DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci make &amp;&amp; make install提示：如果出错，执行rm -f CMakeCache.txt 准备环境变量echo ‘PATH=/app/mysql/bin:$PATH’ &gt; /etc/profile.d/mysql.sh. /etc/profile.d/mysql.sh生成数据库文件cd /app/mysql/scripts/mysql_install_db –datadir=/data/mysql/ –user=mysql准备配置文件cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf准备启动脚本cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld启动服务chkconfig –add mysqld ;service mysqld start 关系型数据库的常见组件数据库：database表：table 行：row 列：column索引：index视图：view用户：user权限：privilege存储过程：procedure存储函数：function触发器：trigger事件调度器：event scheduler，任务计划 SQL语言的兴起与语法标准20世纪70年代，IBM开发出SQL，用于DB21981年，IBM推出SQL/DS数据库业内标准微软和Sybase的T-SQL，Oracle的PL/SQLSQL作为关系型数据库所使用的标准语言，最初是基于IBM的实现在1986年被 批准的。1987年，“国际标准化组织(ISO)”把ANSI(美国国家标准化组织) SQL作为国际标准。SQL：ANSI SQLSQL-1986, SQL-1989, SQL-1992, SQL-1999, SQL-2003 , SQL-2008 SQL-2011 SQL语言规范在数据库系统中，SQL语句不区分大小写(建议用大写)SQL语句可单行或多行书写，以“;”结尾关键词不能跨多行或简写用空格和缩进来提高语句的可读性子句通常位于独立行，便于编辑，提高可读性注释：&ensp;&ensp;SQL标准：&ensp;&ensp;/注释内容/ 多行注释&ensp;&ensp;– 注释内容 单行注释，注意有空格&ensp;&ensp;MySQL注释： # 数据库对象数据库的组件(对象)：&ensp;&ensp;数据库、表、索引、视图、用户、存储过程、函数、触发器、事件调度器等命名规则：&ensp;&ensp;必须以字母开头&ensp;&ensp;可包括数字和三个特殊字符（# _ $）&ensp;&ensp;不要使用MySQL的保留字&ensp;&ensp;同一database(Schema)下的对象不能同名 SQL语句分类SQL语句分类：DDL: Data Defination Language 数据定义语言&ensp;&ensp;CREATE，DROP，ALTERDML: Data Manipulation Language 数据操纵语言&ensp;&ensp;INSERT，DELETE，UPDATEDCL：Data Control Language 数据控制语言&ensp;&ensp;GRANT，REVOKE，COMMIT，ROLLBACKDQL：Data Query Language 数据查询语言&ensp;&ensp;SELECT SQL语句构成SQL语句构成：&ensp;&ensp;Keyword组成clause&ensp;&ensp;多条clause组成语句示例：SELECT * SELECT子句FROM products FROM子句WHERE price&gt;400 WHERE子句说明：一组SQL语句，由三个子句构成，SELECT,FROM和WHERE是关键字 数据库操作创建数据库：&ensp;&ensp;CREATE DATABASE|SCHEMA [IF NOT EXISTS] ‘DB_NAME’;&ensp;&ensp;CHARACTER SET ‘character set name’&ensp;&ensp;COLLATE ‘collate name’删除数据库&ensp;&ensp;DROP DATABASE|SCHEMA [IF EXISTS] ‘DB_NAME’;查看支持所有字符集：&ensp;&ensp;SHOW CHARACTER SET;查看支持所有排序规则：&ensp;&ensp;SHOW COLLATION;获取命令使用帮助：&ensp;&ensp;mysql&gt; HELP KEYWORD;查看数据库列表：&ensp;&ensp;mysql&gt; SHOW DATABASES;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库基础原理]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql数据库基础原理 MYSQL数据库 关系型数据库基础 安装MySQL 管理数据库和表 用户和权限管理 函数，存储过程和触发器 MySQL架构 存储引擎 服务器选项，系统和状态变量 优化查询和索引管理 锁和事务管理 日志管理 备份还原 MySQL集群 数据的时代 涉及的数据量大 数据不随程序的结束而消失 数据被多个应用程序共享 大数据 数据库的发展史 萌芽阶段：文件系统 使用磁盘文件来存储数据 初级阶段：第一代数据库 出现了网状模型、层次模型的数据库 中级阶段：第二代数据库 关系型数据库和结构化查询语言 高级阶段：新一代数据库 “关系-对象”型数据库 文件管理系统的缺点 编写应用程序不方便 数据冗余不可避免 应用程序依赖性 不支持对文件的并发访问 数据间联系弱 难以按用户视图表示数据 无安全控制功能 数据库管理系统的优点 相互关联的数据的集合 较少的数据冗余 程序与数据相互独立 保证数据的安全、可靠 最大限度地保证数据的正确性 数据可以并发使用并能同时保证一致性 数据库管理系统 数据库是数据的汇集，它以一定的组织形式存于存储介质上 DBMS是管理数据库的系统软件，它实现数据库系统的各种功能。是数据库系 统的核心 DBA：负责数据库的规划、设计、协调、维护和管理等工作 应用程序指以数据库为基础的应用程序 数据库管理系统的基本功能 数据定义 数据处理 数据安全 数据备份 网状数据库 最早出现的是网状DBMS（数据库管理系统），1964年通用电气公司的Charles Bachman成功地开发出世界上第一 个网状IDS，也是第一个数据库管理系统，IDS 具有数据模式和日志的特征，只能在GE主机运行 层次数据库 数据库系统的架构 单机架构 大型主机/终端架构 主从式架构（C/S） 分布式架构 关系型数据库 关系型数据库：使用的是sql语言，结构化的查询语言 ，内部机制特性ACID特性：保证数据库的安全稳定，影响性能NOSQL：redis:高性能，高并发 关系 ：关系就是二维表，其中：表中的行、列次序并不重要 行row：表中的每一行，又称为一条记录 列column：表中的每一列，称为属性，字段 主键（Primary key）：用于惟一确定一个记录的字段 域domain：属性的取值范围，如，性别只能是‘男’和‘女’两个值 一个服务器可以搭建多个DBMS（数据库管理系统） DBMS:多个数据库 ，推荐存放一个数据库，防止访问量过大 库：同一个项目的相关系数据，多个表 表：一个表多个字段和记录 关系数据库 RDBMS： MySQL: MySQL, MariaDB, Percona Server PostgreSQL: 简称为pgsql，EnterpriseDB &ensp;&ensp;Oracle MSSQL DB2 数据库排名： https://db-engines.com/en/ranking 实体-联系模型E-R 实体Entity：客观存在并可以相互区分的客观事物或抽象事件称为实体 在E-R图中用矩形框表示实体，把实体名写在框内 属性：实体所具有的特征或性质 联系：联系是数据之间的关联集合，是客观存在的应用语义链 实体内部的联系：指组成实体的各属性之间的联系。如职工实体中，职工号和 部门经理号之间有一种关联关系 实体之间的联系：指不同实体之间联系。例：学生选课实体和学生基本信息实 体之间 实体之间的联系用菱形框表示 联系类型 联系的类型 一对一联系(1:1) 一对多联系(1:n) 多对多联系(m:n) 数据的操作： 数据提取：在数据集合中提取感兴趣的内容。SELECT 数据更新：变更数据库中的数据。INSERT、DELETE、UPDATE 数据的约束条件 ：是一组完整性规则的集合 实体（行）完整性 Entity integrity （每一条记录都与众不同，可以使用主键来限定每条记录的与众不同） 域（列）完整性 Domain Integrity） 参考完整性 Referential Integrity 简易数据规划流程 第一阶段：收集数据，得到字段 收集必要且完整的数据项 转换成数据表的字段 第二阶段：把字段分类，归入表，建立表的关联 关联：表和表间的关系 分割数据表并建立关联的优点 节省空间 减少输入错误 方便数据修改 第三阶段： 规范化数据库 数据库的正规化分析 RDMBS设计范式基础概念 设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不 同的规范要求被称为不同范式，各种范式呈递次规范，越高的范式数据库冗余越小 目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式 （3NF）、巴德斯科范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称 完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上 进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般 数据库只需满足第三范式(3NF）即可 1NF：无重复的列，每一列都是不可分割的基本数据项，同一列中不能有多个 值，即实体中的某个属性不能有多个值或者不能有重复的属性。除去同类型的 字段，就是无重复的列 说明：第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF） 的数据库就不是关系数据库 2NF：属性完全依赖于主键，第二范式必须先满足第一范式，要求表中的每个 行必须可以被唯一地区分。通常为表加上一个列，以存储各个实例的唯一标识 PK，非PK的字段需要与整个PK有直接相关性 3NF：属性不依赖于其它非主属性，满足第三范式必须先满足第二范式。第三 范式要求一个数据库表中不包含已在其它表中已包含的非主关键字信息，非PK 的字段间不能有从属关系 SQL概念 SQL: Structure Query Language 结构化查询语言 SQL解释器： 数据存储协议：应用层协议，C/S S：server, 监听于套接字，接收并处理客户端的应用请求 C：Client 客户端程序接口 CLI 字符、命令行 GUI 图形化 应用编程接口 API ODBC：Open Database Connectivity 开放的数据库连接 JDBC：Java Data Base Connectivity java开放数据库的开发接口 常见数据库的端口 mysql：端口tcp 3306 oracle：端口tcp 1521 sqlserver:端口tcp 1433 约束约束：constraint，表中的数据要遵守的限制&ensp;&ensp;主键pk：一个或多个字段的组合，填入的数据必须能在本表中唯一标识本行； 必须提供数据，即NOT NULL，一个表只能有一个&ensp;&ensp;惟一键uk：一个或多个字段的组合，填入的数据必须能在本表中唯一标识本行； 允许为NULL，一个表可以存在多个&ensp;&ensp;外键fk：一个表中的某字段可填入的数据取决于另一个表的主键或唯一键已有 的数据 ,作用在依赖的表上，被依赖的表上，可以作用主键和唯一键&ensp;&ensp;检查：字段值在一定范围内 基本概念索引：将表中的一个或多个字段中的数据复制一份另存，并且按特定次序排序 存储 （例如：书签，标识）关系运算：&ensp;&ensp;选择：挑选出符合条件的行&ensp;&ensp;投影：挑选出需要的字段&ensp;&ensp;连接：表间字段的关联 数据模型数据抽象：&ensp;&ensp;物理层：数据存储格式，即RDBMS在磁盘上如何组织文件&ensp;&ensp;逻辑层：DBA角度，描述存储什么数据，以及数据间存在什么样的关系&ensp;&ensp;视图层：用户角度，描述DB中的部分数据关系模型的分类：&ensp;&ensp;关系模型&ensp;&ensp;基于对象的关系模型&ensp;&ensp;半结构化的关系模型：XML数据 ：扩展的标记语言 范例：基于xml语言存放的数据12下面目录内的文件都是基于xml语言存放数据的文件[root@centos6 gconf]# cd /etc/gconf/gconf.xml.defaults/ 范例：设置开机自动登陆12345[root@centos6 ~]# vim /etc/gdm/custom.conf # GDM configuration storage[daemon]AutomaticLoginEnable=tureAutomaticLongin=root MySQL历史1979年：TcX公司 Monty Widenius，Unireg1996年：发布MySQL1.0，Solaris版本，Linux版本1999年：MySQL AB公司，瑞典2003年：MySQL 5.0版本，提供视图、存储过程等功能2008年：Sun 收购2009年：Oracle收购sun2009年：Monty成立MariaDB MySQL和MariaDB官方网址：https://www.mysql.com/http://mariadb.org/官方文档https://dev.mysql.com/doc/https://mariadb.com/kb/en/版本演变：MySQL：5.1 –&gt; 5.5 –&gt; 5.6 –&gt; 5.7 –&gt;8.0MariaDB：5.5 –&gt;10.0–&gt; 10.1 –&gt; 10.2 –&gt; 10.3123yum info ..centos6默认光盘安装mysql 5.1.73centos7使用的是mariadb 5.5.56 MYSQL的特性插件式存储引擎：也称为“表类型”，存储管理器有多种实现版本，功能和特 性可能均略有差别；用户可根据需要灵活选择,Mysql5.5.5开始innoDB引擎是 MYSQL默认引擎&ensp;&ensp;MyISAM ==&gt; Aria&ensp;&ensp;InnoDB ==&gt; XtraDB单进程，多线程诸多扩展和新特性提供了较多测试组件开源 raw:裸文件系统：无文件系统：二进制方式存储]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>msql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx高并发内核优化]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[nginx作为负载均衡器高并发内核优化 实现nginx高并发linux内核优化 由于默认的linux内核的参数考虑的是最通用的场景，这明显不符合用于支持高并发访问的web服务器的定义，所以需要修改linux内核的参数，是的nginx可以拥有更高的性能，根据业务的特点来进行调整，当nginx作为静态web内容服务器、反向代理或者提供压缩服务器的服务器时，其内核的参数调整通常都是不同的，这里针对最通用的、使用nginx支持更多并发请求的tcp网络参数做简单的配置，修改/etc/sysctl.conf来更改内核的参数 file-max = 999999 表示单个进程较大可以打开的句柄数即文件描述符的数量 net.ipv4.tcp_rw_reuse = 1 参数设置为1，表示允许将TIME_WAIT状态的socket重新用于新的tcp连接，这对于服务器来说意义重大，因为总有大量TIME_WAIT状态的链接存在 net.ipv4.tcp_keepalive_time = 600 当keeplived启动时。tcp发送keeplived消息的频度；默认为2小时，将其设置为10分钟，可以更快的清理无效的链接 net.piv4.tcp_fin_timeout = 30 当服务器主动关闭连接时，socket保持在FIN_WAIT_2状态的较大时间 net.piv4.tcp_max_tw_buckets - 5000 这个参数表示操作系统允许TIME_WAIT套接字数量的较大值，如果超过这个数字，TIME_WAIT套接字将立刻被抢出并打印警告信息，默认为8000，过多的TIME_WAIT套接字会使web服务器变慢 net.ipv4.ip_local_portrange = 1024 65000 定义UDP和TCP连接的本地端口的取值范围 net.ipv4.tcp_rmem = 1024 87380 12582912 定义TCP接受缓存的最小值、默认值、最大值 net.ipv4.tcp_wmem = 1024 87380 12582912 定义了TCP发送缓存的最小值、默认值、较大值 net.core.netdev_max_backlog = 8096 当网卡接受数据包的速度大于内核处理速度时，会有一个列队保存这些数据包。这个参数表示该列队的较大值 net.core.rmem_default = 6291456 表示内核套接字接受缓存区默认的大小 net.core.wmem_default = 6291456 表示内核套接字发送缓存区默认的大小 net.core.rmem_max = 12582912 表示内核的套接字接受缓存区较大大小 net.core.wmem_max = 12582912 表示内核套接字发送缓存区较大大小 注意：以上四个参数，需要根据业务的逻辑和实际的硬件成本来综合考虑 net.piv4.tcp_syncookies = 1 与性能无关。用于解决tcp的syn攻击 net.ipv4.tcp_max_syn_backlog = 8192 这个参数表示tcp三次握手建立阶段接受syn请求的列队的较大长度，默认1024，将这个参数设置的大一点可使出现nginx繁忙来不及accept新的连接时，linux不至于丢失客户端的发起连接的请求 net.ipv4.tcp_tw_recycle = 1 这个参数用于设置启用timewait快速回收 net.core.somaxconn = 262114 选项默认值为128，这个参数用于调节系统同时发起的tcp连接数，在高并发的请求中，默认的值可能会导致连接超时或者重传，因此需要结合高并发请求数来调节此值 net.ipv4.tcp_max_orphans = 262114 选项用于设定系统中最多有多少个tcp套接字不被关联到任何一个用户文件句柄中。如果超过这个数字，孤立连接将立即被复位输出警告信息。这个限制指示为了防]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的stream模块]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E4%BC%AA%E5%9B%9B%E5%B1%82%E8%B4%9F%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[nginx的stream模块（伪四层负载） nginx伪四层负载 Nginx 1.9.0版本起支持四层负载均衡，从而使得Nginx变得更加强大。目前，四层软件负载均衡器用得比较多的是HaProxy；而Nginx也支持四层负载均衡。 ngx_stream_core_module ngx_stream_core_module模块从1.9.0版本开始可用。默认情况下，此模块不是构建的，它应该使用-with-stream配置参数启用。 (1) listen address:port [ssl] [udp] [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 监听的端口； 默认为tcp协议； udp: 监听udp协议的端口； ngx_stream_proxy_module ngx_stream_proxy_module模块(1.9.0)允许通过TCP、UDP(1.9.13)和unix域套接字代理数据流。 (1) proxy_pass address; 设置代理服务器的地址。该地址可以指定为域名或IP地址、端口或unix域套接字路径。 (2) proxy_timeout timeout; 设置客户端或代理服务器连接上的两个连续读写操作之间的超时。如果在此时间内没有传输数据，则连接将关闭。- 默认为10m; (3) proxy_connect_timeout time; 定义与代理服务器建立连接的超时。- 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 参考：http://nginx.org/en/docs/stream/ngx_stream_core_module.html#stream 范例：123456789101112131415161718192021222324252627282930313233343536实现nginx_stream代理mysql_server服务器面向客户端提供服务 clent nginx_stream : yum install nginx mysql_server : yum istall mariadb-servermysql_server### 创建账号 MariaDB [(none)]&gt; grant all on *.* to daizhe@'%' identified by 'centos'; 生效权限 MariaDB [(none)]&gt; flush privileges;nginx_server#使用stream四层代理时使用的上下文都在stream &#123;&#125; 上下文当中，不要与http同时使用 ~]# vim /etc/nginx/nginx.conf stream &#123; server &#123; listen 3306; proxy_pass 172.18.135.2:3306; #数据库的地址和端口 &#125; &#125; ~]# nginx -t ~]# nginx -s reload ~]# systemctl restart nginx ~]# ss -tnl LISTEN 0 128 *:3306 client测试 #使用client连接nginx_stream_server服务器验证是否被调度 ~]# mysql -udaizhe -pcentos -h172.18.135.1 #地址为nginx地址 MariaDB [(none)]&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445再次启动一个mysql数据库实现客户端访问的负载均衡#模拟两个数据库的效果，为了使客户调度起来无差别感知，使两个mysql授权的账号和数据相同（生产中可以做主从）（后添加）mysql_server### 创建账号 MariaDB [(none)]&gt; grant all on *.* to daizhe@'%' identified by 'centos'; 生效权限 MariaDB [(none)]&gt; flush privileges;配置nginx_stream_server ~]# vim /etc/nginx/nginx.conf stream &#123; upstream dbserver &#123; server 172.18.135.2:3306; server 172.18.135.5:3306; &#125; server &#123; listen 3306; proxy_pass dbserver; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadclient 测试（为了使得看出差别可以在daizhe账号下创建不同的数据库以便看出算法） ~]# while true; do mysql -udaizhe -pcentos -h172.18.135.1 -e "show databases;"; sleep 1 ;done+--------------------+| Database |+--------------------+| information_schema || db1 || mysql || performance_schema |+--------------------++--------------------+| Database |+--------------------+| information_schema || db2 || mysql || performance_schema |+--------------------+]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的http_upstream模块]]></title>
    <url>%2F2019%2F01%2F13%2Fnginx%E4%B8%83%E5%B1%82%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[nginx的http_upstream模块（七层负载） nginx的http_upstream模块 我们知道单台服务器的性能是有上限的，当流量很大时，就需要使用多台服务器来共同提供服务，这就是所谓的集群。 负载均衡服务器，就是用来把经过它的流量，按照某种方法，分配到集群中的各台服务器上。这样一来不仅可以承担 更大的流量、降低服务的延迟，还可以避免单点故障造成服务不可用。一般的反向代理服务器，都具备负载均衡的功能。 负载均衡功能可以由硬件来提供，比如以前的F5设备。也可以由软件来提供，LVS可以提供四层的负载均衡(利用IP和端口)， Haproxy和Nginx可以提供七层的负载均衡(利用应用层信息)。 硬件：F5 BigIP, Citrix NetScaler, A10 A10 软件： 四层调度：lvs, nginx(stream module), haproxy(mode tcp) 七层调度：nginx(http_upstream module), haproxy(mode http), httpd, ats, ... mysql: Proxy_SQL, ... ... ... session sticky：会话粘滞 Source IP: sh, persistence Cookie： session replication： session server： ngx_http_upstream_module 参考文档：http://nginx.org/en/docs/http/ngx_http_upstream_module.html ngx_http_upstream_module模块用于定义可以由proxy_pass、fastcgi_pass、uwsgi_pass、scgi_pass和memcached_pass指令引用的服务器组。 (1) upstream name { ... } 定义后端服务器组；引入一个新的上下文；只能用于http{}上下文中； 默认的调度方法是wrr； (2) server address [parameters]; 定义服务器地址和相关的参数； 地址格式： IP[:PORT] HOSTNAME[:PORT] unix:/PATH/TO/SOME_SOCK_FILE 参数： weight=number 权重，默认为1； max_fails=number 失败尝试的最大次数； fail_timeout=time 设置服务器为不可用状态的超时时长，默认为10秒； backup 把服务器标记为“备用”状态（sory server 只有所有的服务器全部没办法工作时才会上线）； down 手动标记其为不可用； 1server 172.18.135.2 weight=2 backup max_fails=10m; (3) least_conn; 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； (4) ip_hash; 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； (5) hash key [consistent]; 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； consistent：参数，指定使用一致性hash算法； 示例： hash $request_uri consistent hash $remote_addr hash $cookie_name (6) keepalive connections; 可使用长连接的连接数量；每worker与后端服务保持的最大空闲长连接数量； 范例：实现nginx调度123456789101112131415161718192021222324252627282930313233343536373839404142三台主机 client nginx_stream_server :yum install nginx -y web_server1 :yum install httpd -y web_server2 :yum install httpd -y配置两台web_server的页面文件 #为了达到负载均衡的web_server网页文件应该是相同的，这里为了演示调度器调度的差别有意的是web_server的网页文件设置有差别 web_server1 ~]# echo "web_server1" &gt; /var/www/html/index.html web_server2 ~]# echo "web_server2" &gt; /var/www/html/index.html编辑nginx实现负载均衡 #在原http配置 ~]# vim /etc/nginx/nginx.conf http &#123; #仅能在http上下文使用 upstream staticwebsrvs &#123; #定义后端服务器组 server 172.18.135.2; #web_server1 server 172.18.135.5; #web_server2 &#125; .... #server中调用服务器组名称 server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadclient客户端测试#默认1:1轮询算法,支持加权轮询（Round-Robin） ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server2 web_server1 web_server2 算法：使用加权轮询（wrr）123456789101112131415161718192021222324使用加权轮询(默认权重都为1) 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; server 172.18.135.2 weight=2; #将web_server1设置权重比为2 server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server2 算法：least_conn做少连接（wlc）1234567891011121314151617181920212223242526#对短链接最好使用：轮询#对长连接最好使用：wlc使用least_conn做少连接算法 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; least_conn; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done 算法：ip_hash (sh)123456789101112131415161718192021222324252627282930313233343536使用ip_hash：bash原ip地址 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; ip_hash; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server1 web_server1 web_server1工作方式：#对客户端ip做bash计算，把后端服务器按权重bash成静态的数组，而后在数据上取模，取出模几，就映射到第几台服务器上缺点：#如果服务器的总数发生了变化则此前的hash结果则发生变动#当后端服务器宕机后，session会丢失；#来自同一局域网的客户端会被转发到同一个后端服务器，可能导致负载失衡；#不适用于CDN网络，不适用于前段还有代理的情况。 算法：consistent bashing 一致性hash12345678910111213141516171819202122232425262728293031323334#无论权重怎么变，但是hash算法是不变的，仅对固定的进行bash取模#bash:可以对任何数据进行hash#consistent一致性hash,如果不添加则便是静态hash与ip_hash相同hash $remote_addr consistent;对原地址进行bash，不过做了一致性hash 编辑nginx实现负载均衡 ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; hash $remote_addr consistent; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; ~]# nginx -t ~]# nginx -s reloadlient客户端测试 ~]# while true; do curl http://172.18.135.1:8080; sleep 1;done web_server1 web_server1 web_server1 web_server1 web_server1 123456789101112131415161718对用户请求的uri进项hash(适用于后端服务器为缓存服务器，提高命中率)hash $request_uri consistent; ~]# vim /etc/nginx/nginx.conf http &#123; upstream staticwebsrvs &#123; hash $request_uri consistent; server 172.18.135.2 weight=2; server 172.18.135.5; &#125; .... server &#123; listen 8080; server_name www.centos.com; location / &#123; proxy_pass http://staticwebsrvs/; &#125; &#125; 1234nginx+才支持nginx-sticky-module的使用（基于cookie的会话保持）使用sticky_cookie_insert启用会话亲缘关系，这会导致来自同一客户端的请求被传递到一组服务器在同一台服务器。与ip_hash不同之处在于，它不是基于IP来判断客户端的，而是基于cookie来判断。因此可以避免上述ip_hash中来自同一局域网的客户端和前段代理导致负载失衡的情况。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的fastcgi模块]]></title>
    <url>%2F2019%2F01%2F12%2Fnginx%E7%9A%84fastcgi%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx的fastcgi模块 nginx的fastcgi模块1.1 什么是 FastCGI FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等。同时，FastCGI也被许多脚本语言支持，其中就有PHP。 FastCGI是从CGI发展改进而来的。传统CGI接口方式的主要缺点是性能很差，因为每次HTTP服务器遇到动态程序时都需要重新启动脚本解析器来执行解析，然后将结果返回给HTTP服务器。这在处理高并发访问时几乎是不可用的。另外传统的CGI接口方式安全性也很差，现在已经很少使用了。 FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 1.2 Nginx+FastCGI运行原理(nginx+fcgi_module–&gt;fpm(php))=NMP Nginx不支持对外部程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用。FastCGI接口在Linux下是socket（这个socket可以是文件socket，也可以是ip socket）。为了调用CGI程序，还需要一个FastCGI的wrapper（wrapper可以理解为用于启动另一个程序的程序），这个wrapper绑定在某个固定socket上，如端口或者文件socket。当Nginx将CGI请求发送给这个socket的时候，通过FastCGI接口，wrapper接收到请求，然后派生出一个新的线程，这个线程调用解释器或者外部程序处理脚本并读取返回数据；接着，wrapper再将返回的数据通过FastCGI接口，沿着固定的socket传递给Nginx；最后，Nginx将返回的数据发送给客户端。这就是Nginx+FastCGI的整个运作过程， ngx_http_fastcgi_module模块： 1、fastcgi_pass address; address为fastcgi server的地址； location, if in location； 2、fastcgi_index name; fastcgi默认的主页资源; 3、fastcgi_param parameter value [if_not_empty]; 设置应该传递给FastCGI服务器的参数。该值可以包含文本、变量及其组合。(用于向后端的fastcgi或者fpm_server来传递参数) 12345678910111213141516171819202122232425262728293031323334353637383940414243#安装完nginx时在目录中就有fastcgi_paeams文件，里面装的时nginx给fpm服务传递的参数，（每个默认的参数都要启动生效，每一个默认值fastcgi服务端执行fpm服务时要配置启用的参数的默认设定） ~]# ls /etc/nginx/ fastcgi_params 两台主机 client proxy_nginx_server :yum install nginx -y fpm_server :yum install php-fpm编辑代理nginx_server server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; location ~* \.php$ &#123; fastcgi_pass 172.18.135.2:9000; #定义如果客户端请求的资源为.php结尾的文件转发到fpm_server服务器上 fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; #/data是在fpm_server上 include fastcgi_params; &#125; ~]# nginx -t ~]# nginx -s reloadfpm_server创建.php文件供客户端访问 ~]# cat /data/info.php &lt;?php phpinfo(); ?&gt; 编辑fpm的配置文件的允许监听的地址 ~]# vim /etc/php-fpm.d/www.conf listen = 172.18.135.2:9000 listen.allowed_clients = any ~]# systemctl restart php-fpmclient访问 http://172.18.135.1/info.php 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253使用压测工具进行压测（ab） ~]# yum install httpd-tools -y ab 命令（n&gt;c） -c 模拟并发的数量 -n 指定请求的个数对nginx调度器进行压测 ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php Requests per second: 2389.18 [#/sec] (mean)----------------------------------------------------------------------对nginx调度器的fastcgi模块启用缓存#http上下文定义键 ~]# vim /etc/nginx/nginx.conf http &#123; fastcgi_cache_path /var/cache/fastcgi levels=1:1:2 keys_zone=fastcgi:10m max_size=2G; .... #调用http定义的键 server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; location ~* \.php$ &#123; fastcgi_pass 172.18.135.2:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data$fastcgi_script_name; include fastcgi_params; fastcgi_cache fastcgi; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; fastcgi_cache_methods GET HEAD; &#125; ~]# mkdir -p /var/cache/fastcgi ~]# nginx -t ~]# nginx -s reload再次访问测试验证是否加速 ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php #第一次访问生成缓存 [root@centos7 ~]# tree /var/cache/fastcgi/ /var/cache/fastcgi/ └── 5 └── 6 └── af └── 48fe86dcef16714ba3e4f82bba2daf65 3 directories, 1 file ~]# ab -c 100 -n 1000 http://172.18.135.1/infp.php Requests per second: 10657.12 [#/sec] (mean) 4、fastcgi_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE leves=1:2:2 keys_zone=name:size k/v映射的内存空间的名称及大小 inactive=time 非活动时长 max_size=size 磁盘上用于缓存数据的缓存空间上限 5、fastcgi_cache zone | off; 调用指定的缓存空间来缓存数据；http, server, location 6、fastcgi_cache_key string; 定义用作缓存项的key的字符串； 7、fastcgi_cache_methods GET | HEAD | POST …; 为哪些请求方法使用缓存； 8、fastcgi_cache_min_uses number; 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； 9、fastcgi_cache_valid [code …] time; 不同的响应码各自的缓存时长； 10、fastcgi_keep_conn on | off; 默认情况下，FastCGI服务器会在发送响应后立即关闭连接。但是，当这个指令被设置为on时，nginx将指示FastCGI服务器保持连接打开。 范例：fastcgi模块内键有两个url可以输出fastcgi健康状态以及健康页面信息1234567891011121314151617181920212223242526272829303132333435363738fastcgi_server配置文件中开启两个内建的url(这两个url的输出默认使用的fastcgi协议) ~]# vim /etc/php-fpm.d/www.conf 121 pm.status_path = /pm_status 133 ping.path = /ping #ping·pong ~]# systemctl restart php-fpm编辑nginx代理 ~]# vim /etc/nginx/nginx.conf location ~* ^/(pm_status|ping)$ &#123; fastcgi_pass 172.18.135.2:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; include fastcgi_params; &#125; ~]# nginx -t ~]# nginx -s reload客户端访问测试 ~]# curl 172.18.135.1/pm_status pool: www process manager: dynamic start time: 12/Jan/2019:17:09:39 +0800 start since: 57 accepted conn: 1 listen queue: 0 max listen queue: 0 listen queue len: 128 idle processes: 4 active processes: 1 total processes: 5 max active processes: 1 max children reached: 0 slow requests: 0 ~]# curl 172.18.135.1/ping pong]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的proxy模块]]></title>
    <url>%2F2019%2F01%2F10%2Fnginx%E7%9A%84proxy%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx的proxy模块 nginx的proxy模块一、反向代理 1.什么是反向代理（DNAT）通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中由代理服务器向Internet上的web服务器发起请求，最终达到客户机上网的目的（也就是正向代理）。 而反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 Nginx只做请求的转发，后台有多个http服务器提供服务，nginx的功能就是把请求转发给后面的服务器，决定把请求转发给谁 ngx_http_proxy_module模块： 1、proxy_pass URL; Context: location, if in location, limit_except 作用：将用户的请求代理到哪个URL上（完成的是两个路径的映射关系） 注意：proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； 123456789101112131415161718192021222324252627282930313233343536 server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy http://hos[:port]; &#125; ... &#125; http://HOSTNAME/uri --&gt; http://host/uri proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri； server &#123; ... server_name HOSTNAME; location /uri/ &#123; proxy http://host/new_uri/; &#125; ... &#125; http://HOSTNAME/uri/ --&gt; http://host/new_uri/ 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； server &#123; ... server_name HOSTNAME; location ~|~* /uri/ &#123; proxy http://host; &#125; ... &#125; http://HOSTNAME/uri/ --&gt; http://host/uri/； 范例：实现简单的代理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150使用docker镜像创建两个web_server服务器#容易已经绑定宿主机的存储卷，默认安装完docker生成的一个net的地址桥#无需暴漏端口，因为此web_server仅用于和前端内网中的nginx_proxy_server通讯不需要直接和客户端进行通讯 ~]# docker run --name webser1 -it --network bridge -v /vols/websrv1:/vole/htdocs1 busybox / # httpd -f -v -h /vole/htdocs1 #-f 运行在前台 #-v 打印信息在前台 #-h 指定家目录 ~]# docker run --name webser2 -it --network bridge -v /vols/websrv2:/vole/htdocs1 busybox / # httpd -f -v -h /vole/htdocs1在宿主机上创建对应的存储卷上对应的网页文件 ~]# mkdir -p /vols/websrv1 ~]# mkdir -p /vols/websrv2 ~]# echo "webser1" &gt; /vols/websrv1/index.html ~]# echo "webser2" &gt; /vols/websrv2/index.html ~]# curl 172.17.0.2 websrv1 ~]# curl 172.17.0.3 websrv2配置nginx代理 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; location / &#123; proxy_pass http://172.17.0.2/; #proxy_pass的优先级比root的优先级要高 ,/有和无是有区别的。 &#125; &#125; ~]# nginx -t ~]# nginx -s reload客户端请求nginx代理的地址 ~]# curl 172.18.135.1:8080 websrv1-----------------------------------------------------------------------###实验说明/有和无是有区别的##无/## server &#123; listen 8080; root /nginx/html; location /bbs &#123; proxy_pass http://172.17.0.2; &#125; &#125; ~]# mkdir -p /nginx/html/ddb ~]# mkdir -p /nginx/html/bbs ~]# echo "/nginx/html/bbs/index.html" &gt; /nginx/html/bbs/index.html测试 ~]# curl 172.18.135.1:8080/bbs /nginx/html/bbs/index.html查看web_server打印的日志 [::ffff:172.17.0.1]:50650: response:404##有/## server &#123; listen 8080; root /nginx/html; location /bbs &#123; proxy_pass http://172.17.0.2/; &#125; &#125; ~]# curl 172.18.135.1:8080/bbs websrv1查看web_server打印的日志 [::ffff:172.17.0.1]:50648: response:200··············································································范例：使用正则表达式匹配客户端请求的文件进行代理配置nginx代理#"proxy_pass"不能在正则表达式给出的位置中 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; location ~* \.(jpg|png|jpeg) &#123; #如果客户端请求这些资源则代理则将客户段的请求代理到web_server的/images/目录下文件 proxy_pass http://172.17.0.1; #proxy_pass定义的匹配条件后面不可以url（客户的请求资源url和自动补在服务器上，如果客户请求的http://172.18.135.1:8888/bbs/a.jpg,如果后端的web服务器上有这个资源，则客户端也回加载此图片（后面的uri是原封不动的放在后端服务器上的）） &#125; &#125; ~]# nginx -t ~]# nginx -s reload在web_server上放置图片提供访问（从宿主机上查找图片放在容器对应映射在宿主机上的存储卷） ~]# cd /vols/websrv1/ websrv1]# cp /usr/share/cups/www/images/smiley.jpg .客户端访问测试 http://172.18.135.1:8888/smiley.jpg 查看web_server是否接受请求 [::ffff:172.17.0.1]:50720: response:200##测试请求web_server下的其他url的图片宿主机放置资源在存储卷上bbs]# pwd/vols/websrv1/bbs请求测试http://172.18.135.1:8888/bbs/profile.jpg``` - `2、proxy_set_header field value;` - 设定发往后端主机的请求报文的请求首部的值；Context: http, server, location - proxy_set_header X-Real-IP $remote_addr; - proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;`范例：proxy_set_header ：将请求报文发送给后端被代理的服务器时，修改请求报文的某些或者某个首部````bash七层调度是可以操纵两路报文： 第一：把请求转给后端时，可以操作报文 第二：将后端服务器的响应发还给客户端时，可以操作报文-----------------------------------------------------------实现被调度的服务器显示的日志查看到的源地址为客户端的地址#利用变量操作客户端请求被调度的服务器的请求报文的源地址的修改#proxy_set_header X-Real-IP $remote_addr#日志查看被调度的默认的请求的客户端的地址，默认显示的不是真正的客户端的地址，显示的是调度的器的地址（请求报文的源地址）#[::ffff:172.17.0.1]:50728: response:200 （让代理服务器发请求报文时添加特定的请求首部，修改为真正的客户端地址，让后端被调度的服务器记录日志时，改为记录新的日志）编辑被调度的web服务的配置文件 1.查看后端web服务器的使用的日志的格式 CustomLog /path/to/file 格式定义（common、combined、combinedio） 2.修改web后端使用的日志的格式 LogFormat "%&#123;X-Real-IP&#125;i %l %u %t \"%r\" %&gt;s %b" common 3.修改nginx调度器的配置文件 ~]# vim /etc/nginx/nginx.conf server &#123; proxy_set_header X-Real-IP $remote_addr; listen 8888; location ~* \.(jpg|png|jpeg) &#123; proxy_pass http://172.18.135.2; &#125; &#125; ~]# nginx -t ~]# nginx -s reload 4.客户端访问调度器并查看后端的web_server服务器的访问日志信息 ~]# cat /var/log/httpd/access_log 172.18.135.5 - - [12/Jan/2019:10:08:05 +0800] "GET /smiley.jpg HTTP/1.0" 200 14120 (此地址文真实客户端地址) 3、proxy_cache_path 定义可用于proxy功能的缓存；Context: http proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time] [manager_threshold=time] [loader_files=number] [loader_sleep=time] [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time] [purger_threshold=time]; 范例： 定义可用于proxy功能的缓存12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970页面缓存（http服务）#nginx作为反向代理服务器时支持缓存功能的，缓存是由缓存模块个缓存机制来提供的，对于缓存服务来说要想启用起来，是由代理模块自带的，在nginx上想要使用代理，必须要匹配模式，在nginx中的缓存是要先定义在使用的，levels=levels #定义使用几级索引，做多使用三级=每级索引当中打算使用几个字符创建多少个子项（一个字符是16个，两个字符就是256个，2^8）#inactive=time 非活动时间#max_size=size 整个磁盘空间用于缓存的时间的空间的大小#manager_sleep=time 每隔多长时间检查缓存的有效性#manager_threshold=time 如果缓存时间沾满，如何使用LRU（最近最少使用算法）算法激活，并清理缓存范例：配置nginx的proxy功能的页面缓存#直接定义在http的上下文# proxy_cache_path定义缓存的放置路径，并确保定义的缓存的目录的存在,应该放置在当前主机上的io性能最好的设备上（固态硬盘）（缓存对cpu的压力小，但是最磁盘io的压力很大）#levels=1:1:1 定义缓存的路由级别，每个路由有16个子目录#keys_zone 定义内存空间的路径和定义内存数据或者索引数据的缓存（K/V）#max_size=size 指定磁盘空间的大小#proxy_cache 调用缓存的名称#proxy_cache_key $schene$proxy_host$is_args$args; #定义使用的键bash（协议：服务器地址：端口：请求的uri）如果是服务器的地址使用了泛域名解析，则要去掉协议和服务器地址#proxy_cache_valid 定义缓存进来的键被保留多长时间#proxy_cache_methods(默认为GET、POST)(对web服务器来讲通常仅缓存读操作，不缓存写操作，查询缓存时只对读操作查缓存)#proxy_cache_use_stale (缓存的内容不一定是权威的内容，所有能够响应客户端的前提是后端服务器时ok的，如果客户的某一请求来了服务器时不在了，代理联系不到后端的服务器，并且缓存中的内容已经过期了客户端的且缓存中的内容还是存在的，决定代理服务器还要不要给客户端返回结果)off代表如果服务器有问题时代理服务器不拿缓存中数据去对客户端进行响应，定义服务器出现问题是代理继续使用未过期的缓存进行响应proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;编辑nginx代理节点的配置文件#定义缓存功能 ~]# vim /etc/nginx/nginx.conf http &#123; proxy_cache_path /var/cache/nginx levels=1:1:2 keys_zone=webcache:10m max_size=2G; .... #调用缓存 server &#123; proxy_set_header X-Real-IP $remote_addr; listen 8888; location ~* \.(jpg|png|jpeg) &#123; proxy_pass http://172.18.135.2; proxy_cache webcache; proxy_cache_key $request_uri; #设置仅使用uri当客户端请求的bash的键 proxy_cache_valid 200 302 10m; #根据用户第一次请求的响应码定义缓存的时长 proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_methods GET HEAD; &#125; &#125; ~]# nginx -t ~]# nginx -s reload 客户端进行访问测试 http://172.18.135.1:8888/smiley.jpg调度器查看是否生成缓存 ~]# tree /var/cache/nginx /var/cache/nginx └── 2 #一级桶 └── b #二级桶 └── df #三级桶 └── ac2582e15d13e9fa21b8da128b16dfb2 3 directories, 1 file ~]# cat /var/cache/nginx/2/b/df/ac2582e15d13e9fa21b8da128b16dfb2 ޷ 9\YJ9\u9\¼b]"3728-57f392ebe4ca8" KEY: /smiley.jpg HTTP/1.1 200 OK Date: Sat, 12 Jan 2019 05:05:11 GMT Server: Apache/2.4.6 (CentOS) Last-Modified: Sat, 12 Jan 2019 02:00:57 GMT ETag: "3728-57f392ebe4ca8" Accept-Ranges: bytes Content-Length: 14120 Connection: close Content-Type: image/jpeg 4、proxy_cache zone | off; 指明要调用的缓存，或关闭缓存机制；Context: http, server, location 5、 proxy_cache_key string; 缓存中用于“键”的内容； 默认值：proxy_cache_key $scheme$proxy_host$request_uri; 6、proxy_cache_valid [code …] time; 定义对特定响应码的响应内容的缓存时长； 定义在http{…}中； proxy_cache_path /var/cache/nginx/proxy_cache levels=1:1:1 keys_zone=pxycache:20m max_size=1g; 定义在需要调用缓存功能的配置段，例如server{…}； proxy_cache pxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; 7、proxy_cache_use_stale proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off …; 确定在与代理服务器通信期间发生错误时，可以在哪些情况下使用陈旧的缓存响应。 8、proxy_cache_methods GET | HEAD | POST …; 如果在这个指令中列出了客户机请求方法，那么响应将被缓存。“GET”和“HEAD”方法总是添加到列表中，但是建议显式地指定它们。 9、proxy_hide_header field; #操纵发送给客户端的响应报文 默认情况下，nginx不传递头字段“Date”、“Server”、“X-Pad”和“X-Accel-…”从代理服务器到客户机的响应。proxy_hide_header指令设置不传递的其他字段。 (参考文档：http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_purge) 10、proxy_connect_timeout time; 定义与代理服务器建立连接的超时。应该注意的是，这个超时通常不能超过75秒。 默认为60s；最长为75s； 11、proxy_read_timeout time; 定义从代理服务器读取响应的超时。超时仅在两个连续读取操作之间设置，而不是为整个响应的传输设置。 12、proxy_send_timeout time; 设置将请求发送到代理服务器的超时。仅在两个连续的写操作之间设置超时，而不是为整个请求的传输设置超时。如果代理服务器在此期间没有收到任何消息，则连接将关闭。 ngx_http_headers_module模块 ngx_http_headers_module模块允许将“Expires”和“Cache-Control”报头字段以及任意字段添加到响应报头中。 向由代理服务器响应给客户端的响应报文添加自定义首部，或修改指定首部的值； 1、add_header name value [always]; 添加自定义首部； add_header X-Via $server_addr; add_header X-Accel $server_name; 2、expires [modified] time; expires epoch | max | off; 用于定义Expire或Cache-Control首部的值；]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置和使用基础--Webserver]]></title>
    <url>%2F2019%2F01%2F09%2Fnginx%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%802%2F</url>
    <content type="text"><![CDATA[Nginx-Webserver:第二章：配置指令 程序环境 程序环境 配置文件的组成部分： 主配置文件：nginx.conf include conf.d/*.conf fastcgi， uwsgi，scgi等协议相关的配置文件 mime.types：支持的mime类型 主程序文件：/usr/sbin/nginx Unit File：nginx.service 配置： 主配置文件的配置指令： directive value [value2 …]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name nginx支持三类功能在配置文件中放在三个不同的上下文配置段中（一般这三种配置不会同时出现） web http{} mail mail{} 四层调度机制 stream{} 主配置文件结构：1234567891011121314151617181920212223242526272829303132333435 main block：主配置段，也即全局配置段； event &#123; ... &#125;：事件驱动相关的配置； http &#123; ... &#125;：http/https 协议相关的配置段； mail &#123; ... &#125; stream &#123; ... &#125; http协议相关的配置结构 http &#123; ... ...：各server的公共配置 server &#123; ... &#125;：每个server用于定义一个虚拟主机； server &#123; ... listen #监听端口 server_name #服务器名称 root #网页文件根目录 alias location [OPERATOR] URL &#123; ... if CONDITION &#123; ... &#125; &#125; &#125; &#125; 配置指令main配置段常见的配置指令： 分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user #定义子进程的运行身份，主进程不响应用户的请求，所以子进程可以使用普通用户接收客户的响应，前提是普通用户对文件目录要有读权限 Syntax: user user [group]; #定义属主和属组身份 Default: user nobody nobody; Context: main 定义工作进程使用的用户和组凭据。如果省略组，则使用名称与user相同的组。 2、pid /PATH/TO/PID_FILE; 指定存储nginx主进程进程号码的文件路径； 3、include file | mask; 指明包含进来的其它配置文件片断（加载其他配置文件，将功能模块化）； 4、load_module file; 指明要装载的动态模块； 性能优化相关的配置： 1、worker_processes number | auto; worker进程的数量；通常应该等于小于当前主机的cpu的物理核心数； auto：当前主机物理CPU核心数； 2、worker_cpu_affinity cpumask ...; worker_cpu_affinity auto [cpumask]; #自动绑定 nginx进程的CPU亲缘性； CPU MASK：(cpu位掩码称为bit mask) 00000000： 0000 0001：0号CPU 0000 0010：1号CPU 0000 0100：2号CPU … … 0000 0011：0和1号CPU； 优点：提升缓存的命中率 context switch:会产生cpu不必要的消耗 3、worker_priority number; 指定worker进程的nice值，设定worker进程优先级；[-20,20] （数字越小优先级越高，默认的值为0） 4、worker_rlimit_nofile number; worker进程所能够打开的文件数量上限； time_resolution 计时器解析度，降低此值，可减少gettimeofday()系统调用的次数 调试、定位问题：如果是编译安装想要使用一下功能必须在编译时使用–with-debug功能开启 1、daemon on|off; 是否以守护进程方式运行Nignx； 2、master_process on|off; 是否以master/worker模型运行nginx；默认为on；(适用于追踪和调试问题，开启以单进程模式运行nginx，主进程直接处理用户的请求) 3、error_log file [level]; 错误日志和日志级别（web服务器一般有两种日志：访问日志和错误日志） 123456在配置nginx.conf 的时候，有一项是指定错误日志的，默认情况下你不指定也没有关系，因为nginx很少有错误日志记录的。但有时出现问题时，是有必要记录一下错误日志的，方便我们排查问题。error_log 级别分为 debug, info, notice, warn, error, crit 默认为crit, 该级别在日志名后边定义格式如下：error_log /your/path/error.log crit; crit 记录的日志最少，而debug记录的日志最多。如果你的nginx遇到一些问题，比如502比较频繁出现，但是看默认的error_log并没有看到有意义的信息，那么就可以调一下错误日志的级别，当你调成error级别时，错误日志记录的内容会更加丰富。 事件驱动相关的配置:1234#事件驱动中的参数定义决定了每一个子进程支持的并发连接数events &#123; ...&#125; 1、worker_connections number; 每个worker进程所能够打开的最大并发连接数数量； 整个nginx并发连接数（进程数*每个进程可以打开的并发连接数） worker_processes * worker_connections 2、use [epoll|rtsig|select|poll]; 指明并发连接请求的处理方法； 事件驱动机制模型： use epoll; 建议让nginx自行选择 3、accept_mutex on | off;（是否打开互斥锁—防止惊群） 处理新的连接请求的方法；on意味着由各worker轮流处理新请求，Off意味着每个新请求的到达都会通知所有的worker进程； 4、lock_file file; accept_mutex用到的锁文件的路径； http协议的相关配置12345678910111213141516http协议的相关配置： http &#123; #http全局配置，可共享给多个server使用 ... ... server &#123; #一到多个server,每一个server用来定义一个虚拟主机 ... listen server_name root location [OPERATOR] /uri/ &#123; #定义客户请求的url，类似于httpd的directory字段 ... &#125; &#125; server &#123; ... &#125; &#125; 与套接字相关的配置 1、server { … } #仅能使用于http{}上下文，不可再server{}内部嵌套 配置一个虚拟主机； 12345server &#123; listen address[:PORT]|PORT|unix:/PATH/TO/SOCKET_FILE; #指定要监听的地址和端口，仅指定监听的端口，表示监听本机可用的所有此端口，或者指定地址，代表监听此地址的80端口，或者仅监听在本机的unix.socket server_name SERVER_NAME; root /PATH/TO/DOCUMENT_ROOT; &#125; 2、listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] default_server：设定为默认虚拟主机； ssl：限制仅能够通过ssl连接提供服务； http2:要求支持http2协议； backlog=number：后援队列长度； rcvbuf=size：接收缓冲区大小； sndbuf=size：发送缓冲区大小； 3、server_name name …; 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串； 支持*通配任意长度的任意字符； server_name .magedu.com www.magedu. 支持~起始的字符做正则表达式模式匹配； server_name ~^www\d+.magedu.com$ 匹配机制： - (1) 首先是字符串精确匹配; - (2) 左侧*通配符； - (3) 右侧*通配符； - (4) 正则表达式；（尽量不要使用正则表达式，引擎在处理字符串影响效率） 4、 tcp_nodelay on | off; 在keepalived模式下的连接是否启用TCP_NODELAY选项； tcp_nopush on|off; 在sendfile模式下，是否启用TCP_CORK选项； 5、sendfile on | off; 是否启用sendfile功能； 定义路径相关的配置 6、root path; 设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； 可用的位置：http（对整个http生效）, server（仅对一个server生效）, location（仅对一个location生效）, if in location； 7、location [ = | ~ | ~* | ^~ ] uri { ... } 用来表达nginx中，一组有匹配模式的url路径下的资源访问的属性定义和访问控制机制的 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射； ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849客户请求到收到请求，服务端的匹配路由 Nginx--&gt;server_name server server Server--&gt;Location location&#123;&#125; #仅为一个location所匹配处理 if if location&#123;&#125;=：对URI做精确匹配；例如, http://www.9727.top/，http://www.9727.top/index.html location = / &#123; ... &#125; ~：对URI做正则表达式模式匹配，区分字符大小写； ~*：对URI做正则表达式模式匹配，不区分字符大小写； ^~：对URI的左半部分做匹配检查，不区分字符大小写； 不带符号：以URI为前缀的所有uri； 匹配优先级：=, ^~, ～/～*，不带符号； 让我们通过一个例子来说明以上内容： location = / &#123; [ configuration A ] &#125; location / &#123; [ configuration B ] &#125; location /documents/ &#123; [ configuration C ] &#125; location ^~ /images/ &#123; [ configuration D ] &#125; location ~* \.(gif|jpg|jpeg)$ &#123; [ configuration E ] &#125; “ /”请求将匹配配置A，“ /index.html”请求将匹配配置B，“ /documents/document.html”请求将匹配配置C，“ /images/1.gif”请求将匹配配置D，“ /documents/1.jpg”请求将匹配配置E. “ @”前缀定义命名位置。这样的位置不用于常规请求处理，而是用于请求重定向。它们不能嵌套，也不能包含嵌套位置。 范例： 用来表达nginx中，一组有匹配模式的url路径下的资源访问的属性定义和访问控制机制的12345678910111213141516171819~]# vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name www.centos.com; root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123;&#125;&#125; ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful~]# nginx -s reload~]# curl 172.18.135.1:8080/web/nginx/html/index.html~]# curl 172.18.135.1:8080/images//ngx/html/images/index.html 8、alias path; 定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； 范例：alias path123456789101112131415161718192021222324252627282930313233#aliasserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; alias "/ngx/html";&#125;&#125;~]# curl 172.18.135.1:8080/images//ngx/html/index.html#rootserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; root "/ngx/html";&#125;&#125;~]# curl 172.18.135.1:8080/images//ngx/html/images/index.html 9、index file …; 默认资源；http, server, location； 10、error_page code ... [=[response]] uri; 12345#定义一个错误页面即错误重定向 error_page 404 /404.html; location = /404.html &#123; root "/www/error_pages"; &#125; 范例：error_page code ... [=[response]] uri; 定义一个错误页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152status(状态码)：告诉客户端的请求发生的结果：1XX：100-101，信息提示2XX：200-206，成功类型信息3XX：300-305，重定向的资源4XX：400-415，错误类型的信息，客户端的错误，5XX：500-505，错误类型错误，服务器端错误常用的状态码：200：:成功响应，请求的所有数据通过相应报文的entity-body部分发送，OK301：请求的URL执行的资源已经被删除；但在相应报文中通过首部Location指明了资源的所在位置；Moved Permanently （永久重定向）302：与301相似，但在相应报文中通过首部Location指明了资源现在所处临时新位置；Found （临时重定向）304：客户端发出了条件式请求，但服务器的资源为曾发生改变，则通过相应此响应状态码通知客户端，Not Modified401：需要输入账号和密码认证方能访问资源：Unauthorized403：请求被禁止：Forbidden404：服务器无法找到客户端请求的资源：Not Found500：服务器内部错误：InternalServerError502：:代理服务器从后端服务器中收到的一条伪响应：Bad Gateway定义一个404服务器无法找到客户端请求的资源的错误页面~]# vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html"; &#125; location /images &#123; root "/ngx/html"; &#125; error_page 404 /404.html;&#125;~]# curl 172.18.135.1:8080/aaaa//web/nginx/html/404.htmlserver &#123; listen 8080; server_name www.centos.com;# root "/ngx/html"; location / &#123; root "/web/nginx/html";&#125; location /images &#123; root "/ngx/html";&#125; error_page 404 /xx.html; location = /xx.html&#123; root "/etc/nginx/error/"&#125; &#125; 11、try_files file … uri; 定义客户端请求的相关配置 12、keepalive_timeout timeout [header_timeout]; 设定保持连接的超时时长，0表示禁止长连接；默认为75s； 13、keepalive_requests number; 在一次长连接上所允许请求的资源的最大数量，默认为100; 14、keepalive_disable none | browser …; 对哪种浏览器禁用长连接； 15、send_timeout time; 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长； 16、client_body_buffer_size size; 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； 17、client_body_temp_path path [level1 [level2 [level3]]]; 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/client_body 1 2 2 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 对客户端进行限制的相关配置 18、limit_rate rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制； 19、limit_except method … { … } 限制对指定的请求方法之外的其它方法的使用客户端； 1234limit_except GET &#123; allow 192.168.1.0/24; deny all; &#125; 文件操作优化的配置 20、aio on | off | threads[=pool]; 是否启用aio功能； 21、directio size | off; 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m; 22、open_file_cache off; open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息： (1) 文件的描述符、文件大小和最近一次的修改时间； (2) 打开的目录结构； (3) 没有找到的或者没有权限访问的文件的相关信息； max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现缓存管理； inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项； 23、open_file_cache_valid time; 缓存项有效性的检查频率；默认为60s; 24、open_file_cache_min_uses number; 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项； 25、open_file_cache_errors on | off; 是否缓存查找时发生错误的文件一类的信息；modules模块ngx_http_access_module模块：实现基于ip的访问控制功能 26、allow address | CIDR | unix: | all; 27、deny address | CIDR | unix: | all; http, server, location, limit_except 该ngx_http_access_module模块允许限制对某些客户端地址的访问。 访问也可以通过 密码，子请求的 结果或JWT来限制。通过地址和密码同时限制访问由satisf指令控制。 1234567891011示例配置（默认为allow）location / &#123; deny 192.168.1.1; #单独拒绝此地址 allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; # 拒绝所有&#125;按顺序检查规则，直到找到第一个匹配项。在此示例中，仅允许IPv4网络访问 10.1.1.0/16并且192.168.1.0/24 不包括地址192.168.1.1，以及IPv6网络2001:0db8::/32。如果有很多规则， 最好使用 ngx_http_geo_module模块变量。 ngx_http_auth_basic_module模块:实现基于用户的访问控制，使用basic机制进行用户认证； 28、auth_basic string | off; 29、auth_basic_user_file file; 1234567 location /admin/ &#123; alias /webapps/app1/data/; auth_basic "Admin Area"; #注释信息 auth_basic_user_file /etc/nginx/.ngxpasswd; #放置授权加密可以访问的用户名密码文件路径&#125; 注意：htpasswd命令由httpd-tools所提供； 范例：基于ngx_http_auth_basic_module模块:实现基于用户的访问控制，使用basic机制进行用户认证 1234567891011121314151617181920212223242526272829303132333435363738配置nginx实现basic加密认证访问 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/ngx/html"; location / &#123; auth_basic "prvate images"; #注释信息 auth_basic_user_file "/etc/nginx/.ngxpasswd"; #存放用户名密码的文件定义 &#125; &#125;安装htpasswd命令htpasswd命令由httpd-tools所提供 ~]# yum install httpd-tools -y创建存放实现加密的用户名和密码文件 -c 仅用于第一次创建用户时使用 -m 指定MD5加密算法 -b 直接给定密码，不使用交互式 ~]# htpasswd -c -m /etc/nginx/.ngxpasswd daizhe New password: centos Re-type new password: centos Adding password for user daizhe #创建daizhe用户 ~]# htpasswd -m -b /etc/nginx/.ngxpasswd nn centos Adding password for user nn查看创建的加密的账号以及测试访问 ~]# cat /etc/nginx/.ngxpasswd daizhe:$apr1$5kVocZ7d$KIumQtuh5wGySn0iUomd30 nn:$apr1$ayW.DtQE$sN5QCmC4enr.a1rUkTHHK0 ~]# nginx -t ~]# nginx -s reload测试 ngx_http_stub_status_module模块：用于输出nginx的基本状态信息； 30、stub_status; 配置示例： 12345678910111213141516171819202122232425262728293031323334location /basic_status &#123; stub_status; &#125; ``` - Active connections: 291 - server accepts handled requests- 16630948 16630948 31070465 - Reading: 6 Writing: 179 Waiting: 106 - Active connections: 活动状态的连接数； - accepts：已经接受的客户端请求的总数； - handled：已经处理完成的客户端请求的总数； - requests：客户端发来的总的请求数； - Reading：处于读取客户端请求报文首部的连接的连接数； - Writing：处于向客户端发送响应报文过程中的连接数； - Waiting：处于等待客户端发出请求的空闲连接数；范例：ngx_http_stub_status_module模块：用于输出nginx的基本状态信息；```bash~]# vim /etc/nginx/nginx.conf &#125; location = /ngx_status &#123; #声明访问指定的location可以查看nginx的基本状态信息 stub_status; &#125;~]# nginx -t~]# nginx -s reload~]# curl 172.20.101.158:8080/ngx_status Active connections: 1 server accepts handled requests 9 9 8 Reading: 0 Writing: 1 Waiting: 0 ngx_http_log_module模块:ngx_http_log_module模块以指定的格式写入请求日志。 (访问日志) 31、log_format name string ...; string可以使用nginx核心模块及其它模块内嵌的变量； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#string可以使用nginx核心模块及其它模块内嵌的变量#string可以命名为一下变量$bytes_sent发送到客户端的字节数$connection连接序列号$connection_requests通过连接发出的当前请求数（1.1.18）$msec以秒为单位的时间，日志写入时的分辨率为毫秒$pipe“ p”如果请求是流水线的，“ .”否则$request_length请求长度（包括请求行，标题和请求正文）$request_time以毫秒为单位请求处理时间（以秒为单位）; 从客户端读取第一个字节之间经过的时间，并将最后一个字节发送到客户端后的日志写入$status回应状态$time_iso8601当地时间采用ISO 8601标准格式$time_local通用日志格式的本地时间$remote_addr 远程客户端地址$http_referer引用者（盗链）$http_user_agent客户端浏览器$http_x_forwarded_for真实发起请求的客户端地址，而不是显示代理服务器的地址~]# curl -e "www.baidu.com" 172.20.101.158:8080/ngx_status~]# cat /var/log/nginx/access.log 172.20.101.158 - - [10/Jan/2019:10:18:57 +0800] "GET /ngx_status HTTP/1.1" 200 100 "www.baidu.com" "curl/7.29.0" "-"按字母顺序排列的变量索引http://nginx.org/en/docs/varindex.html#查看安装完nginx默认定义的日志的格式#默认放置在http上下文，对所有的sever生效http &#123; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"';#调用此日志格式access_log /var/log/nginx/access.log main; 32、access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; 访问日志文件路径，格式及相关的缓冲的配置； buffer=size flush=time 33、open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; #关闭 缓存各日志文件相关的元数据信息； max：缓存的最大文件描述符数量； min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项； inactive：非活动时长； valid：验正缓存中各缓存项是否为活动项的时间间隔； ngx_http_gzip_module：(压缩传输)ngx_http_gzip_module模块是一个过滤器，它使用“gzip”方法压缩响应。这通常有助于将传输数据的大小减少一半甚至更多 1、gzip on | off; （总开关，是否开启压缩功能）#cpu资源紧缺尽量不要压缩，节省带宽，cpu不紧缺则可以考虑开启压缩传输（对文本文件进行压缩，其他格式的文件内容本身就是压缩的，压缩比不大，或许还可以增长） 2、gzip_comp_level level; 设置响应的gzip压缩级别。可接受的值在1到9之间。（数字越大，压缩比越高，也越消耗cpu） 3、 gzip_disable regex …; 禁用“User-Agent”头字段匹配任何指定正则表达式的请求的响应gzipping。 4、 gzip_min_length length; 启用压缩功能的响应报文大小阈值； (资源压缩的最小下限阀值，一个资源已经3k了还怎么压缩，设置最小的下限) 5、gzip_buffers number size; 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小；（内存资源较为充沛时启用，可以加速压缩的速度） 6、gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any …; nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； off：对代理的请求不启用压缩 no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的Cache-Control的值为此三者中任何一个，则启用压缩功能； any：对任何可以压缩的内容都压缩 7、gzip_types mime-type …; 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；（纯文本和html格式的内容默认就是压缩的内容） 范例：启用压缩123456789101112131415161718192021222324252627定义服务器的压缩功能#定义在http上下文对所有的server都生效，定义在单独的server中仅对单个server生效 ~]# vim /etc/nginx/nginx.conf http &#123; ......... gzip on; #开启压缩 gzip_comp_level 6; #压缩比为6 gzip_min_length 64; #低于64个字节则不压缩 gzip_proxied any; #任何被代理的内容都压缩 gzip_types text/xml text/css application/javasctipt; #压缩的文件类型 ......... ~]# nginx -t ~]# nginx -s reload使用curl命令请求服务端进行压缩 ~]# curl --compressed -I 172.20.101.158 HTTP/1.1 200 OK Server: nginx/1.12.2 Date: Thu, 10 Jan 2019 03:39:11 GMT Content-Type: text/html Last-Modified: Thu, 10 Jan 2019 03:24:04 GMT Connection: keep-alive ETag: W/"5c36bad4-1293ae" Content-Encoding: gzip测试 ngx_http_ssl_module模块：（PKI现代公钥加密的基础设施） 1、 ssl on | off; 为给定的虚拟服务器启用HTTPS协议。 2、ssl_certificate file; 当前虚拟主机使用PEM格式的证书文件； 3、ssl_certificate_key file; 当前虚拟主机上与其证书匹配的私钥文件； 4、ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; 支持ssl协议版本，默认为后三个； 5、ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； [shared:name:size]：在各worker之间使用一个共享的缓存； 6、ssl_session_timeout time; 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； 范例：ssl加密传输nginx12345678910111213141516171819202122232425262728 ~]# vim /etc/nginx/nginx.conf server &#123; listen 443 ssl; ssl_protocols TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #加密算法，不写使用默认的加密算法 ssl_certificate /etc/nginx/certs/nginx.crt; #私钥 ssl_certificate_key /etc/nginx/certs/nginx.key; #证书 ssl_session_cache shared:SSL:10m; #加密传输的缓存的大小10m ssl_session_timeout 10m; location / &#123; root "/web/nginx/html" &#125; &#125; 生成自签名的证书 ~]# cd /etc/nginx/ nginx]# mkdir certs nginx]# cd certs/ certs]# openssl genrsa -out nginx.key 2048 #私钥 certs]# openssl req -new -x509 -key nginx.key -out nginx.crt -days 3650 -subj "/CN=www.centos.com" #证书测试 ~]# mkdir -p /web/nginx/html ~]# echo "123" &gt; /web/nginx/html/index.html ~]# nginx -t ~]# nginx -s reload ngx_http_rewrite_module模块：实现url重写，将用户请求的URI基于regex所描述的模式进行检查，而后完成替换； 1、rewrite regex replacement [flag] 将用户请求的URI基于regex所描述的模式进行检查，匹配到时将其替换为replacement指定的新的URI； 注意：如果在同一级配置块中存在多个rewrite规则，那么会自下而下逐个检查；被某条件规则替换完成后，会重新一轮的替换检查，因此，隐含有循环机制；[flag]所表示的标志位用于控制此循环机制； 如果replacement是以http://或https://开头，则替换结果会直接以重向返回给客户端； 301：永久重定向； [flag]： last：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后对新的URI启动新一轮重写检查；提前重启新一轮循环； break：重写完成后停止对当前URI在当前location中后续的其它重写操作，而后直接跳转至重写规则配置块之后的其它配置；结束循环； redirect：重写完成后以临时重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；302：临时重定向 permanent:重写完成后以永久重定向方式直接返回重写后生成的新URI给客户端，由客户端重新发起请求；301：永久重定向 范例：将用户对bbs的访问，转成对forum的访问12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667~]# mkdir /web/nginx/html/forum~]# echo "/web/nginx/html/forum/index.html" &gt; /web/nginx/html/forum/index.html#此时对forum/index.html访问url路径为：http://172.10.101.158/forum实现用户访问http://172.10.101.158/bbs跳转到http://172.10.101.158/forum响应（bbs目录本机可以不存在）~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/var/www/nginx"; location /bbs/ &#123; rewrite ^/bbs/(.*)$ /forum/$1; #后面未加任何控制符相当于last，$1为后向引用&#125;&#125; #如果访问此server的/var/www/nginx/bbs则重写到此server的/var/www/nginx/forum(此格式仅限单个的重写操作写法)设置用户对bbs的访问和对forum的访问统统改为其他的其他的server访问http://www.centos.com/bbs和http://www.centos.com/forum响应的访问请求一个新的serverwww.linux.com的访问 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name www.centos.com; root "/var/www/nginx"; location ~* ^/(bbs|forum) &#123; rewrite ^/(bbs|froum)/(.*)$ http://www.linux.com/$2;&#125;&#125; server &#123; server_name www.linux.com; listen 8080; root "/web/nginx/forum";&#125;实现对本机的任何的不安全的172.20.101.158下的所有资源都会跳转到www.centos.com的https server &#123; 66 listen 443 ssl; 67 server_name www.centos.com 68 ssl_protocols TLSv1.1 TLSv1.2; 69 ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4- MD5; 70 ssl_certificate /etc/nginx/certs/nginx.crt; 71 ssl_certificate_key /etc/nginx/certs/nginx.key; 72 ssl_session_cache shared:SSL:10m; 73 ssl_session_timeout 10m; 74 location / &#123; 75 root "/web/nginx/html"; 76 &#125; 77 &#125; 78 7 80 server &#123; 81 listen 8080; 82 server_name 172.20.101.158; 83 root "/var/www/nginx"; 84 rewrite ^/(.*)$ https://centos.com/$1; 85 location / &#123; 86 &#125; 87 &#125;临时重定向 rewrite ^/(.*)$ https://centos.com/$1 redirect;永久重定向 rewrite ^/(.*)$ https://centos.com/$1 permanent; 2、return return code [text]; return code URL; return URL; 3、 rewrite_log on | off; 是否开启重写日志； 4、 if (condition) { … } 引入一个新的配置上下文 ；条件满足时，执行配置块中的配置指令；一般用在：server, location； condition： 比较操作符： == != ~：模式匹配，区分字符大小写； ~*：模式匹配，不区分字符大小写； !~：模式不匹配，区分字符大小写； !~*：模式不匹配，不区分字符大小写； 文件及目录存在性判断： -e, !-e -f, !-f -d, !-d -x, !-x 5、set $variable value; #在nginx里自己定义变量 用户自定义变量 ； ngx_http_referer_module模块：ngx_http_referer_module模块用于阻止“Referer”头字段中值无效的请求访问站点。引用者，显示上级url的来源（盗链） 1、valid_referers none | blocked | server_names | string …; 定义referer首部的合法可用值(合法的链接)； none：请求报文首部没有referer首部； blocked：请求报文的referer首部没有值； server_names：参数，其可以有值作为主机名或主机名模式； arbitrary_string：直接字符串，但可使用*作通配符； regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*.a.com； 范例:防盗链123456789101112131415161718#定义正常引用和非正常引用链接的跳转 ~]# vim /etc/nginx/nginx.conf server &#123; listen 8080; server_name 172.20.101.158; valid_referers none blocked server_name 172.20.101.158 172.20.101.82 *.centos.com; #定义允许外链访问的地址 if ($invalid_referer) &#123; #除了上面定义的地址外可以外链访问主页，其余的地址直接跳转至http://172.20.101.158:8080/; return http://172.20.101.158:8080/&#125; root "/var/www/nginx"; rewrite ^/(.*)$ https://www.daizhe.111/$1; location / &#123;&#125;&#125;-e 模拟外链来的地址~]# curl -I -e "www.baidu.com" http://172.20.101.158/]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置和使用基础--Webserver]]></title>
    <url>%2F2019%2F01%2F07%2Fnginx%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Nginx-Webserver:第一章：工作模型 Nginx简介一、Nginx的产生 Nginx是一款高性能的 HTTP 和反向代理服务器，由俄罗斯人Igor Sysoev（伊戈尔·赛索耶夫）为俄罗斯网站Rambler.ru开发的，在Rambler.ru网站平稳的运行了四年，而且俄俄罗斯超过20%的虚拟主机平台采用Nginx作为反向代理服务器。 在国内，使用nginx网站用户有：百度、京东、金山爱词霸、新浪、校内网、、淘宝、YUPOO相册、豆瓣、迅雷看看、网易、腾讯等。 二、Nginx的优点 1.高并发量：根据官方给出的数据，能够支持高达 50,000 个并发连接数的响应 2.内存消耗少：处理静态文件，同样起web 服务，比apache 占用更少的内存及资源，所有它是轻量级的 3.简单稳定：配置简单，基本在一个conf文件中配置，性能比较稳定，可以7*24小时长时间不间断运行 4.模块化程度高：Nginx是高度模块化的设计，编写模块相对简单，包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter，支持 SSL 和 TLSSNI。 5.支持Rwrite重写规则：能够根据域名、URL的不同， 将HTTP请求分发到不同的后端服务器群组。 6.低成本：Nginx可以做高并发的负载均衡，且Nginx是开源免费的，如果使用F5等硬件来做负载均衡，硬件成本比较高。 7.支持多系统：Nginx代码完全用C语言从头写成，已经移植到许多体系结构和操作系统，包括：Linux、FreeBSD、Solaris、Mac OS X、AIX以及Microsoft Windows，由于Nginx是免费开源的，可以在各系统上编译并使用。 三、Nginx的缺点 1.动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，apache作为后端处理动态请求。 2.rewrite弱：虽然nginx支持rewrite功能，但是相比于Apache来说，Apache比nginx 的rewrite 强大。 nginx特征及基础概念 nginx(web 服务器、web代理、反向代理) 调用libevent:高性能的网络服务程序库 epoll():基于事件驱动的开发好的库文件 nginx特性： 模块化设计、较好的扩展性 高可靠(组成部分一个主控进程+多个子进程组成) master—&gt;worker master主控进程负责解析配置文件，启动子进程（读取和验证配置，创建或绑定关闭套接字以及启动终止worker进程以及控制worker进程的个数，无需重新启动进程让新的配置文件加载、完成平滑版本升级等..） worker子进程才是真正响应用户请求的进程（worker子进程有多种种类：有的子进程是实现缓存加载多适用于反向代理、接受用户的请求-接收传入并处理客户端的连接请求，cache实现缓存） 低内存消耗（一个线程相应多个请求） 10000个保持连接状态模式下的连接nginx仅需2.5MB的内存 支持热部署 不停机而且更新配置文件、日志文件滚动、升级程序版本 nginx的基本功能 支持event模型 支持epool机制 支持异步IO（事件驱动） 支持内存映射 基本功能 静态资源的web服务器，能缓存打开的文件描述符 支持http、smtp、pop3协议的反向代理服务器（缓存加速、缓存在本地是基于键值对关系缓存的，键是用户请求的url,值为对应的取得的数据流极大的减轻了后端服务器的压力） 反向代理服务器：仅为接受用户请求并且自行到某个有限的服务器上去取内容（只要是把自己扮演成某个特定服务器的样子） 正向代理：代表客户端出去请求任何网站(把自己扮演成所有服务器的样子) 支持缓存加速、负载均衡机制（反向代理） 支持fastcgi(fpm,LNMP),uWSGI(python)等 模块化（非DSO机制）、过滤器zip，SSI（服务器端包含）及图像打大小调整 支持ssl 扩展功能 基于名称和ip和端口的虚拟主机 支持keepalive 支持平滑升级 定制访问日志、支持日志缓冲区 支持路径别名 支持基于ip以及用户的访问控制 支持速率限制、支持并发数限制 nginx的基本架构特性 一个master进程，生成一个或者多个worker进程 事件驱动：epoll（边缘触发）、Kqueue,/dev/poll IO复用器 select,poll,rt signal(实时信号) 支持sendfile,sendfile64 支持AIO（异步IO） 支持非阻塞模型 支持内存映射（mmap） nginx工作模式：基于非阻塞、事件驱动、由一个master进程生成多个worker线程，每一个worker响应n个请求 一般单机并发3w请求，在反代的情况下会影响其性能 nginx的模块类型 核心模块 标准的http模块（Standard http modules） 可选的http模块（Optional http modules ） 邮件模块（Mail modules） 第三方模块（3rd party modules） nginx是基于epel源安装nginx的安装配置： 官方的预制包： http://nginx.org/packages/centos/7/x86_64/RPMS/ Fedora-EPEL: 1234567891011121314151617181920212223yum安装 yum install nginx 编译安装： ~]# yum groupinstall "Development Tools" "Server Platform Development" ~]# yum install pcre-devel openssl-devel zlib-devel ~]# useradd -r nginx ~]# ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aio # make &amp;&amp; make installnginx -t #检查nginx语法格式nginx -s relod #重新服务配置文件man nginx -s signal Send a signal to the master process. The argument signal can be one of: stop, quit, reopen, reload. The following table shows the cor‐ responding system signals: stop SIGTERM quit SIGQUIT reopen SIGUSR1 reload SIGHUP]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议及io模型]]></title>
    <url>%2F2019%2F01%2F06%2Fio%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[http协议及io模型 HTTP 协议和IO模型一：HTTP协议 http协议：HyperText Transfer Procotol超文本传输协议，http协议是无状态的，监听在80端口，TCP协议上。HTTP协议的特点有以下几点： 1.支持客户/服务器模式。 2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。 由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 二：HTTP协议Procatol 在服务器不是持久连接的状况下，客户端在第一次访问服务器时服务器会记录客户端的个人标志信息，当客户端刷新或者再次访问时，服务器就要要求客户端输个人的标识信息，记录访问者的信息。也就是说在不是持久连接的状况下，服务器无法追踪访问者的来源。 1.于是就出现了 cookie和session html：HyperText Mark Language：超文标记语言 web资源： 静态文件：.jpg .gif .html .txt .js .css.mp3 .avi 动态文件：.php .jsp 2.http早期版本只能传输文本内容，到HTTP/1.0之后支持MIME。使HTTP协议支持传输多媒体信息。 MIME：Multipurpose Internet Mailextention MIME类型：Major/minor text/plain image/jpeg image/gif 3.URI:Uniform Resource Idetifier ：统一资源标识符 URL：Uniform Resource Locate：统一资源定位符 用于描述某服务特定资源的位置 格式：Scheme://Server:Poert/Path/to/resource URN：Uniform Resource Naming：统一资源命名符。 URL方案：scheme 服务器地址：IP：Port 资源路径 基本语法： &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; 4.http事务 （请求—&gt;响应） request:请求报文 报文格式 &lt;method&gt;&lt;URL&gt;&lt;version&gt;&lt;HEADERS&gt;&lt;body&gt; 请求的方法.url.协议版本.请求报文的首部.主体 response:响应报文 响应报文 &lt;version&gt;&lt;status&gt;&lt;reason phrase&gt;&lt;HEADERS&gt;&lt;body&gt; 协议的版本.状态码.原因短语.响应报文的首部.主体 协议格式 文本 二进制 5.method：请求的方法： 常用请求的方法： GET：从服务器获取一个资源 HEAD：只从服务器获取文档的响应首部 POST：向服务器发送要处理的数据 PUT：将请求的主题部分存储服务器上 DEETE：强求删除服务器上指定的文档 TRACE：追踪请求到达服务器中间经过的代理服务器 OPTIONS：请求服务器返回对指定资源支持使用的请求方法 6.status(状态码)：告诉客户端的请求发生的结果： 1XX：100-101，信息提示 2XX：200-206，成功类型信息 3XX：300-305，重定向的资源 4XX：400-415，错误类型的信息，客户端的错误， 5XX：500-505，错误类型错误，服务器端错误 常用的状态码： 200：:成功响应，请求的所有数据通过相应报文的entity-body部分发送，OK 301：请求的URL执行的资源已经被删除；但在相应报文中通过首部Location指明了资源的所在位置；Moved Permanently （永久重定向） 302：与301相似，但在相应报文中通过首部Location指明了资源现在所处临时新位置；Found （临时重定向） 304：客户端发出了条件式请求，但服务器的资源为曾发生改变，则通过相应此响应状态码通知客户端，Not Modified 401：需要输入账号和密码认证方能访问资源：Unauthorized 403：请求被禁止：Forbidden 404：服务器无法找到客户端请求的资源：Not Found 500：服务器内部错误：InternalServerError 502：:代理服务器从后端服务器中收到的一条伪响应：Bad Gateway 7.hearders首部： 通用首部： Date：报文的创建时间 Connection：连接状态，keep-alive,close via：显示报文经过的中间节点 Cache-Control：控制缓存 no-cache： max-age Transfer-Encoding WEB 服务器表明自己对本响应消息体（不是消息体里面的对象）作了怎样的编码，比如是否分块（chunked），例如：Transfer-Encoding: chunked pragma 上图为请求首部： Accept：通过服务器自己能够接受的媒体类型 Accept_Charset Accept_Encoding：告诉服务器自己能接受的编码格式，如gzip Accept-Language：通知服务器自己能接受的语言 Host：请求的服务器名称或者端口号 Referer：包含了当前正在请求的资源的上一级资源。 User-Agent：客户端代理 7.1条件式请求首部 Expect： If-Modified-Since：自从指定的时间之后，请求的资源是否发生过修改 If-Unmodufied-Since： If-None-Match：本地缓存中存储的文档的ETag标签是否与服务器文档的Etag不匹配。 If-Match; 7.2安全请求首部： Authorization:向服务器发送认证信息，如账号密码 Cookie：客户端向服务器发送cookie Cookie2： 7.3代理请求首部： Proxy-authorization:向代理服务器认证 8.响应首部： 信息性： Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多种表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其他首部列表 安全响应首部： Set-Cookie：向客户端设置Cookie Set-Cookie2 WWW-Authenticate：来自服务器的对客户端质询认证表单 9.实体首部： Allow：列出次实体可使用的请求方法： Location：告诉客户端真正的实体位于何处 Content-encoding：编码格式 Content-language Content-Length：实体的长度 Content-Location：实体真正所在的位置 Content-Type：主体的对象类型 缓存相关： Etag:实体的扩展标签 Expires：实体的过期时间 三：web页面，多个资源 浏览器自身的限制是针对于单一域名访问的限制，最多能打开几个线程进行访问，。而在一个公司网站使用多个域名的话，当用户使用浏览器访问时，浏览器会针对不同的域名开启多个线程来访问页面资源。如，在单一域名 www.nginx.com进行访问，浏览器可能开启2个线程进行页面资源的访问。假如在 www.nginx.com 域名下的图片资源又单独使用一个域名 www.image.com 。那么浏览器会再次开启两个线程进行访问。所以在公司内部使用多个域名，这也是提升访问速度的一种方法。 1.web服务器的认证： 基于IP认证： 基于用户认证： basic认证 digest认证 2.web服务器的资源映射 a.DocumentRoot b.路径别名Alias c.虚拟主机DocumentRoot b.用户家目录DocumentRoot 3.支持第三方模块：支持模块的动态加载 四：一次完整的http请求 （1）建立连接或处理连接：接收客户端请求或拒绝请求 （2）接收请求 接收来自网络的请求报文对某一个资源的请求 并发服务器访问响应模型（Web I/O） 单进程I/O机结构：启动一个进程处理用户请求，而且一次只处理一个请求，多个请求被串行响应。 多进程I/O结构：并行启动多个线程，每个进程响应一个请求，一个请求称为一个pv。 复用I/O 结构：一个进程响应多个n个请求 多线程模型：一个进程生成多个线程，每个线程响应一个用户请求。 事件驱动机制：事件回调来完成事件请求：event-driven 复用的多进程I/O结构：启动多个（m）进程，每个进程响应n个请求。 c10K问题 :1w个并发连接： （3）处理请求：对请求报文进行解析，并获取请求的资源及请求方法等相关信息 元数据：请求报文首部 请求方法&lt;method&gt; &lt;method&gt;&lt;URL&gt;&lt;VerSion&gt; （4）访问资源:获取请求报文中请求的资源 web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源，这些资源放置在本地文件系统某路径下，此路径通常为DocRoot web服务器资源路径的映射方式： a.docroot b.路径别名 c.虚拟主机docroot b.用户家目录docroot 5）构建响应报文 MIME类型： 显示分类 魔法分类 协商分类 URL重定向： cdn web服务构建的响应并非客户端请求的资源，而是资源另一个访问路径。 游走重定向： 永久重定向： （6）发送响应报文 （7）记录日志 五：I/O模型 (1)I/O类型： 同步IO和异步IO：synchronous ,asyncronous：关注的是消息通知机制 同步：调用发出之后不会立即返回，但一旦返回，则返回最终结果。 异步：调用发出之后，被调用方立即返回消息，但返回的并不是最终结果被调用者通过状态，通知机制等通知调用者，或通过回调函数来处理结果。 阻塞IO和非阻塞IO：nlock，nonlock：关注的是调用者等待被调用者返回调用结果时的状态：（调用者的状态） 阻塞：调用结果返回之前，调用者会被挂起；调用真只有在得到调用结果之后才能继续。 非阻塞：调用者在调用结果返回之前，不会被挂起，即调用不会阻塞调用者 (2)常用的IO模型： blocking IO ：阻塞型IO noblocking IO 非阻塞型IO IO multiplexing：复用型IO signal driven IO：事件驱动型IO asynchronnous IO：异步型IO 通过磁盘IO总体解释： 一个用户进程发起一次磁盘IO调用时，将有两个阶段组成，一次是内核向磁盘取数据，存放到内存空间，另一次是数据从内存空间取出，将数据存到用户进程的内存中。真正被称为执行IO的阶段是：数据从内核内存到进程内存的过程。 阻塞型IO： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对磁盘read来说内核从磁盘获取数据）。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被block了。 实际上，除非特别指定，几乎所有的IO接口 ( 包括socket接口 ) 都是阻塞型的。这给网络编程带来了一个很大的问题，如在调用send()的同时，线程将被阻塞，在此期间，线程将无法执行任何运算或响应任何的网络请求。 一个简单的改进方案是在服务器端使用多线程（或多进程）。多线程（或多进程）的目的是让每个连接都拥有独立的线程（或进程），这样任何一个连接的阻塞都不会影响其他的连接。具体使用多进程还是多线程，并没有一个特定的模式。传统意义上，进程的开销要远远大于线程，所以如果需要同时为较多的客户机提供服务，则不推荐使用多进程；如果单个服务执行体需要消耗较多的CPU资源，譬如需要进行大规模或长时间的数据运算或文件访问，则进程较为安全。 非阻塞IO： 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 复用型IO： 内核提供了两种调用，select（），poll(),当用户进程发起系统调用时，内核中的selecte会接受这个系统调用，并select自身将系统调用发送给内核，内核再进行准备数据和拷贝数据。当用户进程发起一次系统调用给select之后，用户进程在等待数据返回的过程中，还可以发起多次系统调用，每次系统调用都要经过select发送内核进行处理。也就是说，selects是一个代理。比如，（例子不是很恰当）公司老板向人事部发布通知要裁员，此时老板通过助理把裁员名单送给人事部。在发送和得到结果之前，公司老板还可以通过助理让销售部经理来老板办公室。其实这就相当于复用IO的模型，助理就相当于select。 select不能超过1024个。 prefork模型和worker模型就是基于复用IO模型的。并发响应有限。 调用者被阻塞者select上，但可以处理其他请求或IO 事件驱动型IO： 事件驱动型IO： 在第一阶段内：当用户进程发起系统调用时，内核会立即通知给用户进程系统调用已经收到，并且会在数据收集和准备完成时通知用户进程。此时用户进程就可以处理其他事物。 在第二阶段内：当系统将磁盘数据取到内存空间中后，通知调用者，调用者会使用回调函数进行处理，来获取数据。这个阶段会发生阻塞状况。 假如一个用户进程在第一次发送系统调用请求后，在第一阶段内，继续发送第二次系统调用请求。当用户进程第一次请求被阻塞第二阶段时，内核告知用户进程，第二次请求的数据也已经准备好了，让用户进程来获取。此时就出现了冲突状态 通知机制： 水平触发：多次通知 边缘触发：只通知一次： event模型就是使用的此IO模型。 Nginx支持此IO模型，采用的通知机制为边缘触发。 异步型IO： 异步IO模型和复用IO模型区别之处就是：在数据准备第二阶段，内核将数据直接存放到用户进程的内存空间中，不需要用户进程使用回调函数从内核中获取数据。如当一个web服务进程发送请求后，后续过程直接交给内核，在内核处理的过程时间内，此进程可以响应其他的用户请求。当内核将数据返回到进程内存中后，进程就可以把数据直接返回给用户，这大大提高了响应的速度。 Nginx也支持异步IO模型，还可以基于内存映射的机制来完成数据的发放、所以说Nginx并发能力强。 几种IO模型的比较:]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四层调度和七层调度器的区别]]></title>
    <url>%2F2019%2F01%2F05%2F%E5%9B%9B%E5%B1%82%E8%B0%83%E5%BA%A6%E5%92%8C%E4%B8%83%E5%B1%82%E8%B0%83%E5%BA%A6%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[四层调度和七层调度器的区别 （一） 简单理解四层和七层负载均衡: 1.所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。 2.所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。 比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。 3.负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。 1负载均衡分为L4 switch（四层交换），即在OSI第4层工作，就是TCP层啦。此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）。例子：LVS，F5。 2另一种叫做L7 switch（七层交换），OSI的最高层，应用层。此时，该Load Balancer能理解应用协议。例子： haproxy，MySQL Proxy。 注意：上面的很多Load Balancer既可以做四层交换，也可以做七层交换。 （二） 负载均衡设备也常被称为”四到七层交换机”，那么四层和七层两者到底区别在哪里？ 第一，技术原理上的区别。 所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。 - `所谓七层负载均衡`，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。 - 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。 第二，应用场景的需求。 七层应用负载的好处，是使得整个网络更”智能化”。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。 另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。 现在的7层负载均衡，主要还是着重于应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。 4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。 第三，七层应用需要考虑的问题。 1：是否真的必要，七层应用的确可以提高流量智能化，同时必不可免的带来设备配置复杂，负载均衡压力增高以及故障排查上的复杂性等问题。在设计系统时需要考虑四层七层同时应用的混杂情况。 2：是否真的可以提高安全性。例如SYN Flood攻击，七层模式的确将这些流量从服务器屏蔽，但负载均衡设备本身要有强大的抗DDoS能力，否则即使服务器正常而作为中枢调度的负载均衡设备故障也会导致整个应用的崩溃。 3：是否有足够的灵活度。七层应用的优势是可以让整个应用的流量智能化，但是负载均衡设备需要提供完善的七层功能，满足客户根据不同情况的基于应用的调度。最简单的一个考核就是能否取代后台Nginx或者Apache等服务器上的调度功能。能够提供一个七层应用开发接口的负载均衡设备，可以让客户根据需求任意设定功能，才真正有可能提供强大的灵活性和智能性。 （本节出自 “ADC技术博客” 博客，请务必保留此出处http://virtualadc.blog.51cto.com/3027116/591396） （三） 负载均衡四七层介绍: 负载均衡（Load Balance）建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。 负载均衡有两方面的含义：首先，大量的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间；其次，单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高。 本文所要介绍的负载均衡技术主要是指在均衡服务器群中所有服务器和应用程序之间流量负载的应用，目前负载均衡技术大多数是用于提高诸如在Web服务器、FTP服务器和其它关键任务服务器上的Internet服务器程序的可用性和可伸缩性。 负载均衡技术分类 目前有许多不同的负载均衡技术用以满足不同的应用需求，下面从负载均衡所采用的设备对象、应用的网络层次（指OSI参考模型）及应用的地理结构等来分类。 软/硬件负载均衡 软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，如DNS Load Balance，CheckPoint Firewall-1 ConnectControl等，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。 软件解决方案缺点也较多，因为每台服务器上安装额外的软件运行会消耗系统不定量的资源，越是功能强大的模块，消耗得越多，所以当连接请求特别大的时候，软件本身会成为服务器工作成败的一个关键；软件可扩展性并不是很好，受到操作系统的限制；由于操作系统本身的Bug，往往会引起安全问题。 硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。 负载均衡器有多种多样的形式，除了作为独立意义上的负载均衡器外，有些负载均衡器集成在交换设备中，置于服务器与Internet链接之间，有些则以两块网络适配器将这一功能集成到PC中，一块连接到Internet上，一块连接到后端服务器群的内部网络上。 一般而言，硬件负载均衡在功能、性能上优于软件方式，不过成本昂贵。 本地/全局负载均衡 负载均衡从其应用的地理结构上分为本地负载均衡(Local Load Balance)和全局负载均衡(Global Load Balance，也叫地域负载均衡)，本地负载均衡是指对本地的服务器群做负载均衡，全局负载均衡是指对分别放置在不同的地理位置、有不同网络结构的服务器群间作负载均衡。 本地负载均衡能有效地解决数据流量过大、网络负荷过重的问题，并且不需花费昂贵开支购置性能卓越的服务器，充分利用现有设备，避免服务器单点故障造成数据流量的损失。其有灵活多样的均衡策略把数据流量合理地分配给服务器群内的服务器共同负担。即使是再给现有服务器扩充升级，也只是简单地增加一个新的服务器到服务群中，而不需改变现有网络结构、停止现有的服务。 全局负载均衡主要用于在一个多区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度，也可用于子公司分散站点分布广的大公司通过Intranet（企业内部互联网）来达到资源统一合理分配的目的。 网络层次上的负载均衡 针对网络上负载过重的不同瓶颈所在，从网络的不同层次入手，我们可以采用相应的负载均衡技术来解决现有问题。 随着带宽增加，数据流量不断增大，网络核心部分的数据接口将面临瓶颈问题，原有的单一线路将很难满足需求，而且线路的升级又过于昂贵甚至难以实现，这时就可以考虑采用链路聚合（Trunking）技术。 链路聚合技术（第二层负载均衡）将多条物理链路当作一条单一的聚合逻辑链路使用，网络数据流量由聚合逻辑链路中所有物理链路共同承担，由此在逻辑上增大了链路的容量，使其能满足带宽增加的需求。 现代负载均衡技术通常操作于网络的第四层或第七层。第四层负载均衡将一个Internet上合法注册的IP地址映射为多个内部服务器的IP地址，对每次 TCP连接请求动态使用其中一个内部IP地址，达到负载均衡的目的。在第四层交换机中，此种均衡技术得到广泛的应用，一个目标地址是服务器群VIP（虚拟 IP，Virtual IP address）连接请求的数据包流经交换机，交换机根据源端和目的IP地址、TCP或UDP端口号和一定的负载均衡策略，在服务器IP和VIP间进行映射，选取服务器群中最好的服务器来处理连接请求。 第七层负载均衡控制应用层服务的内容，提供了一种对访问流量的高层控制方式，适合对HTTP服务器群的应用。第七层负载均衡技术通过检查流经的HTTP报头，根据报头内的信息来执行负载均衡任务。 第七层负载均衡优点表现在如下几个方面： 通过对HTTP报头的检查，可以检测出HTTP400、500和600系列的错误信息，因而能透明地将连接请求重新定向到另一台服务器，避免应用层故障。 可根据流经的数据类型（如判断数据包是图像文件、压缩文件或多媒体文件格式等），把数据流量引向相应内容的服务器来处理，增加系统性能。 能根据连接请求的类型，如是普通文本、图象等静态文档请求，还是asp、cgi等的动态文档请求，把相应的请求引向相应的服务器来处理，提高系统的性能及安全性。 第七层负载均衡受到其所支持的协议限制（一般只有HTTP），这样就限制了它应用的广泛性，并且检查HTTP报头会占用大量的系统资源，势必会影响到系统的性能，在大量连接请求的情况下，负载均衡设备自身容易成为网络整体性能的瓶颈。 负载均衡策略 在实际应用中，我们可能不想仅仅是把客户端的服务请求平均地分配给内部服务器，而不管服务器是否宕机。而是想使Pentium III服务器比Pentium II能接受更多的服务请求，一台处理服务请求较少的服务器能分配到更多的服务请求，出现故障的服务器将不再接受服务请求直至故障恢复等等。 选择合适的负载均衡策略，使多个设备能很好的共同完成任务，消除或避免现有网络负载分布不均、数据流量拥挤反应时间长的瓶颈。在各负载均衡方式中，针对不同的应用需求，在OSI参考模型的第二、三、四、七层的负载均衡都有相应的负载均衡策略。 负载均衡策略的优劣及其实现的难易程度有两个关键因素：一、负载均衡算法，二、对网络系统状况的检测方式和能力。 考虑到服务请求的不同类型、服务器的不同处理能力以及随机选择造成的负载分配不均匀等问题，为了更加合理的把负载分配给内部的多个服务器，就需要应用相应的能够正确反映各个服务器处理能力及网络状态的负载均衡算法： 轮循均衡（Round Robin）：每一次来自网络的请求轮流分配给内部中的服务器，从1至N然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。 权重轮循均衡（Weighted Round Robin）：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。例如：服务器A的权值被设计成1，B的权值是 3，C的权值是6，则服务器A、B、C将分别接受到10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。 随机均衡（Random）：把来自网络的请求随机分配给内部中的多个服务器。 权重随机均衡（Weighted Random）：此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程。 响应速度均衡（Response Time）：负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间，而不是客户端与服务器间的最快响应时间。 最少连接数均衡（Least Connection）：客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。 处理能力均衡：此种均衡算法将把服务请求分配给内部中处理负荷（根据服务器CPU型号、CPU数量、内存大小及当前连接数等换算而成）最轻的服务器，由于考虑到了内部服务器的处理能力及当前网络运行状况，所以此种均衡算法相对来说更加精确，尤其适合运用到第七层（应用层）负载均衡的情况下。 DNS响应均衡（Flash DNS）：在Internet上，无论是HTTP、FTP或是其它的服务请求，客户端一般都是通过域名解析来找到服务器确切的IP地址的。在此均衡算法下，分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求，并在同一时间内把此域名解析成各自相对应服务器的IP地址（即与此负载均衡设备在同一位地理位置的服务器的IP地址）并返回给客户端，则客户端将以最先收到的域名解析IP地址来继续请求服务，而忽略其它的IP地址响应。在种均衡策略适合应用在全局负载均衡的情况下，对本地负载均衡是没有意义的。 尽管有多种的负载均衡算法可以较好的把数据流量分配给服务器去负载，但如果负载均衡策略没有对网络系统状况的检测方式和能力，一旦在某台服务器或某段负载均衡设备与服务器网络间出现故障的情况下，负载均衡设备依然把一部分数据流量引向那台服务器，这势必造成大量的服务请求被丢失，达不到不间断可用性的要求。所以良好的负载均衡策略应有对网络故障、服务器系统故障、应用服务故障的检测方式和能力： Ping侦测：通过ping的方式检测服务器及网络系统状况，此种方式简单快速，但只能大致检测出网络及服务器上的操作系统是否正常，对服务器上的应用服务检测就无能为力了。 TCP Open侦测：每个服务都会开放某个通过TCP连接，检测服务器上某个TCP端口（如Telnet的23口，HTTP的80口等）是否开放来判断服务是否正常。 HTTP URL侦测：比如向HTTP服务器发出一个对main.html文件的访问请求，如果收到错误信息，则认为服务器出现故障。 负载均衡策略的优劣除受上面所讲的两个因素影响外，在有些应用情况下，我们需要将来自同一客户端的所有请求都分配给同一台服务器去负担，例如服务器将客户端注册、购物等服务请求信息保存的本地数据库的情况下，把客户端的子请求分配给同一台服务器来处理就显的至关重要了。有两种方式可以解决此问题，一是根据IP地址把来自同一客户端的多次请求分配给同一台服务器处理，客户端IP地址与服务器的对应信息是保存在负载均衡设备上的；二是在客户端浏览器 cookie内做独一无二的标识来把多次请求分配给同一台服务器处理，适合通过代理服务器上网的客户端。 还有一种路径外返回模式（Out of Path Return），当客户端连接请求发送给负载均衡设备的时候，中心负载均衡设备将请求引向某个服务器，服务器的回应请求不再返回给中心负载均衡设备，即绕过流量分配器，直接返回给客户端，因此中心负载均衡设备只负责接受并转发请求，其网络负担就减少了很多，并且给客户端提供了更快的响应时间。此种模式一般用于HTTP服务器群，在各服务器上要安装一块虚拟网络适配器，并将其IP地址设为服务器群的VIP，这样才能在服务器直接回应客户端请求时顺利的达成三次握手。 负载均衡实施要素 负载均衡方案应是在网站建设初期就应考虑的问题，不过有时随着访问流量的爆炸性增长，超出决策者的意料，这也就成为不得不面对的问题。当我们在引入某种负载均衡方案乃至具体实施时，像其他的许多方案一样，首先是确定当前及将来的应用需求，然后在代价与收效之间做出权衡。 针对当前及将来的应用需求，分析网络瓶颈的不同所在，我们就需要确立是采用哪一类的负载均衡技术，采用什么样的均衡策略，在可用性、兼容性、安全性等等方面要满足多大的需求，如此等等。 不管负载均衡方案是采用花费较少的软件方式，还是购买代价高昂在性能功能上更强的第四层交换机、负载均衡器等硬件方式来实现，亦或其他种类不同的均衡技术，下面这几项都是我们在引入均衡方案时可能要考虑的问题： 性能：性能是我们在引入均衡方案时需要重点考虑的问题，但也是一个最难把握的问题。衡量性能时可将每秒钟通过网络的数据包数目做为一个参数，另一个参数是均衡方案中服务器群所能处理的最大并发连接数目，但是，假设一个均衡系统能处理百万计的并发连接数，可是却只能以每秒2个包的速率转发，这显然是没有任何作用的。性能的优劣与负载均衡设备的处理能力、采用的均衡策略息息相关，并且有两点需要注意：一、均衡方案对服务器群整体的性能，这是响应客户端连接请求速度的关键；二、负载均衡设备自身的性能，避免有大量连接请求时自身性能不足而成为服务瓶颈。有时我们也可以考虑采用混合型负载均衡策略来提升服务器群的总体性能，如DNS负载均衡与NAT负载均衡相结合。另外，针对有大量静态文档请求的站点，也可以考虑采用高速缓存技术，相对来说更节省费用，更能提高响应性能；对有大量ssl/xml内容传输的站点，更应考虑采用ssl/xml加速技术。 可扩展性：IT技术日新月异，一年以前最新的产品，现在或许已是网络中性能最低的产品；业务量的急速上升，一年前的网络，现在需要新一轮的扩展。合适的均衡解决方案应能满足这些需求，能均衡不同操作系统和硬件平台之间的负载，能均衡HTTP、邮件、新闻、代理、数据库、防火墙和 Cache等不同服务器的负载，并且能以对客户端完全透明的方式动态增加或删除某些资源。 灵活性：均衡解决方案应能灵活地提供不同的应用需求，满足应用需求的不断变化。在不同的服务器群有不同的应用需求时，应有多样的均衡策略提供更广泛的选择。 可靠性：在对服务质量要求较高的站点，负载均衡解决方案应能为服务器群提供完全的容错性和高可用性。但在负载均衡设备自身出现故障时，应该有良好的冗余解决方案，提高可靠性。使用冗余时，处于同一个冗余单元的多个负载均衡设备必须具有有效的方式以便互相进行监控，保护系统尽可能地避免遭受到重大故障的损失。 易管理性：不管是通过软件还是硬件方式的均衡解决方案，我们都希望它有灵活、直观和安全的管理方式，这样便于安装、配置、维护和监控，提高工作效率，避免差错。在硬件负载均衡设备上，目前主要有三种管理方式可供选择：一、命令行接口（CLI：Command Line Interface），可通过超级终端连接负载均衡设备串行接口来管理，也能telnet远程登录管理，在初始化配置时，往往要用到前者；二、图形用户接口（GUI：Graphical User Interfaces），有基于普通web页的管理，也有通过Java Applet 进行安全管理，一般都需要管理端安装有某个版本的浏览器；三、SNMP（Simple Network Management Protocol，简单网络管理协议）支持，通过第三方网络管理软件对符合SNMP标准的设备进行管理。]]></content>
      <categories>
        <category>lvs</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvs负载均衡]]></title>
    <url>%2F2019%2F01%2F05%2Flvs%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[lvs（内核级）负载均衡器 lvs负载均衡 负载均衡集群是 Load Balance(负载均衡器) 集群。是一种将网络上的访问流量分布于各个节点，以降低服务器压力，更好的向客户端提供服务的一种方式。常用的负载均衡。 调度器分类： 硬负载 (专用硬件) F5-Big Ip NetScaler-Citrix A10-A10 软负载(pc server) 四层：LVS,Nginx(stream模块伪四层),HAProxy（mode tcp） 七层：Nginx,HAProxy,ATS,Envoy,Traefik,Kong… 七层调度器（应用程序调度器） 如果调度器是根据OSI第七层应用层的报文的格式来识别客户端身份并根据算法获取其中数据完成后端客户端挑选的称之为七层调度器或者称之为应用层调度器。。 四层调度器（内核级调度） 仅根据客户端请求时请求的套接字（ip+port）完成后端客户端挑选。 一、负载均衡LVS基本介绍 LB集群的架构和原理很简单，就是当用户的请求过来时，会直接分发到Director Server上，然后它把用户的请求根据设置好的调度算法，智能均衡地分发到后端真正服务器(real server)上。为了避免不同机器上用户请求得到的数据不一样，需要用到了共享存储，这样保证所有用户请求的数据是一样的。 LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的官方网站是 http://www.linuxvirtualserver.org 现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。LVS 是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。 二、LVS的基本工作原理 三、LVS的组成 1.lvs分为两个部分，分别是内核模块和lvs的管理工具。 LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 ipvsadm：用户空间的命令行工具，规则管理器，用于管理集群服务及相关的RealServer； ipvs：工作于内核空间的netfilter的INPUT钩子之上的框架； 目前来说，centos7及其以上的内核版本已经包括了ipvs的相关模块了。 内核支持的ipvs模块 上图中的rr，wrr，lc，wlc，lblc等等都是lvs中调度器的调度算法，根据不同的调度算法可以更好的分配服务，实现负载均衡。 而ipvs(ip virtual server)：一段代码工作在内核空间，实现调度。 ipvsadm客户端管理工具 上图是ipvsadm。负责为ipvs内核框架编写规则，定义谁是集群服务，而谁是后端真实的服务器(Real Server)。1234567891011121314151617181920212223242526#调度算法为内建在内核中的模块一共有10种[root@centos7 ~]# grep -i "ip_vs" /boot/config-3.10.0-862.el7.x86_64 CONFIG_IP_VS=mCONFIG_IP_VS_IPV6=y# CONFIG_IP_VS_DEBUG is not setCONFIG_IP_VS_TAB_BITS=12CONFIG_IP_VS_PROTO_TCP=yCONFIG_IP_VS_PROTO_UDP=yCONFIG_IP_VS_PROTO_AH_ESP=yCONFIG_IP_VS_PROTO_ESP=yCONFIG_IP_VS_PROTO_AH=yCONFIG_IP_VS_PROTO_SCTP=yCONFIG_IP_VS_RR=mCONFIG_IP_VS_WRR=mCONFIG_IP_VS_LC=mCONFIG_IP_VS_WLC=mCONFIG_IP_VS_LBLC=mCONFIG_IP_VS_LBLCR=mCONFIG_IP_VS_DH=mCONFIG_IP_VS_SH=mCONFIG_IP_VS_SED=mCONFIG_IP_VS_NQ=mCONFIG_IP_VS_SH_TAB_BITS=8CONFIG_IP_VS_FTP=mCONFIG_IP_VS_NFCT=yCONFIG_IP_VS_PE_SIP=m 四.LVS的调度算法前面已经说了，调度器（directory） 是通过一定的调度算法将服务请求一个一个的分发下去。现在了解一下调度算法 LVS一共有10种调度算法。 静态算法（算法仅根据算法本身与请求报文特征进行调度 起点公平） 动态算法（额外考虑后端各RS的当前的负载的状态 结果公平） 静态调度算法（4个） 1.rr（轮叫调度） 轮叫调度：这种是最简单的调度算法，就是将请求A一个，B一个，A一个，B一个 …… 循环的发。就算A主机挂掉了，调度器还是会将请求发送到A。十分均衡。 2.wrr（加权轮叫） 加权轮叫调度：这种算法是在rr基础上实现的，只不过加了权重，权重范围为1-100，假设A的服务器性能好，就给A的权重设置的高一点，设为2，而B主机是1。这样就实现A二个，B一个，A二个，B一个 …… 循环的发。这样照顾到了服务器性能。 3.sh（源地址哈希） 源地址散列：主要是实现将此前的session（会话）绑定。将此前客户的源地址作为散列键，从静态的散列表中找出对应的服务器，只要目标服务器是没有超负荷的就将请求发送过去。就是说某客户访问过A,现在这个客户又来了，所以客户请求会被发送到服务过他的A主机。 4.dh（目的地址哈希） 目的地址散列：以目的地址为关键字查找一个静态hash表来获得需要的RS。以目标地址为标准挑选。 功能是和sh近似的，但应用场景不同 （dh举个例子：假设1号客户访问了web集群的一个动态页面，调度器将请求转发个A服务器，A服务器的PHP将这个动态请求运行了一遍，生成了缓存并回应1号客户。这下2号客户也访问了这个动态页面，调度器应该将请求发给A。毕竟A已经跑过这段程序了，有缓存，对吧。所以这既是dh算法） 接下来是动态算法，动态算法与静态算法最大的区别就是动态算法考虑了服务器的压力。活动链接（active）：客户与服务器建立连接并且有数据传送非活动链接（inactive）：只是建立连接，没有数据传送，没有断开连接 动态调度算法（6个） 1.lc（最少链接） 最少连接调度：这种算法是看A，和B的主机谁的连接少，请求就发给谁，如果负载相同，自上而下调度。 负载的简单算法：active*256+inactive （谁小发给谁） 2.wlc（加权最少链接）LVS的理想算法，也是默认的算法 加权最少链接：这种算法就是比lc多了一个加权。 简单算法：( active*256+inactive )/weight (谁小就发给谁) 3.sed（最短期望延迟） 基于wlc算法，假设A，B的权重分别是1，2 。而A的链接数为1，B的链接数为2 。这样的话，用wlc算法得出的结果一样，而明显B的权重大，B的能力较强。用sed算法的话，就可以避免wlc出现的问题。 简单算法：（active+1)256/weight （活动的连接数+1）256/除以权重 谁小发给谁 A：（1+1）/1 B：（2+1）/2 （B小，交给B） 4.nq（永不排队） 基于sed算法：在sed的基础上，若谁的链接数为0，直接将请求发送给他，没二话 5.LBLC（基于局部性的最少连接）类似于dh，目标地址hash 这个算法主要用于Cache集群系统，因为Cache集群的中客户请求报文的目标IP地址的变化，将相同的目标URL地址请求调度到同一台服务器，来提高服务器的访问的局部性和Cache命中率。从而调整整个集群的系统处理能力。但是，如果realserver的负载处于一半负载，就用最少链接算法，将请求发送给活动链接少的主机。 6.LBLCR（带复制的基于局部性的最少链接） 该算法首先是基于最少链接的，当一个新请求收到后，一定会将请求发给最少连接的那台主机的。但这样又破坏了cache命中率。但这个算法中，集群服务是cache共享的，假设A的PHP跑了一遍，得到缓存。但其他realserver可以去A那里拿缓存，这是种缓存复制机制。 五、lvs类型（工作拓扑结构及转发机制） LVS 的工作模式分为4中分别是 NAT，DR，TUN，FULL-NAT。其中做个比较，由于工作原理的关系的，NAT的配置最为简单，但是NAT对调度器的压力太大了，导致其效率最低，DR和TUN的工作原理差不多，但是DR中，所有主机必须处于同一个物理环境中，而在TUN中，所有主机可以分布在不同的位置，服务器一个在纽约，一个在深圳。最多应用的是FULL-NAT。 lvs-nat：修改请求报文的目标IP,多目标IP的DNAT lvs-dr：操纵封装新的MAC地址 lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP 其中的专业术语 DS：Director Server。指的是前端负载均衡器。 RS：Real Server。后端真实的工作服务器。 VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 RIP：Real Server IP，后端服务器的IP地址。 CIP：Client IP，访问客户端的IP地址。 1.NAT模式 客户发出请求，发送请求给链接调度器的VIP，调度器将请求报文中的目标Ip地址改为RIP。这样服务器RealServer将请求的内容发给调度器，调度器再将报文中的源IP地址改为VIP。 (a). 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP (b). PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c). IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP (d). POSTROUTING链通过选路，将数据包发送给Real Server (e). Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP (f). Director Server在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP Nat模型的特点 1.很好配置，原理简单易懂 2.由于调度器的工作量太大，很容易成为整个集群系统的瓶颈。 3.RS应该使用私有地址，RS的网关必须指向DIP 4.支持端口映射 5.多目标IP的DNAT，通过将请求报文中的目标地址和目标端口修改为某挑出的RS的RIP和PORT实现转发； 6.RIP和DIP必须在同一个IP网络，且应该使用私网地址；RS的网关要指向DIP； 7.请求报文和响应报文都必须经由Director转发；Director易于成为系统瓶颈； 8.支持端口映射，可修改请求报文的目标PORT； 9.vs必须是Linux系统，rs可以是任意系统； 2.DR模式 整个DR模式都是停留在第二层的数据链路层。直接修改MAC。实现报文的转发。 (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP (b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c) IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址 (d) 由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。 (e) RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP (f) 响应报文最终送达至客户端 LVS-DR的特点 1.在前端路由器做静态地址路由绑定，将对于VIP的地址仅路由到Director Server 2.arptables：在arp的层次上实现在ARP解析时做防火墙规则，过滤RS响应ARP请求。 3.修改RS上内核参数（arp_ignore和arp_announce）将RS上的VIP配置在网卡接口的别名上，并限制其不能响应对VIP地址解析请求。 4.确保前端路由器将目标IP为VIP的请求报文发往Director： (a) 在前端网关做静态绑定； (b) 在RS上使用arptables； (c) 在RS上修改内核参数以限制arp通告及应答级别； arp_announce arp_ignore 5.RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director； 6.RS跟Director要在同一个物理网络； 7.请求报文要经由Director，但响应不能经由Director，而是由RS直接发往Client； 8.不支持端口映射； 3.TUN模式 和DR模式差不多，但是比DR多了一个隧道技术以支持realserver不在同一个物理环境中。就是realserver一个在北京，一个工作在上海。 在原有的IP报文外再次封装多一层IP首部，内部IP首部(源地址为CIP，目标IIP为VIP)，外层IP首部(源地址为DIP，目标IP为RIP (a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP 。 (b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链 (c) IPVS比对数据包请求的服务是否为集群服务，若是，在请求报文的首部再次封装一层IP报文，封装源IP为为DIP，目标IP为RIP。然后发至POSTROUTING链。 此时源IP为DIP，目标IP为RIP (d) POSTROUTING链根据最新封装的IP报文，将数据包发至RS（因为在外层封装多了一层IP首部，所以可以理解为此时通过隧道传输）。 此时源IP为DIP，目标IP为RIP (e) RS接收到报文后发现是自己的IP地址，就将报文接收下来，拆除掉最外层的IP后，会发现里面还有一层IP首部，而且目标是自己的lo接口VIP，那么此时RS开始处理此请求，处理完成之后，通过lo接口送给eth0网卡，然后向外传递。 此时的源IP地址为VIP，目标IP为CIP (f) 响应报文最终送达至客户端 LVS-TUN的特点 1 .RIP、VIP、DIP全是公网地址 2.RS的网关不会也不可能指向DIP 3.不支持端口映射 4.RS的系统必须支持隧道 lvs-fullnat模式： 通过同时修改请求报文的源IP地址和目标IP地址进行转发； CIP DIP VIP RIP lvs-fullnat 特点： (1) VIP是公网地址，RIP和DIP是私网地址，且通常不在同一IP网络；因此，RIP的网关一般不会指向DIP； (2) RS收到的请求报文源地址是DIP，因此，只能响应给DIP；但Director还要将其发往Client； (3) 请求和响应报文都经由Director； (4) 支持端口映射； 注意：此类型默认不支持；]]></content>
      <categories>
        <category>lvs</category>
      </categories>
      <tags>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker资源限制以及compose基础应用]]></title>
    <url>%2F2019%2F01%2F04%2Fdocker%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[docker资源限制以及compose基础应用 docker资源限制 在使用docker运行容器时，一台主机上可能会运行几百个容器，这些容器虽然互相隔离，但是底层却使用着相同的CPU，内存和磁盘资源。如果不对容器使用的资源进行限制，那么容器之间会互相影响，小的来说会导致容器资源使用不公平;大的来说，可能会导致主机和集群资源耗尽，服务完全不可用.docker 作为容器的管理者，自然提供了控制容器资源的功能。正如使用内核的命名空间来做赚容器之间的隔离，docker也是通过内核的cgroups来做容器的资源限制。 1. 内存（不可压缩资源） 1.1 了解耗尽内存的风险 不让正在运行的容器消耗太多的主机内存是很重要的。在 Linux 主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个 OOME内存耗尽 或 Out Of Memory Exception，并开始查杀进程以释放内存。任何进程都可能被杀掉，包括 Docker 和其他重要应用程序。如果终止了错误进程，有可能导致系统宕机。 Docker 尝试通过调整 Docker 守护进程的 OOM 优先级来降低这些风险，从而使其和系统上的其他进程相比更不容易被杀掉。容器的 OOM 优先级不调整。这使得单个容器被杀死的可能性要比 Docker 守护进程或其他系统进程被终止的可能性要大。不应该通过手动将守护程序或容器上的 –oom-score-adj 设置为极端负数，或通过在容器上设置 –oom-disable-kill 来尝试规避这些安全措施。 生产环境一般不建议使用swap，因为使用swap会严重影响服务器性能。 选项 描述 -m 或 –memory= 容器可用的最大内存。如果设置了这个值，最小可用内存是 4MB。 –memory-swap* 允许容器放入磁盘 swap 中的内存数量。 –memory-swappiness 默认情况下，主机内核可以交换容器使用的匿名页面的百分比。可以设置为介于0和100之间的值，以调整此百分比。用来定义系统是使用的交换分区的倾向性（数值越大越倾向使用，数值越低越少越晚的使用能不用则不用） –memory-reservation 软限制。指定一个小于 –memory 的软限制，当 Docker 检测到主机上的争用或内存不足时，会采用这个限制来替换 –memory。如果使用这个限制，则必须将其设置为低于 –memory，以使其优先。不能保证容器不会超出限制。 –kernel-memory 容器可以使用的最大内核内存量。允许的最小值是 4m。由于内核内存不能被换出，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其他容器产生副作用。 –oom-kill-disable 默认情况下，如果发生内存不足（OOM）错误，内核会杀死容器中的进程。使用 –oom-kill-disable 选项可以更改此行为。注意只能在同时设置了-m/–memory 选项的容器上使用此选项，因为如果未设置 -m 标志，可能会耗尽主机的内存，导致内核需要终止主机系统的进程以释放内存。 1.2 限制容器对内存的访问 Docker 可以对内存实施两种限制：硬限制，允许容器使用不超过给定数量的用户或系统内存；软限制，允许容器使用尽可能多的内存，除非满足某些条件，例如内核检测到内存不足或主机上的争用。其中一些选项在单独使用或同时设置多个选项时会有不同的效果。 这些选项大多数都是一个正整数，后跟一个后缀 b，k，m，g，以表示字节，千字节，兆字节或千兆字节。 1.3 –memory-swap 详情 –memory-swap 是一个修饰符标志，只有在 –memory 也被设置时才有意义。使用 swap 使得容器可以在耗尽所有可用 RAM 时，将多余的内存需求写入磁盘。对于经常将内存交换到磁盘的应用程序会有性能损失。 其设置可能会产生复杂的效果： 如果 –memory-swap 设置为正整数，那么 –memory 和 –memory-swap 都需要设置。–memory-swap 表示所有可用的内存和 swap 之和，并且 –memory 控制非 swap 内存数量。因此，如果 –memory=”300m” 和 –memory-swap=”1g”，则容器可以使用 300MB 内存和 700MB swap。 如果 –memory-swap 设置为 0，则会忽略这个设置。 如果 –memory-swap 设置的值与 –memory相同，并且 –memory 设置为正整数，则容器无法访问 swap。 如果 –memory-swap 未设置，并且 –memory 设置了，如果主机容器配置了交换内存，则容器会使用 –memory 设置值的两倍作为 swap 的大小。例如，如果 –memory=”300m”，–memory-swap没有设置，则容器可以使用 300MB 内存和 600MB swap。 如果 –memory-swap 显式设置为 -1，允许容器使用无限制的 swap，直到达到主机系统可用值。 禁止容器使用 SWAP 如果 –memory-swap 设置的值与 –memory相同，则容器无法访问 swap。这是因为 –memory-swap 设置的值是可用的内存与 swap 之和，而 –memory 是可用的物理内存量。 1.4 –memory-swappiness 详情 值为 0 时，关闭匿名页的 swap。 值为 100 时，所有匿名页都可以 swap。 默认情况下，如果没有设置 –memory-swappiness，会从主机继承这个值。 1.5 –kernel-memory 详情 内核内存限制以分配给指定容器的全部内存来表示。考虑以下情况： 无限内存，无限内核内存：这是默认行为。 无限内存，有限内核内存：当所有 cgroup 所需的内存大于主机上实际存在的内存时，这是合适的。可以将内核内存配置为永远不会覆盖主机上可用的内容，而需要更多内存的容器需要等待。 有限内存，无限内核内存：整个内存是有限的，但内核内存不是。 有限内存，有限内核内存：限制用户和内核内存可用于调试与内存相关的问题。如果某个容器对任意一种内存的使用数量超量，则会导致内存不足但不会影响其他容器或主机。在此设置下，如果内核内存限制低于用户内存限制，则内核内存用尽会导致容器遇到 OOM 错误。如果内核内存限制高于用户内存限制，则内核限制不会导致容器体验 OOM。 当打开任何内核内存限制时，主机会在每个进程的基础上跟踪“high water mark”（高位标记）统计信息，以便跟踪哪些进程（在这种情况下是容器）正在使用多余的内存。可以通过在主机上查看 /proc//status 来查看每个进程。 2. CPU（可压缩资源） 默认情况下，每个容器对主机 CPU 的周期访问是无限的。可以设置各种约束来限制给定容器访问主机的 CPU 周期。大多数用户使用和配置默认的 CFS 调度器。在 Docker 1.13 及更高版本中，还可以配置实时调度器 2.1 配置默认的 CFS 调度器 CFS 是用于普通 Linux 进程的 Linux 内核 CPU 调度程序。几个运行时标志允许配置容器的 CPU 资源访问量。使用这些设置时，Docker 会修改主机上容器的 cgroup 设置。 压测此镜像可以进行压测，参考镜像地址：https://hub.docker.com/r/lorel/docker-stress-ng 12345拖下测试镜像 [root@centos7 ~]# docker pull lorel/docker-stress-ng查看镜像的使用帮助 [root@centos7 ~]# docker run --name pc1 -it --rm lorel/docker-stress-ng --help docker compose容器编排工具官网：https://docs.docker.com/compose/ 1.Compose介绍 Docker Compose是一个用来定义和运行复杂应用的Docker工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose不再需要使用shell脚本来启动容器。 Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。 2.Compose和Docker兼容性 Docker版本变化说明： Docker从1.13.x版本开始，版本分为企业版EE和社区版CE，版本号也改为按照时间线来发布，比如17.03就是2017年3月。 Docker的linux发行版的软件仓库从以前的https://apt.dockerproject.org和https://yum.dockerproject.org变更为目前的https://download.docker.com, 软件包名字改为docker-ce和docker-ee。 范例：打算部署一个wordpress123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960WordPress:1. 在你的主文件夹中创建一个名为my_wordpress的新目录，并将cd放入其中:#yum install docker-compose# systemctl start docker# mkdir ~/my_wordpress/# cd ~/my_wordpress/ # docker pull wordpress:latest# docker pull mysql:5.7 2. 创建一个名为docker-compose的文件。并在此文件夹中添加以下内容。为WORDPRESS_DB_PASSWORD、MYSQL_ROOT_PASSWORD和MYSQL_PASSWORD环境选项设置您自己的密码。为WORDPRESS_DB_PASSWORD和MYSQL_PASSWORD输入的密码应该相同。# rpm -q docker-compose#docker-compose-1.18.0-2.el7.noarchvim docker-compose.ymlversion: '3.3'services: wordpress: #服务 depends_on: - db image: wordpress:latest #互联网镜像为wordpress(http、php、php-mysql、wordpress) volumes: - wordpress_files:/var/www/html ports: - "80:80" #端口映射,左侧宿主机右侧容器 restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_NAME: wordpress WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: my_wordpress_db_password db: #服务 image: mysql:5.7 volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: my_db_root_password MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: my_wordpress_db_passwordvolumes: wordpress_files: db_data: 3. 从my_wordpress目录，开始你的Docker容器:# docker-compose up -d 4. Docker容器启动WordPress和MySQL需要一到两分钟。之后，您可以在web浏览器中访问您的IP地址，您应该被引导到WordPress设置表单。 文档出处， https://www.linode.com/docs/quick-answers/linux/wordpress-with-docker-compose/ docker ps 命令： 过滤器：过滤标志(-f或–filter)格式是key=value。如果超过一个过滤，就传递多个标志(如–filter “foo=bar” –filter “bif=baz”) 目前支持的过滤有如下这些: id(容器id) label(label=或label=&gt;) name(容器名称) exited(整数 – 容器退出码。只在使用–all才有用) status (created restarting running paused exited dead) ancestor([:], or ) – 过滤从指定镜像创建的容器。 before (容器的名称或id) – 过滤在给定id或名称之前创建的容器。 since (容器的名称或id) – 过滤在给定id或名称之后创建的容器。 isolation (default process hyperv) (Windows daemon only) volume (数据卷名称或挂载点) – 过滤挂载有指定数据卷的容器。 network (网络id或名称) – 过滤连接到指定网络的容器。 --format为格式化输出。格式化选项(–format)使用Go模板来美化打印容器输出。 Go模板有效的占位符如下： .ID 容器ID .Image 镜像ID .Command Quoted command .CreatedAt 创建容器的时间点. .RunningFor 从容器创建到现在过去的时间. .Ports 暴露的端口. .Status 容器状态. .Size 容器占用硬盘大小. .Names 容器名称. .Labels 容器所有的标签. .Label 指定label的值 例如&apos;{{.Label “com.docker.swarm.cpu”}}’ .Mounts 挂载到这个容器的数据卷名称 Docker参考手册： https://docs.docker.com/engine/reference/commandline/dockerd/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker私有仓库]]></title>
    <url>%2F2019%2F01%2F03%2Fdocker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E5%92%8C%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[docker私有仓库 ocker Registry 分类 Registry用于保存docker镜像，包括镜像的层次结构和元数据 用户可自建Registry，也可使用官方的Docker Hub 分类 Sponsor Registry：第三方的registry，供客户和Docker社区使用 Mirror Registry：第三方的registry，只让客户使用 Vendor Registry：由发布Docker镜像的供应商提供的registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供的registry Registry(repository and index) Repository 由某特定的docker镜像的所有迭代版本组成的镜像仓库 一个 Registry中可以存在多个Repository Repository可分为“顶层仓库”和“用户仓库” 用户仓库名称格式为“用户名/仓库名” 每个仓库可以包含多个Tag(标签) ，每个标签对应一个镜像 Index 维护用户帐户、镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 docker简单的私有仓库123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180[root@centos7 yum.repos.d]# yum info docker-distributionLoaded plugins: fastestmirror, langpacksRepository extras is listed more than once in the configurationLoading mirror speeds from cached hostfile * base: mirrors.huaweicloud.com * extras: mirrors.tuna.tsinghua.edu.cn * updates: mirrors.huaweicloud.comAvailable PackagesName : docker-distributionArch : x86_64Version : 2.6.2Release : 2.git48294d9.el7Size : 3.5 MRepo : extras/7/x86_64Summary : Docker toolset to pack, ship, store, and deliver contentURL : https://github.com/docker/distributionLicense : ASL 2.0Description : Docker toolset to pack, ship, store, and deliver content #######################################################################################实验前提###################################################################################说明:Docker工具集用于打包、运输、存储和交付内容实现自建简单的docker私有仓库 两台主机间共享私用仓库 发送镜像端:172.18.135.1 distribution服务器：主机名为www.centos7.com(172.18.135.1)####################接收镜像的节点distribution服务器########################################安装docker#############################################################################[root@centos7 yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo[root@centos7 yum.repos.d]# yum install docker-ce -y安装docker-distribution[root@centos7 yum.repos.d]# yum install docker-distribution.x86_64 [root@centos7 ~]# systemctl start docker-distribution[root@centos7 ~]# rpm -ql docker-distribution /etc/docker-distribution/registry/config.yml #配置文件/usr/bin/registry/usr/lib/systemd/system/docker-distribution.service/usr/share/doc/docker-distribution-2.6.2/usr/share/doc/docker-distribution-2.6.2/AUTHORS/usr/share/doc/docker-distribution-2.6.2/CONTRIBUTING.md/usr/share/doc/docker-distribution-2.6.2/LICENSE/usr/share/doc/docker-distribution-2.6.2/MAINTAINERS/usr/share/doc/docker-distribution-2.6.2/README.md/var/lib/registry #存储用户pull下来的所有镜像配置文件[root@centos7 ~]# vim /etc/docker-distribution/registry/config.ymlversion: 0.1 #版本log: #日志 fields: #存储 service: registry storage: cache: #使用本地内存做缓存 layerinfo: inmemory filesystem: #用户所有pull下来的文件存放在/var/lib/registry rootdirectory: /var/lib/registryhttp: #仅提供http协议的传输 addr: :5000 #默认监听本机的所有地址的5000端口启动docker-distribution服务[root@centos7 ~]# systemctl start docker-distribution[root@centos7 ~]# ss -tnlLISTEN 0 128 :::5000 :::* distribution的registry做的非常简单#无用户名认证#默认情况下不区分任何用户空间#仅有顶层仓库，仅供公司内部临时使用####################发送镜像端#################################################打标签发送###########################################################################################打标签时指明distribution服务器地址、端口（确认可以名字解析解析到distribution服务器地址）打标签[root@centos7 ~]# docker tag lamp:v0.1 www.centos7.com:5000/myimg:v0.1[root@centos7 ~]# docker image lswww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 6 hours ago 279MB上传到distribution服务器（失败原因是默认使用的https发送的请求，对端使用的是http接收双方不匹配）[root@centos7 ~]# docker push www.centos7.com:5000/myimg:v0.1 The push refers to repository [www.centos7.com:5000/myimg]Get https://www.centos7.com:5000/v2/: dial tcp 172.18.135.2:5000: connect: no route to host编辑daemon.json 开启明文不安装的仓库传输，默认使用https加密协议，使用明文http协议[root@centos7 ~]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries": ["www.centos7.com:5000"]&#125;[root@centos7 ~]# systemctl restart docker推镜像[root@centos7 ~]# docker push www.centos7.com:5000/myimg:v0.1The push refers to repository [www.centos7.com:5000/myimg]a92cb897b523: Pushed 071d8bd76517: Pushed v0.1: digest: sha256:274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 size: 741####################接收镜像的节点distribution服务器########################################安装docker#############################################################################查看是否推送成功[root@centos7 ~]# ls /var/lib/registry/dockerroot@centos7 ~]# tree /var/lib/registry//var/lib/registry/└── docker └── registry └── v2 ├── blobs │ └── sha256 │ ├── 27 │ │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ │ └── data │ ├── a0 │ │ └── a02a4930cb5d36f3290eb84f4bfa30668ef2e9fe3a1fb73ec015fc58b9958b17 │ │ └── data │ ├── ab │ │ └── ab9147d4eb81842f3eccbb7c75ef8cad91a9dadfd22233050acae0d2f37d9fba │ │ └── data │ └── f3 │ └── f3c216eb1c6f3fe2e271835d79e94e9ede430d7cd75f9734cf44dd9c5fbf095c │ └── data └── repositories └── myimg ├── _layers │ └── sha256 │ ├── a02a4930cb5d36f3290eb84f4bfa30668ef2e9fe3a1fb73ec015fc58b9958b17 │ │ └── link │ ├── ab9147d4eb81842f3eccbb7c75ef8cad91a9dadfd22233050acae0d2f37d9fba │ │ └── link │ └── f3c216eb1c6f3fe2e271835d79e94e9ede430d7cd75f9734cf44dd9c5fbf095c │ └── link ├── _manifests │ ├── revisions │ │ └── sha256 │ │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ │ └── link │ └── tags │ └── v0.1 │ ├── current │ │ └── link │ └── index │ └── sha256 │ └── 274298eab95626cb7c4f0bbb7684d813037650bc11b527e6f31c99910ae28e68 │ └── link └── _uploads31 directories, 10 files使用此镜像（可以解析到本机域名）#本身也不支持httpds修改daemon.json [root@centos7 ~]# cat /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries":["www.centos7.com:5000"]&#125;[root@centos7 ~]# systemctl restart docker[root@centos7 ~]# docker info[root@centos7 ~]# docker pull www.centos7.com:5000/myimg:v0.1[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEwww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 7 hours ago 279MB-------------------------------------------------------------------------将别人的镜像推送到自己的仓库中使用（本地的centos7打个标签传到自己本地的仓库）[root@centos7 ~]# docker tag centos:7 www.centos7.com:5000/centos:7[root@centos7 ~]# docker image lswww.centos7.com:5000/myimg v0.1 f3c216eb1c6f 7 hours ago 279MB[root@centos7 ~]# docker push www.centos7.com:5000/centos:7 Harbor源代码托管在github:https://github.com/goharbor/harbor Harbor是一个开源的可信云本机注册表项目，用于存储，签名和扫描内容。Harbor通过添加用户通常需要的功能（如安全性，身份和管理）来扩展开源Docker Distribution。使注册表更接近构建和运行环境可以提高图像传输效率。Harbor支持在注册表之间复制映像，还提供高级安全功能，如用户管理，访问控制和活动审计。 Harbour由Cloud Native Computing Foundation（CNCF）托管。如果您是一个希望帮助塑造云原生技术发展的组织，请考虑加入CNCF。有关谁参与以及Harbour如何扮演角色的详细信息，请阅读CNCF 公告。 系统要求： 在Linux主机上： docker 17.03.0-ce +和docker-compose 1.10.0+。 下载Harbor版本的二进制文件，然后按照安装和配置指南安装Harbour。 如果您想在Kubernetes上部署Harbour，请使用Harbor图表。 有关如何使用Harbor的更多详细信息，请参阅用户指南。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#Harbor服务传输使用的也是https协议传输，可以将此功能关掉,生产中若使用Harbor建议启用https加密以及从节点复制功能。港口可以通过以下三种方法之一安装： 1.在线安装程序：安装程序从Docker hub下载Harbor的图像。因此，安装程序的尺寸非常小。 2.脱机安装程序：当主机没有Internet连接时使用此安装程序。安装程序包含预先构建的图像，因此其大小更大。安装步骤归结为以下内容： 1.下载安装程序 2.配置harbor.cfg 配置参数位于文件harbor.cfg中。 在harbor.cfg中有两类参数，必需参数和可选参数 3.运行install.sh安装并启动Harbor第一步：安装docker-compose(epel源) [root@centos7 ~]# yum install docker-compose第二步：下载离线安装程序包，并解压 下载地址：https://storage.googleapis.com/harbor-releases/release-1.7.0/harbor-offline-installer-v1.7.0.tgz [root@centos7 local]# pwd /usr/local [root@centos7 local]# tar xvf harbor-offline-installer-v1.7.0.tgz 第三步：编辑harbor配置文件、并运行装载harbor（详细设置参考github中harbor安装手册） [root@centos7 harbor]# pwd /usr/local/harbor [root@centos7 harbor]# vim harbor.cfg 8行 hostname = www.centos7.com #修改主机名，确保此名称可以解析 [root@centos7 harbor]# systemctl start docker #运行 ./install.sh 前确保docker已经启动 [root@centos7 harbor]# pwd /usr/local/harbor [root@centos7 harbor]# ./install.sh [root@centos7 harbor]# docker image ls #可以查看默认的离线下载下来的镜像第四步：此时默认的运行的https容器已经启动，以及访问查看[root@centos7 harbor]# ss -tnl #监听的端口默认映射为宿主机的端口 LISTEN 0 128 :::80 :::* LISTEN 0 128 :::443 :::* LISTEN 0 128 :::4443 :::* http://172.18.135.2/harbor/sign-in#使用默认的账号和密码登陆账号admin密码Harbor12345 1自己创建账号并定义项目名称并向自己定义的仓库中推送镜像 12345678910111213141516171819202122232425第五步：推送镜像到自己创建的harbor仓库中 [root@centos7 harbor]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "insecure-registries":["www.centos7.com"] &#125; [root@centos7 harbor]# systemctl restart docker 查看本地已有的镜像 [root@centos7 harbor]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE goharbor/harbor-db v1.7.0 45d94fe5fee5 3 weeks ago 133MB 打标签 [root@centos7 harbor]# docker tag goharbor/harbor-db:v1.7.0 www.centos7.com/public/harbor:v0.1 登陆、推送到harbor [root@centos7 harbor]# docker login www.centos7.com Username: daizhe Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded [root@centos7 harbor]# docker push www.centos7.com/public/harbor:v0.1]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dockerfile详解]]></title>
    <url>%2F2019%2F01%2F02%2Fdockerfile%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[dockerfile详解 docker的镜像分层 分层 Cow 联合挂载 base image ,app image = base image docker里的镜像绝大部分都是在别的镜像的基础上去进行创建的，也就是使用镜像的分层结构。 那么为什么会有两个镜像呢？这是由于docker的镜像分层结构所导致的，如下图所示。 一个docker镜像由多个可读的镜像层组成，然后运行的容器会在这个docker的镜像上面多加一层可写的容器层，任何的对文件的更改都只存在此容器层。因此任何对容器的操作均不会影响到镜像。 至于容器如何获取镜像层文件而又不影响到是镜像层的呢？docker是这样实现的？ 如果需要获取某个文件，那么容器曾会从上到下去下一层的镜像层去获取文件，如果该层文件不存在，那么就会去下一镜像层去寻找，直到最后一层。 对于用户而言，用户面向的是一个叠加后的文件系统。 而任何对于文件的操作都会记录在容器层，例如说修改文件，容器层会把在镜像层找到的文件拷贝到容器层然后进行修改，删除文件则会在容器层内记录删除文件的记录。 About Dockerfile Dockerfile只不过是建造码头工人的源代码自动图像码头工人可以构建图像读取指令从Dockerfile。 Dockerfile是一个文本文件,包含所有的命令在命令行用户可以叫组装一个图像型码头工人建立用户可以创建一个自动构建执行一些命令行指令 Dockerfile Dockerfile其实可以看做一个命令集。每行均为一条命令。每行的第一个单词，就是命令command。 后面的字符串是该命令所要接收的参数。 比如ENTRYPOINT /bin/bash。ENTRYPOINT命令的作用就是将后面的参数设置为镜像的entrypoint。 至于现有命令的含义，这里不再详述。 DockOne上有很多的介绍。 一、Docker Image building 宿主机指定工作目录： 1.此文件中仅用于放置Dockerfile以及Dockerfile文件中指定要被依赖到的文件，不要放置其他文件或目录。 2.此宿主机的工作目录相当于隐式运行的容器的卷，仅能从此卷中复制文件到容器中。 Dockerfile的文件名也只能叫做Dockerfile，放置在宿主机上的工作目录中。 二、Dockerfile文件格式 格式（Format） #注释 指令参数 该指令本身不区分字符大小 惯例要求的指令要写成纯大写 以便更容易地与参数区分开来 dockerfile文件本身没有循环、选择等分支，也没有跳转语句 一般来讲在dockerfile文件中的第一条指令是“FROM”（新版的dockerfile有松动，早期的dockerfile把第一条执行的第一条指令必须是“FROM”），因为“FROM”就是我们用来指定基础镜像的。 三、Dockerfile的镜像层构建 在dockerfile中构建镜像，与我们手动的显式的启动一个容器构建镜像不同的是dockerfile文件中的每一条指令都会生成一个新的单有的镜像层。 分层过多会导致在读写访问过程中的效率降低，因为首次访问镜像一定是Cow机制完成 镜像分的过于精细的好处是可以其他让镜像让享同一层底层的镜像即镜像层越精细越多越容易共享，越容易共享代表在镜像仓库与客户端和dockerhost之间传输时可以单独传输，传输的过程越易控，起码在打包、分发。 应该把关系比较紧密的操作放置在一层操作当中。 docker镜像制作的两种运行场景 制作新镜像的过程 运行新镜像的阶段 dockerfile环境变量 环境变量(用ENV语句声明)也可以在某些指令中使用，因为Dockerfile将解释的变量在Dockerfile中以$variable名或${variable_name标记 ${variable_name} 语法还支持一些标准的bash修饰符 $ivariable:-word} 表示如果设置了变量，则结果将是该值。 如果变量没有设置，那么结果将是word ${variable:+word} 表示如果设置了变量，则word为结果，否则结果为空字符串 .dockerignore file在docker CLI将上下文发送给docker守护进程之前，它将查找一个名为。如果该文件存在，CLI将修改该上下文以排除与其模式匹配的文件和目录。dockerignore file是一个以新行分隔的模式列表，类似于Unix shell的文件全局 Dockerfile指令build阶段Dockerfile文件中的指令(build阶段：做很多设定以便于在目标镜像文件中可以打包进入所期望的文件或者程序文件) FROM FROM指令是最重的一个且必须为Dockerfile文件开篇的第一个非注释行，用于 为映像文件构建过程指定基准镜像，后续的指令运行于此基准镜像所提供的运 行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在 docker主机上查找指定的镜像文件，在其不存在时，则会从Docker Hub Registry 上拉取所需的镜像文件 如果找不到指定的镜像文件，docker build会返回一个错误信息 Syntax(语法)(repository仓库、tag标签、digest唯一标识id即镜像校验码) FROM &lt;repository&gt;[:&lt;tag&gt;] 或 FROM &lt;resository&gt;@&lt;digest&gt; &lt;reposotiry&gt;：指定作为base image的名称； &lt;tag&gt;：base image的标签，为可选项，省略时默认为latest； LABEL 用于让Dockerfile制作者提供本人的详细信息(支持提供此镜像的任何制作的附加介绍信息以及附加的元数据) Syntax: LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... COPY 用于从Docker主机复制文件至创建的新映像文件 Syntax(语法) COPY &lt;src&gt; ... &lt;dest&gt; 或 COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] &lt;src&gt;：要复制的源文件或目录，支持使用通配符 &lt;dest&gt;：目标路径，即正在创建的image的文件系统路径；建议为&lt;dest&gt;使用绝对路径，否则， COPY指定则以WORKDIR为其起始路径； 注意：在路径中有空白字符时，通常使用第二种格式 文件复制准则 &lt;src&gt;必须是build上下文中的路径，不能是其父目录中的文件 如果&lt;src&gt;是目录，则其内部文件或子目录会被递归复制，但&lt;src&gt;目录自身不会被复制 如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用了通配符，则&lt;dest&gt;必须是一个目录，且必须以/ 结尾 如果&lt;dest&gt;事先不存在，它将会被自动创建，这包括其父目录路径 ADD ADD指令类似于COPY指令，ADD支持使用TAR文件和URL路径 Syntax ADD &lt;src&gt; ... &lt;dest&gt; 或 ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 操作准则 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接被创建为&lt;dest&gt; ；如果&lt;dest&gt;以/结尾，则文件名URL指定的文件将被直接下载并保存为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式的tar文件，它将被展开为一个目录，其行为类似于 “tar -x”命令；然而，通过URL获取到的tar文件将不会自动展开； 如果&lt;src&gt;有多个，或其间接或直接使用了通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径 ；如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt;； WORKDIR 用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定 设定工作目录 Syntax WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指令可出现多次，其路径也可以为相对路径，不过，其是相对此前 一个WORKDIR指令指定的路径 另外，WORKDIR也可调用由ENV指定定义的变量 例如 WORKDIR /var/log WORKDIR $STATEPATH VOLUME 存储卷 用于在image中创建一个挂载点目录，以挂载Docker host上的卷或其它容器上的 卷 Syntax VOLUME &lt;mountpoint&gt; 或 VOLUME [&quot;&lt;mountpoint&gt;&quot;] 如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此 前的所有文件复制到新挂载的卷中 EXPOSE 用于为容器打开指定要监听的端口以实现与外部通信 Syntax EXPOSE &lt;port&gt;[/&lt;protocol&gt;] [&lt;port&gt;[/&lt;protocol&gt;] ...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议,空格分隔可以创建多个 EXPOSE指令可一次指定多个端口， 例如 EXPOSE 11211/udp 11211/tcp ENV 用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其它指令 （如ENV、ADD、COPY等）所调用 调用格式为$variable_name或${variable_name} Syntax ENV &lt;key&gt; &lt;value&gt; 或 ENV &lt;key&gt;=&lt;value&gt; ... 第一种格式中，&lt;key&gt;之后的所有内容均会被视作其&lt;value&gt;的组成部分，因此，一次只 能设置一个变量； 第二种格式可用一次设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果 &lt;value&gt;中包含空格，可以以反斜线(\)进行转义，也可通过对&lt;value&gt;加引号进行标识；另 外，反斜线也可用于续行； 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 ARG ARG指令定义了一个变量，用户可以在构建时将该变量传递给然后使用 `–bulis-arg= flag 如果用户指定了一个没有在dockerfile中定义的构建参数,构建输出一个警告.` syntax ARG&lt;name&gt;[&lt;default value&gt;] 1.使用FROM、LABEL、COPY制作镜像1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#######################################################################################创建docker的工作目录###############################################################################[root@centos7 ~]# mkdir /docker/[root@centos7 ~]# cd /docker/#######################################################################################编写dockerfile#####################################################################################[root@centos7 docker]# vim DockerfileFROM busybox:latest #对宿主机上已有的哪个镜像进行创建LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" #作者描述COPY index.html /data/web/html/ #将宿主机上docker目录下的index.html文件复制到容器中的/data/web/html/目录。如果写为/data/web/html则代表将 index.html改名为html，在容器中的/data/web/html/获取并未存在，可以自动创建。#################################################################################查看宿主机上的dockerfile的工作目录############################################################################[root@centos7 ~]# cd /docker/[root@centos7 docker]# echo "123456" &gt; index.html[root@centos7 docker]# lsindex.html#########################################################################################构建新的镜像############################################################################################dicker image build = docker build[root@centos7 docker]# docker image build -hUsage: docker image build [OPTIONS] PATH | URL | -Options: --add-host list 添加自定义主机到ip映射(主机:ip) --build-arg list 设置构建时变量 --cache-from strings 将图像视为缓存源 --rm 成功构建后删除中间容器(默认为true) -t, --tag list 制定的新的镜像设置新的仓库名和标签'name:tag' [root@centos7 docker]# docker image build /docker/ -t mybox:v0.1 #执行命令的目录，要求写dockerfile文件所在的目录中Sending build context to Docker daemon 3.072kBStep 1/3 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/3 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Running in 746880c7205cRemoving intermediate container 746880c7205c ---&gt; 7ccdca9907ceStep 3/3 : COPY index.html /data/web/html/ ---&gt; 7062cd4f08e0Successfully built 7062cd4f08e0Successfully tagged mybox:v0.1 [root@centos7 docker]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEmybox v0.1 7062cd4f08e0 ############################################################################基于创建的镜像启动容器查看COPY的文件是否存在############################################################################[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.1 /bin/sh/ # cat /data/web/html/index.html 123456 2.COPY本身也是可以是可以支持通配符12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455##################################################################################使用.dockerignore限制copy的文件############################################################################[root@centos7 docker]# pwd/docker[root@centos7 docker]# mkdir /docker/data/[root@centos7 docker]# cd !$cd /docker/data/[root@centos7 data]# echo "123" &gt; test1.html[root@centos7 data]# echo "123" &gt; test2.html[root@centos7 data]# echo "123" &gt; test3.html[root@centos7 docker]# tree.├── data│ ├── test1.html│ ├── test2.html│ └── test3.html└── Dockerfile###################################################################打算将/docker/data/目录下的文件全部复制到容器中排除test3.html文件###################################################################[root@centos7 docker]# vim .dockerignore #定义的.dockerignore 文件要写Dockerfile的相对路径，文件内也支持通配符data/test3.html#######################################################################################编辑Dockerfile文件###########################################################################################[root@centos7 docker]# vim /docker/Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"COPY data /data/web/html/ #如果源是目录会cp源目录下的文件不会cp目录本身##########################################################################################创建新的镜像###########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.4Sending build context to Docker daemon 5.632kBStep 1/3 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/3 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/3 : COPY data /data/web/html/ ---&gt; Using cache ---&gt; 5b5cd427fb81Successfully built 5b5cd427fb81Successfully tagged mybox:v0.4#############################################################################################创建容器查看#####################################################################################[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.4 /bin/sh/ # ls /data/web/html/*/data/web/html/test1.html /data/web/html/test2.html 3.Dockerflie文件中ADD指令123456789101112131415161718192021222324252627282930313233[root@centos7 docker]# pwd/docker[root@centos7 docker]# lsDockerfile wordpress-4.9-zh_CN.tar.gz[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ADD http://nginx.org/download/nginx-1.14.2.tar.gz /data/ #将网上的url打入镜像中，并运行容器是自动下载此压缩包放置在容器中的/data目录中ADD wordpress-4.9-zh_CN.tar.gz /data2/ #此压缩包是放置在docker的工作目录中，会在容器运行时解压到容器中/data2目录中。[root@centos7 docker]# docker image build /docker/ -t mybox:v0.3Sending build context to Docker daemon 10.13MBStep 1/4 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/4 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/4 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz /data/Downloading 1.015MB/1.015MB ---&gt; 62b1d80179e4Step 4/4 : ADD wordpress-4.9-zh_CN.tar.gz /data2/ ---&gt; 6bfaa9b46d21Successfully built 6bfaa9b46d21Successfully tagged mybox:v0.3[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.3 /bin/sh/ # ls /datadata/ data2// # ls /datanginx-1.14.2.tar.gz/ # ls /data2wordpress 4.Dockerfile文件中WORKDIR指令123456789101112131415161718192021222324252627282930313233343536373839404142###########################################################################################定义工作目录##########################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR / #定义工作目录，表示/data/ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ #定义工作目录，表示/data/haha/ADD wordpress-4.9-zh_CN.tar.gz haha/###########################################################################################制作镜像并运行查看######################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.4Sending build context to Docker daemon 10.13MBStep 1/6 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/6 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/6 : WORKDIR / ---&gt; Running in a9ef74256526Removing intermediate container a9ef74256526 ---&gt; 89e2798cf96cStep 4/6 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/Downloading 1.015MB/1.015MB ---&gt; 653df7aeb99bStep 5/6 : WORKDIR /data/ ---&gt; Running in 55e4223e543cRemoving intermediate container 55e4223e543c ---&gt; 471c356643dcStep 6/6 : ADD wordpress-4.9-zh_CN.tar.gz haha/ ---&gt; c1d30647ca27Successfully built c1d30647ca27Successfully tagged mybox:v0.4[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.4 /bin/sh/data # ls /data/haha nginx-1.14.2.tar.gz/data # ls /data/haha/wordpress 5.Dockerfile文件中VOLUME指定存储卷指令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465docker管理的卷（要是想要指定绑定在宿主机的某个目录进行映射关联关系的存储卷继续使用-v选项指定）####################################################################################################docker管理的卷###################################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR /ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ADD wordpress-4.9-zh_CN.tar.gz haha/VOLUME /data/web/html #指定容器中的此目录与宿主机上的某一个目录做存储卷映射关系#####################################################################################################打镜像--运行容器##############################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.5Sending build context to Docker daemon 10.15MBStep 1/7 : FROM busybox:latest ---&gt; 3a093384ac30Step 2/7 : LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;" ---&gt; Using cache ---&gt; 7ccdca9907ceStep 3/7 : WORKDIR / ---&gt; Using cache ---&gt; 89e2798cf96cStep 4/7 : ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/Downloading 1.015MB/1.015MB ---&gt; Using cache ---&gt; 653df7aeb99bStep 5/7 : WORKDIR /data/ ---&gt; Using cache ---&gt; 471c356643dcStep 6/7 : ADD wordpress-4.9-zh_CN.tar.gz haha/ ---&gt; Using cache ---&gt; c1d30647ca27Step 7/7 : VOLUME /data/web/html ---&gt; Running in 388c0312f897Removing intermediate container 388c0312f897 ---&gt; 54cf9694d119Successfully built 54cf9694d119Successfully tagged mybox:v0.5[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.5 /bin/sh/data # ls /data/web/html//data # #################################################################################################宿主机上查看对应的随机的存储卷#########################################################################################[root@centos7 ~]# docker image inspect mybox:v0.5 "Volumes": &#123; "/data/web/html/": &#123;&#125; &#125;,[root@centos7 ~]# docker container inspect pc1 "Mounts": [ &#123; "Type": "volume", "Name": "177fd037174ad4af75866df8d07c575f1e4dbee2ee65613c6e36842b4e6de49e", "Source": "/var/lib/docker/volumes/177fd037174ad4af75866df8d07c575f1e4dbee2ee65613c6e36842b4e6de49e/_data", "Destination": "/data/web/html", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" &#125; 6.Dockerfile中EXPOSE指令1234567891011121314151617181920212223242526272829303132333435363738################################################################################################编写Dockerfile端口暴露tcp80###########################################################################################[root@centos7 docker]# vim Dockerfile FROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR /ADD http://nginx.org/download/nginx-1.14.2.tar.gz data/WORKDIR /data/ADD wordpress-4.9-zh_CN.tar.gz haha/VOLUME /data/web/htmlEXPOSE 80/tcp################################################################################################创建镜像并运行查看端口是否暴露##########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.6[root@centos7 docker]# docker run --name pc1 -it --rm mybox:v0.6 /bin/sh[root@centos7 ~]# docker container inspect pc1 "Config": &#123; "Hostname": "b8bb78bbe2fb", "Domainname": "", "User": "", "AttachStdin": true, "AttachStdout": true, "AttachStderr": true, "ExposedPorts": &#123; "80/tcp": &#123;&#125; &#125;,[root@centos7 _data]# docker container port pc1#默认没有端口暴露，虽然在Dockerfile文件中已经定义，由于网络风险需要在启动容器是指定端口暴露这种暴露和存储卷相同，都是宿主机随机动态#############################################################################################此时可以手动指定开始端口暴漏##################################################################################################[root@centos7 docker]# docker run --name pc1 -it -P --rm mybox:v0.6 /bin/sh[root@centos7 ~]# docker container port pc180/tcp -&gt; 0.0.0.0:32768 7.Dockerfile文件中ENV指令12345678910111213[root@centos7 docker]# vim Dockerfile FROM busybox:latestENV webhome="/data/web/html/"LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR $&#123;webhome&#125;ADD http://nginx.org/download/nginx-1.14.2.tar.gz $&#123;webhome&#125;WORKDIR $&#123;webhome&#125; ADD wordpress-4.9-zh_CN.tar.gz ./ VOLUME $&#123;webhome&#125;EXPOSE 80/tcp[root@centos7 docker]# docker image build /docker/ -t mybox:v0.7[root@centos7 docker]# docker run --name pc2 -it --rm mybox:v0.7 /bin/sh 8.Dockerfile文件中ARG指令1234567891011121314151617181920212223242526build的时对变量传值的做法#Dockerfile中定义了创建容器时的变量参数。如果想临时修改参数可以在命令行中使用ARG定义变量，--build-arg,在执行docker image buil 命令命令行选项可以改变变量的值（docker新版本中支持）########################################################################################################使用ARG定义变量########################################################################################################[root@centos7 ~]# cd /docker/[root@centos7 docker]# vim Dockerfile FROM busybox:latestARG webhome="/data/web/html/"LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"WORKDIR $&#123;webhome&#125; ADD http://nginx.org/download/nginx-1.14.2.tar.gz $&#123;webhome&#125; WORKDIR $&#123;webhome&#125;ADD wordpress-4.9-zh_CN.tar.gz ./ VOLUME $&#123;webhome&#125;EXPOSE 80/tcp######################################################################################打镜像，并使用--build-arg指定新的便令再次打镜像#########################################################################################[root@centos7 docker]# docker image build /docker/ -t mybox:v0.8#这个镜像执行与EVN执行的镜像一样#使用--build-arg指定新的变量的值[root@centos7 docker]# docker image build --build-arg webhome="/var/www/html" /docker/ -t mybox:v0.7[root@centos7 docker]# docker run --name pc2 -it --rm mybox:v0.7 /bin/sh/var/www/html # run阶段Dockerfile文件中的指令 (run阶段：指明在bulid时做一些通过运行shell命令来达到去设定目标镜像的目的） RUN 用于指定docker build过程中运行的程序，其可以是任何命令（run的任何命令代表基础镜像支持的命令） Syntax RUN &lt;command&gt; 或 #以shell解释运行 RUN [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] #不以shell解释运行 第一种格式中，&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程 在容器中的PID不为1，不能接收Unix信号，因此，当使用docker stop &lt;container&gt;命令停止容器 时，此进程接收不到SIGTERM信号； 第二种语法格式中的参数是一个JSON格式的数组，其中&lt;executable&gt;为要运行的命令，后面的 &lt;paramN&gt;为传递给命令的选项或参数；然而，此种格式指定的命令不会以“/bin/sh -c”来发起 ，因此常见的shell操作如变量替换以及通配符(?,*等)替换将不会进行；不过，如果要运行的命令 依赖于此shell特性的话，可以将其替换为类似下面的格式。 RUN [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;] 注意：json数组中，要使用双引号 CMD 类似于RUN指令，CMD指令也可用于运行任何命令或应用程序，不过，二者 的运行时间点不同 RUN指令运行于映像文件构建过程中，而CMD指令运行于基于Dockerfile构建出的新映像 文件启动一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器也 将终止；不过，CMD指定的命令其可以被docker run的命令行选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅最后一个会生效 Syntax CMD &lt;command&gt; 或 #以shell运行 CMD [“&lt;executable&gt;”, “&lt;param1&gt;”, “&lt;param2&gt;”] 或 #不以shell解释运行 CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;] 前两种语法格式的意义同RUN 第三种则用于为ENTRYPOINT指令提供默认参数 ENTRYPOINT 类似CMD指令的功能，用于为容器指定默认运行程序，从而使得容器像是一个 单独的可执行程序 与CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令行指定的 参数所覆盖，而且，这些命令行参数会被当作参数传递给ENTRYPOINT指定 指定的程序 不过，docker run命令的–entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序 Syntax ENTRYPOINT &lt;command&gt; ENTRYPOINT [&quot;&lt;executable&gt;&quot;, &quot;&lt;param1&gt;&quot;, &quot;&lt;param2&gt;&quot;] docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到 ENTRYPOINT命令最后做为其参数使用 Dockerfile文件中也可以存在多个ENTRYPOINT指令，但仅有最后一个会生效 Dockerfile文件中RUN指令12345678910111213141516#运行起来的命令还是shell[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# cat Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/* #删除yum生成的缓存不免刻录至镜像中[root@centos7 dockerlamp]# docker run --name pc1 --rm -it lamp:v0.1 /bin/shsh-4.2# rpm -q httpd phphttpd-2.4.6-88.el7.centos.x86_64php-5.4.16-46.el7.x86_64 Dockerfile文件中CMD指令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#RUN在bulid阶段#CMD在run阶段#实现容器运行起来不是shell而是httpd，实现httpd运行在前台###################################################################如何实现将httpd实现前台运行cat /usr/lib/systemd/system/httpd.service ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND####################################################################[root@centos7 ~]# cd /dockerlamp/[root@centos7 dockerlamp]# cat Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*CMD ["usr/sbin/httpd","-DFOREGROUND"][root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.2[root@centos7 dockerlamp]# docker run --name pc2 -it --rm lamp:v0.2 #烟验证[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf6b5dd3c9664 lamp:v0.2 "usr/sbin/httpd -DFO…" About a minute ago Up About a minute pc2[root@centos7 dockerlamp]# docker exec -it pc2 /bin/bash[root@f6b5dd3c9664 /]# netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN###############################################################################################################改进#####################################################制作Dockerfile文件并添加测试页打包至镜像###################[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# vim php.php&lt;?php phpinfo();?&gt;[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;CMD ["usr/sbin/httpd","-DFOREGROUND"]#########################################################################################################打镜像并运行容器测试##################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.3[root@centos7 dockerlamp]# docker run --name pc3 -it --rm lamp:v0.3 #测试[root@centos7 dockerlamp]# docker exec -it pc3 /bin/bash[root@b1da3c0ce6d8 /]# curl 172.17.0.2#########################################################################################################说明#################################################################################################################此时也可以用户在命令行中运行指定使用/bin/bash运行的##可以手动指定命令来覆盖镜像Dockerfile文件中CMD的##上一个镜像文件中默认已经定义运行容器默认运行的进程为httpd的，可以手动运行/bin/bash[root@centos7 dockerlamp]# docker run --name pc3 -it --rm lamp:v0.3 /bin/bash[root@97ef0a13d4fc /]# [root@97ef0a13d4fc /]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.1 0.1 11820 1884 pts/0 Ss 07:48 0:00 /bin/bashroot 16 0.0 0.0 51740 1732 pts/0 R+ 07:49 0:00 ps aux#Dokcerfile文件中定义的运行httpd已经被覆盖，查看进程httpd进程未被启动，如果想要CMD不被覆盖则此时应该用到ENTRYPOINT Dockerfile文件中ENTRYPOINT指令( --entrypoint )12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#ENTRYPOINT单独使用情况下作用于CMD大致相同除了不可被用户命令行运行容器时任意被覆盖#####################################################################################################常见Dockerfile文件########################################################################################################[root@centos7 dockerlamp]# pwd/dockerlamp[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;EXPOSE 80/tcpVOLUME $&#123;root&#125;ENTRYPOINT ["usr/sbin/httpd","-DFOREGROUND"][root@centos7 dockerlamp]# lsDockerfile php.php#####################################################################################################打镜像运行容器############################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.4[root@centos7 dockerlamp]# docker run --name pc1 -it -P --rm lamp:v0.4#####################################################################################################宿主机检测################################################################################################################[root@centos7 dockerlamp]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0031f963fce6 lamp:v0.4 "usr/sbin/httpd -DFO…" 41 seconds ago Up 41 seconds 80/tcp pc1[root@centos7 dockerlamp]# docker container port pc180/tcp -&gt; 0.0.0.0:32769[root@centos7 dockerlamp]# curl 172.18.135.1:32769######################################################################################测试试图覆盖Docker文件中定义的执行的ENTRYPOINT指令#########################################################################################[root@centos7 dockerlamp]# docker run --name pc1 -P -it --rm lamp:v0.4 /bin/bashUsage: usr/sbin/httpd [-D name] [-d directory] [-f file]#报错拒绝覆盖Docker文件中定义的执行的ENTRYPOINT指令#命令行运行时添加的/bin/bash则当作了Docker文件中定义的执行的ENTRYPOINT指令后面的参数（httpd不支持/bin/bash当作参数）##################################################################################用户执行命令时如何指明强制覆盖Docker文件中定义的执行的ENTRYPOINT指令############################################################################[root@centos7 dockerlamp]# docker run --name pc1 -P -it --rm --entrypoint "/bin/bash" lamp:v0.4[root@5de1663077eb /]# Dockerfile文件中ENTRYPOINT指令于CMD指令同时使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#CMD定义的命令都要统统作为ENTRYPOINT的参数#一下两种格式意义相同CMD ["usr/sbin/httpd","-DFOREGROUND"] #CMD作为ENTRYPOINT的参数执行ENTRYPOINT ["/bin/bash","-c"]=========================================================================CMD /usr/bin/httpd -DFOREGROUD##########################################################################ENTRYPOINT与CMD分隔开来写的意义： 在ENTRYPOINT运行一个脚本，CMD的指令会被当作脚本的参数传递给脚本，脚本作为传统应用程序和容器化运行的中间层，来处理配置文件的，同时此配置文件是可以接受环境变量为参数来设置配置文件。#########################################################################################Dockerfile文件中ENTRYPOINT指令于CMD指令同时使用######################################################################################[root@centos7 dockerlamp]# vim Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD php.php $&#123;root&#125;ADD ent.sh /bin/EXPOSE 8080/tcpVOLUME $&#123;root&#125;CMD ["usr/sbin/httpd","-DFOREGROUND"]ENTRYPOINT ["/bin/ent.sh"]#编写的脚本的解释器一定是基础镜像中所被支持解释的类型[root@centos7 dockerlamp]# vim ent.sh#!/bin/bash##如果用户没定义此为默认的变量listen_port=$&#123;LISTEN_PORT:-8080&#125;server_name=$&#123;SERVER_NAME:-localhost&#125;doc_root=$&#123;DOC_ROOT:-/var/www/html&#125;cat &gt; /etc/httpd/conf.d/myweb.conf &lt;&lt;EOFlisten $listen_port&lt;VirtualHost *:$&#123;listen_port&#125;&gt; ServerName "$server_name" DocumentRoot "$doc_root" &lt;Directory "$doc_root"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/Virtualhost&gt;EOF#引用一个脚本的所有参数,默认的httpd进程/bin/bash的子进程&gt;，要想使得httpd作为init下的一级进程则如下写法(目标进程替换shell进程,让shell自动退出)exec "$@"[root@centos7 dockerlamp]# chmod +x /dockerlamp/ent.sh [root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v0.5[root@centos7 dockerlamp]# docker run --name pc1 -it --rm lamp:v0.5(可以在命令行中使用-e选项对容器中的环境变量传值 使用printenv命令可以查看传入变量的值 )[root@centos7 ~]# docker container port pc1[root@centos7 ~]# curl 172.18.135.1:32777[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@5b32b59d73ef /]# cat /etc/httpd/conf.d/myweb.conf listen 8080&lt;VirtualHost *:8080&gt; ServerName "localhost" DocumentRoot "/var/www/html" &lt;Directory "/var/www/html"&gt; Options none AllowOverride none Require all granted &lt;/Directory&gt;&lt;/Virtualhost&gt;#httpd的进程号为1[root@2967451fc4a9 /]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.7 408092 13436 pts/0 Ss+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 8 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 9 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 10 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 11 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUNDapache 12 0.0 0.3 408092 6748 pts/0 S+ 09:19 0:00 usr/sbin/httpd -DFOREGROUND#########################################################################################run是使用-e选项对容器进行变量复制######################################################################################################(可以在命令行中使用-e选项对容器中的环境变量传值 使用printenv命令可以查看传入变量的值 )[root@centos7 dockerlamp]# docker run --name pc1 -it --rm -P -e LISTEN_PORT=1010 lamp:v0.10[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@067566aa1878 /]# printenv LISTEN_PORT=1010[root@centos7 dockerlamp]# docker run --name pc1 -it --rm -P -e hi=hehe lamp:v0.10[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@2967451fc4a9 /]# echo $hi hehe USER 用于指定运行image时的或运行Dockerfile中任何RUN、CMD或ENTRYPOINT 指令指定的程序时的用户名或UID 默认情况下，container的运行身份为root用户 Syntax USER | 需要注意的是，可以为任意数字，但实践中其必须为/etc/passwd中某用户的有效 UID，否则，docker run命令将运行失败 HEALTHCHECK健康状态检测（新版支持） HEALTHCHECK指令告诉Docker如何测试一个容器，以检查它是否仍在工作。这可以检测出一些情况，比如web服务器陷入无限循环，无法处理新连接，即使服务器进程仍在运行。 HEALTHCHECK指令有两种形式: HEALTHCHECK [OPTIONS] CMD命令(通过在容器内运行命令来检查容器的健康状况) HEALTHCHECK NONE(不做任何健康检测) HEALTHCHECK(2) 在CMD之前可以出现的选项有: –interval=DURATION (default: 30s) #每隔多久检测一次，检测频率默认为30秒 –timeout=DURATION (default: 30s) #相对方发起检测请求，等待超时时长默认为30秒 –start-period=DURATION (default: 0s) #在什么时间开始进程健康检测，0表示容易以启动立刻做第一次健康检测 –retries=N (default: 3) #检测失败，重试检测多少吃后失败再判定为失败，默认为检测3次 命令的退出状态指示容器的健康状态。可能的值是: 0: success 成功 1: unhealthy 不健康 2: reserved 保留 范例： HEALTHCHECK –interval=5m –timeout=3s \ CMD curl -f http://localhost/ || exit 1 Dockerfile文件中HEALTHCHECK健康状态检测指令（新版支持）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657####################################################################################################定制健康检查计划############################################################################################################[root@centos7 ~]# vim /dockerlamp/Dockerfile FROM centos:7LABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"ARG root=/var/www/html/RUN yum makecache &amp;&amp; \ yum -y install httpd php php-mysql curl &amp;&amp; \ yum clean all &amp;&amp; \ rm -rf /var/cache/yum/*ADD ok.html php.php $&#123;root&#125;ADD ent.sh /bin/EXPOSE 8080/tcpVOLUME $&#123;root&#125;HEALTHCHECK --interval=3s --timeout=3s --start-period=2s CMD curl -f http://localhost/ok.html || exit 1CMD ["usr/sbin/httpd","-DFOREGROUND"]ENTRYPOINT ["/bin/ent.sh"][root@centos7 dockerlamp]# lsDockerfile ent.sh php.php[root@centos7 dockerlamp]# echo "ok" &gt; ok.html################################################################################################打镜像测试健康计划############################################################################################################[root@centos7 dockerlamp]# docker image build /dockerlamp/ -t lamp:v1.0[root@centos7 dockerlamp]# docker run --name pc1 -it --rm lamp:v1.0 #查看状态健康的[root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES763a1536b62d lamp:v1.0 "/bin/ent.sh usr/sbi…" 6 seconds ago Up 5 seconds (healthy) 8080/tcp pc1##############################################################################################删除文件查看是否不健康############################################################################################################[root@centos7 ~]# docker exec -it pc1 /bin/bash[root@763a1536b62d /]# rm -rf /var/www/html/ok.html [root@centos7 dockerlamp]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES763a1536b62d lamp:v1.0 "/bin/ent.sh usr/sbi…" 3 minutes ago Up 3 minutes (unhealthy) 8080/tcp pc1#一旦发现容器出错时，手动将容器杀死重新构建，此功能是容器引擎做不到的，需要借助容器编排工具#如果再构建镜像的时候未构建也可以再运行命令行运行容器时手动指定（人为的在外部定义）[root@centos7 dockerlamp]# docker run --helpUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] --health-cmd string Command to run to check health --health-interval duration Time between running the check (ms|s|m|h) (default 0s) --health-retries int Consecutive failures needed to report unhealthy --health-start-period duration Start period for the container to initialize before starting health-retries countdown (ms|s|m|h) (default 0s) --health-timeout duration Maximum time to allow one check to run SHELL 指令允许覆盖命令的SHELL形式所使用的默认SHELL。 Linux上的默认shell是[“/bin/sh”， “-c”] Windows上的默认shell是[“cmd”， “/S”， “/C”] SHELL指令必须以JSON格式写入Dockerfile中 语法:SHELL[“可执行”，”参数”] 外壳指令可以出现多次。每个SHELL指令覆盖前面的所有SHELL指令，并影响后面的所有指令。 STOPSIGNAL 指令设置将发送到容器的系统调用信号以退出 这个信号可以是一个有效的无符号数字 它匹配内核的syscall表中的一个位置，例如9 也可以是SIGNAME格式的一个信号名，例如SIGKILL。 Syntax: STOPSIGNAL signal ONBUILD 用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件，此映像文件亦可作为base image被另一个Dockerfile 用作FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时，将会“触发”创 建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 Syntax ONBUILD 尽管任何指令都可注册成为触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和 MAINTAINER指令 使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild 在ONBUILD指令中使用ADD或COPY指令应该格外小心，因为新构建过程的上下文在缺少指 定的源文件时会失败 Dockerfile文件中的ONBUILD指令12345678910111213141516171819202122232425当别人利用自己的镜像做基础镜像你自己先前定义好的dockerfile，当别人拿自己镜像做基础镜像再次创建的dockerfile文件，自己填写的ONBUILD指令在自己run的时候不会运行，当别人拿自己镜像在此基础上创建的dockerfile执行的时候才会运行自己定义的ONBUILD指令。#定义ONBUILD，当别人拿自己的镜像做基础镜像再次做dockerfile执行时则在/data/data目录中下载URL，自己run时则不执行[root@centos7 ~]# mkdir /test[root@centos7 ~]# cd /test/[root@centos7 test]# vim DockerfileFROM busybox:latestLABEL maintainer="daizhe&lt;daizhe@9527dz.top&gt;"RUN mkdir -p /data/dataONBUILD ADD http://nginx.org/download/nginx-1.2.9.tar.gz /data/data#打镜像[root@centos7 test]# docker image build /test/ -t haha:v0.1#在自己制作的基础上再次制作[root@centos7 ~]# mkdir /test1[root@centos7 ~]# cd !$cd /test1[root@centos7 test1]# vim DockerfileFROM haha:v0.1RUN mkdir -p /data/haha#此时第一次制作的镜像定义的ONBUILD 会执行[root@centos7 test1]# docker image build /test1/ -t hehe:v0.1 如何将自己本地制作的镜像分享给别人1234567891011121314此场景适用于内部临时是使用、本地间的节点间共享将本地的镜像文件打包，剥离远程镜像仓库的格式，打包未tar文件，实现节点共享#####################抽取本地上的镜像######################[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEhehe v0.1 e75cb1954996 7 minutes ago 1.93M[root@centos7 ~]# docker image save hehe:v0.1 -o ./jingxiang.tar[root@centos7 ~]# lsjingxiang.tar#####################复制到其他节点，使用此镜像#################[root@centos7 ~]# docker image load -i jingxiang.tar]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker存储卷]]></title>
    <url>%2F2019%2F01%2F01%2Fdocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[docker容器存储卷 一、什么是存储卷 Docker镜像由多个只读层叠加而成，启动容器时，Docker会加载只读镜 像层并在镜像栈顶部添加一个读写层 如果运行中的容器修改了现有的一个已经存在的文件，那该文件将会 从读写层下面的只读层复制到读写层，该文件的只读版本仍然存在， 只是已经被读写层中该文件的副本所隐藏，此即“写时复制(COW)”机制 关闭并重启容器，其数据不受影响；但删除Docker容器，则其更改将会 全部丢失 存在的问题 存储于联合文件系统中，不易于宿主机访问； •容器间数据共享不便 删除容器其数据会丢失 解决方案：“卷(volume)” “卷”是容器上的一个或多个“目录”，此类目录可绕过联合文件系统，与宿主机 上的某目录“绑定(关联)” Docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在 宿主机上的位置有所不同； 绑定挂载的卷 宿主机上的目录是用户指定的，在容器中的目录也是用户指定的 docker管理的卷 容器中的目录是用户指定的，在宿主机上的目录是在固定目录下自动生成的 脱离容器的生命周期，也可以脱离节点的生命周期 二 、存储卷实现 1.docker管理的卷123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051##################################################################################docker管理的卷###############################################################################1.容器中的目录是用户指定的，在宿主机上的目录是在固定目录下自动生成的，-v选项指定绑定的卷，自动在容器中创建对应的目录，并且指定的容器中的目录与宿主机上目录建立了关联关系#2.创建容器的命令行中使用--rm选项则退出容器时删除容器，宿主机上对应的存储卷则也将删除#3.停止容器宿主机上的存储卷不会被删除#3.如果使用docker container rm 容器，宿主机上对应的存储卷不会被删除[root@centos7 ~]# docker run --name pc1 -it -v /mydata busybox # lsmydata #可查看pc1容器对应的宿主机上的目录的关联关系[root@centos7 ~]# docker volume ls[root@centos7 ~]# docker container inspect pc1 "Mounts": [ &#123; "Type": "volume", "Name": "29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0", "Source": "/var/lib/docker/volumes/29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0/_data", "Destination": "/mydata", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" &#125;#容器中创建文件/ # cd /mydata//mydata # ls/mydata # touch a#宿主机在关联的目录中查看文件是否存在[root@centos7 ~]# cd /var/lib/docker/volumes/29fd92b6acf728b23323168ff82e7e34b588b46f1698db2adb6fe3d6bc9713d0/_data[root@centos7 _data]# lsa#退出容器/mydata # exit#宿主机上查看对应的目录[root@centos7 ~]# docker container ps -a[root@centos7 _data]# lsa#删除容器[root@centos7 ~]# docker container rm pc1pc1#宿主机上查看对应的存储卷目录[root@centos7 _data]# lsa 2.绑定挂载的卷123456789101112131415161718192021222324252627##################################################################################绑定挂载的卷#####################################################################################宿主机上的目录是用户指定的，在容器中的目录也是用户指定的#宿主上指定目录[root@centos7 ~]# mkdir /daizhe#创建容器并指定宿主机上的存储卷和指定容器中的目录进行关联#/daizhe为手动指定的宿主机的目录#/mydata为手动指定的容器中的目录[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox/ # lsmydata#测试/ # cd /mydata//mydata # touch a[root@centos7 ~]# ls /daizhe/a#删除容器卷不会被删除[root@centos7 ~]# docker container rm pc1pc1[root@centos7 ~]# ls /daizhe/a 3.多个容器挂载到宿主机上的同一个存储卷上1234567891011121314151617181920212223242526############################################################################多个容器挂载到宿主机上的同一个存储卷上####################################################################创建三个容器，同时容器到宿主机的存储卷指定为同一个目录[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox[root@centos7 ~]# docker run --name pc2 -it -v /daizhe:/mydata2 busybox[root@centos7 ~]# docker run --name pc3 -it -v /daizhe:/mydata3 busybox#测试是否同时挂载上宿主机上的同一个卷#宿主机在此目录下创建文件[root@centos7 ~]# cd /daizhe/[root@centos7 daizhe]# touch a c ddd#检测宿主机上文件是否存在[root@centos7 ~]# docker container exec pc1 ls /mydataacddd[root@centos7 ~]# docker container exec pc2 ls /mydata2acddd[root@centos7 ~]# docker container exec pc3 ls /mydata3acddd 利用存储卷实现容器间共享数据 名称空间共享 可共享 Net、IPC、UTS 不可共享 Mount、User、PID -v, –volume list 绑定安装卷 –volume-driver string 容器的可选卷驱动程序 –volumes-from list 从指定安装卷 4.容器间共享存储卷即容器间复制存储卷12345678910111213141516171819#创建容器，将容器中的/mydata目录与宿主机的/daizhe进行挂载实现存储卷[root@centos7 ~]# docker run --name pc1 -it -v /daizhe:/mydata busybox / # lsmydata / # touch /mydata/a c ddd/ # ls /mydata/a c ddd#创建一个容器命令为pc2复制pc1的存储卷[root@centos7 ~]# docker run --name pc2 -it --volumes-from pc1 busybox/ # lsbin etc mydata root tmp vardev home proc sys usr/ # ls /mydata/a c ddd#宿主机上查看[root@centos7 daizhe]# lsa c ddd 在容器中使用Volumes12345678- 为docker run命令使用-v选项即可使用Volume - Docker-managed volume - ~]# docker run -it -name bbox1 –v /data busybox - ~]# docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox1 - 查看bbox1容器的卷、卷标识符及挂载的主机目录 - Bind-mount Volume - ~]# docker run -it -v HOSTDIR:VOLUMEDIR --name bbox2 busybox - ~]# docker inspect -f &#123;&#123;.Mounts&#125;&#125; bbox2 详细信息过滤1234567891011#显示的文件为json的文件格式- 字段内嵌[root@centos7 ~]# docker container inspect pc1#引用一级字段过滤[root@centos7 ~]# docker container inspect -f &#123;&#123;.NetworkSettings&#125;&#125; pc1&#123;&#123; c01b6a9b6146da49e5374db58e8aae168286c29b5b2fb0a814673415a4e4d796 false 0 map[] /var/run/docker/netns/c01b6a9b6146 [] []&#125; &#123;3db3b94ed903cdc6e5dfa72af482b30ff16faf23a08d697e4e3d3f0c01175e42 172.17.0.1 0 172.17.0.2 16 02:42:ac:11:00:02&#125; map[bridge:0xc4205aa000]&#125;#引用二级字段过滤[root@centos7 ~]# docker container inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; pc1172.17.0.2 josn格式文件美观显示1[root@centos7 ~]# yum install jq -y]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker网络模型]]></title>
    <url>%2F2018%2F12%2F31%2Fdocker%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[docker网络模型 Docker网络模型详解 docker安装完会修改默认的防火墙规则 将FORWARD链默认的accept修改为drop 如果用到转发的功能可以修改docker的启动文件如下 12345678910111213141516171819202122修改docker的启动文件[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStartPost=/usr/sbin/iptables -P FORWARD ACCEPTExecStart=/usr/bin/dockerd -H unix://ExecReload=/bin/kill -s HUP $MAINPIDTimeoutSec=0RestartSec=2Restart=always~]# systemctl daemon-reload~]# systemctl restart docker~]# iptables -vnLChain FORWARD (policy ACCEPT 0 packets, 0 bytes) 四种网络 桥网络bridge： 默认docker0 NET桥 共享桥、共享接口：（共享网络名称空间） 联盟式网络 容器直接使用宿主机网络的共享 host网络 空网络、无网络、none网络123456查看docker可以使用的网络类型[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE38c0658bea06 bridge bridge local9b7ecc0031ef host host localc0de873b7341 none null local 共享桥 无网络：仅lo,仅自己通讯 –network none 桥网络 (详情查看 dacker network inspact brige) –network brige (默认) 容器间共享网络（联盟式网络） –network contariner:指定已有网容器（相同主机名，不同容器，但是网络是共享，仅共享网络，可以基于127.0.0.1通讯） 共享主机网络 –network host 无网络123456789[root@centos7 ~]# docker run --name pc1 -it --rm --network none busybox:latest/ # ifconfiglo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 桥网络123456789101112131415161718192021# (默认docker0 NET桥,详情查看 dacker network inspact brige)[root@centos7 ~]# docker run --name pc2 -it --rm --network bridge busybox:latest/ # ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:508 (508.0 B) TX bytes:0 (0.0 B)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)#查看默认的net桥的详情[root@centos7 ~]# docker network inspect bridge 容器间共享网络1234567891011121314151617181920212223242526272829303132333435363738394041424344#容器间共享：NET,IPC,UTS第一个容器 [root@centos7 ~]# docker run --name pc2 -it --rm --network bridge busybox:latest / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:7 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:578 (578.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname 45ec3fb534cd第二个容器（共享第一个容器的地址） [root@centos7 ~]# docker run --name pc3 -it --rm --network container:pc2 busybox:latest / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:648 (648.0 B) TX bytes:0 (0.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname 45ec3fb534cd 共享宿主机网络1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 [root@centos7 ~]# docker run --name pc4 -it --rm --network host busybox:latest / # ifconfig docker0 Link encap:Ethernet HWaddr 02:42:D4:BB:AF:CF inet addr:172.17.0.1 Bcast:172.17.255.255 Mask:255.255.0.0 inet6 addr: fe80::42:d4ff:febb:afcf/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:21 errors:0 dropped:0 overruns:0 frame:0 TX packets:41 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:3522 (3.4 KiB) TX bytes:3758 (3.6 KiB) ens33 Link encap:Ethernet HWaddr 00:0C:29:14:4D:62 inet addr:192.168.52.1 Bcast:192.168.52.255 Mask:255.255.255.0 inet6 addr: fe80::bbfd:d184:6a67:3c45/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:264 errors:0 dropped:0 overruns:0 frame:0 TX packets:38 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:29263 (28.5 KiB) TX bytes:4779 (4.6 KiB) ens37 Link encap:Ethernet HWaddr 00:0C:29:14:4D:6C inet addr:172.18.135.1 Bcast:172.18.135.255 Mask:255.255.255.0 inet6 addr: fe80::4587:5c47:4c05:570b/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:33565 errors:0 dropped:0 overruns:0 frame:0 TX packets:8191 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:14694609 (14.0 MiB) TX bytes:1013772 (990.0 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:98 errors:0 dropped:0 overruns:0 frame:0 TX packets:98 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:10996 (10.7 KiB) TX bytes:10996 (10.7 KiB) veth7ff20ba Link encap:Ethernet HWaddr C2:81:A1:34:BA:5F inet6 addr: fe80::c081:a1ff:fe34:ba5f/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:648 (648.0 B) virbr0 Link encap:Ethernet HWaddr 52:54:00:FF:0B:1F inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # hostname centos7.com 其他网络相关的命令123456789101112131415161718192021222324252627282930313233343536373839404142############################指定主机名########################## -h, --hostname string Container host name#默认的主机名是docker容器对应的id[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com busybox:latest / # hostnamep1.com##########################外部指定host文件以及文件的内容############ --add-host list Add a custom host-to-IP mapping (host:ip)#适用于容器间使用主机名通信，可多次使用[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com --add-host wg.p1.com:172.18.0.1 busybox:latest / # cat /etc/hosts127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.18.0.1 wg.p1.com172.17.0.2 p1.com p1[root@centos7 ~]# docker run --name p1 -it --rm --hostname p1.com --add-host wg.p1.com:172.18.0.1 --add-host www.p1.com:8.8.8.8 busybox:latest #############创建容器时指定NDS服务器地址以及搜索域################# --dns list Set custom DNS servers --dns-search list Set custom DNS search domains[root@centos7 ~]# docker run --name pc1 -it --rm --hostname pc1.com --add-host www.pc1.com:1.1.1.1 --dns 8.8.8.8 --dns 114.114.114.114 --dns-search com busybox/ # cat /etc/hosts 127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters1.1.1.1 www.pc1.com172.17.0.2 pc1.com pc1/ # cat /etc/resolv.conf search comnameserver 8.8.8.8nameserver 114.114.114.114 服务暴漏 expose,public让私有网络中的主机上的服务被外部主机访问到—DNAT -p选项的使用格式 -p &lt;containerPort&gt; 将指定的容器端口映射至宿主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; 将容器端口&lt;containerPort&gt;映射至宿主机上指定的主机端口&lt;hostPort&gt;（宿主机上所有地址的此端口） -p &lt;ip&gt;::&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至宿主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;hostPort&gt;:&lt;containerPort&gt; 将指定的容器端口&lt;containerPort&gt;映射至宿主机指定&lt;ip&gt;的端口&lt;hostPort&gt; “动态端口”指随机端口，具体的映射结果可使用docker port命令查看 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596-p选项的使用演示，可重复使用多次##########################################################################docker容器的80端口映射宿主机上的随机端口#######################################################################################[root@centos7 ~]# docker container run --name pc5 -it -p 80 busybox#ctrl + p ctrl + q#宿主机查看防火墙[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 214 packets, 20360 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:32770 to:172.17.0.2:80#可以访问宿主机的映射的端口从而访问容器的httpd服务[root@centos7 ~]# docker exec -it pc5 /bin/sh/ # /bin/httpd -h /etc/ # psPID USER TIME COMMAND 1 root 0:00 sh 7 root 0:00 /bin/sh 13 root 0:00 /bin/httpd -h /etc 14 root 0:00 ps/ # read escape sequence[root@centos7 ~]# curl 172.18.135.1:32770&lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;404 Not Found&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;H1&gt;404 Not Found&lt;/H1&gt;The requested URL was not found&lt;/BODY&gt;&lt;/HTML&gt;###########################################################################docker容器的80端口映射宿主机上的所有地址的80端口#########################################################################[root@centos7 ~]# docker run --name pc2 -it --network bridge -p 80:80 busybox/ # #查看防火墙[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 42 packets, 3276 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7e622f638dba busybox "sh" 3 minutes ago Up 3 minutes 0.0.0.0:80-&gt;80/tcp pc2##########################################################################docker容器的80端口映射宿主机上的指定地址的80端口###########################################################################第一个端口为宿主机的端口，第二个端口为容器的端口[root@centos7 ~]# docker container run --name pc1 -it --rm --network bridge -p 172.18.135.1:80:80 busybox/ # #容器的80地址绑定到宿主机的135.1地址的80端口[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 9 packets, 702 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 172.18.135.1 tcp dpt:80 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe87a037e4348 busybox "sh" About a minute ago Up About a minute 172.18.135.1:80-&gt;80/tcp pc1###########################################################################docker容器的80端口映射宿主机上的指定地址的随机端口##########################################################################[root@centos7 ~]# docker container run --name pc1 -it --rm --network bridge -p 172.18.135.1::80 busybox/ # [root@centos7 ~]# #宿主机检验[root@centos7 ~]# iptables -t nat -vnLChain PREROUTING (policy ACCEPT 15 packets, 1151 bytes) pkts bytes target prot opt in out source destination 0 0 DOCKER all -- * * 0.0.0.0/0 0.0.0.0/0 ADDRTYPE match dst-type LOCALChain DOCKER (2 references) pkts bytes target prot opt in out source destination 0 0 RETURN all -- docker0 * 0.0.0.0/0 0.0.0.0/0 0 0 DNAT tcp -- !docker0 * 0.0.0.0/0 172.18.135.1 tcp dpt:32768 to:172.17.0.2:80[root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8dd54f2321cd busybox "sh" About a minute ago Up About a minute 172.18.135.1:32768-&gt;80/tcp pc1########################################################################################端口映射关系查看#################################################################################################[root@centos7 ~]# docker container port pc2443/tcp -&gt; 192.168.52.1:44380/tcp -&gt; 172.18.135.1:80 范例：-p 选项多重复使用1234567[root@centos7 ~]# docker container run --name pc2 -it --rm --network bridge -p 172.18.135.1:80:80 -p 192.168.52.1:443:443 busybox/ # [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# docker container psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES028e3e9f581f busybox "sh" 13 seconds ago Up 13 seconds 172.18.135.1:80-&gt;80/tcp, 192.168.52.1:443-&gt;443/tcp pc28dd54f2321cd busybox "sh" 5 minutes ago Up 5 minutes 172.18.135.1:32768-&gt;80/tcp pc1 自建网络类型 docker network create [OPTIONS] NETWORK -d, –driver string #指定网络类型，默认为bridge，NET –subnet strings #指定子网地址，默认第一个地址设置为桥接口（网关）的地址 –gateway strings #不使用默认的手动指定网关 –ip-range strings #指定网络分配的地址，如果不指定则除网关外全部分配 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465############################自建网络地址######################[root@centos7 ~]# docker network create -d bridge --subnet 10.0.0.0/24 mybr09902c4e06158ac6bcbabd2aa917b421e3b90d10100c7c457214da834268946e2[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE499e8e1a5fe6 bridge bridge local9b7ecc0031ef host host local9902c4e06158 mybr0 bridge localc0de873b7341 none null local[root@centos7 ~]# ifconfigbr-9902c4e06158: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 ether 02:42:c9:35:05:ce txqueuelen 0 (Ethernet) RX packets 384 bytes 43480 (42.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 38 bytes 4779 (4.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0####################将新创建的容器添加到自建的网络中###############[root@centos7 ~]# docker run --name pc1 --rm -it --network mybr1 busybox[root@centos7 ~]# docker exec -it pc1 /bin/sh[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B)#可以自己修改网卡名字[root@centos7 ~]# ifconfig br-9902c4e06158 down[root@centos7 ~]# ip link set br-9902c4e06158 name mybr0[root@centos7 ~]# ifconfig mybr0 up#但是要重新启动docker[root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl restart docker######################将此容器连接到bridge网络中#################[root@centos7 ~]# docker network connect bridge pc1[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B)eth1 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:7 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:578 (578.0 B) TX bytes:0 (0.0 B)#####################将一个网络接口从此容器中拆除###################[root@centos7 ~]# docker network disconnect bridge pc1[root@centos7 ~]# docker exec pc1 ifconfigeth0 Link encap:Ethernet HWaddr 02:42:C0:A8:02:02 inet addr:192.168.2.2 Bcast:192.168.2.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:24 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2650 (2.5 KiB) TX bytes:0 (0.0 B) 修改默认的docker0桥12345678910111213141516171819自定义docker0桥的网络属性信息：/etc/docker/daemon.json文件[root@centos7 ~]# vim /etc/docker/daemon.json &#123; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com"], "bip": "192.168.1.5/24", "fixed-cidr": "10.20.0.0/16", "fixed-cidr-v6": "2001:db8::/64", "mtu": 1500, "default-gateway": "10.20.1.1", "default-gateway-v6": "2001:db8:abcd::89", "dns": ["10.20.1.2","10.20.1.3"] &#125; 核心选项为bip，即bridge ip之意，用于指定docker0桥自身的IP地址；其它选项可通过此地址计算得出。[root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl restart docker 文档路径： https://docs.docker.com/engine/userguide/networking/default_network/custom-docker0/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker应用基础]]></title>
    <url>%2F2018%2F12%2F30%2Fdocker%E5%BA%94%E7%94%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[docker应用基础 docker：容器使用的前端工具 组件：(彼此间通过http/https协议进行通讯) Client : 客户端 Daemon ：docker守护进程、服务端 Registry : docker镜像仓库 RESTful接口：一种分布式应用程序API调用的开发风格和规范 docker安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105##########################确保时间同步########################[root@centos7 yum.repos.d]# ntpdata ...#######################下载docker yum源######################[root@centos7 yum.repos.d]# pwd/etc/yum.repos.d[root@centos7 yum.repos.d]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #下载的docker源为阿里云#####################安装docker社区版########################如果有报错Error: Package: 3:docker-ce-18.09.0-3.el7.x86_64 (docker-ce-stable) Requires: container-selinux &gt;= 2.9 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigestyum install http://vault.centos.org/centos/7.3.1611/extras/x86_64/Packages/container-selinux-2.9-4.el7.noarch.rpm[root@centos7 yum.repos.d]# yum install docker-ce############################使用镜像加速#####################方式一：aliyun官网镜像加速 https://cr.console.aliyun.com方式二：docker公共加速器 http://www.docker-cn.com/registry-mirror支持两种方式同时使用[root@centos7 ~]# mkdir -p /etc/docker[root@centos7 ~]# tee /etc/docker/daemon.json &lt;&lt;-'EOF'&gt; &#123;&gt; "registry-mirrors": ["https://xr8r3tc3.mirror.aliyuncs.com","https://registry.docker-cn.com"]&gt; &#125;&gt; EOF[root@centos7 ~]# systemctl daemon-reload[root@centos7 ~]# systemctl restart docker###################查看docker客户端版本和服务端版本############查看版本信息[root@centos7 ~]# docker versionClient: #客户端版本 Version: 18.09.0 API version: 1.39 Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:48:22 2018 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community #服务端版本 Engine: Version: 18.09.0 API version: 1.39 (minimum version 1.12) Go version: go1.10.4 Git commit: 4d60db4 Built: Wed Nov 7 00:19:08 2018 OS/Arch: linux/amd64 Experimental: false查看更详细的docker环境信息[root@centos7 ~]# docker infoContainers: 0 #系统上总共有多少个容器 Running: 0 #容器运行态个数 Paused: 0 #容器暂停态个数 Stopped: 0 #容器停止态个数Images: 0 #当前系统上镜像的个数Server Version: 18.09.0Storage Driver: overlay2 #存储驱动 Backing Filesystem: xfs #放置在本地的文件系统的格式，建议使用xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfs #资源配额功能，需要的虚拟文件系统格式Plugins: #插件 Volume: local #存储卷的插件，仅支持本地 Network: bridge host macvlan null overlay #网络插件，支持桥接、主机、叠加、不使用等 Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog #日志系统插件Swarm: inactive #集群管理工具Runtimes: runc #运行时环境Default Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: seccomp Profile: defaultKernel Version: 3.10.0-862.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.779GiBName: centos7.comID: CUT4:A7LF:QJ4B:OORH:POA7:AZ7I:SWFT:7F4H:YKBQ:YFXH:BBBV:WGNQDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: #镜像加速服务 https://xr8r3tc3.mirror.aliyuncs.com/Live Restore Enabled: falseProduct License: Community Engine docker资源管理 两类资源 images:镜像资源管理（静态） docker image -h Usage: docker image COMMAND Commands: build history import inspect #查看镜像的信息 load ls prune pull #从远程下载镜像 push #将本地的镜像上传 rm #删除 docker image rm = docker rmi save tag #给镜像打标签,一个镜像可以有多个标签 container：容器管理（动态） docker一个容器中一个进程 Usage: docker container COMMAND Commands: attach commit #保存镜像 cp create #创建容器 diff exec #执行容器中的命令 export inspect #查看容器的信息 kill #杀死容器 logs ls pause #暂停容器 port prune rename #重命名容器 restart #重启容器 rm #删除容器 run start #启动容器 stats stop #停止容器 top unpause #继续容器 update wait docker容器状态 容器的状态docker container ps = docker ps running 运行态 stopped 停止态 paused 暂停态 created 创建态 deleted 删除态 OOM:内存耗尽 docker容器命令使用 创建容器 docker create docker run -t,tty -i,–interactive –name #容器的名字一定不要同名 docker0 : 桥 172.17.0.0/16 –network : 指定网络接口 –rm : 如果容器停止寓意容器引擎立即将其容器删除 # 适用于临时的容器与-d 选项项抵触 -d,detach : 守护，运行在后台剥离与当前终端的关系 #与–rm选项相抵触不可同时使用 容器中执行命令 #只有终端id号为1 的进程则此容器才会停止 docker container exec = docker exec -i:交互式接口 -t:分配终端 docker常用命令 docker stop #停止容器的运行 docker rm #删除容器，直接删除则容器中的数据也将删除，代表容器内的存储单元也被删除掉，且慎用。 查看容器的日志信息 docker container logs = docker logs docker日志是直接发往终端控制台 查看容器使用占用的内存空间 docker container stats = docker stats 显示容器运行的所有的进程的相关信息 docker container top = docker top 列出所有的相关镜像 docker images = docker image ls 返回容器的终端 docker container attach = docker attach 去docker hub中下载nginx镜像时：最后一位数字为奇数数位金丝雀版，非稳定版，开发版。生产中最好使用偶数或者stable 某一程序如果运行在容器中，并且id号为1的进程时，此进程必须运行在前台。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168###################根据关键字来了解镜像################[root@centos7 ~]# docker search redis###################拖取镜像到本地#########################################默认从hub.docker.com拖取###########[root@centos7 ~]# docker image pull centos:7[root@centos7 ~]# docker pull redis:4-alpine4-alpine: Pulling from library/rediscd784148e348: Pull complete #分层拖下来的，每一个都是一个层48d4c7155ddc: Pull complete 6d908603dbe8: Pull complete fd4371c1c78e: Pull complete e6818dc808c2: Pull complete f1884d594f6f: Pull complete Digest: sha256:775bbf766a5b711acce88e4142faf56cd587d63ddc4d57b49f7872f71d56fab6Status: Downloaded newer image for redis:4-alpine###################显示本地镜像########################REPOSITORY：镜像仓库仓库名TAG：标签IMAGE ID: 镜像idCREATED: 镜像的创建时间SIZE：镜像存储在本地的大小[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEredis 4-alpine 37abb58bfd68 9 days ago 30MB######################删除镜像#########################[root@centos7 ~]# docker image rm 镜像名称#######################查看镜像的详细信息###############[root@centos7 ~]# docker image inspect redis:4-alpine#显示一个jesn格式镜像信息#########################启动容器######################docker run = docker container run - it :交互式，并附加终端--name:容器名字[root@centos7 ~]# docker container run -it --name c1 centos:7 /bin/bash[root@3aee0a6acdfd /]# [root@3aee0a6acdfd /]# yum install net-tools[root@3aee0a6acdfd /]# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255[root@3aee0a6acdfd /]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0如果运行容器主机上默认生成一docker0的桥，默认网段172.17.0.0 ，随后创建的容器都会加载到此桥上，此桥为NET桥[root@centos7 ~]# ifconfigdocker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.17.0.1 netmask 255.255.0.0 broadcast 172.17.255.255 inet6 fe80::42:ddff:fed7:23fb prefixlen 64 scopeid 0x20&lt;link&gt; ether 02:42:dd:d7:23:fb txqueuelen 0 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 14 bytes 1770 (1.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0[root@centos7 ~]# brctl show #容器引擎动态实现bridge name bridge id STP enabled interfacesdocker0 8000.0242ddd723fb no 启动容器后也会生成默认防火墙规则 前期使用建议关闭firewalld##################查看所有运行状态的容器#####################- docker ps = docker container ps[root@centos7 ~]# docker ps -a #查看容器的所有状态[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3aee0a6acdfd centos:7 "/bin/bash" 12 minutes ago Up 12 minutes c1#####################显示当前docker支持的网络接口#############- 默认bridge,代表docker0桥[root@centos7 ~]# docker network lsNETWORK ID NAME DRIVER SCOPE777fc349679b bridge bridge local9b7ecc0031ef host host localc0de873b7341 none null local##################运行redis进程且放到后台不影响当前终端########[root@centos7 ~]# docker run --name redis -d redis:4-alpine 100f426c23ae6f50e015e7ad5fd13cdee33180c9ac43835f7d6ecef422b38f1c- CONTAINER ID：短格式id- IMAGE :容器启动用的镜像- COMMAND：容器运行的命令- CREATED：容器创建的时间- STATUS：容器运行的状态- PORTS：容器监听的端口，监听的端口是在容器内部的- NAMES：容器的名称[root@centos7 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES100f426c23ae redis:4-alpine "docker-entrypoint.s…" 8 seconds ago Up 6 seconds 6379/tcp redis######################删除正在运行容器#########################[root@centos7 ~]# docker container stop redisredis[root@centos7 ~]# docker container rm redis #如果容器停止寓意容器引擎立即将其容器删除redis#####################外部在容器中执行命令##################以交互式接口中运行bash[root@centos7 ~]# docker container exec -it redis /bin/sh/data # /data # ps auxPID USER TIME COMMAND 1 redis 0:00 redis-server #只有终端id号为1 的进程则此容器才会停止，所以退出交互式终端并非结束了次容器 17 root 0:00 /bin/sh 23 root 0:00 ps aux#######################w外部终端查看容器运行状态#############- 在不进入容器的交互式接口，显示的信息为容器内部的运行状态信息[root@centos7 ~]# docker container exec redis ps auxPID USER TIME COMMAND 1 redis 0:00 redis-server 24 root 0:00 ps aux######################创建容器在停止状态是自动删除###########- 拉取一个nginx的镜像 #生产环境中拖取镜像版本尽量使用偶数的服务版本，奇数的版本一般为金丝雀版[root@centos7 ~]# docker image pull nginx:1.15-alpine - 运行执行的/bin/sh,并且退出终端时结束删除此进程[root@centos7 ~]# docker run --name web -it --rm nginx:1.15-alpine /bin/sh/ # / # exit[root@centos7 ~]# docker ps -a######################以守护进程运行nginx#####################-d与--rm 选项不可同时使用[root@centos7 ~]# docker run --name web -d nginx:1.15-alpine [root@centos7 ~]# docker container exec web ifconfigeth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0[root@centos7 ~]# curl 172.17.0.2 #外部主机访问容器中的服务[root@centos7 ~]# wget -O - -q 172.17.0.2[root@centos7 ~]# elinks -dump 172.17.0.2#######################查看容器的日志信息#######################- docker日志是直接发往终端控制台，[root@centos7 ~]# docker container logs web####################显示容器运行的所有的进程的相关信息###########- 仅显示指定的容器的运行的进程的相关信息[root@centos7 ~]# docker top webUID PID PPID C STIME TTY TIME CMD###########################attach########################## 剥离容器当前运行的终端，但是容器仅是退出了运行的终端，但不停止容器# 剥离终端 ctrl+p ,ctrl+q[root@centos7 ~]# docker run --name c2 centos:7[root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2b5aa9c9e6ad centos:7 "/bin/bash" 8 seconds ago Exited (0) 6 seconds ago c2[root@centos7 ~]# docker rm c2c2[root@centos7 ~]# docker run --name c2 -it centos:7[root@49e278ef42ca /]# [root@centos7 ~]# [root@centos7 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES49e278ef42ca centos:7 "/bin/bash" 40 seconds ago Up 39 seconds c2[root@centos7 ~]# docker container attach c2[root@49e278ef42ca /]# docker镜像 About Docker Images Docker镜像含有启动容器所需要的文件系统及其内容，因此，其用 于创建并启动docker容器 采用分层构建机制，最底层为bootfs，其之为rootfs bootfs：用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以 节约内存资源； rootfs：位于bootfs之上，表现为docker容器的根文件系统; 传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为“只读”模式，完整性自检完成 后将其重新挂载为读写模式； docker中，rootfs由内核挂载为“只读”模式，而后通过“联合挂载 ”技术额外挂载一个“可写”层。 Docker Image Layer（层） 位于下层的镜像称为父镜像(parent image)，最底层的称为基础镜像(base image) - 最上层为“可读写”层，其下的均为“只读”层 wirtable最上面的可写层并非镜像提供，而是容器提供的 建构在本地的二级文件系统 /var/lib/docker/image/overlay2/ distribution imagedb layerdb repositories.json Aufs advanced multi-layered unification filesystem：高级多层统一文件系统 用于为Linux文件系统实现“联合挂载” aufs是之前的UnionFS的重新实现，2006年由Junjiro Okajima开发； Docker最初使用aufs作为容器文件系统层，它目前仍作为存储后端之一来支持； aufs的竞争产品是overlayfs，后者自从3.18版本开始被合并到Linux内核； docker的分层镜像，除了aufs，docker还支持btrfs, devicemapper和vfs等 在Ubuntu系统下，docker默认Ubuntu的 aufs；而在CentOS7上，用的是devicemapper。Docker Registry 启动容器时，docker daemon会试图从本地获取相关的镜像；本地镜像 不存在时，其将从Registry中下载该镜像并保存到本地。 分类 Registry用于保存docker镜像，包括镜像的层次结构和元数据 用户可自建Registry，也可使用官方的Docker Hub Sponsor Registry：第三方的registry，供客户和Docker社区使用 Mirror Registry：第三方的registry，只让客户使用 Vendor Registry：由发布Docker镜像的供应商提供的registry Private Registry：通过设有防火墙和额外的安全层的私有实体提供的registry Docker Registry中的镜像通常由开发人员制作，而后推送至“公共”或“ 私有”Registry上保存，供其他人员使用，例如“部署”到生产环境. 制作docker仓库docker Hub https://hub.docker.com 麻雀虽小五脏俱全的linux发行版--很忙的盒子12345678[root@centos7 ~]# docker image pull busybox:latestbusybox:一个微型的linux发行版（很忙的盒子）[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 758ec7f3a1ee 4 days ago 1.15M[root@centos7 ~]# docker run --name box1 -it busybox:latest /bin/sh/ # lsbin dev etc home proc root sys tmp usr var 范例：制作镜像仓库docker container commit –helpUsage: docker container commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Options: -a, –author string #指定镜像的作者 -c, –change list #对底层镜像默认运行的程序 进行修改 -m, –message string -p, –pause #表示制作镜像的时候将容器暂时暂停，避免数据结构不一致 1234567891011121314151617181920212223242526272829303132333435363738394041#########对本地很忙的盒子进行修改并推送到自己docker hub镜像仓库#######[root@centos7 ~]# docker run --name box1 -it busybox:latest /bin/sh/ # lsbin dev etc home proc root sys tmp usr var/ # mkdir /daizhe/ # lsbin dev home root tmp vardaizhe etc proc sys usr#####################保存修改的镜像并打标签########################确保容器终端不要关闭[root@centos7 ~]# docker container commit box1 docker19980110/mybox:v0.1sha256:42956b7e3ff8df5b77abd5b44654aac46bc00fd2ec2e690f1e92847e9879fd99[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox v0.1 c6a32f929f07 15 seconds ago 1.15MB###############本机启动测试查看保存的数据数据结构是否存在#############[root@centos7 ~]# docker run --name mybox -it docker19980110/mybox:v0.1 / # lsbin dev home root tmp vardaizhe etc proc sys usr#####################登陆docker hub###############################[root@centos7 ~]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: docker19980110Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded#####################将本地的镜像推送到docker hub#####################如果原仓库总有相同的镜像，当推送时，仅推送变化的那一层[root@centos7 ~]# docker image push docker19980110/mybox:v0.1 The push refers to repository [docker.io/docker19980110/mybox]5190a84cd271: Pushed 23bc2b70b201: Mounted from library/busybox v0.1: digest: sha256:05ce13e43087ab6249c717c3278e9f2c8d1199310447ac806c527ee85b0dfcb8 size: 734 范例：制作镜像并对底层镜像默认运行的程序 进行修改以及标签设置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465############################很忙的盒子中默认带有http程序####################/ # /bin/httpd -h/bin/httpd: option requires an argument -- hBusyBox v1.29.3 (2018-12-24 21:25:20 UTC) multi-call binary.Usage: httpd [-ifv[v]] [-c CONFFILE] [-p [IP:]PORT] [-u USER[:GRP]] [-r REALM] [-h HOME]or httpd -d/-e/-m STRINGListen for incoming HTTP requests -i Inetd mode -f Don't daemonize -v[v] Verbose -p [IP:]PORT Bind to IP:PORT (default *:80) -u USER[:GRP] Set uid/gid after binding to port -r REALM Authentication Realm for Basic Authentication -h HOME Home directory (default .) -c FILE Configuration file (default &#123;/etc,HOME&#125;/httpd.conf) -m STRING MD5 crypt STRING -e STRING HTML encode STRING -d STRING URL decode STRING####################对很忙的盒子进行修改，启动默认运行httpd############保存原有的镜像#启动运行http -f 前台运行，不适用守护进行 -h 执行家目录[root@centos7 ~]# docker container commit -p -a "daizhe&lt;daizhe.com&gt;" -c 'CMD ["/bin/sh","-c","/bin/httpd -f -h /data/web/html"]' myboxsha256:eced8dbd5d14dcb5c4be938d509103a9440cf3d7080620b49dac8fbbbe309974#保存的镜像未打标签[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZE&lt;none&gt; &lt;none&gt; eced8dbd5d14 26 seconds ago 1.15MB##########################将保存的镜像添加标签######################使用id号指定镜像来重新添加标签[root@centos7 ~]# docker image tag eced8dbd5d14 docker19980110/mybox:v0.2[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox v0.2 eced8dbd5d14 6 minutes ago 1.15MB########################将一个镜像打多个标签#######################latest表示最新的意思[root@centos7 ~]# docker tag docker19980110/mybox:v0.2 docker19980110/mybox:latest[root@centos7 ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEdocker19980110/mybox latest eced8dbd5d14 8 minutes ago 1.15MBdocker19980110/mybox v0.2 eced8dbd5d14 8 minutes ago 1.15MB#########################再次将本地的镜像推送到docker hub仓库########[root@centos7 ~]# docker push docker19980110/mybox:v0.v0.1 v0.2 [root@centos7 ~]# docker push docker19980110/mybox:v0.2 The push refers to repository [docker.io/docker19980110/mybox]355c5bc17ee9: Pushed 5190a84cd271: Layer already exists 23bc2b70b201: Layer already exists v0.2: digest: sha256:ab14ea25f1fbcc40a623343dd44a76224568a0200820f1ee5b61dc81c96ca12a size: 941[root@centos7 ~]# docker push docker19980110/mybox:latest The push refers to repository [docker.io/docker19980110/mybox]355c5bc17ee9: Layer already exists 5190a84cd271: Layer already exists 23bc2b70b201: Layer already exists latest: digest: sha256:ab14ea25f1fbcc40a623343dd44a76224568a0200820f1ee5b61dc81c96ca12a size: 941]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基础]]></title>
    <url>%2F2018%2F12%2F30%2Fdocker%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[docker基础即认识docker 先从认识容器开始 什么是容器？ 先来看看容器较为官方的解释： 一句话概括容器：容器就是将软件打包成标准化单元，以用于开发、交付和部署。 容器镜像是轻量的、可执行的独立软件包 ，包含软件运行所需的所有内容：代码、运行时环境、系统工具、系统库和设置。 容器化软件适用于基于Linux和Windows的应用，在任何环境中都能够始终如一地运行。 容器赋予了软件独立性，使其免受外在环境差异（例如，开发和预演环境的差异）的影响，从而有助于减少团队间在相同基础设施上运行不同软件时的冲突。Container 再来看看容器较为通俗的解释： 如果需要通俗的描述容器的话，我觉得容器就是一个存放东西的地方，就像书包可以装各种文具、衣柜可以放各种衣服、鞋架可以放各种鞋子一样。我们现在所说的容器存放的东西可能更偏向于应用比如网站、程序甚至是系统环境。 容器是一种基础工具；泛指任何可以用于容纳其它物品的工具，可以 部分或完全封闭，被用于容纳、储存、运输物品；物体可以被放置在 容器中，而容器则可以保护内容物； 人类使用容器的历史至少有十万年，甚至可能有数百万年的历史； 容器的类型 • 瓶 - 指口部比腹部窄小、颈长的容器。 • 罐 - 指那些开口较大、一般为近圆筒形的器皿。 箱 - 通常是立方体或圆柱体。形状固定。 篮 - 以条状物编织而成。 桶 - 一种圆柱形的容器。 袋 - 柔性材料制成的容器，形状会受内容物而变化。 瓮 - 通常是指陶制，口小肚大的容器。 碗 - 用来盛载食物的容器。 柜 - 指一个由盒组成的家俱。 鞘 - 用于装载刀刃的容器。 图解物理机、虚拟机与容器 关于虚拟机与容器的对比在后面会详细介绍到，这里只是通过网上的图片加深大家对于物理机、虚拟机与容器这三者的理解。 物理机 虚拟机 容器 再来谈谈Docker的一些概念 通过上面这三张抽象图，我们大概可以通过类比概括出： 容器虚拟化的是操作系统而不是硬件，容器之间是共享同一套操作系统资源的。虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统。因此容器的隔离级别会稍低一些。 相信通过上面的解释大家对于容器这个既陌生又熟悉的概念有了一个初步的认识，下面我们就来谈谈Docker的一些概念。 什么是Docker 关于Docker是什么并太好说，下面我通过四点向你说明Docker到底是个什么东西。 Docker是世界领先的软件容器平台。 Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于LXC。 Docker能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。 用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker思想 集装箱 标准化： ①运输方式、②存储方式、 ③API接口 隔离（linux名称空间 Namespace） IPC：同一主机进程隔离 隔离系统级同一主机上进程间通讯、消息队列、共享内存（跨主机的通讯套接字通讯） Network：网路名称空间隔离 隔离网络设备，网络协议栈，端口，使得容器中的程序监听本机的套接字，其他容器中的程序继续可以使用次套接字。 Mount：根文件系统隔离 PID：进程树--init隔离 User：用户和组隔离 UTS：主机名和域名 Cgroup：将底层的计算资源即cpu、内存、网络IO、磁盘IO，划分为块以后有效的调用在容器之上 Docker容器的特点 轻量，在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。 标准，Docker容器基于开放式标准，能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。 安全，Docker赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。 为什么要用Docker Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现“这段代码在我机器上没问题啊”这类问题；——一致的运行环境 可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。——更快速的启动时间 避免公用的服务器，资源会容易受到其他用户的影响。——隔离性 善于处理集中爆发的服务器使用压力；——弹性伸缩，快速扩展 可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。——迁移方便 使用Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。——持续交付和部署。 容器 VS 虚拟机 容器和虚拟机具有相似的资源隔离和分配优势，但功能有所不同，因为容器虚拟化的是操作系统，而不是硬件，因此容器更容易移植，效率也更高。 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 容器与虚拟机 (VM) 总结 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动 。 虚拟机（VM）是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此占用大量空间。而且VM启动也十分缓慢 。 容器与虚拟机（VM）两者是可以共存的 Docker基本概念 Docker包括三个基本概念： 镜像（Image） 容器（Container） 仓库（Repository） 镜像（Image）——一个特殊的文件系统 操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。 Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。 Docker设计时，就充分利用Union FS的技术，将其设计为分层存储的架构。 镜像实际是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 容器（Container）——镜像运行时的实体 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。前面讲过镜像使用的是分层存储，容器也是如此。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照Docker最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新run，数据却不会丢失。 仓库（Repository）——集中存放镜像文件的地方 镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 一个Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以latest作为默认标签。 Docker Registry公开服务和私有Docker Registry的概念： Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。 最常使用的Registry公开服务是官方的Docker Hub ，这也是默认的Registry，并拥有大量的高质量的官方镜像，网址为：hub.docker.com/ 。在国内访问Docker Hub可能会比较慢国内也有一些云服务商提供类似于Docker Hub的公开服务。 除了使用公开服务外，用户还可以在本地搭建私有Docker Registry 。Docker官方提供了Docker Registry镜像，可以直接使用做为私有Registry服务。开源的Docker Registry镜像只提供了Docker Registry API的服务端实现，足以支持Docker命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis集群]]></title>
    <url>%2F2018%2F12%2F28%2Fredis%E7%BC%93%E5%AD%982%2F</url>
    <content type="text"><![CDATA[redis集群、架构 一： redis 集群 上一个步骤的主从架构无法实现master和slave角色的自动切换，即当master出现redis服务异常、主机断电、磁盘损坏等问题导致master无法使用，而redis高可用无法实现自故障转移(将slave提升为master)，需要手动改环境配置才能切换到slave redis服务器，另外也无法横向扩展Redis服务的并行写入性能，当单台Redis服务器性能无法满足业务写入需求的时候就必须需要一种方式解决以上的两个核心问题，即： 1.master和slave角色的无缝切换，让业务无感知从而不影响业务使用 2.可以横向动态扩展Redis服务器，从而实现多台服务器并行写入以实现更高并发的目的。 Redis 集群实现方式：客户端分片 代理分片 Redis Cluster（做集群一般使用奇数台服务器做集群，3、5、7,损坏的节点剩余要大于总节点的一半） Sentinel(哨兵)：测试主从是否正常通讯：ping GONG(集群实现的前提是要使主从的版本相同) Sentinel 进程是用于监控redis集群中Master主服务器工作的状态，在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用，其已经被集成在redis2.6+的版本中，Redis的哨兵模式到了2.8版本之后就稳定了下来。一般在生产环境也建议使用Redis的2.8版本的以后版本。哨兵(Sentinel) 是一个分布式系统，你可以在一个架构中运行多个哨兵(sentinel) 进程，这些进程使用流言协议(gossipprotocols)来接收关于Master主服务器是否下线的信息，并使用投票协议(Agreement Protocols)来决定是否执行自动故障迁移,以及选择哪个Slave作为新的Master。每个哨兵(Sentinel)进程会向其它哨兵(Sentinel)、Master、Slave定时发送消息，以确认对方是否”活”着，如果发现对方在指定配置时间(可配置的)内未得到回应，则暂时认为对方已掉线，也就是所谓的”主观认为宕机” ，英文名称：Subjective Down，简称SDOWN。有主观宕机，肯定就有客观宕机。当“哨兵群”中的多数Sentinel进程在对Master主服务器做出 SDOWN 的判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后，得出的Master Server下线判断，这种方式就是“客观宕机”，英文名称是：Objectively Down， 简称 ODOWN。通过一定的vote算法，从剩下的slave从服务器节点中，选一台提升为Master服务器节点，然后自动修改相关配置，并开启故障转移（failover）。Sentinel 机制可以解决master和slave角色的切换问题。 1234Sentinel(哨兵)：哨兵判断服务器是否存活的方式 [root@centos7 redis]# redis-cli -h 127.0.0.1 -p 6379 127.0.0.1:6379&gt; ping PONG 实现哨兵默认端口26379(在生产中建议哨兵是一台独立的服务器，这里演示的时redis服务器上实现哨兵，哨兵判断节点的存活状态机制：ping :pang)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475实验准备： 三台主机：全部编译安装，为了避免实验出现差别，尽量使用相同版本 主节点：172.18.135.1 从节点1：172.18.135.2 从节点2：172.18.135.3实验目的如果主节点挂了，自动其中一个从节点上选择一个自动升级为主节点第一步：编辑所有主机的配置文件 修改本机的监听地址 76行 bind 0.0.0.0 修改主从结构的配置 286 replicaof 192.168.7.103 6379 293 masterauth 123456 #master如果密码需要设置 [root@centos7 ~]# systemctl restart redis.service 第二步：首先实现一主两从架构 从节点1： 127.0.0.1:6379&gt; info [ # Replication role:slave master_host:172.18.135.1 master_port:6379 master_link_status:up 从节点2： 127.0.0.1:6379&gt; info [ # Replication role:slave master_host:172.18.135.1 master_port:6379 master_link_status:up第三步：哨兵可以不和Redis服务器部署在一起配置哨兵：编辑配置文件sentinel.conf： master 、slave1、slave2 配置： [root@centos7 ~]# cp /usr/local/src/redis-5.0.3/sentinel.conf /usr/local/redis/etc [root@centos7 ~]# vim /usr/local/redis/etc/sentinel.conf port 26379 daemonize yes pidfile /usr/local/redis/data/redis-sentinel_26379.pid logfile "/usr/local/redis/logs/sentinel_26379.log" dir /usr/local/redis/data sentinel monitor mymaster 172.18.131.1 6379 2 sentinel auth-pass mymaster 123456 sentinel down-after-milliseconds mymaster 15000 #15秒 sentinel parallel-syncs mymaster 1 sentinel failover-timeout mymaster 180000第四步：启动哨兵 每个节点上都启动哨兵 [root@centos7 ~]# /usr/local/redis/bin/redis-sentinel /usr/local/redis/etc/sentinel.conf [root@centos7 etc]# ss -tnl LISTEN 0 511 *:26379 查看哨兵的日志文件第五步：哨兵验证 [root@centos7 ~]# redis-cli -p 26379 127.0.0.1:26379&gt; info Sentinel # Sentinel sentinel_masters:1 sentinel_tilt:0 sentinel_running_scripts:0 sentinel_scripts_queue_length:0 sentinel_simulate_failure_flags:0 master0:name=mymaster,status=ok,address=172.18.135.1:6379,slaves=2,sentinels=3已经实现哨兵 可以创建值，并停用主节点，哨兵自动选举新的主节点 哨兵配置文件详情12345678910111213[root@redis-s1 etc]# grep "^[a-Z]" /usr/local/redis/etc/sentinel.conf bind 0.0.0.0port 26379daemonize yes #守护进程运行pidfile "/usr/local/redis/redis-sentinel.pid"logfile "/usr/local/redis/sentinel_26379.log"dir "/usr/local/redis" # 哨兵运行产生的数据目录sentinel monitor mymaster 192.168.7.101 6379 2 #这里的2表示，多少个哨兵决定主节点挂掉则提升新的主,此实验的哨兵有三个sentinel auth-pass mymaster 123456 #主节点的密码，为了安全建议添加密码sentinel down-after-milliseconds mymaster 30000 #(SDOWN)主观下线的时间，主节点多长时间没有反应则代表下线，根据生产需求设置sentinel parallel-syncs mymaster 1 #发生故障转移时候同时向新master同步数据的slave数量，数字越小总同步时间越长sentinel failover-timeout mymaster 180000 #所有slaves指向新的master所需的超时时间（单位秒）sentinel deny-scripts-reconfig yes #代表没有调用其他脚本 应用程序如何连接redis？： java客户端连接redis是通过jedis来实现的，java代码用的时候只要创建jedis对象就可以建多个jedis连接池来连接redis，应用程序再直接调用连接池即可连接Redis。 而Redis为了保障高可用,服务一般都是Sentinel部署方式，当Redis服务中的主服务挂掉之后,会仲裁出另外一台Slaves服务充当Master。这个时候,我们的应用即使使用了Jedis连接池,Master服务挂了,我们的应用奖还是无法连接新的Master服务，为了解决这个问题,Jedis也提供了相应的Sentinel实现,能够在Redis Sentinel主从切换时候,通知我们的应用,把我们的应用连接到新的Master服务。 Jedis Sentinel的使用也是十分简单的,只是在JedisPool中添加了Sentinel和MasterName参数，Jedis Sentinel底层基于Redis订阅实现Redis主从服务的切换通知，当Reids发生主从切换时，Sentinel会发送通知主动通知Jedis进行连接的切换，JedisSentinelPool在每次从连接池中获取链接对象的时候,都要对连接对象进行检测,如果此链接和Sentinel的Master服务连接参数不一致,则会关闭此连接,重新获取新的Jedis连接对象。 二： Redis Cluster部署 Redis cluster之前的分布式方案： 1) 客户端分区：由客户端程序决定key写分配和写入的redis node，但是需要客户端自己处理写入分配、高可用管理和故障转移等 2)代理方案：基于三方软件实现redis proxy，客户端先连接之代理层，由代理层实现key的写入分配，对客户端来说是有比较简单，但是对于集群管节点增减相对比较麻烦，而且代理本身也是单点和性能瓶颈。 在哨兵sentinel机制中，可以解决redis高可用的问题，即当master故障后可以自动将slave提升为master从而可以保证redis服务的正常使用，但是无法解决redis单机写入的瓶颈问题，即单机的redis写入性能受限于单机的内存大小、并发数量、网卡速率等因素，因此redis官方在redis 3.0版本之后推出了无中心架构的redis cluster机制，在无中心的redis集群汇中，其每个节点保存当前节点数据和整个集群状态,每个节点都和其他所有节点连接，特点如下： 1：所有Redis节点使用(PING-PING机制)互联 2：集群中某个节点的实效是整个集群中超过半数的节点监测都实效才算真正的实效 3：客户端不需要proxy即可直接连接redis，且客户端不需要连接集群中的所有节点，只要连接集群中的任何一个节点即可。 4：redis cluster把所有的redisnode映射到 0-16383个槽位(slot)上，读写需要到指定的redis node上进行操作，因此有多少个reids node相当于redis 并发扩展了多少倍。 5：Redis集群预先分配16384个(slot)槽位，当需要在redis集群中写入一个key -value的时候，会使用CRC16(key) mod 16384之后的值，决定将key写入值哪一个槽位从而决定写入哪一个Redis节点上，从而有效解决单机瓶颈。 Redis cluster基本架构 假如三个主节点分别是：A, B, C 三个节点，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是： 节点A覆盖0－5460 节点B覆盖5461－10922 节点C覆盖10923－16383 此结构缺点是主节点之间无法数据同步 Redis cluster主从架构： Redis cluster的架构虽然解决了并发的问题，但是又引入了一个新的问题，每个Redis master的高可用如何解决？ 部署redis集群：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#####################环境准备####################三台服务器，每台服务器启动6379和6380两个redis 服务，生产环境建议直接6台服务器。另外预留一台服务器做集群添加节点测试。实验方式：基于端口的不同实现（生产环境中最好使用6台主机实现）172.18.135.1:6379/6380 172.18.135.5:6379/6380172.18.135.2:6379/6380 ##############创建redis cluster集群的前提####目前仅有三台节点####1.每个redis node节点采用相同的硬件配置、相同的密码2.每个节点必须开启参数(确保每台节点都是主节点) #编辑配置文件507 requirepass 123456 # 建议每个节点都设置密码，但是保证每个节点的密码保持一致838 cluster-enabled yes #必须开启集群状态，开启后redis 进程会有cluster显示846 cluster-config-file nodes-6380.conf #此文件有redis cluster集群自动创建和维护，不需要任何手动操作################模拟一台节点上创建第二个节点###################每台节点上模拟创建第二台节点实现一台机器上两个节点[root@centos77 ~]# cp /usr/local/redis/etc/redis.conf /usr/local/redis/etc/redis6380.conf #对原配置文件拷贝进行简单修改bind 0.0.0.0port 6380pidfile "/var/run/redis_6380.pid"logfile "/usr/local/redis/logs/6380.log"cluster-config-file nodes-6380.conf创建启动脚本[root@centos77 ~]# cp /usr/lib/systemd/system/redis.service /usr/lib/systemd/system/redis6380.service[root@centos77 ~]# vim !$vim /usr/lib/systemd/system/redis6380[Unit]Description=Redis persistent key-value databaseAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis6380.conf --supervised systemdExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDType=notifyUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755[Install]WantedBy=multi-user.target######################## 启动############################[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.1:/usr/local/redis/etc/[root@centos77 etc]# scp /usr/local/redis/etc/redis6380.conf root@172.18.135.2:/usr/local/redis/etc/[root@centos77 ~]# scp /usr/lib/systemd/system/redis6380.service root@172.18.135.2:/usr/lib/systemd/system/[root@centos77 ~]# scp /usr/lib/systemd/system/redis6380.service root@172.18.135.1:/usr/lib/systemd/system/启动查看端口[root@centos77 etc]# ss -tnl 6379 6380 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657######################创建集群#####################[root@redis-s1 ~]# redis-cli -a 123456 --cluster create 192.168.7.101:6379 192.168.7.101:6380 192.168.7.102:6379 192.168.7.102:6380 192.168.7.103:6379 192.168.7.103:6380 --cluster-replicas 1 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.7.102:6380 to 192.168.7.101:6379Adding replica 192.168.7.101:6380 to 192.168.7.102:6379Adding replica 192.168.7.103:6380 to 192.168.7.103:6379&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[OK] Perfect anti-affinity obtained!M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 #带M的为master slots:[0-5460] (5461 slots) master #当前master的槽位起始和结束位S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 #带S的slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master #当前master的槽位起始和结束位S: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master #当前master的槽位起始和结束位S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afCan I set the above configuration? (type 'yes' to accept): yes #输入yes自动创建集群&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.....&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.101:6379)M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 #master的ID及端口 slots:[0-5460] (5461 slots) master #已经分配的槽位 1 additional replica(s) #分配了一个slaveS: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave #slave没有分配槽位 replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64af[OK] All nodes agree about slots configuration. #所有节点槽位分配完成&gt;&gt;&gt; Check for open slots... #检查打开的槽位&gt;&gt;&gt; Check slots coverage... #检查插槽覆盖范围[OK] All 16384 slots covered. #所有槽位(16384个)分配完成#########################检查状态######################由于未设置masterauth认证密码，所以主从未建立起来，但是集群已经运行，所以需要在每个slave控制台使用config set设置masterauth密码，或者写在每个redis配置文件中，最好是在控制点设置密码之后再写入配置文件当中。 123456789101112131415#######################分别设置masterauth密码#############[root@redis-s1 ~]# redis-cli -h 192.168.7.101 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.101:6380&gt; CONFIG SET masterauth 123456OK[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6380&gt; CONFIG SET masterauth 123456OK[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6380&gt; CONFIG SET masterauth 123456OK#######################确认slave状态为up################## 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465########################验证master状态###################[root@redis-s1 ~]# redis-cli -h 192.168.7.101 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.101:6379&gt; INFO Replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.7.102,port=6380,state=online,offset=840,lag=0master_replid:0aa3281030eb29bf268f3317d4afe401f661a917master_replid2:0000000000000000000000000000000000000000master_repl_offset:840second_repl_offset:-1repl_backlog_active:1repl_backlog_size:4026531840repl_backlog_first_byte_offset:1repl_backlog_histlen:840192.168.7.101:6379&gt;###################管理要用集群的命令管理#######################################验证集群状态#################192.168.7.101:6379&gt; CLUSTER INFOcluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:1474cluster_stats_messages_pong_sent:1507cluster_stats_messages_sent:2981cluster_stats_messages_ping_received:1502cluster_stats_messages_pong_received:1474cluster_stats_messages_meet_received:5cluster_stats_messages_received:2981########################查看集群node对应关系################使用命令cluster nodes：192.168.7.103:6380&gt; cluster nodes7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545659135000 4 connected7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 myself,slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545659135000 6 connectedf4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545659135000 1 connected 0-5460116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545659136000 3 connected 5461-1092270de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545659134000 5 connected 10923-163832b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545659135946 5 connected##########################验证集群写入key##################192.168.7.101:6379&gt; SET key1 value1 #经过算法计算，当前key的槽位需要写入指定的node (error) MOVED 9189 192.168.7.102:6379 #槽位不在当前node所以无法写入192.168.7.103:6379&gt; SET key1 value1 (error) MOVED 9189 192.168.7.102:6379 192.168.7.102:6379&gt; SET key1 value1 #指定的node就可以写入OK192.168.7.102:6379&gt; KEYS *1) "key1"192.168.7.101:6379&gt; KEYS *(empty list or set)192.168.7.103:6379&gt; KEYS *(empty list or set)#############################集群状态监控#################### redis-cli -a 123456 --cluster check 192.168.7.101:6379 Redis cluster集群节点维护 集群运行时间长久之后，难免由于硬件故障、网络规划、业务增长等原因对已有集群进行相应的调整， 比如增加Redis node节点、减少节点、节点迁移、更换服务器等。增加节点和删除节点会涉及到已有的槽位重新分配及数据迁移。 集群维护之动态添加节点： 增加Redis node节点，需要与之前的Redis node版本相同、配置一致，然后分别启动两台Redis node，因为一主一从。 案例： 因公司业务发展迅猛，现有的三主三从redis cluster架构可能无法满足现有业务的并发写入需求，因此公司紧急采购一台服务器192.168.7.104，需要将其动态添加到集群当中其不能影响业务使用和数据丢失，则添加过程如下: 1234567891011121314为了满足生产需求创建新的服务器##同步之前Redis node的配置文件到192.168.7.104 Redis编译安装目录，注意配置文件的监听 IP##scp redis.conf 192.168.7.104:/usr/local/redis/etc/scp redis_6380.conf 192.168.7.104:/usr/local/redis/etc/##################分别启动redis服务##########################systemctl daemon-reloadsystemctl restart redis/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis_6380.conf################将新创建的新的服务器添加节点到集群############在新创建的节点上配置（新加入的节点是没有槽位的）要添加的redis节点IP和端口 添加到的集群中的master IP:端口# redis-cli -a 123456 --cluster add-node 192.168.7.104:6379 192.168.7.101:6379 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#############################分配槽位######################添加主机之后需要对添加至集群种的新主机重新分片否则其没有分片在新创建的节点上配置（分配的槽位是从以前每个节点上瓜分槽位来给新加入的服务器）使用命令重新分配槽位:[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.104:6379 Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.104:6379)M: 886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379 slots: (0 slots) masterM: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62S: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaM: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afM: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 4096 #分配多少个槽位192.168.7.104:6379What is the receiving node ID? 886338acd50c3015be68a760502b239f4509881c #手动输入192.168.7.104的node IDPlease enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1: all #将哪些源主机的槽位分配给192.168.7.104:6379，all是自动在所有的redis node选择划分，如果是从redis cluster删除主机可以使用此方式将主机上的槽位全部移动到别的redis主机……………………………….. Moving slot 6823 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6824 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6825 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 6826 from 116c4c6de036fdbac5aaad25eb1a61ea262b64af Moving slot 10923 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10924 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10925 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 Moving slot 10926 from 70de3821dde4701c647bd6c23b9dd3c5c9f24a62………………………………….. Moving slot 1364 from f4cfc5cf821c0d855016488d6fbfb62c03a14fdaDo you want to proceed with the proposed reshard plan (yes/no)? yes #确认分配##################验证重新分配槽位之后的集群状态#############重新分配槽位是自动从每个Redis node上移动一些槽位到新的master上 123456789101112131415161718192021222324252627282930313233###################为新的master添加slave节点################master节点必须有salvae一但挂掉损失惨重命令格式：(这样加入的192.168.7.104:6380 默认为master)# redis-cli -a 123456 --cluster add-node 192.168.7.104:6380 192.168.7.104:6379###################更改新节点更改状态为slave###############需要手动将其指定为某个master 的slave，否则其默认角色为master[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6380 -a 123456 #登录到新添加节点Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6380&gt; CLUSTER NODES #查看当前集群节点，找到目标master 的ID7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545700464964 3 connected116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545700470516 3 connected 6827-109222b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545700468498 5 connectedb9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 myself,master - 0 1545700464000 0 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 master - 0 1545700465468 7 connected 0-1364 5461-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545700467489 5 connected 12288-16383f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545700464461 1 connected 1365-54607186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545700469508 1 connected192.168.7.104:6380&gt; CLUSTER REPLICATE 886338acd50c3015be68a760502b239f4509881c #将其设置slave，设置为192.168.7.104:6379的slave #命令格式为cluster replicate MASTERIDOK192.168.7.104:6380&gt; CLUSTER NODES #再次查看集群节点状态，验证节点是否已经更改为指定master 的slave7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545700517970 3 connected116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545700514942 3 connected 6827-109222b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380@16380 slave 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 0 1545700518979 5 connectedb9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 myself,slave 886338acd50c3015be68a760502b239f4509881c 0 1545700509000 0 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 master - 0 1545700516456 7 connected 0-1364 5461-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545700519988 5 connected 12288-16383f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379@16379 master - 0 1545700515953 1 connected 1365-54607186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave f4cfc5cf821c0d855016488d6fbfb62c03a14fda 0 1545700516962 1 connected192.168.7.104:6380&gt;#########################验证当前集群状态######################## 集群维护之动态删除节点 添加节点的时候是先添加node节点到集群，然后分配槽位，删除节点的操作与添加节点的操作正好相反，是先将被删除的Redis node上的槽位迁移到集群中的其他Redis node节点上，然后再将其删除。如果一个Redis node节点上的槽位没有被完全迁移，删除该node的时候会提升有数据且无法删除。 案例： 由于192.168.7.101服务器使用年限已经超过三年，已经超过厂商质保期而且硬盘出现异常报警，经运维部架构师提交方案并同开发同事开会商议，决定将现有Redis集群的4台服务器分别是192.168.7.101/192.168.7.102/192.168.7.103/192.168.7.104中的192.168.7.101临时下线，三台服务器的并发写入性能足够支出未来1-2年的业务需求，则删除Redis node 192.168.7.101的操作如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748##############迁移master 的槽位之其他master##################[root@redis-s1 ~]# redis-cli -a 123456 --cluster reshard 192.168.7.102:6379Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.7.102:6379)M: 116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)M: 70de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s)S: 7eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380 slots: (0 slots) slave replicates 116c4c6de036fdbac5aaad25eb1a61ea262b64afS: b9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380 slots: (0 slots) slave replicates 886338acd50c3015be68a760502b239f4509881cS: 7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380 slots: (0 slots) slave replicates f4cfc5cf821c0d855016488d6fbfb62c03a14fdaS: 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 192.168.7.101:6380 slots: (0 slots) slave replicates 70de3821dde4701c647bd6c23b9dd3c5c9f24a62M: f4cfc5cf821c0d855016488d6fbfb62c03a14fda 192.168.7.101:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 4096 #迁移master上的多少个槽位What is the receiving node ID? 886338acd50c3015be68a760502b239f4509881c #接收槽位的服务器IDPlease enter all the source node IDs. Type 'all' to use all the nodes as source nodes for the hash slots. Type 'done' once you entered all the source nodes IDs.Source node #1: f4cfc5cf821c0d855016488d6fbfb62c03a14fda #从哪个服务器迁移4096个槽位Source node #2: done #写done，表示没有其他master了 Moving slot 5457 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5458 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5459 from f4cfc5cf821c0d855016488d6fbfb62c03a14fda Moving slot 5460 from f4cfc5cf821c0d855016488d6fbfb62c03a14fdaDo you want to proceed with the proposed reshard plan (yes/no)? yes #是否继续迁移完成！######################验证槽位迁移完成######################## 123456789101112131415161718192021####################从集群删除服务器##########################虽然槽位已经迁移完成，但是服务器IP信息还在集群当中，因此还需要将IP信息从集群删除命令格式： redis-cli -a 123456 --cluster del-node IP:Port ID#删除master：[root@redis-s1 ~]# redis-cli -a 123456 --cluster del-node 192.168.7.101:6379 f4cfc5cf821c0d855016488d6fbfb62c03a14fdaWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Removing node f4cfc5cf821c0d855016488d6fbfb62c03a14fda from cluster 192.168.7.101:6379&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.#删除slave：该节点上如果还有其他节点上master 的slave，但是由于服务器下架也要一并删除，因此要提前把保证每个master至少有一个slave。[root@redis-s1 ~]# redis-cli -a 123456 --cluster del-node 192.168.7.101:6380 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.&gt;&gt;&gt; Removing node 2b6e5d9c3944d79a5b64a19e54e52f83d48438d6 from cluster 192.168.7.101:6380&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node.####################验证node 是否删除######################发现192.168.7.101已经被删除，但是由于192.168.7.101:6380之前是192.168.7.103:6379的slave，所以删除后会导致相应的master缺少slave，需要重新为没有slave的master分配slave。可以发现下图的192.168.7.104有两个slave，分别是192.168.7.102:6380和192.168.7.104:6380，因此需要将其中一个slave转移为192.168.7.103的slave。 12345678910111213141516####################重新分配slave#########################将192.168.7.104:6380 转移为192.168.7.103的slave[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6379&gt; CLUSTER NODES116c4c6de036fdbac5aaad25eb1a61ea262b64af 192.168.7.102:6379@16379 master - 0 1545708439000 3 connected 6827-10922b9a00d59fa3c2a322080a1c7d84f53a2c853b089 192.168.7.104:6380@16380 slave 886338acd50c3015be68a760502b239f4509881c 0 1545708440717 7 connected7186c6d03dd9a5e3be658f2d08e800bc55b04a09 192.168.7.102:6380@16380 slave 886338acd50c3015be68a760502b239f4509881c 0 1545708437682 7 connected886338acd50c3015be68a760502b239f4509881c 192.168.7.104:6379@16379 myself,master - 0 1545708439000 7 connected 0-6826 10923-1228770de3821dde4701c647bd6c23b9dd3c5c9f24a62 192.168.7.103:6379@16379 master - 0 1545708440000 5 connected 12288-163837eda0bcf0c01bb7343313b81267c42dd1b26c8a6 192.168.7.103:6380@16380 slave 116c4c6de036fdbac5aaad25eb1a61ea262b64af 0 1545708438697 3 connected192.168.7.104:6380&gt; CLUSTER REPLICATE 70de3821dde4701c647bd6c23b9dd3c5c9f24a62OK##################验证集群Master与Slave对应关系#################Redis Slave节点一定不能个master在一个服务器，必须为跨主机交叉备份模式，避免主机故障后主备全部挂掉，如果出现Redis Slave与Redis master在同一台Redis node的情况，则需要安装以上步骤重新进行slave分配，直到不相互交叉备份为止。 集群维护之模拟Master宕机123456789101112131415161718192021目前的架构为三主三从，互为跨主机master slave模式。#####################测试数据写入###########################测试在master写入数据，并在其对应的slave验证数据：192.168.7.102:6379&gt; SET key1 value1OK192.168.7.102:6379&gt; get key1"value1"#######################slave验证数据########################192.168.7.103:6380&gt; KEYS *1) "key1"192.168.7.103:6380&gt; get key1(error) MOVED 9189 192.168.7.102:6379 #slave不提供读写，只提供数据备份即master选举####################停止master并验证故障转移################Redis Master服务停止之后，其对应的slave会被选举为master继续处理数据的读写操作。# systemctl stop redis######################验证slave 日志######################## tail -f /usr/local/redis/redis_6380.log 1#####################验证slave状态######################## 123456789101112######################验证数据读写#########################确认slave 192.168.7.103:6380切换为master之后可以继续为业务提供读写业务且数据没有丢失。192.168.7.103:6380&gt; KEYS *1) "key1"192.168.7.103:6380&gt; SET aaa bbbOK192.168.7.103:6380&gt; get key1"value1"192.168.7.103:6380&gt; get aaa"bbb"192.168.7.103:6380&gt;注：服务恢复之后重新验证各master的slave。 集群维护之导入现有Redis数据 导入数据需要redis cluster不能与被导入的数据有重复的key名称，否则导入不成功或中断。 案例： 公司将redis cluster部署完成之后，需要将之前的数据导入之Redis cluster集群，但是由于Redis cluster使用的分片保存key的机制，因此使用传统的AOF文件或RDB快照无法满足需求，因此需要使用集群数据导入命令完成。1234567891011121314151617181920212223242526272829303132333435363738394041#########################基础环境准备#####################导入数据之前需要关闭各redis 服务器的密码，包括集群中的各node和源Redis server，避免认证带来的环境不一致从而无法导入，但是可以加参数--cluster-replace 强制替换Redis cluster已有的key。[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6379&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.102 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.102:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6379&gt; CONFIG SET requirepass ""OK192.168.7.103:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.103 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.103:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6379 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6379&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit[root@redis-s1 ~]# redis-cli -h 192.168.7.104 -p 6380 -a 123456Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe.192.168.7.104:6380&gt; CONFIG SET requirepass ""OK192.168.7.104:6379&gt; exit#######################执行数据导入###########################将源Redis server的数据直接导入之redis cluster。命令格式：#redis-cli --cluster import 集群服务器IP:PORT --cluster-from 外部Redis node-IP:PORT --cluster-copy --cluster-replace[root@redis-s2 redis]# redis-cli --cluster import 192.168.7.103:6379 --cluster-from 192.168.7.101:6379 --cluster-copy 1#####################edis cluster验证数据#################### redis扩展集群方案 除了Redis 官方自带的Redis cluster集群之外，还有一写开源的集群解决方案可供参考使用 codis： Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有显著区别 (不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。 codis-proxy相当于redis，即连接codis-proxy和连接redis是没有任何区别的，codis-proxy无状态，不负责记录是否在哪保存，数据在zookeeper记录，即codis proxy向zookeeper查询key的记录位置，proxy 将请求转发到一个组进行处理，一个组里面有一个master和一个或者多个slave组成，默认有1024个槽位，redis cluster 默认有16384个槽位，其把不同的槽位的内容放在不同的group。 Github 地址：https://github.com/CodisLabs/codis/blob/release3.2/doc/tutorial_zh.md twemproxy 由Twemproxy代替客户端实现分片，即代替用户将数据分片并到不同的后端服务器进行读写，其还支持memcached，可以为proxy配置算法，缺点为twemproxy是瓶颈，不支持数据迁移 官方github地址https://github.com/twitter/twemproxy/ Github 地址：https://github.com/twitter/twemproxy]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis缓存]]></title>
    <url>%2F2018%2F12%2F26%2Fredis%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[redis缓存及架构 一： 缓存概念： 缓存概念 缓存是为了调节速度不一致的两个或多个不同的物质的速度，在中间对速度较快的一方起到一个加速访问速度较慢的一方的作用，比如CPU的一级、二级缓存是保存了CPU最近经常访问的数据，内存是保存CPU经常访问硬盘的数据，而且硬盘也有大小不一的缓存，甚至是物理服务器的raid 卡有也缓存，都是为了起到加速CPU 访问硬盘数据的目的，因为CPU的速度太快了，CPU需要的数据硬盘往往不能在短时间内满足CPU的需求，因此PCU缓存、内存、Raid 卡以及硬盘缓存就在一定程度上满足了CPU的数据需求，即CPU 从缓存读取数据可以大幅提高CPU的工作效率。 系统缓存 1.buffer与cache：buffer：缓冲也叫写缓冲，一般用于写操作，可以将数据先写入内存在写入磁盘，buffer 一般用于写缓冲，用于解决不同介质的速度不一致的缓冲，先将数据临时写入到里自己最近的地方，以提高写入速度，CPU会把数据线写到内存的磁盘缓冲区，然后就认为数据已经写入完成看，然后内核的线程在后面的时间在写入磁盘，所以服务器突然断电会丢失内存中的部分数据。cache：缓存也叫读缓存，一般用于读操作，CPU读文件从内存读，如果内存没有就先从硬盘读到内存再读到CPU，将需要频繁读取的数据放在里自己最近的缓存区域，下次读取的时候即可快速读取。 2.cache的保存位置： 客户端：浏览器 内存：本地服务器、远程服务器 硬盘：本机硬盘、远程服务器硬盘 速度对比： 客户端浏览器-内存-远程内存-硬盘-远程硬盘。 3.cache的特性： 过期时间 强制过期，源网站更新图片后CDN是不会更新的，需要强制是图片缓存过期 命中率，即缓存的读取命中率 用户层缓存： 1.DNS缓存： 默认为60秒，即60秒之内在访问同一个域名就不在进行 DNS解析： 查看chrome浏览器的DNS缓存： chrome://net-internals/#dns 浏览器缓存过期机制： 最后修改时间： 系统调用会获取文件的最后修改时间，如果没有发生变化就返回给浏览器304的状态码，表示没有发生变化，然后浏览器就使用的本地的缓存展示资源， Etag标记： 基于Etag标记是否一致做判断页面是否发生过变化 过期时间： 以上两种都需要发送请求，即不管资源是否过期都要发送请求进行协商，这样会消耗不必要的时间，因此有了缓存的过期时间，即第一次请求资源的时候带一个资源的过期时间，默认为30天，当前这种方式使用的比表较多，但是无法保证客户的时间都是准确并且一致的，因此假如一个最大生存周期，使用用户本地的时间计算缓存数据是否超过多少天，下面的过期时间为2027年，但是缓存的最大生存周期计算为天等于3650天即10年，过期时间如下： CDN缓存： 什么是CND： 内容分发网络（Content Delivery Network），通过将服务内容分发至全网加速节点，利用全球调度系统使用户能够就近获取，有效降低访问延迟，提升服务可用性，CDN 第一降低机房的使用带宽，因为很多资源通过CDN就直接返回用户了，第二解决不同运营商之间的互联，因为可以让联通的网络访问联通让电信的网络访问电信，起到加速用户访问的目的， 第三：解决用户访问的地域问题，就近返回用户资源。 百度CDN：https://cloud.baidu.com/product/cdn.html 阿里CDN：https://www.aliyun.com/product/cdn?spm=5176.8269123.416540.50.728y8n 腾讯CDN：https://www.qcloud.com/product/cdn 用户请求CDN流程： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根据访问的热度不同而进行不同级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。 CDN主要优势： 提前对静态内容进行预缓存，避免大量的请求回源，导致主站网络带宽被打满而导致数据无法更新，另外CDN可以将数据根据访问的热度不通而进行不通级别的缓存，例如访问量最高的资源访问CDN 边缘节点的内存，其次的放在SSD或者SATA，再其次的放在云存储，这样兼顾了速度与成本。缓存-缓存到最快的地方如内存，缓存的数据准确命中率高，访问速度就快 调度准确-将用户调度到最近的边缘节点 性能优化-CDN 专门用于缓存响应速度快 安全相关-抵御攻击 节省带宽：由于用户请求由边缘节点响应，因此大幅降低到源站带宽。 应用层缓存： Nginx、PHP等web服务可以设置应用缓存以加速响应用户请求，另外有些解释性语言比如PHP/Python不能直接运行，需要先编译成字节码，但字节码需要解释器解释为机器码之后才能执行，因此字节码也是一种缓存，有时候会出现程序代码上线后字节码没有更新的现象。 其他层面缓存： CPU缓存(L1的数据缓存和L1的指令缓存)、二级缓存、三级缓存 磁盘缓存 RAID卡 分布式缓存：redis、memcache # MegaCli64 -LDinfo -Lall -aAll 二： redis部署与使用： redis基础： 官网地址：https://redis.io/ Redis和Memcached是非关系型数据库也成为NoSQL，MySQL、Mariadb、SQL Server、PostgreSQL、Oracle 数据库属于关系型数据(RDBMS, Relational Database Management System) redis简介： Redis(Remote Dictionary Server)在2009年发布，开发者Salvatore Sanfilippo是意大利开发者，他本想为自己的公司开发一个用于替换MySQL的产品Redis，但是没有想到他把Redis开源后大受欢迎，短短几年，Redis就有了很大的用户群体，目前国内外使用的公司有知乎网、新浪微博、GitHub等 redis是一个开源的、遵循BSD协议的、基于内存的而且目前比较流行的键值数据库(key-value database)，是一个非关系型数据库，redis提供将内存通过网络远程共享的一种服务，提供类似功能的还有memcache，但相比memcache，redis还提供了易扩展、高性能、具备数据持久性等功能。Redis在高并发、低延迟环境要求比较高的环境使用量非常广泛，目前redis在DB-Engine月排行榜https://db-engines.com/en/ranking 中一直比较靠前，而且一直是键值型存储类的首位。 redis对比memcached： 支持数据的持久化：可以将内存中的数据保持在磁盘中，重启redis服务或者服务器之后可以从备份文件中恢复数据到内存继续使用。 支持更多的数据类型：支持string(字符串)、hash(哈希数据)、list(列表)、set(集合)、zet(有序集合) 支持数据的备份：可以实现类似于数据的master-slave模式的数据备份，另外也支持使用快照+AOF。 支持更大的value数据：memcache单个key value最大，支持1MB，而redis最大支持512MB。 Redis 是单线程，而memcache是多线程，所以单机情况下没有memcache并发高，但redis 支持分布式集群以实现更高的并发，单Redis实例可以实现数万并发。 支持集群横向扩展：基于redis cluster的横向扩展，可以实现分布式集群，大幅提升性能和数据安全性。 都是基于C语言开发。 redis 典型应用场景： Session 共享：常见于web集群中的Tomcat或者PHP中多web服务器session共享 消息队列：ELK的日志缓存、部分业务的订阅发布系统 计数器：访问排行榜、商品浏览数等和次数相关的场景 缓存：数据查询、电商网站商品信息、新闻内容 微博/微信社交场合：共同好友、点赞评论等 Redis安装及使用： 官方下载地址：http://download.redis.io/releases/ yum安装redis 123456789[root@centos7 ~]# yum list redisLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileAvailable Packagesredis.x86_64 3.2.12-2.el7 [root@centos7 ~]# yum install redis -y[root@centos7 ~]# systemctl start redis &amp;&amp; systemctl enable redis[root@centos7 ~]# redis-cli127.0.0.1:6379&gt; 编译安装redis 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101官方的安装命令： https://redis.io/download 创建一个适合自己程序防止路径 [root@centos7 ~]# mkdir -pv /usr/local/src [root@centos7 ~]# cd !$ cd /usr/local/src [root@centos7 src]# pwd /usr/local/src [root@centos7 src]# ls redis-5.0.3.tar.gz解压 [root@centos7 src]# tar xvf redis-5.0.3.tar.gz 安装开发包组 [root@centos7 redis-5.0.3]# yum groupinstall "Development Tools"编译安装（大小写敏感） [root@centos7 redis-5.0.3]# make PREFIX=/usr/local/redis install [root@centos7 redis]# cd /usr/local/redis/bin/ [root@centos7 bin]# ls redis-benchmark redis-check-rdb redis-sentinel redis-check-aof redis-cli redis-server创建主配置文件以及程序文件 [root@centos7 ~]# cd /usr/local/redis/ [root@centos7 redis]# ls bin [root@centos7 redis]# mkdir etc logs run data root@centos7 redis]# cp /usr/local/src/redis-5.0.3/redis.conf /usr/local/redis/etc/ [root@centos7 redis]# ln -sv /usr/local/redis/bin/* /usr/bin/初次启动解决当前警报启动 [root@centos7 redis]# redis-server /usr/local/redis/etc/redis.conf 34186:C 26 Dec 2018 22:10:01.659 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 34186:C 26 Dec 2018 22:10:01.659 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=34186, just started 34186:C 26 Dec 2018 22:10:01.659 # Configuration loaded 34186:M 26 Dec 2018 22:10:01.660 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 34186 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 34186:M 26 Dec 2018 22:10:01.662 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 34186:M 26 Dec 2018 22:10:01.662 # Server initialized 34186:M 26 Dec 2018 22:10:01.662 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect. 34186:M 26 Dec 2018 22:10:01.662 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. 34186:M 26 Dec 2018 22:10:01.662 * Ready to accept connections解决第一次启动出现的三个报警 [root@centos7 ~]# vim /etc/sysctl.conf net.core.somaxconn = 512 vm.overcommit_memory = 1 [root@centos7 ~]# sysctl -p net.core.somaxconn = 512 vm.overcommit_memory = 1 [root@centos7 ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 永久生效写进配置文件间，开机自动加载 vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled chmod a+x /etc/rc.d/rc.local再次启动则无报警 [root@centos7 ~]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 35112:C 27 Dec 2018 10:17:12.662 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 35112:C 27 Dec 2018 10:17:12.662 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=35112, just started 35112:C 27 Dec 2018 10:17:12.662 # Configuration loaded 35112:M 27 Dec 2018 10:17:12.663 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 35112 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 35112:M 27 Dec 2018 10:17:12.667 # Server initialized 35112:M 27 Dec 2018 10:17:12.667 * Ready to accept connections 解决当前的警告提示： 警报：tcp-backlog： backlog参数控制的是三次握手的时候server端收到client ack确认号之后的队列值。 net.core.somaxconn = 512 警报：vm.overcommit_memory： 0、表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。 1、表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 2、表示内核允许分配超过所有物理内存和交换空间总和的内存 vm.overcommit_memory = 1 警报：transparent hugepage： 开启大页内存动态分配，需要关闭让redis 负责内存管理。 临时生效 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 永久生效写进配置文件间，开机自动加载 vim /etc/rc.d/rc.local echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled chmod a+x /etc/rc.d/rc.local 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051redis启动默认使再前台工作，编写启动脚本将服务的启动送往后台执行服务启动对应的端口已经默认监听的端口 [root@centos7 ~]# ss -tnl LISTEN 0 511 127.0.0.1:6379 编辑redis服务启动脚本 服务的配置文件放在了/usr/local/redis/bin/redis-servier 服务的主配置文件放在了/usr/local/redis/etc/redis.conf [root@centos7 ~]# vim /usr/lib/systemd/system/redis.service [Unit] Description=Redis persistent key-value database After=network.target After=network-online.target Wants=network-online.target [Service] ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf --supervised systemd ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID Type=notify User=redis Group=redis RuntimeDirectory=redis RuntimeDirectoryMode=0755 [Install] WantedBy=multi-user.target编辑主配置文件 vim /usr/local/redis/etc/redis.conf daemonize yes #让redis作为守护进程运行创建redis 用户和数据目录： [root@centos7 ~]# useradd redis -s /sbin/nologin [root@centos7 ~]# chown -R redis.redis /usr/local/redis/ [root@centos7 ~]# systemctl daemon-reload [root@centos7 ~]# systemctl start redis.service [root@centos7 ~]# ss -tnl LISTEN 0 511 127.0.0.1:6379 创建命令软连接 [root@centos7 ~]# ln -sv /usr/local/redis/bin/* /usr/bin/修改服务器的监听端口，默认监听在本机的127.0.0.1 [root@centos7 ~]# vim /usr/local/redis/etc/redis.conf bind 127.0.0.1 172.18.135.1 (bind 地址绑定到本机哪个地址供谁可以访问0.0.0.0代表本机监听在本机的所有的地址)使用客户端连接本机的redis服务器 [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; info 编译安装后的命令： [root@redis-s1 ~]# ll /usr/local/redis/bin/total 32656 -rwxr-xr-x 1 redis redis 4365488 Dec 13 09:21 redis-benchmark #redis性能测试工具 -rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-aof #AOF文件检查工具 -rwxr-xr-x 1 redis redis 8088920 Dec 13 09:21 redis-check-rdb #RDB文件检查工具 -rwxr-xr-x 1 redis redis 4800752 Dec 13 09:21 redis-cli #redis #客户端工具 lrwxrwxrwx 1 redis redis 12 Dec 13 09:21 redis-sentinel -&gt; redis-server #哨兵，软连接到 使用客户端连接redis： #/usr/local/redis/bin/redis-cli -h IP/HOSTNAME -p PORT -a PASSWORD redis配置文件： redis主要配置项： bind 0.0.0.0 #监听地址，可以用空格隔开后多个监听IP protected-mode yes #redis3.2 之后加入的新特性，在没有设置bind IP和密码的时候只允许访问127.0.0.1:6379 port 6379 #监听端口 tcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值。 timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时。 tcp-keepalive 300 #tcp 会话保持时间 daemonize no #认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes,当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面 supervised no #和操作系统相关参数，可以设置通过upstart和systemd管理Redis守护进程，centos 7以后都使用systemd pidfile /var/run/redis_6379.pid #pid文件路径,确定生成的日志目录是有权限的，实际上存放的就是进程号。 loglevel notice #日志级别 logfile “” #日志路径 databases 16 #设置db 库数量，默认16个库，可以连接到redis后使用select # ,切换库 always-show-logo yes #在启动redis 时是否显示log save 900 1 #在900秒内有一个键内容发生更改就出就快照机制 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes #快照出错时是否禁止redis 写入操作（默认为yes，建议使用no，出错的原因，磁盘满了，权限问题，改为no的原因是系统是由监控的，所以不会等磁盘满了防止数据丢失） rdbcompression yes #持久化到RDB文件时，是否压缩，”yes”为压缩，”no”则反之 rdbchecksum yes #是否开启RC64校验，默认是开启（检查RDB文件是否完整） dbfilename dump.rdb #快照文件名 dir ./ #快照文件保存路径 replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式：1) 如果replica-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果replica-serve-stale-data设置为no，除去指定的命令之外的任何请求都会返回一个错误”SYNC with master in progress”。 replica-read-only yes #是否设置从库只读 repl-diskless-sync no #是否使用socket方式复制数据，目前redis复制提供两种方式，disk和socket，如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件，有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave，socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave，disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件，socket的方式就是一个个slave顺序复制，只有在磁盘速度缓慢但是网络相对较快的情况下才使用socket方式，否则使用默认的disk方式 repl-diskless-sync-delay 5 #diskless复制的延迟时间，设置0为关闭，一旦复制开始还没有结束之前，master节点不会再接收新slave的复制请求，直到下一次开始 repl-ping-slave-period 10 #slave根据master指定的时间进行周期性的PING 监测 repl-timeout 60 #复制链接超时时间，需要大于repl-ping-slave-period，否则会经常报超时 repl-disable-tcp-nodelay no #在socket模式下是否slave套接字发送SYNC之后禁用 TCP_NODELAY，如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果你选择了 “no” 数据传输到salve的延迟将会减少但要使用更多的带宽 repl-backlog-size 1mb #复制缓冲区大小，只有在slave连接之后才分配内存。 repl-backlog-ttl 3600 #多次时间master没有slave连接，就清空backlog缓冲区。 replica-priority 100 #当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。 requirepass foobared #设置redis 连接密码 rename-command #重命名一些高危命令 maxclients 10000 #最大连接客户端（根据生产进行调整） maxmemory #最大内存，单位为bytes字节，8G内存的计算方式8(G)1024(MB)1024(KB)*1024(Kbyte)，需要注意的是slave的输出缓冲区是不计算在maxmemory内。（如果不限制，则redis无限使用物理内存，最后将服务器的进程kill掉，最好给予系统内存的一半，生产使用redis建议服务器16G给redis服务器8G） appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。 appendfilename “appendonly.aof” #AOF文件名 appendfsync everysec #aof持久化策略的配置,no表示不执行fsync,由操作系统保证数据同步到磁盘,always表示每次写入都执行fsync，以保证数据同步到磁盘,everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。 no-appendfsync-on-rewrite no在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。默认为no,表示”不暂缓”,新的aof记录仍然会被立即同步，Linux的默认fsync策略是30秒，如果为yes 可能丢失30秒数据，但由于yes性能较好而且会避免出现阻塞因此比较推荐。 auto-aof-rewrite-percentage 100 # 当Aof log增长超过指定比例时，重写log file， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，而确保保存最完整的数据。 auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件尺寸 aof-load-truncated yes #是否加载由于其他原因导致的末尾异常的AOF文件(主进程被kill/断电等) aof-use-rdb-preamble yes #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内存则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）。 lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒 cluster-enabled yes #是否开启集群模式，默认是单机模式 cluster-config-file nodes-6379.conf #由node节点自动生成和的集群配置文件 cluster-node-timeout 15000 #集群中node节点连接超时时间 cluster-replica-validity-factor 10 #在执行故障转移的时候可能有些节点和master断开一段时间数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移 cluster-migration-barrier 1 #一个主节点拥有的至少正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。 cluster-require-full-coverage yes #集群槽位覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes情况下redis集群槽位验证不全就不再对外提供服务，而no则可以继续使用但是会出现查询数据查不到的情况(因为有数据丢失)。 cluster-replica-no-failover no#Slow log 是 Redis 用来记录查询执行时间的日志系统，slow log 保存在内存里面，读写速度非常快，因此你可以放心地使用它，不必担心因为开启 slow log 而损害 Redis 的速度。 slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。 slowlog-max-len 128 #记录多少条慢日志保存在队列，超出后会删除最早的，以此滚动删除 三： redis持久化： redis 虽然是一个内存级别的缓存程序，即redis 是使用内存进行数据的缓存的，但是其可以将内存的数据按照一定的策略保存到硬盘上，从而实现数据持久保存的目的，redis支持两种不同方式的数据持久化保存机制，分别是RDB和AOF RDB模式： RDB：基于时间的快照，只保留当前最新的一次快照，特点是执行速度比较快，缺点是可能会丢失从上次快照到当前快照未完成之间的数据。 RDB实现的具体过程Redis从主进程先fork出一个子进程，使用写时复制机制，子进程将内存的数据保存为一个临时文件，比如dump.rdb.temp，当数据保存完成之后再将上一次保存的RDB文件替换掉，然后关闭子进程，这样可以保存每一次做RDB快照的时候保存的数据都是完整的，因为直接替换RDB文件的时候可能会出现突然断电等问题而导致RDB文件还没有保存完整就突然关机停止保存而导致数据丢失的情况，可以手动将每次生成的RDB文件进程备份，这样可以最大化保存历史数据。 RDB模式的优缺点： 优点： RDB快照保存了某个时间点的数据，可以通过脚本执行bgsave(非阻塞)或者save(阻塞)命令自定义时间点北备份，可以保留多个备份，当出现问题可以恢复到不同时间点的版本。 可以最大化o的性能，因为父进程在保存RDB 文件的时候唯一要做的是fork出一个子进程，然后的-操作都会有这个子进程操作，父进程无需任何的IO操作 RDB在大量数据比如几个G的数据，恢复的速度比AOF的快 缺点： 不能时时的保存数据，会丢失自上一次执行RDB备份到当前的内存数据 数据量非常大的时候，从父进程fork的时候需要一点时间，可能是毫秒或者秒 AOF模式： AOF:按照操作顺序依次将操作添加到指定的日志文件当中，特点是数据安全性相对较高，缺点是即使有些操作是重复的也会全部记录。 AOF和RDB一样使用了写时复制机制，AOF默认为每秒钟fsync一次，即将执行的命令保存到AOF文件当中，这样即使redis服务器发生故障的话顶多也就丢失1秒钟之内的数据，也可以设置不同的fsync策略，或者设置每次执行命令的时候执行fsync，fsync会在后台执行线程，所以主线程可以继续处理用户的正常请求而不受到写入AOF文件的IO影响 AOF模式优缺点： AOF的文件大小要大于RDB格式的文件 根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec即每秒执行一次fsync 四： redis 数据类型： 1.字符串(string)： 字符串是所有编程语言中最常见的和最常用的数据类型，而且也是redis最基本的数据类型之一，而且redis中所有的key的类型都是字符串。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182连接redis [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; 添加一个key 172.18.135.1:6379&gt; set key1 value1 （后面可以添加过期时间，如果不加则永不过期） OK查看key对应的值 172.18.135.1:6379&gt; get key1 "value1"查看key的类型 172.18.135.1:6379&gt; type key1 string（字符串）删除key的值 （DEL可以删除任何类型的key） 172.18.135.1:6379&gt; DEL key1 (integer) 1 (返回值为1，则表示成功，0表示不成功) 172.18.135.1:6379&gt; get key1 (nil)批量创建多个key 172.18.135.1:6379&gt; mset key1 value1 key2 value2 .... OK批量获取多个key的值 172.18.135.1:6379&gt; mget key1 key2 1) "value1" 2) "value2"批量删除多个key 172.18.135.1:6379&gt; del key1 key2 (integer) 2 172.18.135.1:6379&gt; mget key1 key2 1) (nil) 2) (nil)清空当前库的所有数据 172.18.135.1:6379&gt; flushdb OK查看当前数据库的所有key值 172.18.135.1:6379&gt; keys * (empty list or set)清空所有数据库的key 172.18.135.1:6379&gt; FLUSHALL数值递增：（必须是数字且数个整数） 172.18.135.1:6379&gt; SET num 0 OK 172.18.135.1:6379&gt; INCR num (integer) 1 172.18.135.1:6379&gt; GET num "1"数值递减 172.18.135.1:6379&gt; INCR num (integer) 2 172.18.135.1:6379&gt; GET num "2" 172.18.135.1:6379&gt; DECR num (integer) 1 172.18.135.1:6379&gt; GET num "1"向列表追加数据： 127.0.0.1:6379&gt; LPUSH list1 tom (integer) 2 127.0.0.1:6379&gt; RPUSH list1 jack (integer) 3获取列表长度： 127.0.0.1:6379&gt; LLEN list1 (integer) 3移除列表数据： 127.0.0.1:6379&gt; RPOP list1 #最后一个 "jack" 127.0.0.1:6379&gt; LPOP list1 #第一个 "tom" 2.集合(set)： Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455生成集合key:SADD：无序集合 127.0.0.1:6379&gt; SADD set1 v1 (integer) 1 127.0.0.1:6379&gt; SADD set2 v2 v4 (integer) 2 127.0.0.1:6379&gt; TYPE set1 set 127.0.0.1:6379&gt; TYPE set2 set查看集合中的所有值 127.0.0.1:6379&gt; SMEMBERS set1追加数值：追加的时候不能追加已经存在的数值 127.0.0.1:6379&gt; SADD set1 v2 v3 v4 (integer) 3 127.0.0.1:6379&gt; SADD set1 v2 #没有追加成功 (integer) 0 127.0.0.1:6379&gt; TYPE set1 set 127.0.0.1:6379&gt; TYPE set2 set查看集合的所有数据：同set的值不可重复，不同 set的值可以相同 127.0.0.1:6379&gt; SMEMBERS set1 1) "v4" 2) "v1" 3) "v3" 4) "v2" 127.0.0.1:6379&gt; SMEMBERS set2 1) "v4" 2) "v2"获取集合的差集：差集：已属于A而不属于B的元素称为A与B的（差集） 127.0.0.1:6379&gt; SDIFF set1 set2 1) "v1" 2) "v3"获取集合的交集：交集：已属于A且属于B的元素称为A与B的(交集） 127.0.0.1:6379&gt; SINTER set1 set2 1) "v4" 2) "v2"获取集合的并集：并集：已属于A或属于B的元素为称为A与B的(并集） 127.0.0.1:6379&gt; SUNION set1 set2 1) "v2" 2) "v4" 3) "v1" 4) "v3" 3.sorted set(有序集合): Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员，不同的是每个元素都会关联一个double(双精度浮点型)类型的分数，redis正是通过分数来为集合中的成员进行从小到大的排序，序集合的成员是唯一的,但分数(score)却可以重复，集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)， 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950生成有序集合： 127.0.0.1:6379&gt; ZADD zset1 1 v1 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 2 v2 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 2 v3 (integer) 1 127.0.0.1:6379&gt; ZADD zset1 3 v4 (integer) 1 127.0.0.1:6379&gt; TYPE zset1 zset 127.0.0.1:6379&gt; TYPE zset2 zset排行案例： 192.168.7.104:6379&gt; ZADD paihangbang 10 key1 20 key2 30 key3 (integer) 3 192.168.7.104:6379&gt; ZREVRANGE paihangbang 0 -1 withscores 1) "key3" 2) "30" 3) "key2" 4) "20" 5) "key1" 6) "10"批量添加多个数值： 127.0.0.1:6379&gt; ZADD zset2 1 v1 2 v2 4 v3 5 v5 (integer) 4获取集合的长度数： 127.0.0.1:6379&gt; ZCARD zset1 (integer) 4 127.0.0.1:6379&gt; ZCARD zset2 (integer) 4基于索引返回数值： 127.0.0.1:6379&gt; ZRANGE zset1 1 3 1) "v2" 2) "v3" 3) "v4" 127.0.0.1:6379&gt; ZRANGE zset1 0 2 1) "v1" 2) "v2" 3) "v3"返回某个数值的索引： 127.0.0.1:6379&gt; ZRANK zset1 v2 (integer) 1 127.0.0.1:6379&gt; ZRANK zset1 v3 (integer) 2 4.哈希(hash)： hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象,Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。 12345678910111213141516171819202122232425262728生成hash key： 127.0.0.1:6379&gt; HSET hset1 name tom age 18 (integer) 1 127.0.0.1:6379&gt; TYPE hset1 hash获取hash key字段值： 127.0.0.1:6379&gt; HGET hset1 name "tom" 127.0.0.1:6379&gt; HGET hset1 age "18"删除一个hash key的字段： 127.0.0.1:6379&gt; HDEL hset1 age (integer) 1获取所有hash表中的字段： 127.0.0.1:6379&gt; HSET hset1 name tom age 19 (integer) 1 127.0.0.1:6379&gt; HKEYS hset1 1) "name" 2) "age"设定key的过期时间 127.0.0.1:6379&gt; set test1 value1 ex 5 #设定这个key的过期时间，43200半天时间，g根据用户需求设定查看key的过期时长 127.0.0.1:6379&gt; TTL key1 五： 消息队列：消息队列主要分为两种，分别是生产者消费者模式和发布者订阅者模式，这两种模式Redis都支持 生产者消费者模式： 1.在生产者消费者(Producer/Consumer)模式下，上层应用接收到的外部请求后开始处理其当前步骤的操作，在执行完成后将已经完成的操作发送至指定的频道(channel)当中，并由其下层的应用监听该频道并继续下一步的操作，如果其处理完成后没有下一步的操作就直接返回数据给外部请求，如果还有下一步的操作就再将任务发布到另外一个频道，由另外一个消费者继续监听和处理。 2.模式介绍： 生产者消费者模式下，多个消费者同时监听一个队里，但是一个消息只能被最先抢到消息的消费者消费，即消息任务是一次性读取和处理，此模式在分布式业务架构中非常常用，比较常用的软件还有 RabbitMQ、Kafka、RocketMQ、ActiveMQ等 3.队列介绍： 队列当中的 消息由不同的生产者写入也会有不同的消费者取出进行消费处理，但是买一个消息一定是只能被取出一次也就是被消费一次。 12345678910111213141516171819202122232425262728293031323334353637383940生产者发布消息： [root@redis-s4 ~]# redis-cli 127.0.0.1:6379&gt; AUTH 123456 OK 127.0.0.1:6379&gt; LPUSH channel1 msg1 #从管道的左侧写入 (integer) 1 127.0.0.1:6379&gt; LPUSH channel1 msg2 (integer) 2 127.0.0.1:6379&gt; LPUSH channel1 msg3 (integer) 3 127.0.0.1:6379&gt; LPUSH channel1 msg4 (integer) 4 127.0.0.1:6379&gt; LPUSH channel1 msg5 (integer) 5切换终端模拟消费者，查看队列所有消息：#（0，-1代表查看所有的消息） 127.0.0.1:6379&gt; LRANGE channel1 0 -1 #切换其他客户端查看则已经看不到此条消息队列，因为已经被当前客户端取走 1) "msg5" 2) "msg4" 3) "msg3" 4) "msg2" 5) "msg1"消费者消费消息： 127.0.0.1:6379&gt; RPOP channel1 #从管道的右侧消费 "msg1" 127.0.0.1:6379&gt; RPOP channel1 "msg2" 127.0.0.1:6379&gt; RPOP channel1 "msg3" 127.0.0.1:6379&gt; RPOP channel1 "msg4" 127.0.0.1:6379&gt; RPOP channel1 "msg5" 127.0.0.1:6379&gt; RPOP channel1 (nil)切换主机模拟消费者，再次验证队列消息： 127.0.0.1:6379&gt; LRANGE channel1 0 -1 (empty list or set) #队列中的消息已经被已全部消费完毕 发布者订阅模式： 1.模式简介： 在发布者订阅者模式下，发布者将消息发布到指定的channel里面，凡是监听该channel的消费者都会收到同样的一份消息，这种模式类似于是收音机模式，即凡是收听某个频道的听众都会收到主持人发布的相同的消息内容。 此模式常用语群聊天、群通知、群公告等场景。 Subscriber：订阅者 Publisher：发布者 Channel：频道 1234567891011121314151617181920212223242526订阅者监听频道： [root@redis-s4 ~]# redis-cli 127.0.0.1:6379&gt; AUTH 123456 OK 127.0.0.1:6379&gt; SUBSCRIBE channel1 #订阅者订阅指定的频道,也就是客户端监听服务端的频道，此时可以模拟多个客户端监听服务端的此频道 Reading messages... (press Ctrl-C to quit) 1) "subscribe" 2) "channel1" 3) (integer) 1发布者发布消息：#服务端在此频道发布消息，此时客户端监听在服务端的此频道，都会接受到消息 127.0.0.1:6379&gt; PUBLISH channel1 test1 #发布者发布消息 (integer) 2 127.0.0.1:6379&gt; PUBLISH channel1 test2 (integer) 2 127.0.0.1:6379&gt;订阅多个频道：订阅指定的多个频道 127.0.0.1:6379&gt; SUBSCRIBE channel1 channel2 订阅所有频道： 127.0.0.1:6379&gt; PSUBSCRIBE *订阅匹配的频道： 127.0.0.1:6379&gt; PSUBSCRIBE chann* #匹配订阅多个频道 六： redis其他命令：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859CONFIG： config 命令用于查看当前redis配置、以及不重启更改redis配置等 127.0.0.1:6379&gt;config get * #获取config的命令配置帮助,或当前配置更改最大内存： 127.0.0.1:6379&gt; CONFIG set maxmemory 8589934592 OK 127.0.0.1:6379&gt; CONFIG get maxmemory #获取此配置项的值 1) "maxmemory" 2) "8589934592"设置连接密码：(可以先修改配置文件再动态命令行设置，这样避免重启服务生效) 127.0.0.1:6379&gt; CONFIG SET requirepass 123456 OK #通过CONFIG设置密码后立即生效 重现连接测试 172.18.135.1:6379&gt; CONFIG SET requirepass 123456 OK 172.18.135.1:6379&gt; exit [root@centos7 ~]# redis-cli -h 172.18.135.1 -p 6379 172.18.135.1:6379&gt; keys * (error) NOAUTH Authentication required. 172.18.135.1:6379&gt; auth 123456 #auth认证连接 OK 172.18.135.1:6379&gt; keys * 1) "key1"编辑配置文件设置连接redis的密码永久生效 #可以先在redis动态控制台设置完再在配置文件中修改这样会避免重启服务器代来不必要的损失 [root@centos7 ~]# vim /usr/local/redis/etc/redis.conf 507行 requirepass 123456info：显示当前节点redis运行状态信息 172.18.135.1:6379&gt; info SELECT：切换数据库 172.18.135.1:6379&gt; keys:查看当前库下的所有key：#keys * 慎用，相当于将数据库中的所有数据拿出，如果数据较多全部显示则会把机器卡死BGSAVE：手动在后台执行RDB持久化操作 172.18.135.1:6379&gt; BGSAVEDBSIZE：返回当前库下的所有key 数量 172.18.135.1:6379&gt; DBSIZEFLUSHDB：强制清空当前库中的所有key 172.18.135.1:6379&gt; FLUSHDBFLUSHALL：强制清空当前redis服务器所有数据库中的所有key，即删除所有数据 172.18.135.1:6379&gt; FLUSHALL 七： redis高可用于集群——配置redis主从 虽然Redis可以实现单机的数据持久化，但无论是RDB也好或者AOF也好，都解决不了单点宕机问题，即一旦redis服务器本身出现系统故障、硬件故障等问题后，就会直接造成数据的丢失，因此需要使用另外的技术来解决单点问题。 配置reids 主从： 主备模式，可以实现Redis数据的跨主机备份。 程序端连接到高可用负载的VIP，然后连接到负载服务器设置的Redis后端real server，此模式不需要在程序里面配置Redis服务器的真实IP地址，当后期Redis服务器IP地址发生变更只需要更改redis 相应的后端real server即可，可避免更改程序中的IP地址设置。 Slave主要配置： Redis Slave 也要开启持久化（RDB\AOF）并设置和master同样的连接密码，因为后期slave会有提升为master的可能,Slave端切换master同步后会丢失之前的所有数据。（最好将slave的配置于master相同，密码相同为了master宕机提升slave为新的主，如果开始同步，从节点上的原有的值则被清空，所以最好是要当从节点的服务器为干净的redis服务系统，后期如果将从节点强制和主节点断开的话则从节点的数据不会丢失） 一旦某个Slave成为一个master的slave，Redis Slave服务会清空当前redis服务器上的所有数据并将master的数据导入到自己的内存，但是断开同步关系后不会删除当前已经同步过的数据。 命令行配置12345678910方法1：从节点命令行方式将称为主节点的slave 当前状态为master，需要转换为slave角色并指向master服务器的IP+PORT+Password 192.168.7.104:6379&gt; SLAVEOF 192.168.7.103 6379 OK 192.168.7.104:6379&gt; CONFIG SET masterauth 123456 OK 关闭从节点的从属性 127.0.0.1:6379&gt; SLAVEOF NO ONE 在终端配置文件主从选项在重启服务后失效 保存在配置文件中123456789方法2:此配置文件是编译安装的配置文件vim /usr/local/redis/etc/redis.conf replicaof 192.168.7.103 6379masterauth 123456 #master如果密码需要设置，这里设置的密码为主节点的密码从节点查看 重启服务查看 127.0.0.1:6379&gt; info 1234567891011验证slave数据：确定slave的数据是不是从主节点的数据同步来的，可以一致观察这从节点的日志 127.0.0.1:6379&gt; KEYS * 1) "num" 2) "hset1" 3) "key1" 4) "name1" 5) "zset2" 6) "key2" 7) "zset1" 8) "set2"slave 状态只读无法写入数据， 主从复制过程： Redis支持主从复制分为全量同步和增量同步，首次同步是全量同步，主从同步可以让从服务器从主服务器备份数据，而且从服务器还可与有从服务器，即另外一台redis服务器可以从一台从服务器进行数据同步，redis 的主从同步是非阻塞的，其收到从服务器的sync(2.8版本之前是PSYNC)命令会fork一个子进程在后台执行bgsave命令，并将新写入的数据写入到一个缓冲区里面，bgsave执行完成之后并生成的将RDB文件发送给客户端，客户端将收到后的RDB文件载入自己的内存，然后主redis将缓冲区的内容在全部发送给从redis，之后的同步从服务器会发送一个offset的位置(等同于MySQL的binlog的位置)给主服务器，主服务器检查后位置没有错误将此位置之后的数据包括写在缓冲区的积压数据发送给redis从服务器，从服务器将主服务器发送的挤压数据写入内存，这样一次完整的数据同步，再之后再同步的时候从服务器只要发送当前的offset位 置给主服务器，然后主服务器根据响应的位置将之后的数据发送给从服务器保存到其内存即可。 Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 1）从服务器连接主服务器，发送SYNC命令； 2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB快照文件并使用缓冲区记录此后执行的所有写命令； 3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令； 7）后期同步会先发送自己slave_repl_offset位置，只同步新增加的数据，不再全量同步。 主从同步优化： Redis在2.8版本之前没有提供增量部分复制的功能，当网络闪断或者slave Redis重启之后会导致主从之间的全量同步，即从2.8版本开始增加了部分复制的功能。repl-diskless-sync no #yes为支持disk，master将RDB文件先保存到磁盘在发送给slave，no为maste直接将RDB文件发送给slave，默认即为使用no，Master RDB文件不需要与磁盘交互。 repl-diskless-sync-delay 5 #Master准备好RDB文件后等等待传输时间 repl-ping-slave-period 10 #slave端向server端发送pings的时间区间设置，默认为10秒 repl-timeout 60 #设置超时时间 repl-disable-tcp-nodelay no #是否启用TCP_NODELAY，如设置成yes，则redis会合并小的TCP包从而节省带宽，但会增加同步延迟（40ms），造成master与slave数据不一致，假如设置成no，则redis master会立即发送同步数据，没有延迟，前者关注性能，后者关注一致性 repl-backlog-size 1mb #master的写入数据缓冲区，用于记录自上一次同步后到下一次同步过程中间的写入命令，计算公式：b repl-backlog-size = 允许从节点最大中断时长 主实例offset每秒写入量，比如master每秒最大写入64mb，最大允许60秒，那么就要设置为64mb60秒=3840mb(3.8G)= repl-backlog-ttl 3600 #如果一段时间后没有slave连接到master，则backlog size的内存将会被释放。如果值为0则表示永远不释放这部份内存。 slave-priority 100 #slave端的优先级设置，值是一个整数，数字越小表示优先级越高。当master故障时将会按照优先级来选择slave端进行恢复，如果值设置为0，则表示该slave永远不会被选择。 #min-slaves-to-write 0 # #min-slaves-max-lag 10 #设置当一个master端的可用slave少于N个，延迟时间大于M秒时，不接收写操作。 \Master的重启会导致master_replid发生变化，slave之前的master_replid就和master不一致从而会引发所有slave的全量同步。 Slave同步过程日志：master同步日志： slave切换master：123456789101112131415161718192021222324252627282930313233当前状态： 从节点的状态信息 192.168.7.101:6379&gt; info Replication # Replication role:slave master_host:192.168.7.103 master_port:6379 master_link_status:up master_last_io_seconds_ago:8 master_sync_in_progress:0停止slave同步并查看当前状态： 192.168.7.101:6379&gt; SLAVEOF no one OK 192.168.7.101:6379&gt; info Replication # Replication role:master connected_slaves:0 master_replid:ac3475e5e4fae8c5f47711a643e465b9520c4182 master_replid2:8ee6bc1ac452fd4d2ccbaa660a219f78d218399a master_repl_offset:8840 second_repl_offset:8841 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:8547 repl_backlog_histlen:294测试能从节点否写入数据： 192.168.7.101:6379&gt; set key1 value1 #从节点停止主从结构时就是本机的自己的主，所以自然可以都自己的值进行写入 OK 192.168.7.101:6379&gt;虽然从节点脱离了主从结构，但是从节点的数据，依然保留着主节点同步时的数据。 Slave节点再有Slave： 在有slave的”master”查看状态： # Replication role:slave master_host:192.168.7.102 master_port:6379 master_link_status:up master_last_io_seconds_ago:9 #最近一次与master通信已经过去多少秒。 master_sync_in_progress:0 #是否正在与master通信。 slave_repl_offset:5334 #当前同步的偏移量。 slave_priority:100 #slave优先级，master故障后值越小越优先同步，一半设置相同的数值让它同时同步。 slave_read_only:1 connected_slaves:1 slave0:ip=192.168.7.104,port=6379,state=online, offset=5334,lag=1 master_replid:0f0318c25a022add7fd51d4438c470cf608631f9 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:5334 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:5334 常见问题汇总： master密码不对： 即配置的master密码不对，导致验证不通过而无法建立主从同步关系。 Redis版本不一致： 不同的redis 版本之间存在兼容性问题，因此各master和slave之间必须保持版本一致。 无法远程连接： 在开启了安全模式情况下，没有设置bind地址和密码]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM.virsh命令使用入门]]></title>
    <url>%2F2018%2F12%2F25%2FKVM-virsh%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[KVM-virsh命令使用入门 虚拟化技术 主机级虚拟化：infrastructure 容器级虚拟化（用户空间虚拟化即容器）：Container 内核名称空间： NET Mount PID UTS IPC User 程序级虚拟化： JVM PVM 云计算环境： SaaS：软件即服务 CaaS:容器即服务 FWaaS:防火墙即服务 LBaaS:负载均衡即服务 DBaaS:数据库即服务 IaaS:基础设施即服务 PaaS:平台即服务 虚拟主机通讯： 物理桥：主机过多，主机间交换报文发生瓶颈 隧道、叠加网络 virsh家族的虚拟机创建后，即使物理机重启了虚拟机也还在。 12345678910- 所有的虚拟机创建完成后，/etc/libvirt作为的配置文件的工作目录 [root@centos7 ~]# ls /etc/libvirt/ libvirt-admin.conf lxc.conf qemu.conf storage libvirt.conf nwfilter qemu-lockd.conf virtlockd.conf libvirtd.conf qemu secrets virtlogd.conf使用qemu+kvm创建虚拟服务时，配置文件保存在qemu文件中（每个创建的虚拟机都表现为一个.xml文件，立案包含了所有创建虚拟机的所有的相关配置） [root@centos7 vms]# ls /etc/libvirt/qemu altlinux7.0.xml 虚拟的主机中虚拟cpu核心，仅表现为宿主机中线程 virsh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122列创建的虚拟机 [root@centos7 vms]# virsh list Id Name State ---------------------------------------------------- 12 altlinux7.0 running## virsh list帮助 [root@centos7 vms]# virsh list --help OPTIONS --inactive 列出不活跃的域 --all 不活跃和活跃的域列表 --transient 列出临时域 --persistent 列出持久域 --with-snapshot 列出现有的快照的域 --without-snapshot 列出没有快照的域 --state-running 运行状态的域列表 --state-paused 列出暂停状态的域 --state-shutoff 列出关闭状态的域 --state-other 列出其他状态的域 --autostart 列出启用antostart的域 --no-autostart 列出禁用antostart的域 --with-managed-save 列出有管理的保存状态的域 --without-managed-save 列出没有管理的保存状态的域 --uuid 只列出 uuid --name 只列出域名 --table 列出表格（默认） --managed-save 标记有管理的保存状态的域 --title show domain title [root@centos7 vms]# virsh list --all Id Name State ---------------------------------------------------- 12 altlinux7.0 running [root@centos7 vms]# virsh list --name altlinux7.0查看虚拟机的详细信息（实际上看的就是此虚拟机的xml的配置文件） [root@centos7 vms]# virsh dumpxml altlinux7.0可以将查看虚拟机的详细信息保存在/etc/libvirt作为的配置文件的工作目录中，加以修改实现创建一台新的虚拟系统 [root@centos7 ~]# virsh dumpxml altlinux7.0 &gt; /etc/libvirt/qemu/c1.xml 编辑c1.xml 必须修改项（行）： 2：名字 3：删除uuid，启动自动生成 38：修改本地对应镜像文件 71：网卡MAC创建虚拟机（此实现的前提时建立在上一章kvm虚拟机基础应用的实验的，下一执行命令是在kvm服务器上） virsh help create :查看创建虚拟机并且启动的帮助 virsh help define :查看仅创建但不启动的帮助 virsh help start :查看启动的帮助 virsh define &lt;xmlfile&gt; --validate : 检查xml文件格式是否有误 启动虚拟机，并指顶xml文件 检查语法 [root@centos7 ~]# virsh define /etc/libvirt/qemu/c1.xml --validate Domain c1 defined from /etc/libvirt/qemu/c1.xml 创建 [root@centos7 ~]# virsh define /etc/libvirt/qemu/c1.xml Domain c1 defined from /etc/libvirt/qemu/c1.xml 查看是否创建成功 [root@centos7 ~]# virsh list --all Id Name State ---------------------------------------------------- 12 altlinux7.0 running - c1 shut off 启动 [root@centos7 ~]# virsh start c1 Domain c1 started [root@centos7 ~]# virsh list Id Name State ---------------------------------------------------- 12 altlinux7.0 running 13 c1 running 查看创建的虚拟机的地址 [root@centos7 ~]# virsh domifaddr c1 ## 查看virsh控制台 virsh help console 使用连接控制台连接虚拟机 [root@centos7 ~]# virsh console c1 login as 'cirros' user. default password: 'cubswin:)'. use 'sudo' for root. 退出当前连接 ctrl + ] kvm虚拟机的暂停：所有的占用内存，仍然在内存中，只是不响应任何请求。定在内存中，如果宿主机掉电，则虚拟机的所有数据将会丢失 kvm虚拟机的挂起:是将宿主机上的所有的虚拟机的使用内存抽取掉，保存成二进制文件，放在磁盘上，下次再次开启虚拟机可以将磁盘中的二进制文件读出来恢复至内存中 暂停kvm虚拟机c1 [root@centos7 vms]# virsh suspend c1 恢复kvm虚拟机c1 [root@centos7 vms]# virsh resume c1 挂起kvm虚拟机c1（建议挂起虚拟机的时候将虚拟机先暂停） [root@centos7 vms]# virsh save c1 /tmp/c1.bin --paused 取消挂起kvm虚拟机c1 [root@centos7 vms]# virsh restore /tmp/c1.bin --running 重启kvm虚拟机c1（热重启） virsh reboot c1 重启kvm虚拟机c1（冷重启,如同使用电源按钮重新设定目标） virsh reset c1 关机 virsh shutdown c1 /相当于在主虚拟机内部shutdown -0 暴力拨电，销毁虚拟机的运行状态(销毁的只是虚拟机的运行状态并非是虚拟机的系统程序文件) virsh destroy c1 删除虚拟机（取消定义一个域或者持久转换为临时） vrish undefine c1 将虚拟机设置为随宿主机启动开启 [root@centos7 vms]# virsh autostart c1]]></content>
      <categories>
        <category>linux服务</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm虚拟机基础应用]]></title>
    <url>%2F2018%2F12%2F25%2Fkvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E7%A1%80%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[kvm虚拟机基础应用 kvm: Kernel-based Virtual Machine Qumranet公司 –&gt; RedHat (1) X86_64 (2) HVM: Intel VT AMD AMD-v KVM的组件： 两类组件： (kvm.ko)/dev/kvm：工作为hypervisor，在用户空间可通过系统调用ioctl()与内核中的kvm模块交互，从而完成虚拟机的创建、启动、停止、删除等各种管理功能； qemu-kvm进程：工作于用户空间，用于实现IO设备模拟；用于实现一个虚拟机实例； KVM模块load进内存之后，系统的运行模式： 内核模式：GuestOS执行IO类的操作时，或其它的特殊指令操作时的模式；它也被称为“Guest-Kernel”模式；用户模式：Host OS的用户空间，用于代为GuestOS发出IO请求； 来宾模式：GuestOS的用户模式；所有的非IO类请求； 运行中的一个kvm虚拟机就是一个qemu-kvm进程，运行qemu-kvm程序并传递给它合适的选项及参数即能完成虚拟机启动，终止此进程即能关闭虚拟机； 安装使用KVM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131安装kvm的主机上：判断CPU是否支持硬件虚拟化： [root@centos7 ~]# grep -i -E '(vmx|svm|lm)' /proc/cpuinfo cpu型号： vmx：Intel VT-x svm：AMD AMD-v lm:64位cpu加载kvm模块使得内核支持kvm,并判断是否成功加载此模块 [root@centos7 ~]# modprobe kvm [root@centos7 ~]# lsmod | grep kvm kvm_intel 174841 0 kvm 578518 1 kvm_intel irqbypass 13503 1 kvm [root@centos7 ~]# file /dev/kvm （字符设备） /dev/kvm: character special安装qemu-kvm,使用户空间具有控制工具 [root@centos7 ~]# yum install qemu-kvm -y [root@centos7 ~]# rpm -ql qemu-kvm /usr/libexec/qemu-kvm 命令行工具被放在了非PATH变量中，红帽防止用户手动创建虚拟主机。此工具很底层使用virt-manager管理kvm(libvirt-daemon-kvm守护进程工具 qemu-kvm virt-manager图形化工具 libvirt库) [root@centos7 ~]# yum install libvirt-daemon-kvm qemu-kvm virt-manager libvirt -y （因为已经安装图形化界面的管理工具，确保宿主机上已经安装图像化相关的库 yum groupinstall GNOME Desktop）如果宿主机上已经安装有图像化相关的库则启动libvirt守护进程 [root@centos7 ~]# systemctl start libvirtdlibvirtd安装好默认仅提供了一个net网络创建桥接网络 将物理网卡当交换及使用 将软交换机当物理网卡使用创建物理桥（交换机） [root@centos7 ~]# cd /etc/sysconfig/network-scripts/ [root@centos7 network-scripts]# cp ifcfg-ens37 ifcfg-br0配置网卡的配置文件，使br0当网卡使用，将ens37当交换机使用 [root@centos7 network-scripts]# vim ifcfg-ens37 HWADDR=00:0C:29:14:4D:6C TYPE=Ethernet BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens37 DEVICE=ens37 BRIDGE=br0 ONBOOT=yes [root@centos7 network-scripts]# vim ifcfg-br0 NAME=br0 DEVICE=br0 TYPE=Bridge PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none IPADDR=172.18.135.1 PREFIX=24 GATEWAY=172.18.0.1 DNS1=8.8.8.8 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6_FAILURE_FATAL=no IPV6_PRIVACY=no ONBOOT=yes [root@centos7 network-scripts]# systemctl restart network 此时br0已经是网卡了，ens37变成了交换机 [root@centos7 network-scripts]# ifconfig br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.18.135.1 netmask 255.255.255.0 broadcast 172.18.135.255 inet6 fe80::20c:29ff:fe14:4d6c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 590 bytes 75531 (73.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 53 bytes 8801 (8.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens37: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 7333 bytes 809500 (790.5 KiB) RX errors 0 dropped 2 overruns 0 frame 0 TX packets 1275 bytes 194949 (190.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0------------------------------------------------------------------------------------------------------------------------远程连接安装kvm的主机一下操作在远程连接的主机上操作 查看网卡已经多了一个virbr0b设备，次接口是libvirtd自动生成的net模式类型的接口 [root@centos7 ~]# ssh -X 安装kvm的主机地址 [root@centos7 ~]# systemctl start libvirtd [root@centos7 ~]# ifconfig br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.18.135.1 netmask 255.255.255.0 broadcast 172.18.135.255 inet6 fe80::20c:29ff:fe14:4d6c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 3006 bytes 1312927 (1.2 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 412 bytes 58640 (57.2 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens37: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 ether 00:0c:29:14:4d:6c txqueuelen 1000 (Ethernet) RX packets 18644 bytes 3281398 (3.1 MiB) RX errors 0 dropped 28 overruns 0 frame 0 TX packets 1827 bytes 281257 (274.6 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1000 (Local Loopback) RX packets 312 bytes 32472 (31.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 312 bytes 32472 (31.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 virbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt; mtu 1500 inet 192.168.122.1 netmask 255.255.255.0 broadcast 192.168.122.255 ether 52:54:00:ff:0b:1f txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0检查libvirtd程序是否启动，级运行virt-manager图形化 [root@centos7 ~]# systemctl status libvirtd [root@centos7 ~]# virt-manager 以下操作在远程远程连接的主机上使用pxe安装环境 使用本地的镜像（导入现有磁盘映像）123456789[root@centos7 ~]# lscirros-0.3.0-x86_64-disk.img[root@centos7 ~]# mkdir /vms[root@centos7 ~]# mv cirros-0.3.0-x86_64-disk.img /vms/[root@centos7 ~]# cd /vms/[root@centos7 vms]# lscirros-0.3.0-x86_64-disk.img[root@centos7 vms]# cp cirros-0.3.0-x86_64-disk.img pc1.img[root@centos7 vms]# cp cirros-0.3.0-x86_64-disk.img pc2.img 点击Browse Local本地浏览 本机客户端访问外部网络 SNAT源地址转换适用于隐藏客户端地址 主要原因是ipv4地址不够用，私网的地址在互联网没办法被路由。 本机服务端，放在互联网被客户访问。 DNET目标地址转换，仅考虑请求报文，不考虑响应报文，适用于隐藏服务端的地址]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>kvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络基础架构]]></title>
    <url>%2F2018%2F12%2F22%2F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[企业网络架构介绍 网络: 多个终端设备 网络传输介质设备实现通讯 局域网：最小的网络、本地、公司 广域网：不通的局域网连接 城域网：比广域网小，例如：一个城市 无线网（AP） CCNA CCNP 企业网络远程互联 企业网络组网不受地域限制，可以通过各种远程互联技术把分布在不同的地域的网络的网络连接在一起 ipsu mpls vpn 专线 广域网：逻辑的层次划分 小型企业组网：扁平 大型网络组网：层次 思想： 业务 冗余 层次-安全 传输介质介绍 通讯网络除了包含通讯设备的本身之外，还包含连接这些设备的传输介质，如同线缆、双绞线、和光纤等，不同的传输介质具有不用的特征，这些特性直接影响到通讯诸多方面，如线路编码方式、传输速度和传输距离等。 路由 交换机 传输介质：连接设备的线缆 网线 光线 两个终端，用一条能承载数据传输的物理介质（也成为传输介质），连接起来，组成了一个最简单的网络。 介质 光猫：光纤设置转换为网络设备进入网络 白色：单模光纤 黄色：多模光纤 共享式网络中可能会出现信号冲突现象 CSMA/CD: 载波侦听多路访问/冲突检测技术 工作原理：先听先发，边听边发，冲突避让，等待重发。 以太网的最大包长和最小包长 最大包长1518byte,其中三层数据1500byte（称为MTU）只是一个规定而言 最小包长64byte 原因：如果A主机发送的帧很小，很快完成帧的发送，而两台冲突主机相差很远，在主机A发送的帧传输到B的前一刻，B开始发送帧，这样，当A的帧到达B时，B检测到冲突，于是发送冲突信号。假如在B冲突信号传输到A之前，A的帧已经发送完毕，那么A将检测不到冲突而误认为已经发送成功，因此必须有最小包长的限制。 两种双工模式都支持双向数据传输 冲突与：半双工模式 分层模型及以太网帧结构 不同的协议栈用于定义和管理不同的网络的数据转发规则 什么是协议 为了使数据可以在网络上从源传递到目标地址，网络上所有设备需要“讲”相同的语言 数据通讯协议的定义 决定数据的格式和传输的一组规则和一组惯例 网络通讯的过程很复杂 数据以电子信号的形式穿越介质到达正确的计算机，然后转换为最初的形式，以便接收者可以阅读 为了降低网络设计的复杂性，将协议进行了分层设计 分层设计的意义 通讯服务层的模块设计可相对独立于具有的通讯路线和通讯接口的差别 而通信服务层的模块设计又可相对独立具体用户应用的要求不同 简化了相关的网络操作，提供了不不同的厂商之间的兼容性；促进了标准化工作，结构上进行了分层；易于学习和操作 各个层次独立，一层的变化不会影响到邻层 OSI参考模型 国际标准化组织ISO于1984年提出了OSI RM 。OSI参考模型很快成了计算机网络的基础模型 OSI参考模型具有的优点：简化了相关的网络操作，提供了不同的厂商之间的兼容性；促进了标准化工作；结构上进行了分层；易于学习和操作 OSI参考模型各个层次的功能如下： 网络层：在设备之间传输比特流，规定了电平、速度和断缆针脚 数据链路层：将比特流组合成了字节，再将字节组合成帧，使用链路层地址（以太网使用MAC地址）来访问介质，并进行排差错检测 网络层：提供逻辑地址，供路由确定路径 传输层：提供面向连接或者非面向连接的数据传递以及进行排差错检测 会话层：负责建、管理和终止表示层实体之间的通讯会话。该层的通信由不同的设备中的应用程序之间的服务请求和响应组成（通信设备可能存在多个会话） 表示层：提供各种用于应用层数据的编码和转换功能，确保一个系统的应用层发送的数据能够被另一个系统的应用层识别（数据表、加密、图片、文档、文字） 应用层：OSI参考模型中最靠近用户的一层，为应用程序提供网络服务 OSI层次设计的理念 建立七层模型的主要目的使为解决异种网络互连时所遇到的兼容性问题 它的优点：将服务、接口和协议这三个概念明确地区分开来 服务：某一层为上一层提供什么功能 接口：上层如何使用下层的服务 协议：如何实现本层的服务 这样各层之间具有很强的独立性，互联网络中各尸体采用什么样的协议时没有限制的，只要向上提供形同的服务并且不改变相邻层的接口就可以了]]></content>
      <categories>
        <category>网络基础架构</category>
      </categories>
      <tags>
        <tag>网络基础架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFS服务器]]></title>
    <url>%2F2018%2F12%2F19%2Fnfs%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[NFS服务器 NFSNFS：Network File System 网络文件系统，基于内核的文件系统。Sun公司 开发，通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的 文件，基于RPC（Remote Procedure Call Protocol远程过程调用）实现 RPC采用C/S模式。客户机请求程序调用进程发送一个有进程参数的调用信息 到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用 信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发 送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信 息，获得进程结果，然后调用执行继续进行 NFS优势：节省本地存储空间，将常用的数据,如home目录,存放在NFS服务 器上且可以通过网络访问，本地终端将可减少自身存储空间的使用 12345678910111213常用系统的驱动查看模块[root@centos7 ~]# locate xfs.ko/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/xfs/xfs.ko.xz[root@centos7 ~]# ls /usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/binfmt_misc.ko.xz cifs ext4 gfs2 mbcache.ko.xz nls udfbtrfs cramfs fat isofs nfs overlayfs xfscachefiles dlm fscache jbd2 nfs_common pstoreceph exofs fuse lockd nfsd squashfslinux内核默认已经安装nfs文件系统，已经加载驱动模块[root@centos7 ~]# locate nfs.ko/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/drivers/xen/xenfs/xenfs.ko.xz/usr/lib/modules/3.10.0-862.el7.x86_64/kernel/fs/nfs/nfs.ko.xz NFS文件系统 NFS工作原理 NFS各个版本的对比s NFS服务介绍软件包：nfs-utils（并非服务器包时文件系统即工具）Kernel支持:nfs.ko端口：2049(nfsd), 其它端口由portmap(111)分配配置文件：/etc/exports,/etc/exports.d/*.exportsCentOS7不支持同一目录同时用nfs和samba共享，因为使用锁机制不同相关软件包:rpcbind（必须rpcbind， 服务如果不可用则nfs服务也不可用），tcp_wrappersCentOS6开始portmap进程由rpcbind代替NFS服务主要进程：&ensp;&ensp;rpc.nfsd 最主要的NFS进程，管理客户端是否可登录&ensp;&ensp;rpc.mountd 挂载和卸载NFS文件系统，包括权限管理&ensp;&ensp;rpc.lockd 非必要，管理文件锁，避免同时写出错&ensp;&ensp;rpc.statd 非必要，检查文件一致性，可修复文件日志：/var/lib/nfs/ 范例：查看nfs对应的端口123456[root@centos7 ~]# rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper此服务使用的随机端口比较多，所以此服务一般不会跨网络使用，最好在局域网内使用 范例：配置防火墙，将随机端口绑死，实现跨网络12345678910配置防火墙，开放NFS服务 配置NFS使用固定端口 vim /etc/sysconfig/nfs RQUOTAD_PORT=875 LOCKD_TCPPORT=32803 LOCKD_UDPPORT=32769 MOUNTD_PORT=892 STATD_PORT=662 STATD_OUTGOING_PORT=2020 防火墙除开放上述端口，还需开放TCP和UDP的111和2049共4个端 范例：实现共享文件夹1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677服务端：创建共享的目录 [root@centos7 ~]# mkdir /data/a [root@centos7 ~]# mkdir /data/b编辑服务器的配置文件（此配置配置文件是系统的基本文件，此文件可以定义共享的目录的策略） [root@centos7 ~]# rpm -qf /etc/exports setup-2.8.71-9.el7.noarch [root@centos7 ~]# vim /etc/exports （*代表所有人可以访问） /data/a * 生效配置文件（提示我们没有配置策略使用默认的配置策略，sync直接写磁盘，不放buffer） [root@centos7 ~]# exportfs -r exportfs: No options for /data/a *: suggest *(sync) to avoid warning客户端： 创建挂载点，使用服务端共享的目录进行挂载 [root@centos7 ~]# mkdir /data/nfs1 /data/nfs2 [root@centos7 ~]# showmount -e 192.168.52.179 Export list for 192.168.52.179: /data/a * 挂载指向服务端的地址 [root@centos7 ~]# mount 192.168.52.179:/data/a /data/nfs1 [root@centos7 ~]# df 192.168.52.179:/data/a 20961280 33024 20928256 1% /data/nfs1服务端在共享的目录中创建文件，客户端查看是否同步 [root@centos7 ~]# touch /data/a/a.txt [root@centos7 ~]# ls /data/nfs1/ a.txt 查看共享默认的权限：只读属性 [root@centos7 ~]# touch /data/nfs1/b.txt touch: cannot touch ‘/data/nfs1/b.txt’: Read-only file system 客户端查看挂载属性：默认使用的挂载版本为vers=4 [root@centos7 ~]# mount 192.168.52.179:/data/a on /data/nfs1 type nfs4 (rw,relatime,vers=4.1,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=192.168.52.179,local_lock=none,addr=192.168.52.179) 客户端挂载指定版本挂载 [root@centos7 ~]# mount -o vers=3 192.168.52.179:/data/a /data/nfs1 [root@centos7 ~]# mount | tail -n1 192.168.52.179:/data/a on /data/nfs1 type nfs (rw,relatime,vers=3,rsize=262144,wsize=262144,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,mountaddr=192.168.52.179,mountvers=3,mountport=20048,mountproto=udp,local_lock=none,addr=192.168.52.179)服务端修改挂载的目录权限 [root@centos7 ~]# vim /etc/exports /data/a *(sync,ro) 同步，只读 /data/b *(rw) 可读可写 生效并查看权限 [root@centos7 ~]# exportfs -r [root@centos7 ~]# exportfs -v （root_squash压榨root权限 no_all_squash普通用户不压榨） /data/a &lt;world&gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) /data/b &lt;world&gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash)客户端挂载:挂载也是有读写权限的但是还是不可以创建文件 [root@centos7 ~]# mkdir /data/nfs2/ [root@centos7 ~]# mount 192.168.52.179:/data/b /data/nfs2/ [root@centos7 ~]# touch /data/nfs2/a.txt touch: cannot touch ‘/data/nfs2/a.txt’: Permission denied 因为客户端访问服务端的共享目录的身份默认的是以nfsnoboby身份服务端授权设置acl [root@centos7 ~]# setfacl -m u:nfsnobody:rwx /data/b/客户端测试 [root@centos7 ~]# touch /data/nfs2/a.txt [root@centos7 ~]# ll !$ ll /data/nfs2/a.txt -rw-r--r--. 1 nfsnobody nfsnobody 0 Dec 19 20:17 /data/nfs2/a.tx客户端使用客户端的普通用户，在服务端共享的目录中创建文件显示权限不足（因为客户端创建的用户为普通用户，如果有同名用户则显示相同的用户，如果没有则显示客户端的用户的id）(映射成id相同的人，普通用户不压榨) 导出的文件系统的格式：&ensp;&ensp;/dir 主机1(opt1,opt2) 主机2(opt1,opt2)… #开始为注释 主机格式：&ensp;&ensp;/单个主机：ipv4，ipv6，FQDN&ensp;&ensp;/IP networks：两种掩码格式均支持&ensp;&ensp;/&ensp;&ensp;/172.18.0.0/255.255.0.0&ensp;&ensp;/&ensp;&ensp;/172.18.0.0/16&ensp;&ensp;/wildcards：主机名通配，例如.magedu.com，IP不可以&ensp;&ensp;/netgroups：NIS域的主机组，@group_name&ensp;&ensp;/anonymous：表示使用通配所有客户端 nfs配置文件每个条目指定目录导出到的哪些主机，及相关的权限和选项&ensp;&ensp;默认选项：(ro,sync,root_squash,no_all_squash)&ensp;&ensp;ro,rw 只读和读写 • async 异步，数据变化后不立即写磁盘，性能高&ensp;&ensp;sync（1.0.0后为默认）同步，数据在请求时立即写入共享&ensp;&ensp;no_all_squash （默认）保留共享文件的UID和GID&ensp;&ensp;all_squash 所有远程用户(包括root)都变成nfsnobody&ensp;&ensp;root_squash （默认）远程root映射为nfsnobody,UID为65534，早期版本 是4294967294 (nfsnobody)&ensp;&ensp;no_root_squash 远程root映射成root用户&ensp;&ensp;anonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非 nfsnobody,可配合all_squash使用 1234567不压榨远程root用户的权限 [root@centos7 ~]# vim /etc/exports /data/a *(sync,ro) /data/b *(rw,no_root_squash) [root@centos7 ~]# exportfs -v /data/a &lt;world&gt;(ro,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) /data/b &lt;world&gt;(rw,sync,wdelay,hide,no_subtree_check,sec=sys,secure,root_squash,no_all_squash) NFS工具rpcinfo&ensp;&ensp;rpcinfo -p hostname&ensp;&ensp;rpcinfo –s hostname 查看RPC注册程序 exportfs&ensp;&ensp;–v 查看本机所有NFS共享&ensp;&ensp;–r 重读配置文件，并共享目录&ensp;&ensp;–a 输出本机所有共享&ensp;&ensp;–au 停止本机所有共享 showmount -e hostnamemount.nfs 挂载工具NFSv4支持通过挂载NFS服务器的共享“根”，从而浏览NFS服务器上的共享 目录列表&ensp;&ensp;mount nfsserver:/ /mnt/nfs 客户端NFS挂载基于安全考虑，建议使用nosuid,nodev,noexec挂载选项NFS相关的挂载选项：&ensp;&ensp;fg（默认）前台挂载，bg后台挂载&ensp;&ensp;hard（默认）持续请求，soft 非持续请求&ensp;&ensp;intr 和hard配合，请求可中断&ensp;&ensp;rsize和wsize 一次读和写数据最大字节数，rsize=32768&ensp;&ensp;_netdev 无网络不挂载示例：&ensp;&ensp;mount -o rw,nosuid,fg,hard,intr 172.16.0.1:/testdir /mnt/nfs/开机挂载:/etc/fstab&ensp;&ensp;172.16.0.1:/public /mnt/nfs nfs defaults 0 0 自动挂载可使用autofs按需要挂载NFS共享，在空闲时自动卸载由autofs包提供系统管理器指定由/etc/auto.master自动挂载器守护进程控制的挂载点自动挂载监视器访问这些目录并按要求挂载文件系统文件系统在失活的指定间隔5分钟后会自动卸载为所有导出到网络中的NFS启用特殊匹配 -host 至“browse”参看帮助：man 5 autofs支持含通配符的目录名&ensp;&ensp;* server:/export/&amp; 直接匹配直接匹配包括绝对路径名称不会影响本地目录结构示例：&ensp;&ensp;/etc/auto.master:&ensp;&ensp;/- /etc/auto.direct &ensp;&ensp;/etc/auto.direct:&ensp;&ensp;/foo server1:/export/foo&ensp;&ensp;/user/local/ server1:/usr/local]]></content>
      <categories>
        <category>NFS服务器</category>
      </categories>
      <tags>
        <tag>NFS服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux防火墙]]></title>
    <url>%2F2018%2F03%2F06%2Flinux%E9%98%B2%E7%81%AB%E5%A2%99%2F</url>
    <content type="text"><![CDATA[linux防火墙 本章内容安全技术 入侵检测与管理系统（Intrusion Detection Systems）：特点是不阻断任何网络 访问，量化、定位来自内外网络的威胁情况，主要以提供报告和事后监督为主， 提供有针对性的指导措施和安全决策依据。一般采用旁路部署方式 入侵防御系统（Intrusion Prevention System）：以透明模式工作，分析数据包 的内容如：溢出攻击、拒绝服务攻击、木马、蠕虫、系统漏洞等进行准确的分析 判断，在判定为攻击行为后立即予以阻断，主动而有效的保护网络的安全，一般 采用在线部署方式 防火墙（ FireWall ）：隔离功能，工作在网络或主机边缘，对进出网络或主机的 数据包基于一定的规则检查，并在匹配某规则时由规则定义的行为进行处理的一 组功能的组件，基本上的实现都是默认情况下关闭所有的通过型访问，只开放允 许访问的策略(防范非授权网络) linux操作系统的空间：内核空间和用户空间端口：进程地址 防火墙的分类防火墙的分类 主机防火墙：服务范围为当前主机 网络防火墙：服务范围为防火墙一侧的局域网 硬件防火墙：在专用硬件级别实现部分功能的防火墙；另一个部分功能基于软件 实现，Checkpoint,NetScreen 软件防火墙：运行于通用硬件平台之上的防火墙的应用软件 网络层防火墙：OSI模型下四层 应用层防火墙/代理服务器：代理网关，OSI模型七层 网络型防火墙网络层防火墙 包过滤防火墙 网络层对数据包进行选择，选择的依据是系统内设置的过滤逻辑，被称为访问控制 列表（ACL），通过检查数据流中每个数据的源地址，目的地址，所用端口号和协议 状态等因素，或他们的组合来确定是否允许该数据包通过 优点：对用户来说透明，处理速度快且易于维护 缺点：无法检查应用层数据，如病毒等 应用层防火墙应用层防火墙/代理服务型防火墙（Proxy Service） 将所有跨越防火墙的网络通信链路分为两段 内外网用户的访问都是通过代理服务器上的“链接”来实现 优点：在应用层对数据进行检查，比较安全 缺点：增加防火墙的负载 现实生产环境中所使用的防火墙一般都是二者结合体&ensp;&ensp;即先检查网络数据，通过之后再送到应用层去检查 iptables的基本认识Netfilter组件&ensp;&ensp;内核空间，集成在linux内核中&ensp;&ensp;扩展各种网络服务的结构化底层框架&ensp;&ensp;内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、 FORWARD、PREROUTING、POSTROUTING)，而这五个hook function 向用户开放，用户可以通过一个命令工具（iptables）向其写入规则&ensp;&ensp;由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则 被分组放在链（chain）上 三种报文流向：netfilter内核级别的框架，，人是不可和内核打交道，使用用户空间的工具iptables，规则编辑器，内核级的系统级别netfilter的调用接口，将写的规则送到内核中的钩子hook上直接生效，直接送到内存中，说明主机关机则规则就没有了，所以想永久生效，可以放在内核启动时初始化时读取到的文件中，或者在或者启动完后，自动执行某个命令或者启动某个服务来调用（即刻生效，但是不会永久有效）路由前：PREROUTING流入：INPUT流出：OUTPUT转发：FORWARD路由后：POSTROUTING &ensp;&ensp;流入本机：PREROUTING --&gt; INPUT--&gt;用户空间进程&ensp;&ensp;流出本机：用户空间进程 --&gt;OUTPUT--&gt; POSTROUTING&ensp;&ensp;转发：PREROUTING --&gt; FORWARD --&gt; POSTROUTING linux早期没有防火墙的，仿照unix的发行版的OpenBSD，著名的以安全为目标的发行版OpenBSD：纯软件，内核级只负责传输层一下级检测实现，进行工作和防护 定制防火墙规则：黑名单、白名单&ensp;&ensp;黑名单适用于知道改拒绝谁&ensp;&ensp;百名单高效的仅授权可以连接的 iptables的基本认识防火墙工具iptables&ensp;&ensp;命令行工具，工作在用户空间&ensp;&ensp;用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包 firewalld&ensp;&ensp;CentOS 7 引入了新的前端管理工具&ensp;&ensp;管理工具：&ensp;&ensp;&ensp;&ensp;firewall-cmd 命令行&ensp;&ensp;&ensp;&ensp;firewall-config 图形 历史ipfw -&gt; ipchains -&gt; iptables -&gt; nftables(rhel8) 主机级别防火墙：INPUT---OUTPUTS网络级别防火墙：FROWARD NAT：网络地址转换 iptables： 四个功能：table filter:过滤 nat:地址转换 mangle:报文修改，fwmark raw:关闭连接追踪 Centos：使用iptables的方式 netfilter:内核框架（framework） syscall:系统调用接口，iptables命令行工具，管理规则（服务化的管理工具） firewalld:守护进程，firewall-cmd(默认安装，但是尽量不使用) 禁用firewalld123456[root@centos7 ~]# systemctl stop firewalld[root@centos7 ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.[root@centos7 ~]# systemctl is-enabled firewallddisabled 报文流向： 到本机内部：prerouting–&gt;input 由本机发现：output–&gt;postrouting 转发：prerouting –&gt;forward–&gt;postrouting tables&lt;--&gt;CHANS链: filter: INPUT,PORWARD,OUTPUT nat: PREROUTING,INPUT,OUTPUT,POSTROUTING mangle: PREROUTING,INPUT,FOREARD,OUTPUT,POSTROUIING raw: PREROUTING,OUTPUT 查看各表中的链的规则：123456789[root@centos7 ~]# iptables -t filter -nLChain INPUT (policy ACCEPT)target prot opt source destination Chain FORWARD (policy ACCEPT)target prot opt source destination Chain OUTPUT (policy ACCEPT)target prot opt source destination Netfilter表和链对应的关系 数据包过滤匹配流程 命令的使用格式123456789101112131415161718192021222324252627282930SYNOPSIS iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specification ip6tables [-t table] &#123;-A|-C|-D&#125; chain rule-specification iptables [-t table] -I chain [rulenum] rule-specifica‐ tion iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches...] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] iptables [-t tables,如果不指定则代表使用默认的filter] SUBCMMAND子命令 chain [rulenum规则号码] [rule-spce] rule-specification=[matches匹配条件][-j target处理动作] CRUD:增删改查（指定多个规则隐含的是与关系，符合所有的条件才是满足定义的条件的） 子命令： 管理规则： -A ：append,尾部追加 -I ：inset,插入 -D ：删除 -R ：替换 管理链 -N ：new,新增加一条链 -X : 删除一条自定义、空的，不可有规则、引用计数为0的链 -E : rename 改自定义引用技术为0的链 -P ： policy,设置链的默认策略 -F ： flush,清空 -Z ： zero,置零，计数器归零 iptables的每条规则和每个链都有专用的两个计数器：pkts规则匹配到的报个数计数器，bytes报文体积计数器kbytes 查看 -L -n : 以数字显示主机的地址和端口 -v : -vv : 显示详细的信息 -x : exact，避免单位的换算显示精准的信息 –line-numbers : 显示行号 链 内置链 自定义链 匹配条件 检查报文 TCP或UDP首部：源端口，目标端口 FSM:有限状态机 IP首部：sip,dip（源ip和目标ip） MAC首部:MAC地址 匹配条件 通用匹配 [!] -s,–sip,–spurce-ip:报文的源地址,其值可以是ip或者是网络地址，不可使离散的网络（!为取反） [!] -d,–dip,–destination:报文的目标地址 -i,–in-interface : 表示从哪个网卡进入（PREROUTING，INPUT,FORWARD） -o,–out-interface : 表示从哪个网卡出去(,OUTPUT,POSTRUTING,FORWARD) -p protocol:四层协议，tcp,udp,icmp 扩展匹配 隐式扩展 -p tcp :隐含 -m tcp [!] –source-port ,–sport port [:port] : 匹配报文中的传输层的源端口,连续的端口范围，22，21：22 [!] –destination-port ,–dport poet [:port] :匹配报文中传输层的目标端口 [!] –tcp-flags mask comp SYN,ACK,RST,，FIN,URG,PSH mask:需要检查的标志位列表，以逗号分隔； comp:必须为1的标志列表，余下的出现在mask列表中的标志位则必须为0 范例:-tcp-flags SYN,ACK,FIN,RST SYN 表示检查报文tcp首部，syn为1，其余的为0，代表只检查源报文来的第一次握手 [!] –syn : tcp发送报文三次握手的第一次（相当于：–tcp-flags SYN,SCK,FINRST SYN） -p udp : 隐含了-m udp: [!] –source-port ,–sport port[:port] :匹配报文中传输层的源端口 [!] –destination-port,–dport port[:port] :匹配报文中传输层的目标端口 -p icmp(互联网控制协议) ： 隐含了-m udp: [!] –lcmp-type {type[/code]|typename} 8 : echo-request回显请求 0 : echo-reply 回显应答 显示扩展 ； 必须使用-m选项指出matchname(模块),有的match可能存在专用的选项 1.matchname扩展 以离散的或连续的方式定义多端口匹配条件 [!] –source-ports,–sports port[,port|,port:port]…:指定多个源端口,逗号隔开最多制定15个 [!] –destnation-ports,–dports port[,port|,port:port]…:制定多个目标端口 [!] –ports port[,port|,port:port]…:指定多个端口 2.iprange扩展 以连续的ip地址范围指明连续的多地址匹配条件 3.set扩展 依赖于ipset命令行工具 set存在的类型： hash:net : 网络地址的集合 hash:ip ：目标ip地址 使用方式： 先创建集合 ：ipset create NAMETYPE 向集合中添加元素 ：ipset add NAMETYPE 4.string扩展 对报文的应用层数据做字符串匹配检测 [!] –string pattern : 要检测的字符串模式 [!] –hex-string pattern : 要检测的字符串模式，16进制编码 –algo {bm|kmp} 5.time扩展 根据报文到达的时间与指定的时间范围进行匹配度检测 –datestart YYYY[-MM[-DD]Thh[:mm]:ss]]]]] : 起始日期时间 –datestop YYYY[-MM[-DD]Thh[:mm]:ss]]]]] : 结束日期时间 –timestart hh:mm[:ss] –timestop hh:mm[:ss] [!] –monthdays day[,day…] ： 每月几号的时间 [!] –weekdays day[,day…] ： 每周几的时间 –kerneltz : 使用内核中的配置的时区 6、connlimit扩展 根据每客户端IP做并发连接数匹配； –connlimit-upto n：连接数数量小于等于n，此时应该允许； –connlimit-above n：连接数数量大于n，此时应该拒绝； ~]# iptables -A INPUT -d 172.16.100.67 -p tcp –dport 23 -m connlimit –connlimit-upto 2 -j ACCEPT 7、limit扩展 基于收发报文的速率进行匹配； –limit rate[/second|/minute|/hour|/day]：平均速率 –limit-burst number：峰值速率 8、state扩展 状态检测；连接追踪机制（conntrack）； INVALID：无法识别的状态； ESTABLISHED：已建立的连接； NEW：新连接； RELATED：相关联的连接； UNTRACKED：未追踪的连接； nf_conntrack内核模块； 追踪到的连接：/proc/net/nf_conntrack文件中； 能追踪的最大连接数量定义在：/proc/sys/net/nf_conntrack_max 此值可自行定义，建议必要时调整到足够大； 不同的协议的连接追踪的时长： /proc/sys/net/netfilter/ [!] –state STATE 如何开放被模式的ftp服务： (1) 装载追踪ftp协议的模块； # modprobe nf_conntrack_ftp - (2) 放行命令连接 - ~] # iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT - ~] # iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state NEW -j ACCEPT - (3) 放行数据连接 - ~] iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state RELATED -j ACCEPT 处理动作target DROP : 丢弃 REJECT : 拒绝 ACCEPT : 接受 RETURN : 无匹配的链的时候自动调回 REDIRECT : 重定向 SANT : 源地址转换 DNAT: 目标地址转换 MASQUERADE : 地址伪装 LOG : 日志 自定义链 管理机制 ： 两不兼容，最好不要并行 firewalld : firewalld-cmd iptables ： iptables-save,iptables-restore yum install iptables-services1234567891011每一个内核就是一个扩展 xt开头[root@centos7 ~]# cd /lib/modules/3.10.0-862.el7.x86_64/kernel/net/netfilter/[root@centos7 netfilter]# lsipset xt_connlimit.ko.xzipvs xt_connmark.ko.xznf_conntrack_amanda.ko.xz xt_CONNSECMARK.ko.xznf_conntrack_broadcast.ko.xz xt_conntrack.ko.xznf_conntrack_ftp.ko.xz xt_cpu.ko.xznf_conntrack_h323.ko.xz xt_CT.ko.xznf_conntrack_irc.ko.xz xt_dccp.ko.xznf_conntrack.ko.xz xt_devgroup.ko.xz 1234567891011121314151617181920212223242526272829查看某表中的规则[root@centos7 ~]# iptables -t filter -vnL将某表中的INPUT链计数器置零[root@centos7 ~]# iptables -t filter -Z INPUT规则显示详情[root@centos7 ~]# iptables -t filter -vnL pkts(报文数) bytes(字节数) target（目标） prot（协议） opt（选项） in（报文流入的接口） out（报文流出的接口） source（源地址） destination（目标地址） 显示iptables表的本文和自己的精确的显示以及行号的显示[root@centos7 ~]# iptables -t filter -vxnL --line-numbers-N 自定义规则链（见名知意）[root@centos7 ~]# iptables -N web_rules[root@centos7 ~]# iptables -vnLChain web_rules (0 references) 0个引用 pkts bytes target prot opt in out source destination -E 修改自定义的规则链名称（改名通常适用于修改自定义规则连0引用的规则链）[root@centos7 ~]# iptables -E web_rules cifs_rules-X 删除自定义的规则链：计数为0，若不为0 可以将主链中的调用删除再进行清空删除[root@centos7 ~]# iptables -F cifs_rules[root@centos7 ~]# iptables -X cifs_rules内部规则： Chain OUTPUT (policy ACCEPT 1 packets, 356 bytes)具有规则链和接收器 范例：使得iptables定义的规则永久有效12345678命令：内核中定义的规则标准输出至屏幕 [root@centos7 ~]# iptables-save 将标准的输入重定向到文件中 [root@centos7 ~]# iptables-save &gt; /data/iptables.txt 模拟清空防火墙规则 [root@centos7 ~]# iptables -F 还原防火墙的规则 [root@centos7 ~]# iptables-restore /data/iptables.txt 范例：如何将定义的防火墙规则开机自动生效123456yum install iptables-services -y服务方式管理的iptables[root@centos7 ~]# /usr/libexec/iptables/iptables.init restrtUsage: iptables &#123;start|stop|reload|restart|condrestart|status|panic|save&#125; 显示扩展1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461：multiport显示扩展：匹配多个源、目标端口 定义入栈规则 [root@centos7 ~]# iptables -I INPUT -p tcp -m multiport --dports 21:22,80,139,445 定义出栈规则 [root@centos7 ~]# iptables -I OUTPUT -p tcp -m multiport --sports 21:22,80,139,445 删除入栈规则的第#条 [root@centos7 ~]# iptables -D INPUT #2：iprange扩展：匹配ip地址的连续范围（仅开放给有限的地址去怕ping） 入栈 [root@centos7 ~]# iptables -I INPUT 4 -p icmp --icmp-type 8 -m iprange --src-range 192.168.10.10-192.168.10.20 -j ACCEPT 出栈 [root@centos7 ~]# iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m iprange --dst-range 192.168.10.10-192.168.10.20 -j ACCEPT3：set扩展:非连续的ip地址，人为定义ip地址集后续调用 安装 [root@centos7 ~]# yum install ipset -y 查看帮助用法 ipset -h 创建集合ip哈希表 [root@centos7 ~]# ipset create pinghosts hash:ip (如果为多个网段hash:net) [root@centos7 ~]# ipset list Name: pinghosts Type: hash:ip Revision: 1 Header: family inet hashsize 1024 maxelem 65536 Size in memory: 16528 References: 0 Members: 向集合中添加允许的主机地址 [root@centos7 ~]# ipset add pinghosts 192.168.10.10 [root@centos7 ~]# ipset add pinghosts 192.168.10.20 [root@centos7 ~]# ipset list Name: pinghosts Type: hash:ip Revision: 1 Header: family inet hashsize 1024 maxelem 65536 Size in memory: 16560 References: 0 Members: 192.168.10.20 192.168.10.10 设置规则允许集合表中的主机对本机进行ping 入栈 [root@centos7 ~]# iptables -I INPUT 4 -p icmp --icmp-type 8 -m set --match-set pinghosts src -j ACCEPT 出栈 [root@centos7 ~]# iptables -I OUTPUT 4 -p icmp --icmp-type 0 -m set --match-set pinghosts dst -j ACCEPT [root@centos7 ~]# iptables -vnL4：string扩展：对报文的应用层数据做字符串匹配检测 假设web网页中的敏感字体进行字符串匹配检测 入栈 [root@centos7 ~]# iptables -I INPUT -m string --string "敏感字" --algo bm -j REJECT 出栈 [root@centos7 ~]# iptables -I OUTPUT -m srting --string "敏感字" --algo bm -j REJECT多个扩展可一起使用，与的关系，满足所有的条件time扩展 ： 根据报文到达的时间与指定的时间范围进行匹配度检测 [root@centos7 ~]# iptables -I INPUT 5 -p icmp --icmp-type 8 -m set --match-set pinghosts src -m time --timestart 08:00:00 --timestop 14:00:00 --weekdays Tue,Thu,Sat --kerneltz -j ACCEPT5：connlimit扩展：并发连接数限制 根据每个客户端ip做并发连接数数量匹配，可防止CC攻击。 --connlimit-upto # :连接的数量小于等于#时匹配 --connlimit-above # : 连接的数量大于#时匹配 通常分别与默认的拒绝或允许策略配合使用（默认的意思并非默认规则，而是定义的规则已经有允许，在此基础上做连接数量限制，定义在已经有的允许的规则之前） 限制ssh连接本机的连接数限制 [root@centos7 ~]# iptables -I INPUT 2 -p tcp --dport 22 -m connlimit --connlimit-above 2 -j REJECT6：limit扩展 基于收发报文的速度做匹配(报文传输速率限制) 令牌桶过滤器 --limit # [/second|/minute|/hour|/day] --limit-burst number 允许别人ping自己仅能按照特定的速率进行ping 出去的速率无需控制，仅控制本机进来的速率 限制ping速率为每3秒钟一个，限制突发速率为5个 [root@centos7 ~]# iptables -I INPUT -p icmp --icmmp-type 8 -s 192.168.52.177 -d 192.168.52.182 -m limit --limit 20/minute --limit-burst 5 -j ACCEPT7：state状态扩展 根据“连续追踪机制”去检查连接的状态，较消耗资源 - conntrack机制：追踪本机上的请求和响应之间的关系 状态有如下几种： - NEW：新发出的请求，连接追踪信息库中不存在此链接的相关信息条目，因此，将其识别为第一次触发的请求（新人） - ESTABLISHED:NEW状态之后，连接追踪信息库中为其建立的条目失效之前期间内所进行的通讯状态（熟人） - RELATED:新发起的但与已有连接相关的连接，如：ftp协议中的数据连接与命令连接之间的关系（熟人的熟人） - INVALID:无效的连接，如flag标记不正确（识别不出的连接） - UNTRACKED:未进行的追踪的连接，如raw表中关闭追踪（未追踪的） - SNAT:源地址转换 - DNAT:目标地址转换 示例： iptables -A INPUT -d 172.16.1.10 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT iptables -A OUTPUT -s 172.16.1.10 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT 已经追踪到的并记录下来的连接信息库 /proc/net/nf_conntrack 调整连接追踪功能所能够容纳的最大连接数量 /proc/sys/net/nf_conntrack_max 永久生效修改的所能够容纳的最大的连接数量 [root@centos7 ~]# vim /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 10000000 [root@centos7 ~]# sysctl -p /etc/sysctl.d/nf_conntrack_max.conf net.nf_conntrack_max = 100000 [root@centos7 ~]# cat /proc/sys/net/nf_conntrack_max 100000 不同的协议的连接追踪时长 /proc/sys/net/netfilter/ 注意：CentOS7 需要加载模块： modprobe nf_conntrack范例： 允许所有已经连结果的请求入栈出栈 [root@centos7 ~]# iptables -A INPUT -m state --state ESTABLISHED -j ACCEPT [root@centos7 ~]# iptables -A OUTPUT -m state --state ESTABLISHED -j ACCEPT [root@centos7 ~]# iptables -A INPUT -p tcp -m multiport --dports 21:22,80 -m state --state NEW -j ACCEPT [root@centos7 ~]# iptables -A OUTPUT ! -i lo -j REJECT [root@centos7 ~]# iptables -A OUTPUT ! -o lo -j REJECT 服务端开放客户端ftp服务，客户端主动访问服务端，服务端数据端口为随机端口，在客户端添加规则 [root@centos7 ~]# iptables -I INPUT 2 -p tcp -m state --state RELATED -j ACCEPT 实现ftp RELATED 需要手动载入一个模块 [root@centos7 ~]# modprobe nf_conntrack [root@centos7 ~]# modinfo nf_conntrack [root@centos7 ~]# lsmod | grep nf_conntrack 手动载入的模块，重启后失效，大量的ftp服务就会被肆意的放行，如何让ftp连接状态iptabless开机继续生效（自动装入模块） 方法1： [root@centos7 ~]# vim /etc/sysconfig/iptables-config 第六行 IPTABLES_MODULES="nf-conntrack_ftp" 方法2： [root@centos7 ~]# vim /etc/sysconfig/modules/nf_conntrack.mudules #!/bin/bash /sbin/modprobe nf_conntrack_ftp [root@centos7 ~]# chmod +x /etc/sysconfig/modules/nf_conntrack.mudules 前提是已经安装启动iptables.services [root@centos7 ~]# systemctl restart iptables [root@centos7 ~]# systemctl enable iptables]]></content>
      <categories>
        <category>iptables防火墙</category>
      </categories>
      <tags>
        <tag>iptables防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旧事-大好河山]]></title>
    <url>%2F2017%2F10%2F01%2F%E6%97%A7%E4%BA%8B-%E5%A4%A7%E5%A5%BD%E6%B2%B3%E5%B1%B1%2F</url>
    <content type="text"><![CDATA[输入密码,PC:Enter查看,Phone:输入法换行查看. U2FsdGVkX1+rRIdOXWzSYFLvT+VJuGtl9wLbJC5JOZSQnJUZr3S/C5FLtQibb6EyKMZ8KiUhwoO+OZ8QpKcah8P50R8+sBhivPxApu5WVShoyBCL5QaHt0Xn1cEtHzW3cqBQCteSk0E1NmvJ2Rkehbcg69zXH1LhNO9VV2Dn7OzFJReSqQo60CW1ws5SNZqYa/RyB+eQgea33rBLw6AurTf8wF93XzhzQon8+rhVUaSEzgVdr3oinIT4DnSZyjxneh40YC2BEcCUU9SDBoz4HYCSCkNKNFcHblsfBstfaMMI8CWREPQiTAqusFXIk0P1GuurDclHq7PKVeqsJ4h5onIM2lw9gmT40dDvkOt4lis=]]></content>
      <categories>
        <category>旧事，杂记</category>
      </categories>
      <tags>
        <tag>旧事，杂记</tag>
      </tags>
  </entry>
</search>
